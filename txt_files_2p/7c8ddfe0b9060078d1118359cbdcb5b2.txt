Questions Chapter 3 (Artificial Neural Networks) 

other 

network 

1. Name and describe the three properties decisive for the functioning of a 
- Architecture of the network, describes how the neurons are connected to each 
- Learning algorithm, used to set the weights of the network 
- While the connections between the neurons determine whether they can 
- Activation function which determines the output of each neuron  

influence each other, the weights define the strength of this influence  

2. Explain the functioning of a formal neuron and illustrate its structure 
- building blocks of ANN’s 
- Compared to biological neurons, it is a very simple abstraction and rather 
- Explain by means of figure: 

primitive 
- we have d input signals that form an input vector  
- each input is multiplied by a synaptic weight (can be positive or negative) 
- they determine how much influence the output of a neuron has on other, 
- in addition to the weights, an artificial neuron is subject to a bias b 
- acts as a threshold by either increasing or decreasing the activation of the 
- if we sum over the weighted inputs and the bias we get the activation of the 
- usually, the bias is included in the sum by adding a constant component to the 
- the output y of the neuron in computed by applying an activation function to 

connected neurons 

input vector 

neuron 

neuron 

the activation 

3. Name and describe the three types of architectures 
- The simplest form of a neural network is a single-layer network 
- Consists of only an input layer which projects directly onto an output layer, 
- The layers don’t have to be fully connected 
- Various forms of partially connected nets are also possible 
- Regarding the name: input layers are typically not counted as layers since they 

usually in a feedforward fashion 

do not perform any computation 

observed from either the input or the output of the network 

- A network with several layers is called a multilayer network  
- Has not only input/output layer but also hidden layer(s) 
- called ”hidden” because their structure and properties cannot be directly 
- Harder to design than input/output layers because #neurons and their 
- Hidden layers perform certain computation of the input and transform it before it 
- Presence of hidden layers makes multilayer networks much more powerful and 

connections are not directly predicted by the external problem 

is passed on to the next layer 

provides them with the ability to solve more complicated problems 

- Another class of neural network architectures are recurrent networks 
- fundamentally different from single- and multilayer networks 
- contain at least one feedback loop 
- in feedforward net, the input is not affected by the previous activation of the net 
- different in recurrent networks where we have internal inputs (feedback) 
- The feedback in a recurrent network can take many different forms 
- Much harder to train than feedforward networks 
- but have capacities that cannot be achieved by feedforward nets 

the function 

4. Describe the sigmoid activation function, provide its formula and sketch 
- Sigmoid activation functions are commonly used in multilayer networks since 
they have several advantages when training the net with a backpropagation 
algorithm 

- For example, the derivative of the function can be represented in terms of the 
- The most popular sigmoid functions are the logistic sigmoid and the hyperbolic 
- Logistic sigmoid formula (see slides) 
- Maps the input a onto a real number in the interval (0, 1) as an output 
- Hence, it is often used in neural networks whose desired output values are either 

function itself 

tangent 

binary or in the interval (0, 1) 

