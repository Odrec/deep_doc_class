 

 

 

SPSS Tutorial 

Marcus Schulz & Elisabeth Ehling im April 2016  

 

LegendCluster 1: mediocreCluster 2: unsatisfactoryCluster 3: bad 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Inhalt 
Was ist SPSS ............................................................................................................................................. 2 

Arbeiten mit SPSS .................................................................................................................................... 2 

Grafiken erstellen mit SPSS ..................................................................................................................... 6 

Deskriptive Statistik mit SPSS ................................................................................................................ 10 

Korrelationsanalysen mit SPSS .............................................................................................................. 13 

Regressionsanalysen mit SPSS ............................................................................................................... 15 

Lineare Regressionsanalysen ............................................................................................................. 15 

Nichtlineare Regression ..................................................................................................................... 17 

Varianzanalysen mit SPSS ...................................................................................................................... 19 

Einfaktorielle Varianzanalyse ............................................................................................................ 19 

Zweifaktorielle Varianzanalyse .......................................................................................................... 20 

Nichtparametrische Tests mit SPSS ....................................................................................................... 22 

Nichtparametrische Varianzanalyse (Kruskal-Wallis-H-Test) ............................................................ 22 

Kolmogorov-Smirnov-Test ................................................................................................................. 23 

Faktorenanalysen mit SPSS ................................................................................................................... 24 

Unrotierte Faktoranalyse .................................................................................................................. 24 

Rotierte Faktoranalyse ...................................................................................................................... 27 

Clusteranalysen mit SPSS ...................................................................................................................... 28 

Multidimensionale Skalierung mit SPSS ................................................................................................ 31 

Diskriminanzanalyse mit SPSS ............................................................................................................... 34 

Kontingenzanalyse mit SPSS .................................................................................................................. 38 

Logistische Regressionsanalysen mit SPSS ............................................................................................ 41 

Neuronale Netze mit SPSS ..................................................................................................................... 45 

 

 

 

 

 

1 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

‚IBM  SPSS  Statistics‘) 

Was ist SPSS 
Die  kommerzielle  Statistiksoftware  SPSS  (genauer 
ist  ein  modulares 
Programmpaket,  das  im  Gegensatz  zu  R  nicht  kommandozeilenorientiert  ist,  sondern  sich  einfach 
über  eine  Windows-Benutzeroberfläche  bedienen 
lässt.  Das  Basismodul  ermöglicht  das 
grundlegende  Datenmanagement  und  umfangreiche  statistische  und  grafische  Datenanalysen  mit 
den gängigsten statistischen Verfahren. Darüber hinaus verfügt SPSS über eine Programmiersprache, 
mit der beispielsweise statistische Analysen automatisiert werden können. Der Entwickler von SPSS, 
SPSS  Inc.,  wurde  2009  von  IBM  übernommen,  welches  SPSS  fortentwickelt,  so dass  fast  jedes  Jahr 
eine  neue  Programmversion  von  SPSS  erscheint.  Dieses  Tutorial  arbeitet  mit  der  Version  20.0. 
Lizenzfreie Alternativen zu SPSS sind PSPP, R und Mystat (Studentenversion von Systat). 

Arbeiten mit SPSS 
SPSS  öffnet  sich  wie  jedes  Windowsprogramm  mit  Doppelklick  auf  das  SPSS-Symbol  auf  dem 
Desktop. SPSS verfügt über eine Datenansicht (Abbildung 1) und eine Variablenansicht (Abbildung 2). 

In der Datenansicht stehen Variablen in Spalten und Datensätze in Zeilen. Zunächst ist das Datenblatt 
leer, und die Variablen haben noch keine Namen.  

Abbildung 1: Datenansicht von SPSS. 

 

 

 

2 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Abbildung 2: Variablenansicht von SPSS. 

Mit dem Menübefehl 

<Datei> <Öffnen>  

aus  der  Datenansicht  können  SPSS-Tabellenblätter  (*.sav)  geöffnet  werden.  Weitere  Dateiformate 
wie Excel-Tabellenblätter sind in SPSS zu importieren (Abbildung 3). 

 

Abbildung 3: Öffnen eines Tabellenblattes mit Daten. 

 

3 

 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

SPSS kann automatisch die erste Zeile des Tabellenblattes als Variablennamen erkennen, so dass sich 
in unserem Fall nach Öffnen des Tabellenblattes ‚Gesamtsumme‘ (Abbildung 4) die Datenansicht in 
Abbildung 5 ergibt. 

Abbildung 4: Öffnen eines Tabellenblattes aus einer Excel-Arbeitsmappe. 

 

 

Abbildung  5:  Datenansicht  des  geöffneten  Tabellenblattes  ‚Gesamtsumme‘  aus  der  Excel-Datei 
‚Gesamtsumme.xlsx‘. 

Die  in  diesem  Beispiel  gezeigten  Variablen  sind  Abundanzen  von  Müllzählungen  an  verschiedenen 
europäischen Stränden. Jede Spalte [BE1, BE2,…] beinhaltet jeweils eine Zeitreihe von Müllzählungen 
an  einem  Strand.  Jede  Zeile  beinhaltet  alle  Müllzählungen  an  verschiedenen  Stränden  zu  einem 
bestimmten Termin. 

Mit dem Öffnen einer Datei öffnet sich gleichzeitig der SPSS-Viewer (Abbildung 6), der die Ergebnisse 
der nachfolgenden Analysen aufnimmt. 

 

4 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Abbildung 6: SPSS-Viewer nach dem Öffnen einer Datei. 

Die  SPSS-Datendatei  und  die  Ergebnisdatei  im  SPSS-Viewer  (*.sav)  werden  separat  aus  dem 
jeweiligen Fenster heraus abgespeichert: 

<Datei> <Speichern unter>. 

Die Variablenansicht bietet nach dem Öffnen des Excel-Tabellenblattes folgendes Bild (Abbildung 7): 

 

Abbildung 7: Variablenansicht des geöffneten Tabellenblattes ‚Gesamtsumme‘ aus der Excel-Datei 
‚Gesamtsumme.xlsx‘. 

In  der  Variablenansicht  werden  Namen,  Typen,  Skalenniveaus  und  Formate  der  Variablen 
dokumentiert  und  festgelegt.  Die  Analysen,  die  wir  in  unserem  Kurs  vornehmen,  verlangen 

 

 

5 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

durchgehend  den  Variablentyp  ‚numerisch‘.  Mit  ‚Spaltenformat‘  wird  die  Spaltenbreite  in  der 
Datenansicht festgelegt. ‚Dezimalstellen‘ gibt die Anzahl der Dezimalstellen der Werte an. Dabei ist 
zu  beachten,  dass  SPSS  sich  bei  der  Ausgabe  der  Analysenergebnisse  im  SPSS-Viewer  an  den  hier 
festgelegten  Dezimalstellen  der  Eingangsvariablen  orientiert.  Weiterhin  ist  das  Messniveau  der 
Variablen wichtig. SPSS bietet hierbei die  Auswahlmöglichkeiten  ‚Skala‘ (= metrisch), ‚Nominal‘ und 
‚Ordinal‘. 

Grafiken erstellen mit SPSS 
Es gibt in SPSS eine Vielzahl von Möglichkeiten, Grafiken zu erstellen. Im Folgenden sei beispielhaft 
die Erstellung und Bearbeitung eines Streudiagramms vorgestellt. 

Diagramme werden erstellt über die Menübefehle 

<Diagramme> <Diagrammerstellung>. 

Es  öffnet sich folgendes Fenster (Abbildung 8), das in einer Liste  und einer Icon-Liste eine  Auswahl 
von Diagrammtypen bietet. 

Abbildung 8: Fenster zur Erstellung von Diagrammen. 

 

6 

 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Es  sollen  nun  in  einem  Streudiagramm  zwei  Zeitreihen  von  Müllabundanzen  gegeneinander 
aufgetragen  werden.  Mit  gedrückter  linker  Maustaste  kann  der  gewünschte  Diagrammtyp  aus  der 
Icon-Liste  in  das  Auswahlfenster  gezogen  werden.  Ebenso  werden  die  Eingangsvariablen  in  die 
Platzhalter an den beiden Achsen gezogen.  

In  dem  sich  bei  Auswahl  des  Diagrammtyps  öffnenden  Fenster  ‚Elementeigenschaften‘  kann 
ausgewählt  werden,  ob  beispielsweise  die  Rohdaten  oder  aggregierte  Werte  wie  Mittelwerte 
dargestellt  werden  sollen  (Abbildung  9).  Bei  aggregierten  Werten  besteht  die  Möglichkeit, 
Fehlerbalken auszuwählen und ihnen ein Streuungsmaß zuzuordnen. 

Abbildung 9: Das Fenster ‚Diagrammerstellung‘ mit dem Unterfenster ‚Elementeigenschaften‘. 

Mit <Zuweisen> im Fenster ‚Elementeigenschaften‘ und <OK> im Fenster ‚Diagrammerstellung‘ wird 
das Streudiagramm im SPSS-Viewer erstellt (Abbildung 10). 

 

Abbildung 10: Beispielhaftes Streudiagramm im SPSS-Viewer. 

 

 

7 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Im  SPSS-Viewer  kann  die  Grafik  weiterbearbeitet  werden.  So  sollen  die  Achsenbeschriftungen  mit 
Einheiten versehen werden, und der Bildhintergrund soll farblos erscheinen. Dazu doppelklicken wir 
im SPSS-Viewer auf die Grafik. Es öffnet sich daraufhin der Diagrammeditor. Nun doppelklicken wir 
im  Diagrammeditor  auf  den  Hintergrund  der  Grafik.  Es  öffnet  sich  das  Fenster  ‚Eigenschaften‘ 
(Abbildung  11).  Im  Fenster  ‚Eigenschaften‘  wählen  wir  die  Option  farblos  aus  und  wählen 
anschließend <Zuweisen> und <Schließen>. Im Diagrammeditor ist der Hintergrund nun weiß. 

Abbildung 11: Das Fenster ‚Eigenschaften‘ im Diagrammeditor. 

 

Nun klicken wir zweimal hintereinander (kein Doppelklicken) im Diagrammeditor auf die Beschriftung 
der  y-Achse  und  bearbeiten  sie  über  die  Tastatur  (Abbildung  12).  Ebenso  verfahren  wir  mit  der 
Beschriftung der x-Achse. 

 

8 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Abbildung 12: Bearbeitung der Achsenbeschriftung im Diagrammeditor. 

Nach Schließen des Diagrammeditors erscheint das Diagramm im SPSS-Viewer in bearbeiteter Form. 
Das  Diagramm  soll  nun  in  ein  Word-Dokument  eingefügt  werden.  Hierzu  wird  mit  der  rechten 
Maustaste  im  SPSS-Viewer  auf  das  Diagramm  geklickt  und  im  erscheinenden  Kontextmenü  die 
Option  <Kopieren>  ausgewählt.  Damit  wird  die  Grafik  in  die  Zwischenablage  kopiert  und  kann  von 
anderen Programmen genutzt werden (Abbildung 13). 

 

 

9 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Abbildung 13: Über die Zwischenablage importiertes bearbeitetes Streudiagramm. 

 

Deskriptive Statistik mit SPSS 
SPSS bietet mehrere Möglichkeiten der deskriptiven Statistik. Mit 

<Analysieren> <Deskriptive Statistiken> <Explorative Datenanalyse> 

erhält man mehrere Lage- und Streuungsmaße auf einmal (Abbildung 14). 

Abbildung 14: Auswahl der Option <Explorative Datenanalyse> zur deskriptiven Statistik. 

Nach  Auswahl  dieser  Option  öffnet  sich  das  Fenster  ‚Explorative  Datenanalyse‘.  In  diesem  Fenster 
wählen wir aus der linken Liste der Variablen (Zeitreihen) die beiden Strände BE1 und BE2 aus. Mit 

 

10 

 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

dem  Pfeil  neben  der  Liste  werden  die  beiden  Zeitreihen  in  den  Auswahlbereich  der  ‚Abhängigen 
Variablen‘ (rechte Liste) überführt (Abbildung 15). 

Abbildung 15: Das Fenster ‚Explorative Datenanalyse‘. 

Danach  wählen  wir  im  Fenster  ‚Explorative  Datenanalyse‘  die  Option  <Statistiken>,  woraufhin  sich 
das Fenster ‚Explorative Datenanalyse: Statistik‘ öffnet (Abbildung 16). In diesem Fenster klicken wir 
die Kontrollkästchen ‚Deskriptive Statistik‘ und ‚Perzentile‘ aus. Danach schließen wir das Fenster mit 
der Option <Weiter>. 

 

Abbildung 16: Das Fenster ‚Explorative Datenanalyse: Statistik‘. 

 

Mit  der  Option  <OK>  im  Fenster  ‚Explorative  Datenanalyse‘  wird  der  Befehl  zur  Berechnung  der 
deskriptiven  Statistiken  erteilt.  Im  SPSS-Viewer  erhält  man  anschließend  folgende  Ergebnisse 
(Tabellen 1 und 2): 

 

 

 

11 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Tabelle 1: Deskriptive Statistik nach der explorativen Datenanalyse. 

 

Mittelwert 

Deskriptive Statistik 

Statistik  Standardfehler 

95% Konfidenzintervall des Mittelwerts 

Untergrenze 

Obergrenze 

5% getrimmtes Mittel 

Median 

Varianz 

BE1 

Standardabweichung 

Minimum 

Maximum 

Spannweite 

Interquartilbereich 

Schiefe 

Kurtosis 

Mittelwert 

95% Konfidenzintervall des Mittelwerts 

Untergrenze 

Obergrenze 

5% getrimmtes Mittel 

Median 

Varianz 

BE2 

Standardabweichung 

Minimum 

Maximum 

Spannweite 

Interquartilbereich 

Schiefe 

Kurtosis 

166,93 
58,36   
275,51   
139,76   
88,00   
38438,781   
196,058   
20   
803   
783   
169   

2,719 

8,546 

76,00 
46,26   
105,74   
70,78   
70,00   
2883,857   
53,702   
16   
230   
214   
57   

1,722 

4,242 

50,622 

,580 

1,121 

13,866 

,580 

1,121 

 
Tabelle 2: Perzentile als Ergebnisse der explorativen Datenanalyse. 

 

Perzentile 

Perzentile 

5 

10 

25 

50 

75 

90 

95 

Gewichtetes Mittel (Definition 1) 

BE1  20,00  30,20  47,00  88,00  216,00  497,60 

Tukey-Angelpunkte 

 

BE2  16,00  16,00  34,00  70,00  91,00  169,40 
BE1   
BE2   

49,00  88,00  192,50   
41,00  70,00  85,50   

 

 

12 

. 

. 

 

 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

 
Weiterhin werden im SPSS-Viewer automatisch Box-Whisker-Plots ausgegeben (Abbildung 17). 

 
Abbildung  17:  Box-Whisker-Plot  als  Ergebnis  der  explorativen  Datenanalyse  und  Mittel  zur 
Darstellung  der  Häufigkeitsverteilung  einer  metrischen  Variable  (‚Box‘  =  ‚Schachtel‘,  ‚Whisker‘  = 
‚Barthaar‘). 

 

Korrelationsanalysen mit SPSS 
Durch die deskriptive Statistik haben wir die Hauptmenüoption <Analysieren> schon kennengelernt. 
Hierüber  werden  alle  statistischen  Analysen  ausgeführt.  Zur  Berechnung  einer  Korrelationsmatrix 
wählen wir  

<Analysieren> <Korrelation> <Bivariat>. 

Daraufhin öffnet sich das Fenster ‚Bivariate Korrelationen‘ (Abbildung 18). Aus der linken Liste ziehen 
wir  mit  dem  Pfeil  die  obersten  fünf  Variablen  in  die  Auswahlliste  der  zu  analysierenden  Variablen. 
Wir  gehen  davon  aus,  dass  alle  Variablen  normalverteilt  sind  und  klicken  das  Kontrollkästchen 
‚Pearson‘  an.  Mit  <OK>  wird  die  Berechnung  der  Korrelationsmatrix  ausgeführt.  Im  SPSS-Viewer 
erhält man die in Tabelle 3 gezeigte Korrelationsmatrix. 

 

13 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Abbildung 18: Das Fenster ‚Bivariate Korrelationen‘. 

Tabelle 3: Mit SPSS berechnete Korrelationsmatrix. 

Korrelationen 

 

BE1 

BE2 

DE1 

DE2 

DE3 

 

Korrelation nach Pearson 

1 

BE1 

Signifikanz (2-seitig) 

 

N 

Korrelation nach Pearson 

BE2 

Signifikanz (2-seitig) 

N 

Korrelation nach Pearson 

DE1 

Signifikanz (2-seitig) 

N 

Korrelation nach Pearson 

DE2 

Signifikanz (2-seitig) 

N 

17 

,139 
,622   

15 

-,147 

,601 

15 

-,154 

,652 

11 

,139 

,622 

15 

1 

16 

-,421 
,134   

14 

-,290 

,417 

10 

-,147 

-,154 

-,353 

,601 

,652 

,197 

15 

-,421 

,134 

14 

1 

34 

-,078 
,711   

25 

15 

-,014 

,963 

14 

-,028 

,876 

34 

,063 

,766 

25 

1 

11 

-,290 

,417 

10 

-,078 

,711 

25 

1 

26 

,063 
,766   

Korrelation nach Pearson 

-,353 

-,014 

-,028 

DE3 

Signifikanz (2-seitig) 

,197 

,963 

,876 

N 

15 

14 

34 

25 

34 

 

 

14 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

 

Regressionsanalysen mit SPSS 

Lineare Regressionsanalysen 
Einfache und multiple lineare Regressionsanalysen werden über die Option 

<Analysieren> <Regression> <Linear> 

ausgeführt. Es öffnet sich das Fenster ‚Lineare Regression‘ (Abbildung 19). Wir tun so, als hätten die 
Variablen BE1 und BE2 möglicherweise einen kausalen Einfluss auf die Variable DE1, auch wenn das 
allem Anschein nach unsinnig ist. Aus der Liste der verfügbaren Variablen ziehen wir mit den Pfeilen 
die Variable DE1 in die Auswahlliste für abhängige  Variablen und die Variablen BE1 und BE2 in die 
Auswahlliste für unabhängige Variablen. Danach wählen wir die Option <Statistiken>, so dass sich das 
Fenster 
in  unserem  Beispiel 
anzuklickenden Kontrollkästchen sind Abbildung 20 zu entnehmen. Mit <Weiter> wird dieses Fenster 
wieder  geschlossen.  Nun  wählen  wir  die  Option  <Optionen>.  Es  öffnet  sich  das  Fenster  ‚Lineare 
Regression:  Optionen‘  (Abbildung  21).  Hierin  klicken  wir  das  Kontrollkästchen  ‚Konstante  in 
Gleichung  einschließen‘  an  und  schließen  das  Fenster  mit  der  Option  <Weiter>.  Abschließend  wird 
die Berechnung der Regression mit der Option <OK> im Fenster ‚Lineare Regression‘ ausgeführt. 

‚Lineare  Regression:  Statistiken‘  öffnet  (Abbildung  20).  Die 

Abbildung 19: Das Fenster ‚Lineare Regression‘. 

 

 

15 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Abbildung 20: Das Fenster ‚Lineare Regression: Statistiken‘. 

 

Abbildung 21: Das Fenster ‚Lineare Regression: Optionen‘. 

 

Als  Ergebnisse  werden  im  SPSS-Viewer  zahlreiche  Tabellen  ausgegeben,  deren  Informationen 
zunächst verwirrend erscheinen. Wichtig sind die Tabellen ‚Modellzusammenfassung‘ (Tabelle 4) und 
‚Koeffizienten‘ (Tabelle 5). In diesen beiden Tabellen sind die relevanten Parameter rot markiert. 

 

 

 

16 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

 

Ergebnisse 
Tabelle 
‚Modellzusammenfassung‘. 

4: 

der 

linearen  multiplen 

Regression 

im 

SPSS-Viewer: 

Modell  R 

R-

Korrigiertes 

Standardfehler 

Änderungsstatistiken 

Quadrat 

R-Quadrat 

des Schätzers 

Änderung 

Änderung 

df1  df2 

Sig. 

Durbin-

Watson-

Modellzusammenfassungb 

in R-

in F 

Änderung 

Statistik 

Quadrat 

in F 

,420a 

,177 

,012 

312,014 

,177 

1,072 

2  10 

,379 

2,301 

1 

 

Tabelle 5: Ergebnisse der linearen multiplen Regression im SPSS-Viewer: ‚Koeffizienten‘. 

Koeffizientena 

Modell 

Nicht standardisierte Koeffizienten 

Standardisierte 

T 

Sig.  Kollinearitätsstatistik 

Koeffizienten 

(Konstante) 

RegressionskoeffizientB  Standardfehler 
166,429   

441,238 

Beta 

Toleranz 

VIF 

2,651  ,024   

 

BE1 

1 

BE2 

 

,095 

1,311 

,023 

,072  ,944 

,780 

1,282 

-2,341 

1,766 

-,431 

-

1,326 

,214 

,780 

1,282 

Nichtlineare Regression 
Für  die  Berechnung  einer  nichtlinearen  Regression  geben  wir  in  ein  leeres  SPSS-Datenblatt  die  in 
Abbildung 22 gezeigten Daten ein. 

Abbildung 22: Daten für eine nichtlineare Regression. 

17 

 

 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Sie werden erkennen, dass mit den Daten näherungsweise eine Parabel wiedergegeben wird, wenn 
Variable 1 die unabhängige und Variable 2 die abhängige Variable ist. Wählen Sie nun die Befehle 

<Analysieren> <Regression> <nichtlinear>. 

 

Es erscheint das Fenster ‚Nichtlineare Regression‘. Geben Sie in diesem Fenster die in Abbildung 23 
gezeigten Terme für die abhängige Variable und die Modellformel ein. 

Abbildung 23:  Eingabe des Regressionsmodells im Fenster ‚Nichtlineare Regression‘. 

Wählen Sie anschließend die Option ‚Parameter‘, um den zu schätzenden Parameter festzulegen. Es 
erscheint  das  Fenster  ‚Nichtlineare  Regression:  Parameter‘  (Abbildung  24).  Geben  Sie  in  diesem 
Fenster einen Namen für den zu schätzenden Parameter ein (er sollte identisch mit dem Namen in 
der Modellformel sein), und legen Sie einen Startwert für die iterative Schätzung fest. 

 

 

Abbildung  24:  Definition  des  zu  schätzenden  Parameters  im  Fenster  ‚Nichtlineare  Regression: 
Parameter‘. 

 

18 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Wählen  Sie  anschließend  die  Option  <Hinzufügen>,  und  schließen  Sie  das  Fenster  mit  der  Option 
<Weiter>. 

Starten  Sie  anschließend  die  Berechnung  des  zu  schätzenden  Parameters  im  Fenster  ‚Nichtlineare 
Regression‘  mit  <OK>.  Als  ein  Ergebnis  der  Berechnung  erhalten  Sie  im  SPSS-Viewer  die  Tabelle 
‚Parameterschätzer‘  (Tabelle  6),  aus  der  Sie  erwartungsgemäß  für  k  einen  Schätzwert  nahe  bei  2 
entnehmen können. 

Tabelle  6:  Tabelle  ‚Parameterschätzer‘  im  SPSS-Viewer  als  ein  Ergebnis  der  nichtlinearen 
Regression. 

Parameterschätzer 

Parameter 

Schätzer  Standardfehler 

95%-Konfidenzintervall 

k 

2,003 

,003 

1,997 

2,009 

Untere Grenze  Obere Grenze 

Varianzanalysen mit SPSS 

Einfaktorielle Varianzanalyse 
Geben Sie zunächst die in Abbildung 25 gezeigten Daten in ein SPSS-Datenblatt ein. Es seien Variable 
1  und  Variable  2  zwei  Faktoren,  und  Variable  3  sei  im  Rahmen  unserer  eindimensionalen 
Varianzanalysen die abhängige Variable. 

Abbildung 25: Daten für eindimensionale Varianzanalysen. 

 

19 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

 

Wählen Sie nun den Befehl 

<Analysieren> <Mittelwerte vergleichen> <Einfaktorielle ANOVA>. 

Es öffnet sich das Fenster ‚Einfaktorielle ANOVA‘ (Abbildung 26). Legen Sie in diesem Fenster Variable 
3 als abhängige Variable und Variable 1 als Faktor fest, und starten Sie die Varianzanalyse mit <OK>. 

 

Abbildung 26: Das Fenster ‚Einfaktorielle ANOVA‘. 

Als Ergebnis erhalten Sie im SPSS-Viewer die Tabelle ‚Einfaktorielle ANOVA‘ (Tabelle 7). Darin sind die 
relevanten Ergebnisse rot markiert. 

Tabelle 7: Die Tabelle ‚Einfaktorielle ANOVA‘ als Ergebnis einer einfaktoriellen Varianzanalyse im 
SPSS-Viewer. 

VAR00003 

 

Zwischen den Gruppen 

Innerhalb der Gruppen 

Gesamt 

 

Einfaktorielle ANOVA 

Quadratsumme 

df 

Mittel der 

Quadrate 

F 

Signifikanz 

195,768 

7,808 

203,576 

2 

15 
17   

97,884 
,521   
 

188,037 

,000 

 
 

Zweifaktorielle Varianzanalyse 
Für das Beispiel einer zweifaktoriellen Varianzanalyse werden die Daten verwendet, die wir schon für 
eine einfaktorielle Varianzanalyse benutzt haben (Abbildung 25). Wählen Sie den Befehl 

<Analysieren> <Allgemeines lineares Modell> <Univariat>. 

Es erscheint das Fenster ‚Univariat‘ (Abbildung 27). Legen Sie hierin Variable 3 als abhängige Variable 
und die Variablen 1 und 2 als Zufallsfaktoren fest (es handelt  sich um eine  Stichprobe).  Wir gehen 
davon aus, dass Varianzhomogenität vorliegt. Starten Sie daher die Varianzanalyse mit <OK>. 

 

20 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Abbildung 27: Das Fenster ‚Univariat‘ für eine zweifaktorielle Varianzanalyse. 

 

Die  wesentlichen  Ergebnisse 
in  der  Tabelle 
Zwischensubjekteffekte‘ (Tabelle 8). Darin sind die relevanten Ergebnisse rot markiert. 

im  SPSS-Viewer 

finden  Sie 

‚Tests  der 

Tabelle  8:  Die  Tabelle  ‚Tests  der  Zwischensubjekteffekte‘  als  ein  Ergebnis  einer  zweifaktoriellen 
Varianzanalyse im SPSS-Viewer. 

Tests der Zwischensubjekteffekte 

Abhängige Variable: VAR00003 

Quelle 

Quadratsumme 

df 

vom Typ III 

Mittel der 

Quadrate 

F 

Sig.  

437,094 
101,306a   

97,884 
,113b   

3,536 
,113b   

,113 
,032c   

4,315 

,165 

865,803 

31,273 

3,570 

 

 

 

 

,000 

,004 

,052 

Konstanter Term 

Hypothese 

437,094 

1 

Fehler 

216,746 

2,140 

2 

4 

2 

4 

4 

9 

VAR00001 

VAR00002 

VAR00001 * VAR00002 

 

Hypothese 

195,768 

Fehler 

Hypothese 

Fehler 

Hypothese 

Fehler 

,452 

7,071 

,452 

,452 

,285 

21 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

 

Nichtparametrische Tests mit SPSS 

Nichtparametrische Varianzanalyse (Kruskal-Wallis-H-Test) 
Für  das  Beispiel  einer  nichtparametrischen  Varianzanalyse  werden  die  Daten  verwendet,  die  wir 
schon  für  eine  einfaktorielle  Varianzanalyse  benutzt  haben  (Abbildung  25).  Es  wird  angenommen, 
dass keine Varianzhomogenität vorliegt. Wählen Sie daher den Befehl 

<Analysieren> <Nichtparametrische Tests> <Unabhängige Stichproben>. 

Es  öffnet  sich  das  Fenster  ‚Nichtparametrische  Tests:  Mindestens  zwei  unabhängige  Stichproben‘. 
Wählen  Sie  auf  der  Registerkarte  Ziel  das  Kontrollkästchen  ‚Verteilungen  zwischen  Gruppen 
automatisch vergleichen‘. Definieren Sie  auf der Registerkarte ‚Felder‘ die abhängige  Variable 3 als 
Testfeld  und  Variable  1  als  Gruppe.  Wählen  Sie  auf  der  Registerkarte  Einstellungen  das 
Kontrollkästchen ‚Tests anpassen‘ und als auszuführenden Test den Kruskal-Wallis-H-Test (Abbildung 
28). Starten Sie die Analyse mit <Ausführen>. 

Abbildung 28: Das Fenster ‚Nichtparametrische Tests: Mindestens zwei unabhängige Stichproben‘ 
zur Ausführung eines Kruskal-Wallis-H-Tests. 

Als  Ergebnis  erhält  man  im  SPSS-Viewer  die  Tabelle  ‚Übersicht  über  Hypothesentest‘  (Tabelle  9), 
deren Inhalte selbsterklärend sind. 

 

 

 

 

22 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Tabelle 9:  Die Tabelle  ‚Übersicht  über  Hypothesentest‘  als Ergebnis des  Kruskal-Wallis-H-Tests  im 
SPSS-Viewer. 

 

Kolmogorov-Smirnov-Test 
Als Beispielvariable für die Untersuchung auf Normalverteilung diene Variable 3 aus den vorherigen 
Kapiteln (Abbildung 25). Wählen Sie die Option 

<Analysieren> <Nichtparametrische Tests> <Eine Stichprobe>. 

Es  erscheint  das  Fenster  ‚Nichtparametrische  Tests  bei  einer  Stichprobe‘.  Ziehen  Sie  auf  der 
Registerkarte  ‚Felder‘  Variable  3  in  das  Feld  ‚Testfelder‘.  Wählen  Sie  auf  der  Registerkarte 
‚Einstellungen‘ die Kontrollkästchen ‚Tests anpassen‘ und ‚Kolmogorov-Smirnov-Test‘ (Abbildung 29). 
Wählen  Sie  unter  ‚Kolmogorov-Smirnov-Test‘  die  Option  <Optionen>.  Es  erscheint  das  Fenster 
‚Kolmogorov-Smirnov-Test:  Optionen‘.  Wählen  Sie  in diesem  Fenster  die  Kontrollkästchen  ‚Normal‘ 
und  ‚Stichprobe  verwenden‘.  Schließen  Sie  dieses  Fenster  mit  <OK>.  Anschließend  starten  Sie  die 
Analyse  mit  <Ausführen>  aus  dem  Fenster  ‚Nichtparametrische  Tests  bei  einer  Stichprobe‘.  Als 
Ergebnis erhalten Sie im SPSS-Viewer die Tabelle ‚Übersicht über Hypothesentest‘ (Tabelle 10), deren 
Inhalte selbsterklärend sind. 

Abbildung  29:  Das  Fenster  ‚  Nichtparametrische  Tests  bei  einer  Stichprobe‘  zur  Ausführung  eines 
Kolmogorov-Smirnov-Tests‘. 

 

 

23 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Tabelle 10: Die Tabelle ‚Übersicht über Hypothesentest‘ als Ergebnis des Kolmogorov-Smirnov-Tests 
auf Normalverteilung im SPSS-Viewer. 

 

Faktorenanalysen mit SPSS 

Unrotierte Faktoranalyse 
Bei  der  Faktoranalyse  begegnet  uns  wieder  das  Tabellenblatt  ‚Gesamtsumme‘,  auch  wenn  es  sich 
hierbei  um  Zeitreihen  von  verschiedenen  Stränden  handelt,  die  sich  allenfalls  regional  zu  Faktoren 
bündeln lassen. Wählen Sie den Befehl 

<Analysieren> <Dimensionsreduzierung> <Faktorenanalyse>. 

Es öffnet sich automatisch das Fenster ‚Faktorenanalysen‘ (Abbildung 30). 

Abbildung 30: Das Fenster ‚Faktorenanalysen‘. 

 

Ziehen Sie  die Variablen DE1, DE2, DE3 und DE5 in das  Auswahlfenster ‚Variablen‘. Wählen Sie  die 
Option  <Deskriptive  Statistik>.  Daraufhin  öffnet  sich  das  Fenster  ‚Faktorenanalysen:  Deskriptive 
Statistik‘ (Abbildung 31). 

 

24 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Abbildung 31: Das Fenster ‚Faktorenanalysen: Deskriptive Statistik‘. 

 

Klicken Sie in diesem Fenster an, dass Sie das Kaiser-Meyer-Olkin-Kriterium (KMO) berechnen wollen. 
Schließen Sie dieses Fenster mit <Weiter>. 

Wählen  Sie  nun  im  Fenster  ‚Faktorenanalyse‘  die  Option  <Extraktion>.  Es  öffnet  sich  das  Fenster 
‚Faktorenanalyse: Extraktion‘ (Abbildung 32). 

Abbildung 32: Das Fenster ‚Faktorenanalyse: Extraktion‘. 

 

In diesem Fenster können Sie die Methode der Extraktion und die Anzahl der Faktoren, die extrahiert 
werden  sollen,  auswählen.  Wählen  Sie  die  in  Abbildung  32  gewählten  Auswahlmöglichkeiten 
(Hauptachsenanalyse und Kaiser-Kriterium), und schließen Sie das Fenster mit <Weiter>. 

Wählen  Sie  anschließend  im  Fenster  ‚Faktorenanalyse‘  die  Option  <Werte>  (Abbildung  33).  Im 
Fenster ‚Faktoranalyse: Faktorwerte‘ können Sie angeben, ob Sie Faktorwerte als neue Variablen im 
Datenblatt ausgeben lassen wollen. 

 

25 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Abbildung 33: Das Fenster ‚Faktorenanalyse: Faktorwerte‘. 

 

Schließen  Sie  dieses  Fenster  wieder  mit  <Weiter>.  Nun  können  Sie  die  Faktoranalyse  im  Fenster 
‚Faktoranalyse‘ mit dem Befehl <OK> starten.  

Im  SPSS-Viewer  werden  nun  als  Ergebnisse  Werte  des  KMO-Tests  (Tabelle  11),  eine  Matrix  der 
Kommunalitäten  (Tabelle  12),  eine  Tabelle  mit  den  Eigenwerten  der  Faktoren  (‚Erklärte 
Gesamtvarianz‘, Tabelle 13), ein Screeplot sowie eine Faktorladungsmatrix (‚Faktorenmatrix‘, Tabelle 
14) ausgegeben. Offensichtlich war  die Datengrundlage  kaum  für eine  Faktoranalyse geeignet,  was 
anhand  des  KMO-Wertes  und  der  geringen  Varianzerklärung  zum  Ausdruck  kommt.  In  den 
nachfolgenden Tabellen sind die wesentlichen Ergebnisse der Faktoranalyse rot markiert. 

Tabelle 11: Die Tabelle ‚KMO- und Bartlett-Test‘ als ein Ergebnis der Faktoranalyse im SPSS-Viewer. 

KMO- und Bartlett-Test 

Maß der Stichprobeneignung nach Kaiser-Meyer-Olkin. 

Ungefähres Chi-Quadrat 

Bartlett-Test auf Sphärizität 

df 

Signifikanz nach Bartlett 

,472 

3,886 

6 

,692 

 

Tabelle 12: Die Tabelle ‚Kommunalitäten‘ als ein Ergebnis der Faktoranalyse im SPSS-Viewer. 

Kommunalitäten 

 

Anfänglich  Extraktion 

,026 

,142 

,040 

,148 

,045 

,423 

,426 

,342 

 

DE1 

DE2 

DE3 

DE5 

 
 

 

26 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Tabelle  13:  Die  Tabelle  ‚Erklärte  Gesamtvarianz‘  als  ein  Ergebnis  der  Faktorenanalyse  im  SPSS-

Viewer. 

Erklärte Gesamtvarianz 

Faktor 

Anfängliche Eigenwerte 

Summen von quadrierten Faktorladungen für 

Extraktion 

Gesamt  % der Varianz 

Kumulierte % 

Gesamt 

% der Varianz 

Kumulierte % 

1,387 

1,129 

,886 

,598 

34,676 

28,222 

22,144 

14,958 

34,676 

62,898 
85,042   
100,000   

,764 

,472 

 
 

19,099 

11,812 

19,099 

30,911 

 
 

1 

2 

3 

4 

 

Tabelle 14: Die Tabelle ‚Faktorenmatrix‘ als ein Ergebnis der Faktoranalyse im SPSS-Viewer. 

Faktorenmatrixa 

 

Faktor 

1 

2 

-,094 

,620 

-,170 

,584 

,191 

,197 

,630 

,005 

DE1 

DE2 

DE3 

DE5 

 

Rotierte Faktoranalyse 
Bei  der  rotierten  Faktoranalyse  wird  bis  auf  wenige  Abweichungen  so  vorgegangen  wie  bei  der 
nichtrotierten.  Folgende  Änderungen 
im  Fenster 
‚Faktorenanalyse‘  die  Option  <Rotation>.  Es  öffnet  sich  das  Fenster  ‚Faktorenanalyse:  Rotation‘ 
(Abbildung  34).  In  diesem  Fenster  können  Sie  angeben,  ob  Sie  eine  rotierte  Lösung  wünschen  und 
nach welcher Methode sie berechnet werden soll. 

jedoch  notwendig:  Wählen  Sie 

sind 

 

Abbildung 34: Das Fenster ‚Faktorenanalyse: Rotation‘. 

 

27 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Schließen Sie dieses Fenster nach den in Abbildung 34 gezeigten Anklicken von Kontrollkästchen mit 
<Weiter>, und starten Sie die Faktoranalyse aus dem Fenster ‚Faktoranalyse‘ mit <OK>. 

Über  die  im  vorherigen  gezeigten  Tabellen  hinaus  erhalten  Sie  neben  zusätzlichen  Tabellen  und 
Grafiken eine rotierte Faktorladungsmatrix (Tabelle 15). 

Tabelle  15:  Die  Tabelle  ‚Rotierte  Faktorenmatrix‘  als  ein  Ergebnis  der  rotierten  Faktoranalyse  im 
SPSS-Viewer. 

Rotierte Faktorenmatrixa 

 

Faktor 

DE1 

DE2 

DE3 

DE5 

1 

2 

-,041 

,650 

,000 

,566 

,209 

,029 

,653 

-,147 

Clusteranalysen mit SPSS 
Für  eine  exemplarische  Clusteranalyse  mit  dem  Algorithmus  ‚Ward‘  wird  wieder  das  Datenblatt 
‚Gesamtsumme‘ verwendet. Clusteranalysen werden mit dem Befehl 

<Analysieren> <Klassifizieren> <Hierarchische Cluster> 

begonnen. Es öffnet sich automatisch das Fenster ‚Hierarchische Clusteranalysen‘ (Abbildung 35), in 
dem wir die ersten sieben Strände in die Auswahlliste ‚Variablen‘ ziehen. Diese sieben Strände sollen 
nach euklidischen Distanzen gruppiert werden. 

Abbildung 35: Das Fenster ‚Hierarchische Clusteranalyse‘. 

 

28 

 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Dazu  ist  es  notwendig,  dass  Sie  das  Kontrollkästchen  ‚Variablen‘  statt  ‚Fälle‘  anklicken,  weil  die 
Strände in Spalten stehen. Wählen Sie die Option <Diagramme>, um sich die Ergebnisse der Analyse 
als  Dendrogramm  ausgeben  zu  lassen.  Es  öffnet  sich  das  Fenster  ‚Hierarchische  Clusteranalyse: 
Diagramme‘  (Abbildung  36),  in  dem  Sie  anklicken,  dass  Sie  ein  vertikales  Dendrogramm  erzeugen 
möchten. 

Abbildung 36: Das Fenster ‚Hierarchische Clusteranalyse: Diagramme‘. 

 

Schließen Sie dieses Fenster mit <Weiter>. Nun müssen noch der Gruppierungsalgorithmus und das 
Distanzmaß  ausgewählt  werden.  Dazu  müssen  Sie  im  Fenster  ‚Hierarchische  Clusteranalyse‘  die 
Option <Methode> auswählen, woraufhin sich das Fenster ‚Hierarchische Clusteranalyse: Methode‘ 
(Abbildung 37) öffnet.  

Abbildung 37: Das Fenster ‚Hierarchische Clusteranalyse: Methode‘. 

 

 

29 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Legen Sie in diesem Fenster als ‚Cluster-Methode‘ ‚Ward‘ und als ‚Intervall‘ ‚Euklidische Distanz‘ fest. 
Nachdem Sie dieses Fenster mit <Weiter> geschlossen haben, können Sie im Fenster ‚Hierarchische 
Clusteranalyse‘ die Analyse mit <OK> starten. 

Als wichtigste Ergebnisse dieser Analyse erhalten Sie im SPSS-Viewer eine Zuordnungsübersicht der 
Strände zu Clustern (Tabelle 16), in welcher der Prozess der Gruppierung dokumentiert wird, und ein 
Dendrogramm (Abbildung 38).  

Tabelle 16: Die Tabelle ‚Zuordnungsübersicht als ein Ergebnis der Clusteranalyse im SPSS-Viewer. 

Schritt 

Zusammengeführte Cluster 

Koeffizienten 

Erstes Vorkommen des Clusters  Nächster Schritt 

Cluster 1 

Cluster 2 

Cluster 1 

Cluster 2 

Zuordnungsübersicht 

1 

2 

3 

4 

5 

6 

 

2 

4 

2 

1 

1 

1 

6 

5 

7 

4 

2 

3 

5,701 

40,215 

138,307 

283,515 

515,061 

1341,145 

0 

0 

1 

0 

4 

5 

0 

0 

0 

2 

3 

0 

3 

4 

5 

5 

6 

0 

 
Abbildung 38: Dendrogramm als ein Ergebnis der Clusteranalyse im SPSS-Viewer. 

 

 

30 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Multidimensionale Skalierung mit SPSS 
Wieder kommt das Datenblatt ‚Gesamtsumme‘ zum Einsatz. Mit einer zweidimensionalen Skalierung 
sollen  wie  bei  der  Clusteranalyse  die  ersten  sieben  Strände  konfiguriert  werden.  Überlegen  Sie, 
warum es eigentlich nicht zulässig ist, eine zweidimensionale Konfiguration von sieben Stränden zu 
berechnen. Wählen Sie zunächst die Option 

<Analysieren> <Skalierung> <Multidimensionale Skalierung: ALSCAL>. 

ALSCAL  ist  als  Unterprogramm  in  SPSS  integriert.  Es  öffnet  sich  das  Fenster  ‚Multidimensionale 
Skalierung‘  (Abbildung  39).  Darin  ziehen  Sie  bitte  wieder  die  ersten  sieben  Strände  in  die 
Auswahlliste  der  Variablen.  Weiterhin  müssen  Sie  das  Kontrollkästchen  ‚Distanzen  aus  Daten 
erzeugen‘ anklicken, da es sich bei den Strandmülldaten um Abundanzen handelt. 

Abbildung 39: Das Fenster ‚Multidimensionale Skalierung‘. 

Mit  der  euklidischen  Distanz  ist  die  richtige  Distanzmetrik  schon  ausgewählt.  Wählen  Sie  nun  die 
Option <Modell>. Es öffnet sich das Fenster ‚Multidimensionale Skalierung: Modell‘ (Abbildung 40), 
in  dem  Sie  die  Anzahl  der  Dimensionen  begrenzen  können.  Weiterhin  müssen  Sie  ein  Messniveau 
festlegen. Wählen Sie als Messniveau die metrische ‚Verhältnisskala‘. 

 

 

31 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

 

Abbildung 40: Das Fenster ‚Multidimensionale Skalierung: Modell‘. 

Schließen Sie dieses Fenster mit <Weiter>, und wählen Sie anschließend die Option <Optionen>. Es 
öffnet sich das Fenster ‚Multidimensionale Skalierung: Optionen‘ (Abbildung 41). Hierin können Sie 
festlegen, welche Ergebnisse im SPSS-Viewer angezeigt werden sollen. Wählen Sie die in Abbildung 
41  gezeigten  Kontrollkästchen.  Belassen  Sie  die  numerischen  Kriterien  zur  Berechnung  der 
Konfiguration auf den voreingestellten Werten. Sie können in einer zweiten Analyse diese Kriterien 
verändern,  falls  Sie  in  der  ersten  Analyse  keine  sinnvollen  Ergebnisse  (hohes  Stressmaß)  erzielen 
sollten. 

Abbildung 41: Das Fenster ‚Multidimensionale Skalierung: Optionen‘. 

 

 

32 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Schließen Sie dieses Fenster mit <Weiter>, und starten Sie die Analyse im Fenster ‚Multidimensionale 
Skalierung‘ mit <OK>. 

Als  Ergebnis  erhalten  Sie  im  SPSS-Viewer  eine  Übersicht  der  von  ALSCAL  gemachten  numerischen 
Iterationen.  Bei  der  numerischen  Berechnung  verwendet  ALSCAL  kein  Stress-Maß  von  Kruskal.  Es 
wird daher im SPSS-Viewer auch nicht angegeben. Jedoch erhalten Sie als Ergebnisse im SPSS-Viewer 
eine Konfiguration (Abbildung 42) und ein Shephard-Diagramm (Abbildung 43). Anhand des letzteren 
können Sie die Güte der Konfiguration beurteilen. 

Abbildung 42: Zweidimensionale Konfiguration als ein Ergebnis der multidimensionalen Skalierung 
im SPSS-Viewer. 

 

Abbildung  43:  Shephard-Diagramm  als  ein  Ergebnis  der  multidimensionalen  Skalierung  im  SPSS-
Viewer. 

 

 

 

 

33 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Diskriminanzanalyse mit SPSS 
Geben Sie zunächst die in Abbildung 44 gezeigten Daten in ein leeres SPSS-Datenblatt ein. Dabei ist 
Variable  1  die  Gruppierungsvariable,  und  die  Variablen  2  und  3  dienen  zur  Unterscheidung  zweier 
Gruppen  von  Käufern  unterschiedlicher  Marken  eines  Produktes.  Die  Diskriminanzanalyse  wird 
initiiert mit 

<Analysieren> <Klassifizieren> <Diskriminanzanalyse>. 

Es öffnet sich das Fenster ‚Diskriminanzanalyse‘ (Abbildung 45). 

Abbildung 44: Datengrundlage für eine exemplarische Diskriminanzanalyse. 

 

Abbildung 45: Das Fenster ‚Diskriminanzanalyse‘. 

 

Ziehen Sie Variable 1 in die Auswahlliste für die Gruppierungsvariable und die Variablen 2 und 3 in 
die Auswahlliste der unabhängigen Variablen. Sie müssen SPSS noch mitteilen, wie viele Gruppen der 
Analyse  zugrunde  liegen.  Hierzu  wählen  Sie  die  Option  <Bereich  definieren>.  Es  öffnet  sich  das 
Fenster  ‚Diskriminanzanalyse:  Bereich  definieren‘  (Abbildung  46),  in  dem  Sie  die  Mindest-  und 

 

34 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Höchstwerte der Gruppierungsvariable definieren müssen. Schließen Sie dieses Fenster anschließend 
mit <Weiter>. 

Abbildung 46: Das Fenster ‚Diskriminanzanalyse: Bereich definieren‘. 

 

Wenn Sie die Option <Statistiken> anwählen, öffnet sich das Fenster ‚Diskriminanzanalyse: Statistik‘, 
in dem Sie beispielsweise anklicken können, dass Sie Fisher-Koeffizienten berechnen lassen möchten, 
um  eventuell  einen  potentiellen  Käufer  einer  Gruppe  zuzuordnen  (Abbildung  47).  Schließen  Sie 
dieses Fenster nach Anklicken geeigneter Parameter mit <Weiter>. 

Abbildung 47: Das Fenster ‚Diskriminanzanalyse: Statistik‘. 

 

Wählen  Sie  nun  im  Fenster  ‚Diskriminanzanalyse‘  die  Option  <Klassifizieren>.  Daraufhin  öffnet  sich 
das Fenster ‚Diskriminanzanalyse: Klassifizieren‘ (Abbildung 48), in dem Sie unter anderem definieren 
können,  was  berechnet  werden  soll.  Klicken  Sie  in  unserem  Fall  unter  ‚A-priori-Wahrscheinlichkeit‘ 
das  Kontrollkästchen  ‚Aus  der  Gruppengröße  berechnen‘  an,  da  die  beiden  Gruppen  offensichtlich 
unterschiedlich  groß  sind.  Weitere  Kontrollkästchen  stehen  in  diesem  Fenster  zur  Verfügung,  um 
bestimmte  Grafiken  und  Tabellen  als  Ergebnisse  ausgeben  zu  lassen.  Schließen  Sie  auch  dieses 
Fenster mit <Weiter>. 

 

35 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Abbildung 48: Das Fenster ‚Diskriminanzanalyse: Klassifizieren‘. 

Endlich  wählen  Sie  im  Fenster  ‚Diskriminanzanalyse‘  die  Option  <Speichern>.  Es  öffnet  sich  das 
Fenster  ‚Diskriminanzanalyse:  Speichern‘,  in  dem  Sie  die  Möglichkeit  haben,  mit  Anklicken  von 
Kontrollkästchen weitere Analysenergebnisse im SPSS-Datenblatt abzuspeichern (Abbildung 49). 

 

Abbildung 49: Das Fenster ‚Diskriminanzanalyse: Speichern‘. 

 

Schließen Sie auch dieses Fenster mit <Weiter>, und starten Sie im Fenster ‚Diskriminanzanalyse‘ die 
Berechnung mit <OK>. 

Als Ergebnisse erhalten Sie im SPSS-Viewer zahlreiche Tabellen, von denen nachfolgend (Tabellen 17 
- 22) die wichtigsten gezeigt werden. In den Tabellen sind die wesentlichen Parameter rot markiert. 

Tabelle 17: Die Tabelle ‚Eigenwerte‘ als ein Ergebnis der Diskriminanzanalyse im SPSS-Viewer.  

Eigenwerte 

Funktion 

Eigenwert 

% der Varianz 

Kumulierte % 

Kanonische 

Korrelation 

1 

4,869a 

100,0 

100,0 

,911 

a. Die ersten 1 kanonischen Diskriminanzfunktionen werden in dieser Analyse verwendet. 

36 

 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Tabelle 18: Die Tabelle ‚Wilks‘ Lambda‘ als ein Ergebnis der Diskriminanzanalyse im SPSS-Viewer.  

Test der Funktion(en) 

Wilks-Lambda 

Chi-Quadrat 

df 

Signifikanz 

Wilks' Lambda 

1 

 

,170 

26,545 

2 

,000 

Tabelle  19:  Die  Tabelle  ‚Standardisierte  kanonische  Diskriminanzfunktionskoeffizienten‘  als  ein 
Ergebnis der Diskriminanzanalyse im SPSS-Viewer. 

Standardisierte kanonische Diskriminanzfunktionskoeffizienten 

 

VAR00002 

VAR00003 

Funktion 

1 

,886 

-,542 

 
Tabelle  20:  Die  Tabelle  ‚A-Priori-Wahrscheinlichkeiten  der  Gruppen‘  als  ein  Ergebnis  der 
Diskriminanzanalyse im SPSS-Viewer.  

A-priori-Wahrscheinlichkeiten der Gruppen 

VAR00001 

A-priori 

In der Analyse verwendete Fälle 

Ungewichtet 

Gewichtet 

1,00 

2,00 

Gesamt 

,556 

,444 

1,000 

10 

8 

18 

10,000 

8,000 

18,000 

 
Tabelle 21: Die Tabelle ‚Klassifizierungskoeffizienten‘  als ein Ergebnis der Diskriminanzanalyse im 
SPSS-Viewer.  

Klassifizierungsfunktionskoeffizienten 

 

VAR00001 

1,00 

2,00 

VAR00002 

VAR00003 

3,015 

2,601 

6,857 

1,021 

(Konstant) 

-12,674 

-24,562 

Lineare Diskriminanzfunktionen nach Fisher 

 

 
 

 

37 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Tabelle  22:  Die  Tabelle  ‚Klassifizierungsergebnisse‘  als  ein  Ergebnis  der  Diskriminanzanalyse  im 
SPSS-Viewer. 

 

 

Original 

Kreuzvalidiertb 

 

 

Anzahl 

% 

Anzahl 

% 

Klassifizierungsergebnissea,c 

VAR00001 

Vorhergesagte Gruppenzugehörigkeit 

Gesamt 

1,00 

2,00 

1,00 

2,00 

1,00 

2,00 

1,00 

2,00 

1,00 

2,00 

10 

0 

100,0 

,0 

10 

0 

100,0 

,0 

0 

8 

,0 

10 

8 

100,0 

100,0 

100,0 

0 

8 

,0 

10 

8 

100,0 

100,0 

100,0 

a. 100,0% der ursprünglich gruppierten Fälle wurden korrekt klassifiziert. 

b. Die Kreuzvalidierung wird nur für Fälle in dieser Analyse vorgenommen. In der Kreuzvalidierung ist jeder Fall 

durch die Funktionen klassifiziert, die von allen anderen Fällen außer diesem Fall abgeleitet werden. 

c. 100,0% der kreuzvalidierten gruppierten Fälle wurden korrekt klassifiziert. 

Kontingenzanalyse mit SPSS 
Starten Sie die Kontingenzanalyse nach laden der Daten mit  

<Analysieren> <Deskriptive Statistik> <Kreuztabellen>. 

Es  öffnet  sich  das  Fenster  ‚Kreuztabellen‘  (Abbildung  50),  in  dem  Sie  die  Variablen  für  Spalten  und 
Zeilen in das jeweilige Auswahlfenster ziehen können. 

Abbildung 50: Das Fenster ‚Kreuztabellen‘. 

 

38 

 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Klicken Sie in diesem Fenster die Option <Statistiken> an. Es öffnet sich das Fenster ‚Kreuztabellen: 
Statistik‘ (Abbildung 51), in dem Sie verschiedene Gütemaße anwählen können, die bei der Analyse 
ausgegeben werden sollen. 

Abbildung 51: Das Fenster ‚Kreuztabellen: Statistik‘. 

 

Klicken  Sie  im  Fenster  ‚Kreuztabellen‘  auf  die  Option  <Zellen>.  Es  öffnet  sich  das  Fenster  ‚Zellen 
anzeigen‘  (Abbildung  52).  Darin  können  Sie  angeben,  welche  Kreuztabellen  im  SPSS  Viewer 
ausgegeben werden sollen. 

 

39 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Abbildung 52: Das Fenster ‚Zellen anzeigen‘. 

Führen Sie die Analyse aus dem Fenster ‚Kreuztabellen‘ anschließend mit dem Befehl  <OK> aus. Im 
SPSS Viewer erhalten Sie unter anderem folgende Ergebnisse (Tabellen 23 – 25): 

 

 

Tabelle 23: Kreuztabelle im SPSS Viewer. 

Kreuztabelle Alter*Raucher 

Raucher 

1 

2 

Gesamtsumme 

Alter 

1 

Anzahl 

Erwartete Anzahl 

2 

Anzahl 

Erwartete Anzahl 

Gesamtsumme 

Anzahl 

Erwartete Anzahl 

11 

13,0 

15 

13,0 

26 

26,0 

11 

9,0 

7 

9,0 

18 

18,0 

22 

22,0 

22 

22,0 

44 

44,0 

 

40 

 

 
 

 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Tabelle 24: Tabelle ‚Chi-Quadrat-Tests‘ im SPSS Viewer. 
 

Chi-Quadrat-Tests 

 

Pearson-Chi-Quadrat 

Kontinuitätskorrekturb 

Likelihood-Quotient 

1,504a 

,846 

1,514 

Exakter Test nach Fisher 

 

 

Zusammenhang linear-mit-

linear 

Anzahl der gültigen Fälle 

1,470 

44   

Wert 

df 

(zweiseitig) 

(zweiseitig) 

(einseitig) 

Asymp. Sig. 

Exakte Sig. 

Exakte Sig. 

1 

1 

1 

1 

 

 

,220   
,358   
,219   

,225   

 

,358 

 
 
 

 

 

,179 

a. 0 Zellen (0,0%) haben die erwartete Anzahl von weniger als 5. Die erwartete Mindestanzahl ist 9,00. 

b. Berechnung nur für eine 2x2-Tabelle 

 
 Tabelle 25: Tabelle ‚Symmetrische Maße‘ im SPSS Viewer. 

Symmetrische Maße 

 

 

Nominal bezüglich Nominal  Phi 

Cramer-V 

Kontingenzkoeffizient 

Anzahl der gültigen Fälle 

Näherungsweis

Wert 

e Sig. 

-,185 

,185 

,182 
44   

,220 

,220 

,220 

Logistische Regressionsanalysen mit SPSS 
Nach Laden der Eingangsdaten starten Sie logistische Regressionsanalysen mit 

<Analysieren> <Regression> <Binär logistisch>. 

Es öffnet sich das Fenster ‚Logistische Regression‘ (Abbildung 53). 

 

41 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

 

Abbildung 53: Das Fenster ‚Logistische Regression‘. 

In diesem Fenster ziehen Sie die abhängige Variable in das betreffende Feld und die Regressoren in 
das Feld ‚Kovariaten‘. 

Wenn  Sie  die  Option  <Kategorial>  anwählen,  können  Sie  im  Fenster  ‚Logistische  Regression: 
Kategoriale  Variablen  definieren‘  die  ausgewählten  Regressoren  als  kategoriale  Variablen  anlegen 
(Abbildung 54). 

Abbildung 54: Das Fenster ‚Logistische Regression: Kategoriale Variablen definieren‘. 

 

 

 

 

42 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Wählen  Sie  im  Fenster  ‚Logistische  Regression‘  die  Option  <Speichern>.  Im  Fenster  ‚Logistische 
Regression: Speichern‘ (Abbildung 55) können Sie angeben, ob und wie Sie die Gruppenzugehörigkeit 
in SPSS speichern wollen. 

Abbildung 55: Das Fenster ‚Logistische Regression: Speichern‘. 

 

Im  Fenster  ‚Logistische  Regression:  Optionen‘  (Abbildung  56),  das  sich  nach  Anklicken  der  Option 
<Optionen> öffnet, können Sie z. B. anwählen, dass SPSS eine Klassifikationsmatrix berechnen soll. 

Abbildung 56: Das Fenster ‚Logistische Regression: Optionen‘. 

 

 

 

43 

 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Starten  Sie  die  Analyse  mit  <OK>  aus  dem  Fenster  ‚Logistische  Regression‘,  und  Sie  erhalten  z.B. 
folgende Tabellen im SPSS Viewer (Tabellen 26 – 28): 

Tabelle 26: Die Tabelle ‚Variablen in der Gleichung‘ im SPSS Viewer. 

 

 

Variablen in der Gleichung 

B 

Standardfehler 

Wald 

df 

Sig. 

Exp(B) 

Schritt 0  Konstante 

-,105 

,265 

,158 

1 

,691 

,900 

 
Tabelle 27: Die Tabelle ‚Modellübersicht‘ im SPSS Viewer. 

 

Modellübersicht 

-2 Log-

R-Quadrat nach 

R-Quadrat nach 

Schritt 

Likelihood 

Cox & Snell 

Nagelkerke 

1 

28,807a 

,584 

,780 

a. Die Schätzung wurde bei Iteration Nummer 7 beendet, da 

Parameterschätzungen sich um weniger als ,001 geändert 

haben. 

 
Tabelle 28: Die Tabelle ‚Klassifikationstabelle‘ im SPSS Viewer. 

 

 

 

 

Klassifikationstabellea 

Vorhersagewert 

Arbeit 

Prozentsatz 

Beobachtet 

0 

1 

richtig 

Schritt 1  Arbeit 

0 

1 

Gesamtprozentsatz 

a. Der Trennwert ist ,500 

 

 

27 

4 

 

3 

23 

90,0 

85,2 

87,7 

44 

 
 

 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Neuronale Netze mit SPSS 
Mit <Analysieren> <Neuronale Netze> <Mehrschichtiges Perzeptron>  

legen  Sie  in  SPSS  Feedforward  neuronale  Netze  an.  Es  öffnet  sich  das  Fenster  ‚Mehrschichtiges 
Perzeptron‘, in dem Sie mehrere Reiter haben, die im Folgenden der Reihe nach behandelt werden. 
Im  Reiter  ‚Variablen‘  (Abbildung  57)  legen  Sie  die  abhängigen  Variablen  und  die  unabhängigen 
Variablen  als  Kovariaten  fest.  Achten  Sie  darauf,  dass  Sie  bei  der  Option  <Erneute  Skalierung  von 
Kovariaten> ‚Keine‘ auswählen. 

Abbildung 57: Das Fenster ‚Mehrschichtiges Perzeptron‘ mit dem Reiter ‚Variablen‘. 

Im Reiter ‚Partitionen‘ (Abbildung 58) können Sie  festlegen, ob Sie  eine  zufällige  Auswahl der Test- 
und  Trainingsdaten  vornehmen  wollen,  oder  ob  Sie  die  Eingangsdaten  mit  einer 
Partitionierungsvariablen festlegen wollen. 

 

 

45 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Abbildung 58: Das Fenster ‚Mehrschichtiges Perzeptron‘ mit dem Reiter ‚Partitionen‘. 

Im Reiter ‚Architektur‘ (Abbildung 59) legen Sie die Anzahl der Zwischenschichten und deren Zellzahl 
fest.  Außerdem  legen  Sie  hier  die  Aktivierungsfunktionen  für  die  Zwischenschicht  und  die  Output-
Schicht fest. 

 

Abbildung 59: Das Fenster ‚Mehrschichtiges Perzeptron‘ mit dem Reiter ‚Architektur‘. 

 

 

 

46 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Im  Reiter  ‚Training‘  (Abbildung  60)  definieren  Sie  den  Trainingsalgorithmus.  Es  bietet  sich  an,  das 
Kontrollkästchen ‚Gradientenabstieg‘ anzuklicken. 

Abbildung 60: Das Fenster ‚Mehrschichtiges Perzeptron‘ mit dem Reiter ‚Training‘. 

Im Reiter ‚Ausgabe‘ können Sie wählen, welche Tabellen und Grafiken SPSS automatisch erstellen soll 
(Abbildung 61). 

 

Abbildung 61: Das Fenster ‚Mehrschichtiges Perzeptron‘ mit dem Reiter ‚Ausgabe‘. 

 

 

 

47 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Im Reiter ‚Speichern‘ legen Sie fest, ob und wie Sie Ihre Modellergebnisse in SPSS speichern wollen 
(Abbildung 62). 

Abbildung 62: Das Fenster ‚Mehrschichtiges Perzeptron‘ mit dem Reiter ‚Speichern‘. 

Starten  Sie  die  Analyse  aus  einem  beliebigen  Reiter  mit  Anwahl  von  <OK>.  Sie  erhalten  unter 
anderem im SPSS Viewer folgende Ergebnisse (Abbildungen 63 und 64, Tabelle 29): 

 

Abbildung 63: Struktur des neuronalen Netzes im SPSS Viewer. 
 

 

 

 

48 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

 
Abbildung 64: Streudiagramm modellierter und gemessener Werte einer beispielhaften 
abhängigen Variablen. 
 

 

 

 

49 

 

SPSS Tutorial – Marcus Schulz & Elisabeth Ehling 

Tabelle 29: Die Tabelle ‚Modellübersicht‘ im SPSS Viewer. 
 

Modellübersicht 

Training  Quadratsummenfehler 

Durchschnittlicher relativer Gesamtfehler 

Relativer Fehler für metrische 

Tourism 

abhängige Variablen 

Shipping 

Fishing 

Verwendete Stoppregel 

1 

27,785 

,772 

,574 

,965 

,776 

Trainingszeit 

Test 

Quadratsummenfehler 

Durchschnittlicher relativer Gesamtfehler 

Relativer Fehler für metrische 

Tourism 

abhängige Variablen 

Shipping 

Fishing 

a. Fehlerberechnungen basieren auf der Teststichprobe. 

aufeinanderfolgende(r) 

Schritt(e) ohne 

Verringerung des 

Fehlersa 

0:00:00,00 

22,150 

,972 

,555 

1,291 

27,805 

 

 

 

50 

