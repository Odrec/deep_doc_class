D
N
A

L
A
C
I
G
O
L
O
H
C
Y
S
P

S
E
C
N
E
I
C
S

E
V
I
T
I
N
G
O
C

Eye movement evidence that readers maintain and
act on uncertainty about past linguistic input

Roger Levya,1, Klinton Bicknella, Tim Slatteryb, and Keith Raynerb

Departments of aLinguistics and bPsychology, University of California at San Diego, 9500 Gilman Drive, La Jolla, CA 92093

Edited by Edward E. Smith, Columbia University, New York, NY, and approved October 20, 2009 (received for review July 14, 2009)

In prevailing approaches to human sentence comprehension, the
outcome of the word recognition process is assumed to be a
categorical representation with no residual uncertainty. Yet per-
ception is inevitably uncertain, and a system making optimal use of
available information might retain this uncertainty and interac-
tively recruit grammatical analysis and subsequent perceptual
input to help resolve it. To test for the possibility of such an
interaction, we tracked readers’ eye movements as they read
sentences constructed to vary in (i) whether an early word had near
neighbors of a different grammatical category, and (ii) how
strongly another word further downstream cohered grammatically
with these potential near neighbors. Eye movements indicated
that readers maintain uncertain beliefs about previously read word
identities, revise these beliefs on the basis of relative grammatical
consistency with subsequent input, and use these changing beliefs
to guide saccadic behavior in ways consistent with principles of
rational probabilistic inference.

psycholinguistics 兩 language comprehension 兩
probabilistic models of cognition

A critical part of understanding a sentence is identifying the

words that comprise it. It is well understood that humans
achieve this goal through a combination of top-down (contex-
tual) and bottom-up (perceptual) cues (1, 2). In spoken word
recognition, comprehenders’ conclusions about a given word’s
identity can be affected by phonetic and lexical cues from
adjacent words (3, 4), and by subsequent semantic context when
the speech stream is manipulated to make bottom-up evidence
ambiguous (5, 6). It has also recently become clear that even
relatively unambiguous bottom-up evidence regarding spoken
word identity can be overridden by subsequent evidence within
the same word (7, 8). It is unknown, however, whether word-
identity uncertainty is maintained as a matter of course after
perceptual cues have been encountered in full upon hearing or
first reading a word in a sentence. It could be that, under normal
circumstances, a categorical commitment is made to a unique
candidate word, which is then integrated into an incremental
sentence representation. Such a strategy could be efficient if
considerable effort is required to construct and maintain syn-
tactic/semantic relationships for multiple candidate words at a
given position within the sentence (9). This possibility also
coincides with the treatment of grammatical analysis in most
formal models of language comprehension as a process that
takes a word sequence as its input (10–12), and with the
treatment in leading models of eye-movement control in reading
(13, 14). On the other hand, it is also possible that the perceptual
input from a given word gives rise to multiple candidate word
representations entering the stream of syntactic/semantic pro-
cessing. This strategy would have the advantage of greater
robustness, permitting identification and correction of percep-
tual noise or speaker error early in a sentence on the basis of
additional
information obtained late in a sentence (15). In
addition, maintaining and continually reassessing uncertainty
about word identity could be useful in guiding behavior during
real-time comprehension. In reading, eye movements could be
directed to previous parts of a sentence where word-identity

uncertainty is high; in spoken language comprehension, alloca-
tion of attentional resources could be updated on the basis of
word uncertainty, or the listener could prompt the speaker for
clarification about parts of a message that were unclear. Whether
uncertainty about word identity is maintained and revised, and
if so, according to what principles, is thus a question of funda-
mental interest in the study of language comprehension.

A Sharp Test for Word-Level Uncertainty
In the past, providing a sharp test of whether word-identity
uncertainty is maintained has proven elusive because existing
results could be interpreted as involving categorical word mis-
identification. For example, the word flour is reread more often
in sentence 1a than in sentence 1b or than the word wheat in
sentence 1c (16):
1a. He swept the flour that he spilled.
1b. The baker needed more flour for the special bread.
1c. He swept the wheat that he spilled.
Crucially, the word flour has an orthographically similar ‘‘near-
neighbor,’’ floor, that is semantically incompatible with the
continuations of sentences 1a or 1c. The sentence-initial context
in sentence 1a is more strongly predictive of floor than of flour,
so it is possible that the distinctive rereading behavior is due to
the comprehender initially maintaining some uncertainty as to
whether the critical word was flour or floor, and subsequently
returning to this word to confirm that it is indeed flour. This same
result could, however, be obtained under a theory in which
uncertainty about word identity is not maintained after initial
word recognition, but there is an occasional categorical misiden-
tification of flour as floor in sentence 1a upon first reading, and
the incongruous downstream word spilled triggers a return of the
eyes to the initial locus of semantic anomaly.

In the present work, we provide a sharper test of whether
word-identity uncertainty is maintained by using sentences in
which categorical misidentification should in principle facilitate,
rather than hinder, downstream processing. We turn to sentences
with a combination of grammatical constructions that has at-
tracted considerable recent attention for the theoretically prob-
lematic comprehension behavior it elicits. Despite near meaning
equivalence, sentence 2a is considerably more difficult to read
and comprehend than sentences 2b and 2c (17–19):
2a. The coach smiled at the player tossed the frisbee.
2b. The coach smiled at the player thrown the frisbee.
2c. The coach smiled at the player who was tossed the frisbee.

Author contributions: R.L., K.B., T.S., and K.R. designed research; R.L., K.B., and T.S.
performed research; R.L., T.S., and K.R. contributed new reagents/analytic tools; R.L., K.B.,
T.S., and K.R. analyzed data; and R.L. wrote the paper.
The authors declare no conﬂict of interest.
This article is a PNAS Direct Submission.
1To whom correspondence should be addressed. E-mail: rlevy@ling.ucsd.edu.
This article contains supporting information online at www.pnas.org/cgi/content/full/
0907664106/DCSupplemental.

www.pnas.org兾cgi兾doi兾10.1073兾pnas.0907664106

PNAS Early Edition 兩 1 of 5

Processing difficulty in sentence 2a is localized at the word
tossed, whose grammatical part of speech is in principle ambig-
uous between finite verb and past participle (17). This difficulty
pattern is similar to that obtained in classic ‘‘garden-path’’
sentences such as the horse raced past the barn fell (20), where the
part-of-speech ambiguity of raced permits a misanalysis of raced
past the barn as part of the sentence’s main clause when in fact
it is a reduced relative clause that is part of the sentence’s
main-clause subject. There is a critical difference in sentences
like 2a, however, in that the potentially ambiguous word tossed
appears at a point in the sentence where the prior context (in
particular the words smiled at, which signal that the player is
inside a verb-modifying prepositional phrase) should rule out
this main-clause misanalysis. The comprehension difficulty ob-
served for this and similar types of sentences (19, 21) is at odds
with a long history of theoretical accounts and empirical evi-
dence that prior context guides inferences about the grammatical
analysis of new words in a sentence (10–12, 22–25), and thus
poses a major challenge for most leading accounts of language
comprehension.

One way in which these results could be reconciled with a
strong guiding role of prior context is if the representation of
prior context is less categorical than has previously been as-
sumed. Levy (15) recently proposed a model in which these
results arise from a combination of top-down grammatically
driven expectations with nonveridical bottom-up input through
noisy-channel Bayesian inference. This move is analogous to
probabilistic and constraint-based approaches that assume prob-
ability distributions over structural analyses of a sentence (10–
12, 26–29), only in this case probability distributions are ex-
tended over the content of the sentence, as well as over its
analysis. In this model, the comprehender takes perceptual noise
into account when making inferences about sentence form and
structure, so that at all times the comprehender has a probability
distribution over the sequence of words comprising the current
sentence, taking into account perceptually similar and gram-
matically permissible variants of the sentence read thus far. In an
experimental setting, researchers know the true sentence w*
presented to a reader, but cannot observe the noisy perceptual
input I on which the reader bases his/her inferences about
sentence form and structure. However, we can marginalize over
I to obtain expected inferences as follows:

P共w兩w*兲 ⫽ P C共w兲冕I

P C共I兩w兲P T共I兩w*兲

P C共I兲

dI

[1]

[2]

⬀ PC共w兲Q共w, w*兲,

where PC is a probability distribution encoding the comprehend-
er’s knowledge of his/her language and environment, PT is the
true distribution of perceptual noise, and Q(w,w*) is propor-
tional to the integral in Eq. 1 and represents the average effect
of perceptual noise. To model the behavioral consequences of
reading a new word wi* in a sentence, Levy (15) assumed that if
wi* dramatically changes the comprehender’s beliefs about the
earlier content of a sentence, then the comprehender will tend
to respond behaviorally by longer fixation times and possibly
making regressive saccades. If Pi(w[0,j)) is defined to be the
probability distribution over the sequence of words starting at
the beginning of the sentence and continuing up to but not
including the position occupied by wj*, conditioning on the
input obtained from words w1…i*, the Kullback-
perceptual
Leibler (K-L) divergence D(Pi(w[0,i))储Pi⫺1(w[0,i))) is a natural
metric quantifying the change in this probability distribution
sentence induced by reading wi* (30).

In this model of rational probabilistic inference under uncer-
tain input, the behavioral difficulty of sentence 2a arises because

0
2

.

0

)
s
t
i

b
(
 
n
o

5
1

.

0

i
t

u
b
i
r
t
s
d
 
y
t
i
l
i

i

b
a
b
o
r
p

 
t
x
e

0
1

.

0

t

n
o
c
 
n

i
 

5
0

.

0

e
g
n
a
h
C

0
0

.

0

0

1

at + ambig
at + unambig
toward + ambig
toward + unambig

2

3

Noise parameter λλ (low=noisy)

4

5

6

7

Fig. 1.
Size of change (K-L divergence) in expected probability distribution
over preceding word sequences upon encountering tossed/thrown in sen-
tences 2 and 3, under noisy-channel Bayesian inference. The parameter ␭,
expressing the level of perceptual noise, is free in the model; over a wide range
of parameter values, the sentence types observed to be harder for humans to
process are those in which the shift in probability distribution is larger.
Variants of the true context have probability exponentially decreasing in ␭
times the Levenshtein edit distance from the true context. See SI Appendix for
model details.

the conditional probability of tossed given the true preceding
context is considerably lower than its conditional probability
given visually similar but grammatically different contexts, such
as those obtained by substituting for at the orthographically
similar (near-neighbor) words as or and, or by inserting who after
coach or player. This difference in conditional probability arises
because any of these substitutions or insertions changes the
sentence‘s grammatical structure such that the word after player
is highly likely to be a finite verb. As a result, when the model
is instantiated using a probabilistic context-free grammar esti-
mated from the parsed Brown corpus (31, 32) and a noise
function Q based on the Levenshtein distance between words in
w and w*, Bayesian inference upon reading tossed creates a large
shift in the probability distribution over preceding-context word
sequences away from the true context and toward these near-
neighbor contexts; reading thrown in sentence 2b does not lead
to a similar shift because it cannot be a finite verb (Fig. 1, black
and green lines). If reading is influenced by principles of rational
inference and decision theory, then these large changes in belief
about prior context would be likely to induce comprehenders to
slow their reading rate, and would be likely to trigger regressive
eye movements to earlier parts of a text and the locus of
uncertainty.

Crucial to this model, however, is the comprehender’s ability to
maintain uncertainty about the identities of words that have already
been read. Furthermore, if the prior context is changed such that
there are fewer near-neighbor contexts for which the conditional
probability of the critical word tossed is higher than under the true
context, then in the model the ensuing shift of the probability
distribution over preceding contexts at the critical word should be
reduced. This observation leads to an experimental design in which
comprehenders read not only sentences like 2a and 2b but also

2 of 5 兩 www.pnas.org兾cgi兾doi兾10.1073兾pnas.0907664106

Levy et al.

