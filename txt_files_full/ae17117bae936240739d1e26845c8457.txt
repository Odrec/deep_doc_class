Universität Osnabrück

AUSARBEITUNG

zum Seminar

Software Engineering

im Sommersemester 2016

Thema:

Applying topic modeling to source code for promoting program comprehension

Erstellt am 4. Juni 2016

Vorgelegt von:

Katrin Ihler
942515
Meller Str. 185a
49084 Osnabrück
kihler@uos.de

Inhaltsverzeichnis
1 Einführung

2 Program Comprehension

2.1 Das Integrierte Program Comprehension Modell . . . . . . . . . . . . . . . . .
2.2 Das Program Interleaving Problem . . . . . . . . . . . . . . . . . . . . . . . .
2.3 Program Slicing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2

3
3
6
8

3 Topic Modeling

10
3.1 LDA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.2 LDA-DF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
ITM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
3.3
3.4 LDAvis
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15

4 Topic Modeling für Software

18
4.1 Die Bedeutung von Themen in Software . . . . . . . . . . . . . . . . . . . . . 18
4.2 Herausforderungen bei der Anwendung von Topic Modeling auf Software . . . 20

5 ITMViz

22
5.1 Preprocessing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
5.2
Interaktives Topic Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
5.3 Visualisierung und Interpretation . . . . . . . . . . . . . . . . . . . . . . . . . 23

6 Zusammenfassung

A Abbildungsverzeichnis

B Literaturverzeichnis

25

26

27

i

Applying topic modeling to source code for

promoting program comprehension

Katrin Ihler
4. Juni 2016

Software Engineers verbringen bis zu 70% ihrer Arbeitszeit mit dem Verste-
hen von Programmcode, der sogenannten Program Comprehension. Ein gutes
Verständnis eines Programms ist essentiell, um Wartungsarbeiten durchführen
zu können, seien es Fehlerbehebungen oder das Hinzufügen neuer Features. Die
Wissenschaft beschäftigt sich deswegen schon seit mehreren Jahrzehnten mit
den Fragen, wie der Prozess des Verstehens eines Programms abläuft, welche
Eigenschaften ein Programm schwer verständlich machen und wie man das Ver-
ständnis fördern kann. Um eine Übersicht über ein größeres Software-System zu
liefern, wird zunehmend Topic Modeling eingesetzt, ein statistisches Modell, das
die Themen aus einer Menge von Dokumenten inferiert.

Diese Arbeit liefert einen Überblick über die wichtigsten Erkenntnisse in der
Erforschung von Program Comprehension, stellt Topic Modeling vor und be-
schäftigt sich mit der Frage, wie Topic Modeling erfolgreich eingesetzt werden
kann, um das Verständnis von Software zu verbessern. Als konkretes Tool wird
ITMViz vorgestellt, ein interaktives Topic Modeling-Framework für die Anwen-
dung auf Quellcode, das die resultierenden Themen in einer Webanwendung
darstellt.

1

1 Einführung
Das Verstehen von Software ist ein wichtiger Teil des Alltags von Software-Entwicklern.
Eine Studie von [MaL15] zeigt, dass Programmierer durchschnittlich 70% ihrer Zeit damit
verbringen - Zum Vergleich: Für das Editieren und Navigieren von Quellcode werden gerade
einmal 4 bzw. 5% aufgewendet. Es lassen sich somit während der Software-Entwicklung Zeit
und somit Kosten einsparen, wenn das Verständnis erleichtert wird.

Gerade große Software-Systeme, die bereits vor längerer Zeit entwickelt wurden (soge-
nannte Legacy-Systeme), sind jedoch häuﬁg schwer zu verstehen: Die Komplexität der Soft-
ware hat sich im Laufe der Entwicklung erhöht, die ursprünglichen Entwickler haben das
Projekt zu diesem Zeitpunkt meist verlassen, Dokumentation ist unvollständig, inkonsistent
oder gar nicht vorhanden. Diese Systeme erzeugen somit oft einen hohen Wartungsaufwand.
[Boe81] zeigte schon 1981, dass die Wartungsphase von allen Phasen des Lebenszyklus eines
Software-Systems die kostenintensivste ist.

Um einen Überblick über größere Software-Systeme zu gewinnen, wird zunehmend To-
pic Modeling eingesetzt. Bei Topic Modeling handelt es sich um statistische Modelle, die
verwendet werden, um latente Zusammenhänge aus Texten herauszuarbeiten. Die Ergebnis-
se sind sogenannte Themen, die den Texten zugrunde liegen und in Beziehung zueinander
stehen. Sie können genutzt werden, um zu verstehen, wovon die Texte handeln.

Bei der Anwendung auf Quellcode können Topic Models aufzeigen, aus welchen Kompo-
nenten ein Software-System besteht und wie diese zusammenhängen. Dies kann hilfreich
sein, um die relevanten Code-Fragmente für die Behebung eines Fehlers oder dem Hinzufü-
gen eines neuen Features zu ﬁnden. Die Ergebnisse können aber auch die Umstrukturierung
der Systemarchitektur unterstützen, da sie die wahre Struktur widerspiegeln, unabhängig
davon, wie die Klassen und Pakete momentan angeordnet sind.

Inzwischen existieren einige Tools, die Topic Modeling auf Quellcode anwenden. Eines da-
von ist eine Webanwendung namens ITMViz, die interaktives Topic Modeling auf Software-
Projekte anwendet und die Ergebnisse visualisiert. Dieses Tool ist besonders interessant, da
es einige Erweiterungen für ihr Topic Model verwendet, um die Ergebnisse zu verbessern.
Im Laufe dieser Arbeit werden zunächst die wichtigsten Erkenntnisse bei der Erforschung
von Program Comprehension vorgestellt (Abschnitt 2). Dies beinhaltet sowohl ein Modell
für den Prozess des Verstehens von Software, der im Kopf eines Programmierers abläuft,
als auch die Fragen, welche Eigenschaften eines Programms dazu führen, dass es schwer
verständlich ist, und welche Strategien verfolgt werden, um Programme besser zu verstehen.
Abschnitt 3 beschreibt Topic Modeling zunächst allgemein. Mit LDA wird das wichtigste
Topic Model vorgestellt, das auch ITMViz zugrunde liegt. Außerdem werden hier die Er-
weiterungen für die interaktive Nutzung und Visualisierung von Topic Models eingeführt,
die ITMViz verwendet.

Abschnitt 4 beschäftigt sich dann mit der sinnvollen Anwendung von Topic Models auf
Quellcode. Es wird die Frage erörtert, welche Bedeutung Themen in einem Quellcode-Korpus
zukommt. Außerdem werden verschiedene Anwendungsbeispiele vorgestellt und die Unter-
schiede zwischen der Anwendung von Topic Models auf natürlichsprachlichem Text und
Quellcode diskutiert.

In Abschnitt 5 wird ITMViz vorgestellt. Die einzelnen Komponenten werden erläutert

und in Bezug zu vorhergehenden Abschnitten dieser Arbeit gesetzt.

Abschnitt 6 fasst abschließend die Ergebnisse dieser Arbeit zusammen.

2

2 Program Comprehension
Das Verstehen von Programmen wird in einer frühen Arbeit von [KR91] deﬁniert als „Der
Prozess, Programmcode zu verstehen, der dem Programmierer unbekannt ist“. Dabei läuft
im Gehirn des Programmierers ein komplexer kognitiver Prozess ab. Häuﬁg verfolgen Pro-
grammierer dabei ein konkretes Ziel, zum Beispiel die Behebung eines Fehlers oder das
Hinzufügen eines neuen Features. Während des Verstehensprozesses stellt sich der Pro-
grammierer eine Reihe von Fragen (z.B. „Was tut diese Methode?“), für deren Antwort er
Hypothesen aufstellt („Ich glaube, diese Methode berechnet das Ausmaß der Überlappung
zwischen zwei Kreisen“), die er dann anhand des Quellcodes überprüft, verbessert oder
wieder verwirft. Abschnitt 2.1 beschreibt ein Model, das den Prozess des Verstehens eines
Programms beschreibt.

Das Verstehen von Software ist schwer. Tatsächlich ist das Program Comprehension Pro-
blem deﬁniert nach [WY96] sogar NP-schwer. Allerdings sind einige Programme leichter zu
verstehen als andere. Da der kognitive Prozess aber intern stattﬁndet, kann die Verständ-
lichkeit eines Programms nur anhand von Indikatoren gemessen werden. In Experimenten
mit Entwicklern kann deren Verständnis eines Programms zum Beispiel anhand von kon-
kreten Aufgaben geprüft werden. Häuﬁg werden Versuchspersonen auch aufgefordert, ihre
Gedanken laut zu äußern, um so den internen Prozess nachvollziehen zu können. (Nähe-
res zum Messen von Program Comprehension mit Experimenten ﬁndet man in [SKA+13].)
Auch messbare Eigenschaften des Programms selbst wie die Anzahl der Code-Zeilen oder
Verzweigungen können Hinweise auf die Verständlichkeit geben. Abschnitt 2.2 beschreibt
mit Program Interleaving eine Eigenschaft von Software, die das Verständnis erschwert.

Da das Verstehen und Warten von Programmen ein wichtiger Aspekt der Arbeit eines
Software Engineers ist, kritisiert [Gla02], dass dies im Studium zu wenig berücksichtigt wird.
Studenten lernen hauptsächlich, eigenen Code zu schreiben, und weniger, Software zu lesen
und zu verstehen oder sogar aus fremden Code zu lernen.

Aus der Wichtigkeit von Program Comprehension folgt das Bedürfnis, das Verstehen von
Programmen zu erleichtern. Dies bedeutet sowohl, Software so zu konstruieren, dass sie
leichter zu verstehen und zu warten ist, als auch zusätzliche Strategien und Technologien zu
entwickeln, um den Software Engineer zu unterstützen. Diese rangieren vom Syntax High-
lighting über die automatische Generierung von Dokumentation wie z.B. UML-Diagrammen
bis hin zur Anwendung von statistischen Algorithmen wie Topic Models (vgl. spätere Ab-
schnitte). Abschnitt 2.3 stellt mit Program Slicing exemplarisch eine Strategie vor, um dem
Program Interleaving Problem aus Abschnitt 2.2 zu begegnen.

2.1 Das Integrierte Program Comprehension Modell
Program Comprehension Modelle versuchen, den Prozess zu erklären, den Programmierer
anwenden, um Programme verstehen. Im Laufe der letzten Jahrzehnte wurden einige ver-
schiedene Modelle entwickelt, die sich zum Teil überlappen oder beinhalten. (Einen guten
Überblick über die verschiedenen Modelle liefert [vMV94].) In diesem Abschnitt werden
zunächst einige grundlegende Ansätze zum Verstehen von Software vorgestellt, die dann in
einem integrierten Modell zusammengeführt werden.

Es lassen sich zwei grundlegende Ansätze zum Verstehen von Programmen unterscheiden:

Top-down und bottom-up (vgl. [Sto05]):

3

Top-down Dieser Ansatz wird angewendet, wenn dem Programmierer das Programm zu-
mindest vage vertraut ist. Er ist dann in der Lage, eine erste Hypothese über den
Zweck des Programms zu bilden, die er dann anhand des Programms zu bestätigen
und zu verfeinern sucht.

Bottom-up Ist dem Programmierer das Programm hingegen gänzlich unbekannt, beginnt
er damit, einzelne Codezeilen zu verstehen, die er dann zu immer größeren Code-
Fragmenten zusammenfügt, deren Zweck er verstanden hat (sogen. Chunking), bis
er sich irgendwann eine Hypothese über den Zweck des gesamten Programms bilden
kann.

Tatsächlich verwenden Programmierer meist nicht exklusiv einen Ansatz, sondern wech-
seln während des Prozesses zwischen top-down und bottom-up in Abhängigkeit davon, ob
es ihnen möglich ist, eine Hypothese über ein Code-Fragment zu bilden (top-down) oder
nicht (bottom-up).

Weiterhin lässt sich der Prozess des Verstehens von Programmen dahingehend unter-
scheiden, ob ein systematischer oder ein opportunistischer Ansatz gewählt wird. Ziel des
systematischen Ansatzes ist es, das gesamte Programm auf globaler Ebene zu verstehen.
Der opportunistische Ansatz verfolgt hingegen ein konkretes Ziel, zum Beispiel die Behe-
bung eines Bugs, das nicht erfordert, das gesamte Programm zu verstehen. In diesem Fall
konzentriert sich der Programmierer nur auf die Teile des Codes, die er als relevant für seine
Aufgabe wahrnimmt. Der systematische Ansatz führt zu einem besseren Verständnis des
Programms, ist bei großen Programmen allerdings schwer umzusetzen.

Das Integrierte Program Comprehension Modell von [vML99] vereint verschiedene Ansät-
ze zur Program Comprehension in einem Modell (vgl. Abbildung 2.1 für eine Darstellung).
Es besteht aus vier Komponenten:

• Top-down-Model
• Program Model
• Situation Model
• Knowledge Base

Die ersten drei Komponenten stellen die verschiedenen Prozesse zum Verstehen von Soft-
ware dar, zwischen denen der Programmierer wechseln kann. Die letzte Komponente ist
die Wissensbasis, die sowohl erlangtes Wissen über das zu verstehende Programm beinhal-
tet als auch Wissen darüber hinaus, z.B. über die Programmiersprache und Software im
Allgemeinen. Alle drei Prozesse nutzen diese Wissensbasis (in der Abbildung in der Mitte
dargestellt) und fügen neues Wissen über das Programm hinzu.

4

5

Abbildung 2.1: Das Integrierte Program Comprehension Modell (Quelle: [vMV94])

ProgramModelChunkingMicro–StructureMacro–StructureShort–TermBeaconsSituationModelLow–LevelMappingsMappingsHighLevelChunkingSchema(Plan)CurrentMentalRepresentationofProgramUnderstandingProcessOpportunisticC. Rules of DiscourseA. Strategic PlansB. Tactical PlansC. Implementation Plans1. Control PrimesProgramA. Text–StructureProblem Domain(Real World Knowledge)B. Plan KnowledgeA. FunctionalStructuresStructuresProgramModelTop–DownStructuresSituationModelCompre–hensionShort–termMemoryMatchCompre–hensionDocuments & CodeDocuments &CodeReadMemoryDocumentsBeaconsBottom–upOpportunistic orReadProcessRules of DiscourseProgramming Plans(Plan Knowledge)Knowledge1. Algorithms2. Control Sequence3. Data–Structures4. Data–Flow (slices)5. SyntaxDomainKnowledgeKnowledgeKnowledgeMatchProcessSystematicTop–DownSystematic Bottom–upFrom ProgramModelFromTop–DownModelDas Top-down Model (in der Abbildung oben), auch Domain Model genannt, funktioniert
wie oben beschrieben und basiert auf dem Model von [SAE88]. Das Program Model und das
Situation Model beschreiben verschiedene Varianten des bottom-up Ansatzes und basieren
auf der Arbeit von [Pen87]. Mit dem Program Model (in der Abbildung links) wird zu-
nächst systematisch eine Abstraktion des Kontrollﬂusses des Programms aufgebaut, um zu
verstehen, wie verschiedene Module zusammenhängen. Anschließend kann mit dem Situati-
on Model (in der Abbildung rechts) systematisch oder opportunistisch eine Abstraktion des
Datenﬂusses erarbeitet werden. Da der Programmierer zwischen verschiedenen Modulen und
Abstraktionsebenen des Programms wechseln kann, stößt er immer wieder auf unbekannten
Code, für dessen Verständnis er die verschiedenen Prozessen nutzen kann.

2.2 Das Program Interleaving Problem
Eine Eigenschaft von Programmen, die die Verständlichkeit erschwert, ist Program Inter-
leaving. [RSW95] deﬁnieren Program Interleaving als Code, der Fragmente für scheinbar
unzusammenhängende Aufgaben enthält und diese miteinander verwebt. Dies kann entwe-
der gewollt entstehen, zum Beispiel aufgrund von Eﬃzienz-Optimierungen, oder sich unge-
wollt im Laufe der Entwicklung und Wartung eines Programms durch Bugﬁxes und dem
Hinzufügen neuer Features entwickeln.

[RSW95] führen als Charakteristiken von Program Interleaving drei Eigenschaften auf:

Delokalisierung Die Codezeilen für einen bestimmten Zweck sind verteilt über den gesamten
Code, anstatt an einer Stelle gekapselt zu sein. Dies erschwert das Verständnis und
kann bei Wartungsarbeiten zu unvollständigen Änderungen führen.
Abbildung 2.2 zeigt als Beispiel einen Teil einer in FORTRAN geschriebenen Sub-
routine, die sowohl den nächsten Punkt eines Ellipsoids zu einer Linie berechnet als
auch die kürzeste Distanz des Ellipsoids zu der Linie. Um numerische Ungenauigkeiten
zu vermeiden, werden die Daten zunächst herunterskaliert, bevor die Berechnungen
stattﬁnden, und danach wieder hochskaliert. Die für die Skalierung zuständigen Co-
dezeilen sind in der Abbildung markiert. Sie sind delokalisiert, und aufgrund ihrer
Abhängigkeit von den Berechnungen ist es nicht leicht, sie zu kapseln.

Ressource-Sharing Code für verschiedene Zwecke teilt sich gemeinsamen Code oder arbeitet
auf gemeinsamen Daten. Dies tritt häuﬁg bei gewolltem Interleaving auf und ist ein
Zeichen dafür, dass die verschiedenen Aufgaben in Beziehung zueinander stehen. Diese
Art von Interleaving erschwert es häuﬁg, zu erkennen, welchen Eﬀekt eine Änderung
der geteilten Ressource haben wird.
Abbildung 2.3 zeigt einen anderen Ausschnitt aus der gleichen Subroutine wie Ab-
bildung 2.2. Diese Subroutine verfolgt zwei verschiedene Zwecke: Die Berechnung des
nächsten Punkts, aber auch die Berechnung der Distanz. Die Distanzberechnung pro-
ﬁtiert von den Zwischenergebnissen, die bei der Berechnung des nächsten Punkts ent-
stehen; die Aufgaben teilen sich also Ressourcen.

6

Abbildung 2.2: Code-Beispiel in FORTRAN für Delokalisierung bei Program Interleaving

(Quelle: [RSW96])

Abbildung 2.3: Code-Beispiel in FORTRAN für geteilte Ressourcen bei Program Inter-

leaving (Quelle: [RSW96])

7

Unabhängigkeit Trotz Gemeinsamkeiten dienen die miteinander verwobenen Codezeilen
unterschiedlichen Zwecken. Diese Unabhängigkeit wird von dem Interleaving verschlei-
ert. Theoretisch können die unterschiedlichen Aufgaben voneinander getrennt werden,
dies führt jedoch möglicherweise zu einer Verschlechterung der Eﬃzienz oder erfor-
dert die Duplikation von Code. Hier muss ein Kompromiss zwischen Eﬃzienz und
Wartbarkeit gefunden werden.

2.3 Program Slicing
Program Slicing ist eine Dekompositionstechnik, die ursprünglich von [Wei81] entwickelt
wurde. Dabei werden aus einem Programm die Statements extrahiert, die für eine bestimm-
te Berechnung relevant sind. Diese bilden eine sogenannte Slice, die somit die Frage be-
antwortet: „Welche Statements können potentiell die Berechnung einer Variable v in einem
Statement s beeinﬂussen?“ Für diese Berechnung irrelevante Statements werden unsichtbar
gemacht, der Programmierer blickt sozusagen durch ein Fenster auf den relevanten Teil des
Programms (siehe Abbildung 2.4).

Diese Art der Ansicht ist besonders dann hilfreich, wenn das Program ein hohes Maß
an Interleaving (vgl. Abschnitt 2.2) aufweist, da Statements, die nicht zu der betrachteten
Aufgabe gehören, herausgeﬁltert werden.

Abbildung 2.4: Links das gesamte Programm, rechts die Slice in Abhängigkeit von State-

ment s (heller Kasten) (Quelle: [BG96])

Eine Slice hängt ab von einem Slicing-Kriterium, das aus einem Statement s und einer

Variable v besteht. Es ist auch möglich, mehrere Slices miteinander zu vereinen.

Die von [Wei81] eingeführten Slices bezeichnet man heute als Executable Backward Static
Slices: Die Slices sind ausführbar, sie sind rückwärtsgewandt (sie können erzeugt werden,
indem man den Abhängigkeitsgraphen des Programms rückwärts durchläuft) und sie sind
nur abhängig vom statischen Zustand des Programms.

8

An dieser Stelle sei ein Beispiel aus [HH01] gezeigt. Das gesamte Code-Beispiel sieht

folgendermaßen aus:
x = 1;
y = 2;
z = y - 2;
r = x;
z = x + y;

Die Slice wird in Abhängigkeit vom letzten Statement und Variable z erzeugt:

x = 1;
y = 2;
z = x + y;

1
2
3
4
5

1
2
3

Alle irrelevanten Statements werden herausgeﬁltert; dies gilt auch für z = y - 2;, da der

Wert später überschrieben wird.

Im Laufe der Jahre wurden eine Reihe weiterer Arten von Slices entwickelt. Es ist möglich,
Slices zu erzeugen, die nicht ausführbar sind. Forward Slices durchlaufen das Programm
ausgehend von s vorwärts statt rückwärts; sie beantworten die Frage: „Welche Statements
werden beeinﬂusst von Variable v an Statement s?“ Dynamische Slices werden jeweils für
einen festgelegten Input erzeugt.

Program Slicing kann nicht nur das Programmverständnis, sondern auch Debugging und
Wartungsarbeiten unterstützen, indem nur die relevanten Teile des Programms betrachtet
werden. Die Technik kann von Programmierern manuell angewendet werden, es existieren
aber auch automatische Tools.

Für einen detaillierteren Überblick über Program Slicing vgl. [BG96].

9

3 Topic Modeling
In einer zunehmend digitalisierten Welt steht der Mensch häuﬁg vor der Aufgabe, große
Mengen an Daten zu verstehen, zu analysieren und organisieren. Topic Modeling kann diese
Aufgabe erleichtern, indem es die Themen ﬁndet, die ein Set von Dokumenten durchziehen,
und herausarbeitet, wie diese Themen zusammenhängen. Dies kann einen Überblick über die
Daten schaﬀen und auch die Suche nach konkreten Sachverhalten erleichtern, indem statt
einer Stichwortsuche ein relevantes Thema gesucht wird, zu dem dann die dazugehörigen
Dokumente angezeigt werden können.

Abbildung 3.1 stellt exemplarisch die Ergebnisse der Anwendung eines Topic Models
auf Artikel des Yale Law Journal dar. Die wichtigsten Themen sind mit ihren häuﬁgsten
Wörtern abgebildet. Es ist zu erkennen, dass das das dritte Thema wahrscheinlich um
Scheidungen und Sorgerechtsstreitigkeiten handelt, das erste von Steuererklärungen usw.

Abbildung 3.1: Themen von Artikeln aus dem Yale Law Journal mit ihren häuﬁgsten

Wörtern (Quelle: [Ble11])

Dokumente müssen allerdings keine Zeitungsartikel sein, Topic Models können auch auf
Tweets oder Programmcode (vgl. Abschnitt 4), aber auch auf Bild- oder Audiodateien an-
gewendet werden. Es handelt sich bei Topic Models um statistische Algorithmen, die die
enthaltenen Worte in den Dokumenten analysieren, um auf die zugrundeliegende Themen-
struktur zu schließen.

Im Folgenden soll zunächst das einfachste und zugleich bekannteste Topic Model LDA vor-
gestellt werden (Abschnitt 3.1. Abschnitt 3.2 beschäftigt sich mit der Frage, wie zusätzliches
Wissen von Nutzern für LDA kodiert werden kann, um die Ergebnisse zu verbessern. Ab-
schnitt 3.3 baut auf dieser Frage auf, indem die Möglichkeit erörtert wird, wie die Ergebnisse
eines Topic Models von Nutzern iterativ verbessert werden können. Im letzten Abschnitt
wird schließlich LDAvis vorgestellt; ein Framework, um resultierende Themenstrukturen zu
visualisieren.

3.1 LDA
Bei LDA (Latent Dirichlet Allocation) von [BNJ03] handelt es sich um ein häuﬁg verwen-
detes einfaches Topic Model, das für verschiedene Zwecke angepasst oder erweitert werden

10

consumptionearningsestateexemptionfundsincomeorganizationsrevenuesubsidiestaxtaxationtaxestaxpayerstreasuryyearbargainingcollectiveemployeeemployeesemployeremployersemploymentindustrialjoblaborunionunionsworkworkerworkerschildchildrendiscriminationfamilyfemalegendermalemarriagemenparentssexsexualsocialwomanwomenkann. Man stellt sich dabei vor, dass alle Wörter in den Dokumenten anhand von zugrun-
deliegenden Wahrscheinlichkeitsverteilungen über Wörter in Themen und Themen in Doku-
menten zufällig generiert werden. Der Algorithmus versucht dann anhand der beobachteten
Dokumente den Prozess der Generierung umzukehren, um auf die verborgene Themen-
struktur hinter den Dokumenten zu schließen. Dies ist gleichbedeutend damit, die bedingte
Wahrscheinlichkeit der Verteilung der Themen bei gegebenen Dokumenten zu berechnen.

Abbildung 3.2: Generierung der Dokumente (Quelle: [Ble11])

Der Prozess der Generierung läuft folgendermaßen ab:
Ein Thema ist deﬁniert als eine Wahrscheinlichkeitsverteilung über ein feste Menge von
Wörtern. (Zum Beispiel ist bei einem Thema über Software Engineering die Wahrschein-
lichkeit von „UML“ höher als von „Konditionierung“, das wiederum in einem Thema über
Psychologie eher auftreten würde.)

Man stellt sich nun vor, dass eine Menge von Themen bereits speziﬁziert ist und aus diesen
die Dokumente generiert werden. Der Prozess der Generierung ist in Abbildung 3.2 darge-
stellt. Die Themen mit ihren Wahrscheinlichkeitsverteilungen für die einzelnen Wörter sind
links notiert. Für jedes Dokument wird zunächst zufällig eine Wahrscheinlichkeitsverteilung
über die Themen gewählt (in der Abbildung das Histogramm rechts). Dann wird jedes Wort
des Dokuments wie folgt erzeugt: Anhand der soeben gewählten Verteilung wird ein Thema
gewählt (die farbigen Kreise), dann wird anhand der Wahrscheinlichkeitsverteilung über die
Wörter, die das Thema beinhaltet, ein zufälliges Wort gewählt.

Ein Dokument beinhaltet somit Wörter, die von verschiedenen Themen generiert wurden.
In Abbildung 3.3 ist exemplarisch ein Zeitungsartikel dargestellt, dessen Wörter jeweils zu
einem von drei Themen gehören. (Bindewörter wie „and“ und „the“ wurden dabei ausge-
spart.)

Selbstverständlich werden die Wörter in den Dokumenten nicht tatsächlich zufällig gene-

riert. Diese Vorstellung dient nur dazu, die Idee von LDA zu beschreiben.

11

figure 1. the intuitions behind latent Dirichlet allocation. We assume that some number of “topics,” which are distributions over words,exist for the whole collection (far left). each document is assumed to be generated as follows.first choose a distribution over the topics (thehistogram at right); then, for each word, choose a topic assignment (the colored coins) and choose the word from the corresponding topic.the topics and topic assignments in this fgure are illustrative—they are not ft from real data. See figure 2 for topics ft from data.. , ,. , ,. . .genednageneticlifeevolveorganismbrainneuronnervedatanumbercomputer. , ,TopicsDocumentsTopic proportions andassignments0.040.020.010.040.020.010.020.010.010.020.020.01datanumbercomputer., ,0.020.020.01Abbildung 3.3: News-Artikel mit seinen Themen (Quelle: [BNJ03])

LDA versucht nun also, anhand der Dokumente auf die Themen zu schließen. Da es aller-
dings exponentiell viele mögliche Themenstrukturen gibt, wird die Verteilung approximiert.
Dies kann nach unterschiedlichen Methoden geschehen. Stichproben-basierte Algorithmen
nutzen Stichproben der posterioren Verteilung zur Approximation. Die am häuﬁgsten ver-
wendete Methode dafür ist Gibbs-Sampling von [GS04], bei der alle gesuchten latenten
Variablen (bei LDA häuﬁg die Themenverteilung in den Dokumente und die Wörtervertei-
lung in den Themen) bis auf eine (die Themenzugehörigkeit von jedem Wort) festgehalten
werden und die letzte Variable aus der resultierenden bedingten Verteilung gezogen wird.
Um die Inferenz der posterioren Verteilung zu beschleunigen, entwickelten [YMM09] Spar-
seLDA als Variante von Gibbs Sampling, die deutlich weniger Speicherverbrauch und eine
geringere Laufzeit aufweist.

Um LDA zu konﬁgurieren, werden eine Reihe von Parametern eingesetzt, deren richtige
Wahl Thema einiger Studien ist (vgl. Abschnitt 4.2 zur optimalen Wahl der Parameter bei
der Anwendung von LDA auf Quellcode):

tc Deﬁniert die Anzahl der gesuchten Themen.
α Beeinﬂusst, wie einheitlich die Themenverteilung in den Dokumenten ist. Bei einem hohen
Wert enthält ein Dokument eher viele Themen gleichmäßig, bei einem niedrigen Wert
eher wenige Themen oder ein Thema prominent.

β Beeinﬂusst in derselben Weise wie α die Wortverteilung in den Themen.

12

Zusätzlich muss auch das Stichprobenverfahren entsprechend eingestellt werden:

b Anzahl der Burn-in-Iterationen
n Anzahl der Stichproben
si Stichproben-Intervall

Abbildung 3.4: LDA angewendet auf Artikel des Science-Magazins (Quelle: [Ble11])

Abbildung 3.4 zeigt beispielhaft das Ergebnis einer Anwendung von LDA auf zahlreiche
Artikel des Science-Magazins. Das Histogramm auf der linken Seite stellt die Themenvertei-
lung für das Dokument aus Abbildung 3.2 dar. Auf der rechten Seite sind die vier häuﬁgsten
Themen des Dokuments mit ihren häuﬁgsten Begriﬀen dargestellt.

Einer der Hauptvorteile von LDA ist seine Anpassbarkeit und Erweiterbarkeit für kom-
plexere Anwendungsfälle. So berücksichtigt LDA standardmäßig weder die Reihenfolge von
Worten in einem Dokument, noch die Reihenfolge von Dokumenten im Korpus (letzteres ist
besonders für Analysen über Zeitspannen hinweg interessant). Die Anzahl der Themen, die
LDA sucht, ist festgelegt, kann allerdings auch während der Inferenz der posterioren Ver-
teilung geschätzt werden. LDA kann ebenso erweitert werden, um zur Verfügung stehende
Metadaten miteinzubeziehen. (Für eine Diskussion der besonderen Herausforderungen bei
der Anwendung auf Quellcode sei auf Abschnitt 4.2 verwiesen.)

3.2 LDA-DF
Die resultierenden Themen eines Topic Models sind nicht immer so sinnvoll wie erhoﬀt. So
vermischen einige Themen vielleicht unterschiedliche Sachverhalte miteinander, andere sind
Duplikate, manche ergeben überhaupt keinen Sinn. Die objektive Funktion, die ein Topic
Model optimiert, stimmt außerdem nicht immer mit dem überein, was Menschen für gute
Themen halten.

Die Ergebnisse können verbessert werden, indem Nutzer dem System zusätzliches Wissen
darüber mitteilen, welche Wörter in einem gemeinsamen Thema oder in getrennten Themen
auftreten sollen. Um solches Wissen für LDA zu enkodieren, entwickelten [AZC09] Dirichlet
Forest Priors für LDA. Das Wissen wird dabei in zwei Arten von Constraints übersetzt:

13

“Genetics”humangenomednageneticgenessequencegenemolecularsequencingmapinformationgeneticsmappingprojectsequenceslifetwo“Evolution”evolutionevolutionaryspeciesorganismsoriginbiologygroupsphylogeneticlivingdiversitygroupnewcommon“Disease”diseasehostbacteriadiseasesresistancebacterialnewstrainscontrolinfectiousmalariaparasiteparasitesunitedtuberculosis“Computers”computermodelsinformationdatacomputerssystemnetworksystemsmodelparallelmethodsnetworkssoftwarenewsimulations18162636465666768696TopicsProbability0.00.10.20.30.4Must-Links Deﬁnieren Paare von Wörtern, die wahrscheinlich zu demselben Thema gehören
und somit eine ähnliche Auftretenswahrscheinlichkeit in den Themen haben sollten;
somit sind entweder beide wahrscheinlich oder beide eher unwahrscheinlich in einem
Thema. Ein Beispiel wäre Must-Link(software,programming).

Cannot-Links Sind Paare von Wörtern, die wahrscheinlich nicht zu demselben Thema gehö-
ren, somit dürfen beide eine geringe oder eines eine hohe und das andere eine geringe
Auftretenswahrscheinlicheit in einem Thema haben, aber nicht beide eine hohe. Ein
Beispiel wäre Cannot-Link(programming,philosophy).

Nutzerwissen kann somit in ein Set von diesen Constraints übersetzt werden. So lässt sich
ein Thema in mehrere aufteilen, indem man Cannot-Links zwischen den einzelnen Teilen
und Must-Links innerhalb dieser Teile deﬁniert. Mehrere Themen lassen sich mit Must-Links
zu einem großen Thema verschmelzen und häuﬁge Worte, die in vielen Themen vorkommen,
kann man isolieren, indem man unter ihnen Must-Links und zu allen sehr wahrscheinlichen
Worten der anderen Themen Cannot-Links formuliert. Deﬁnierte Constraints dürfen dabei
nicht in Konﬂikt zueinander stehen.

Wie stark dieses zusätzliche Wissen in das Topic Model einﬂießt, kann mit dem Parameter

η beeinﬂusst werden. Es handelt sich hier also eher um „Soft Constraints“.

Um dieses Wissen für LDA zu kodieren, werden Bäume für die Darstellung der a priori
Wahrscheinlichkeit aller Wörter verwendet. Diese ersetzen die symmetrische Verteilung, die
LDA verwendet und die keinerlei Beziehungen zwischen Wörtern kennt. Diese symmetrische
Verteilung kann man sich als ein Baum vorstellen, der nur eine Wurzel und die Wörter als
Blätter hat.

Um Constraints umzusetzen, erhalten diese Wörter zusätzliche Knoten zwischen sich
selbst und der Wurzel. Der Parameter β, der die Sparsity festlegt, kann nun für verschie-
dene Constraints verschiedene Werte einnehmen: Wird β3 klein gewählt, wird mit hoher
Wahrscheinlichkeit nur eines der Wörter „tea“ oder „space“ gewählt (Cannot-Link). Wird
β2 höher gewählt, ist die Wahrscheinlichkeit für „drive“ und „ride“ eher gleich (Must-
Link). Abbildung 3.5 zeigt den resultierenden Baum mit zwei daraus gezogenen Themen-
Wahrscheinlichkeitsverteilungen.

Abbildung 3.5: Enkodierung von Constraints in Bäumen (Quelle: [HBGS11])

14

Überlappen sich Wörter in mehreren Constraints, gibt es Regeln, um diese zu einem Baum
zusammenzufügen. Must-Links sind transitiv, Cannot-Links jedoch nicht, da im schlimmsten
Fall dann nur noch ein Wort pro Thema erlaubt wäre. Auf eine detaillierte Erklärung für
diesen Prozess wird hier aus Platzgründen verzichtet, bei Interesse siehe [HBGS11].

3.3 ITM
Mit den Dirichlet Forest Priors von [AZC09] ist es uns möglich, Constraints für LDA zu
kodieren, um die Themen zu verbessern. Es ist allerdings schwierig, sinnvolle Constraints
festzulegen, bevor man überhaupt Themen gesehen hat. [HBGS11] entwickelten deshalb
ITM (Interactive Topic Modeling), ein Framework, das es erlaubt, die Ergebnisse mit Cons-
traints iterativ immer weiter zu verbessern (dargestellt in Abbildung 3.6). Dabei werden
die vorherigen Ergebnisse in der nächsten Iteration nicht einfach weggeworfen; stattdessen
werden nur die Themen neu gelernt, mit denen der Nutzer nicht zufrieden ist. Dies spart
Zeit, erhöht die Qualität des Outputs und erspart es dem Nutzer, in jedem Durchgang alles
neu verstehen zu müssen.

Abbildung 3.6: Ablauf des interaktiven Topic Modeling (Quelle: [HBGS11])

Da sich die Inferenz der posterioren Verteilung bei Baum-basierten Topic Models kompli-
zierter gestaltet und bei interaktiven Systemen eine möglichst geringe Latenz gewünscht ist,
um eine angenehme Nutzererfahrung zu schaﬀen, entwickelten [HBGS11] zusätzlich einen
schnelleren Inferenz-Algorithmus für Baum-basierte Topic Models auf der Basis von Spar-
seLDA (siehe Abschnitt 3.1.

Außerdem entwarfen [HBGS11] eine Methode, um Must-Links und Cannot-Links automa-
tisiert vorzuschlagen, basierend darauf, welche Wörter häuﬁg zusammen in einem Referenz-
Korpus auftreten.

3.4 LDAvis
Der Output eines Topic Models kann je nach Anzahl der gesuchten Themen und der Menge
an Dokumenten sehr komplex werden. Um das Verständnis zu erleichtern, wurden im Lau-
fe der Jahre verschiedene Tools zur Visualisierung entwickelt. Eines dieser Tools soll hier
vorgestellt werden.

15

Bei LDAvis 1 von [SS14] handelt es sich um ein webbasiertes interaktives Visualisierungs-
tool für LDA. Mithilfe der Interaktivität kann eine Ansicht dargestellt werden, die sowohl
kompakt als auch detailliert ist.

Abbildung 3.7: Screenshot von LDAvis (Quelle: [SS14])

In Abbildung 3.7 ist ein Screenshot der Anwendung abgebildet. Die linke Seite liefert eine
globale Übersicht über die gefundenen Themen. Sie liefert Informationen darüber, welche
Themen vorherrschen (Größe der Kreise) und wie verschiedene Themen miteinander zu-
sammenhängen (Abstände der Kreise). Dafür werden zunächst die inhaltlichen Distanzen
zwischen den Themen berechnet und dann mit multidimensionaler Skalierung in die zweidi-
mensionale Ebene transformiert. (Verschiedene Methoden zur Skalierung und Berechnung
der Distanzen können in der Anwendung eingestellt werden.)

Für einen besseren Überblick bei einer hohen Anzahl von Themen können Cluster von
Themen gebildet werden. Diese werden mit dem k-Means-Algorithmus anhand des Ortes
der Themen in der Ebene gebildet.

Wird auf der linken Seite ein Thema ausgewählt, liefert die rechte Seite in Form eines
Balkendiagramms die Begriﬀe, die das Thema am besten beschreiben, und wie häuﬁg sie im
Thema (rote Balken) und im gesamten Korpus (graue Balken) vorkommen. Mithilfe dieser
Informationen lässt sich die Bedeutung eines Themas erschließen. Bei Auswahl eines Begriﬀs
wird auf der linken Seite wiederum dessen Verteilung über alle Themen dargestellt.

Die Wahl dieser Begriﬀe ist dabei nicht trivial. Üblicherweise wird eine absteigenden Liste
der wahrscheinlichsten Begriﬀe eines Themas verwendet. Dabei stehen allerdings an der Spit-
1https://github.com/benmarwick/LDAviz

16

ze oft Begriﬀe, die im gesamten Korpus häuﬁg vorkommen, wodurch es schwieriger wird, die
Themen voneinander abzugrenzen. [SS14] verwenden deshalb das neue Kriterium der Rele-
vanz, bei dem der gewichtete Mittelwert aus der Wahrscheinlichkeit eines Begriﬀs innerhalb
eines Themas und dem sogenannten Lift berechnet wird. Der Lift ist dabei deﬁniert als
das Verhältnis zwischen der Wahrscheinlichkeit eines Begriﬀs innerhalb eines Themas und
über den gesamten Korpus hinweg. Das Ziel ist es, eine gewisse Exklusivität der Begriﬀe
zu erreichen, damit die Bedeutung eines Themas leichter erkennbar wird. Die Gewichtung
kann mit dem Parameter λ beeinﬂusst werden.

17

4 Topic Modeling für Software
Topic Models können neben normalsprachlichen Texten auch auf Quellcode von Software-
Projekten angewendet werden. Während allerdings die Bedeutung von Themen, die zum
Beispiel die Artikel einer Zeitung durchziehen, intuitiv verständlich ist, stellt sich die Frage,
was Themen in Quellcode überhaupt bedeuten und inwiefern sie hilfreiche Informationen
liefern. Abschnitt 4.1 setzt sich mit dieser Frage auseinander und stellt außerdem drei An-
wendungsbeispiele für Topic Modeling auf Software vor.

Bei der Anwendung von Topic Models auf Quellcode ist außerdem zu berücksichtigen,
dass Quellcode sich in einigen wichtigen Eigenschaften von normalsprachlichem Text unter-
scheidet. Dies kann die resultierenden Themen beeinträchtigen, aber auch genutzt werden,
um die Ergebnisse zu verbessern. Abschnitt 4.2 diskutiert möglich Probleme und Lösungen.

4.1 Die Bedeutung von Themen in Software
Die Frage, was Themen in einem Software-System bedeuten, ist nicht so leicht intuitiv
zu beantworten. Für ein besseres Verständnis werden im Laufe dieses Abschnitts deshalb
mehrere Anwendungsbeispiele vorgestellt, um den Nutzen der Anwendung auf Code zu
verdeutlichen.

Es hat sich gezeigt, dass Themen mit implementierten Konzepten oder Features im Code
zusammenhängen. Sie sind deshalb in der Lage, dem Programmierer einen Gesamtüberblick
über die Struktur eines Software-Systems zu vermitteln und darzustellen, wie die verschie-
denen Komponenten miteinander in Beziehung stehen.

Abbildung 4.1: TopicXP Screenshot (Quelle: [SDGP10])

18

Abbildung 4.1 stellt beispielhaft einen Screenshot des Tools TopicXP von [SDGP10] dar,
das Software Engineers dabei unterstützen soll, eine Übersicht über ein größeres Software-
System zu erlangen. Jede Box repräsentiert ein Thema mit seinen assoziierten Wörtern,
Klassen und Paketen. Pfeile indizieren, wenn Code, der zu einem Thema gehört, Code aus
einem anderen Thema aufruft.

[GCS12] haben des Weiteren festgestellt, dass gefundene Themen in Quellcode mit der
Entwicklungsgeschichte des Programms zusammenhängen: Anhand der Themen lässt sich
erkennen, welche Teile des Programms gemeinsam geändert wurden. Für den Vergleich wur-
den die Änderungseinträge in einem Versionskontrollsystem (z.B. git) verwendet. Dabei wur-
den kleinere Änderungen, die zusammen eine logische Änderung des Programms bedeuten,
zu sogenannten Changelists zusammengefasst.

Abbildung 4.2 stellt den Zusammenhang zwischen Themen und Changelists dar. Die Zei-
len stehen für die einzelnen Changelists, sortiert nach Zeit, die Spalten für die Themen. Die
Kreise zeigen an, ob und wie viele Codefragmente des jeweiligen Themas in der jeweiligen
Changelist enthalten sind. Anhand dieser Visualisierung lassen sich nun mehrere Muster
erkennen: Vertikale Reihen von Kreisen stehen für die Entwicklung eines bestimmten Kon-
zepts, gehörig zu einem bestimmten Thema, über die Zeit hinweg. Horizontale Reihen stellen
wiederum systemweite Änderungen dar. Es ist zu erkennen, dass vertikale Reihen häuﬁger
auftreten, d.h. gleichzeitige Änderungen ﬁnden zumeist in nur wenigen Themen oder in nur
einem Thema statt. Ein Thema entspricht also einer Menge von Code-Fragmenten, die ge-
meinsam gewartet wird. Diese Erkenntnisse können nicht nur dazu verwendet werden, um
die Entwicklung eines Software-Systems nachzuvollziehen, sondern auch, um dafür zu sor-
gen, dass zukünftige Änderungen vollständig durchgeführt werden. So entwickelten [GC14]
auf Basis ihrer Forschungsergebnisse ein System, das auf Basis der Ergebnisse eines To-
pic Models bei Änderung des Quellcodes weitere Funktionen vorschlägt, die wahrscheinlich
ebenfalls angepasst werden sollten.

Abbildung 4.2: Zusammenhang zwischen Themen und Changelists (Quelle: [GCS12])

19

Da Topic Models die grundlegende Struktur eines Software-Systems herausarbeiten, kön-
nen sie auch eingesetzt werden, um die Modulstruktur eines Programms zu verbessern.
Im Laufe der Entwicklung degradiert häuﬁg die Paketstruktur, was die Übersicht und das
Verständnis behindert. [BGO+14] entwickelten dafür R3, das für eine Klasse nicht nur ein
passenderes Paket vorschlägt, sondern auch ein Conﬁdence Level und eine Begründung mit-
liefert (siehe Abbildung 4.3). Im Gegensatz zu anderen Ansätzen wird hierbei nicht die
komplette Modulstruktur neu erstellt, sondern nur zwischen bereits vorhandenen Paketen
verschoben.

Abbildung 4.3: Automatisierte Verschiebung von Klassen in ein anderes Paket mit

R3(Quelle: [BGO+14])

[BLLB08] entwickelten außerdem eine Methode, um mit Topic Modeling die Verständlich-
keit eines Softwaresystems messen zu können. Dabei deﬁnieren sie ein Programm als schwer
verständlich, wenn Code für unterschiedliche Zwecke über das System verteilt und mitein-
ander verwoben ist (dies entspricht der Deﬁnition des Program Interleaving Problems, siehe
Abschnitt 2.2). Dies kann gemessen werden, indem man die Wahrscheinlichkeitsverteilungen
von einem Thema über die Dateien und von einer Datei über die Themen betrachtet.

4.2 Herausforderungen bei der Anwendung von Topic Modeling auf Software
Quellcode unterscheidet sich in einigen wichtigen Eigenschaften von natürlichsprachlichem
Text, wie er z.B. in einem Zeitungsartikel auftritt. So ist Quellcode deutlich strukturierter,
wiederholt öfter Wörter und ist leichter vorherzusagen (vgl. [HBS+12]).

Wird dieser Unterschied bei der Anwendung von Topic Modeling auf Software nicht be-
rücksichtigt, kann dies zu schlechteren Ergebnissen führen. Dies betriﬀt besonders die Wahl
der Parameter für das Topic Model und das verwendete Stichprobenverfahren, die einen
großen Einﬂuss auf die Qualität der Ergebnisse haben (für eine Auﬀührung der Parameter
siehe Abschnitt 3.1). Parameterwerte, die sich bei der Anwendung auf natürlichsprachlichen
Texten bewährt haben, sollten nicht einfach übernommen, sondern sorgfältig gewählt wer-
den. [BHLO14] beschreiben in ihrer Arbeit den Einﬂuss der verschiedenen Parameter bei der

20

method_1...method_nattr_1...attr_mClass AMove Class RecommenderSuggested RefactoringMove Class Afrom P3 to P2DeveloperSelect a class to be re-packagedRationaleConfdenceLevel1.0Topic Class A[user, role, admin]Topic P2[user, role]Anwendung von LDA auf Quellcode mit dem Ziel, das Finden guter Parameterwerte für ver-
schiedene Software-Engineering-Probleme zu erleichtern. Eine Alternative stellen [PDO+13]
in Form eines genetischen Algorithmus vor, der automatisiert eine Parameter-Konﬁguration
nahe des Optimums für verschiedene Software-Engineering-Aufgaben ﬁndet.

Die Tatsache, dass Quellcode strukturierter aufgebaut ist, könnte auch für eine Verbes-
serung der Themen genutzt werden. LDA nutzt diese Informationen jedoch nicht aus, da
die Reihenfolge von Wörtern in Dokumenten nicht berücksichtigt wird und die Struktur
somit verloren geht. Es existieren jedoch Erweiterungen von LDA, die mehr Informationen
ausnutzen können (vgl. Blei2011).

21

5 ITMViz
ITMViz2 von [SHKJ15] ist ein webbasiertes Toolkit 3 für interaktives Topic Modeling zur
Analyse von Quellcode. Es wurde als Teil von Gelato (kurz für GEneric LAnguage TOols,
siehe [SHKJ13]) entwickelt, einem Toolset von sprachunabhängigen Tools, um Legacy Soft-
ware zu analysieren.

ITMViz baut auf dem Interactive-Topic-Modeling-Framework (ITM) von [HBGS11] (vgl.
Abschnitt 3.3 auf und verwendet zur Visualisierung der Ergebnisse LDAvis von [SS14] (vgl.
Abschnitt 3.4).

Die Infrastruktur der Anwendung besteht aus 3 Komponenten, die in den folgenden Ab-

schnitten näher dargestellt werden (siehe dazu auch Abbildung 5.1:
Preprocessing Aus dem Quellcode-Korpus wird eine Bag-of-words-Repräsentation erstellt

(näher beschrieben in Abschnitt 5.1)

Interaktives Topic Modeling Das Topic Model arbeitet aus dem Bag-of-words die latente

Themenstruktur heraus (vgl. Abschnitt 5.2)

Visualisierung und Interpretation Die Themenstruktur wird dem Nutzer dargestellt, dieser
kann die Ergebnisse mit Constraints verfeinern, bis sie zufriedenstellend sind (vgl.
Abschnitt 5.3)

Abbildung 5.1: ITMViz Architektur (Quelle: [SHKJ15])

5.1 Preprocessing
Zuerst wird der gesamte Quellcode des Programms verarbeitet, um ihn in einen Bag-of-words
zu übertragen, der die Dokumente als Vektoren mit Worthäuﬁgkeiten repräsentiert. Dazu
werden die Begriﬀe aus Kommentaren, Variablennamen und Literalen aus dem Quellcode
extrahiert. Zusammengesetzte Begriﬀe werden aufgeteilt, zum Beispiel nach der CamelCase-
Konvention („InputStreamReader“ wird zu den Begriﬀen „Input“,„Stream“ und „Reader“).
Allgemeine Begriﬀe wie „is“ und „the“ werden herausgeﬁltert, ebenso Begriﬀe, die Teil der
verwendeten Programmiersprache sind (in Java beispielsweise „extends“ und „implements“).
Die resultierenden Wörter werden normalisiert, indem sie auf ihre Wortstämme reduziert
werden („programmer“ und „programming“ werden zu „program“). Somit wird vermieden,
2Der Code ist auf Github verfügbar unter https://github.com/amirms/ITMViz
3Eine Demonstration der Anwendung ist auf Youtube zu ﬁnden unter https://www.youtube.com/watch?

v=Is4ywW5oiUI

22

dass dasselbe Wort in unterschiedlichen grammatikalischen Formen im Bag-of-words ent-
halten ist.

Ebenso möchte man Begriﬀe ausschließen, die in vielen oder sogar allen Dokumenten
auftreten, da sie als Input für das Topic Model wenig informativ sind. Dies können zum
Beispiel Lizenzinformationen sein, die zu Beginn jeder Datei aufgeführt werden. Hierzu wird
das Tf-idf-Maß (tf = term frequency, idf = inverse document frequency) verwendet, das die
Anzahl des Vorkommens eines Begriﬀs in einem bestimmten Dokument ins Verhältnis zur
inversen Häuﬁgkeit im gesamten Korpus setzt. Alle Begriﬀe, deren tf-idf einen festgelegten
Grenzwert unterschreiten, werden ausgeschlossen.

5.2 Interaktives Topic Modeling
Um die Themen aus dem resultierenden Bag-of-words herauszuarbeiten und interaktiv zu
verfeinern verwendet ITMViz das ITM-Framework von [HBGS11], das in Abschnitt 3.3 vor-
gestellt wurde. Damit können Nutzer die resultierenden Themen iterativ verbessern, indem
sie mittels Constraints festlegen, welche Wörter eher in einem bzw. eher in verschiedenen
Themen auftreten sollen. Zur Festlegung der Parameter für LDA und das verwendete Stich-
probenverfahren orientieren sich [SHKJ15] an [BHLO14](siehe Abschnitt 4.2) und justieren
die Werte anhand ihrer Visualisierung nach. Aus ihrer Arbeit wird jedoch nicht genau klar,
ob ITMViz auch das von [HBGS11] entwickelte verbesserte Inferenz-Verfahren für die Stich-
probenziehung nutzt.

Für die Evaluation wird das Open-Source-Projekt jEdit4 verwendet, bei dem es sich um

einen Texteditor zum Programmieren ähnlich wie emacs oder vim handelt.

5.3 Visualisierung und Interpretation
Bei ITMViz handelt es sich um eine Webanwendung, die online zur Verfügung steht5 und
aus mehreren Seiten besteht, die oben über die Navigationsleiste ausgewählt werden können.
Diese Seiten symbolisieren die einzelnen Schritte in der Verwendung von ITMViz und sollen
hier näher erläutert werden:

Existing Projects Auf der Startseite von ITMViz können die Parameter für LDA, die Ge-
wichtung der Constraints und das Stichprobenverfahren eingestellt werden. Als ein-
ziges Projekt steht momentan jEdit zur Verfügung, neue Projekte können nicht ana-
lysiert werden. Nach Abschluss der Konﬁguration beginnt das Topic Model mit der
Berechnung.

Topic Visualization Sobald die Themen zur Verfügung stehen, werden sie hier mit ihren
relevantesten Begriﬀen dargestellt und können erforscht werden. Die Visualisierung
basiert auf LDAvis (für eine nähere Erläuterung der Darstellung siehe Abschnitt 3.4
über LDAvis), die entsprechenden Parameter und Darstellungsmethoden können oben
gewählt werden.

Topic Analysis Hier können einzelne Themen als eine Wolke ihrer relevantesten Begriﬀe be-
trachtet werden. Zusätzlich kann der Nutzer den Themen Beschreibungen hinzufügen,

4http://www.jedit.org
5ITMViz ist verfügbar unter https://gelato.shinyapps.io/ITMViz/

23

wenn er ihre Bedeutung ergründet hat. Dies erleichtert die Übersicht in den anderen
Ansichten.

Constraints An dieser Stelle kann der Nutzer Must-Links und Cannot-Links festlegen, um

die Ergebnisse zu verbessern. Anschließend werden die Themen neu berechnet.

Cluster Documents Diese Ansicht ist ähnlich aufgebaut wie die „Topic Visualiation“, stellt
allerdings statt Themen mit ihren Begriﬀen die Dokumente mit ihren Themen dar (vgl.
dazu Abbildung 5.2). Da diese Ansicht in der Arbeit von [SS14] nicht beschrieben ist,
ist davon auszugehen, dass sie für ITMViz aus LDAvis adaptiert wurde.

Abbildung 5.2: Screenshot der Dokumenten-Ansicht von ITMViz (Quelle: [SHKJ15])

24

6 Zusammenfassung
In dieser Arbeit wurde ITMViz vorgestellt, ein Framework für die Anwendung von inter-
aktivem Topic Modeling auf Software-Projekte. Es erlaubt dem Nutzer nicht nur, sich die
Themen anzeigen zu lassen, die ein Programm durchziehen, sondern diese auch anhand ei-
gener Erfahrungen zu verfeinern. Somit wird ein guter Überblick über die Struktur eines
Software-Systems vermittelt und Wartungsarbeiten erleichtert.

Einige Aspekte lassen sich allerdings kritisieren. So ist zum Beispiel die öﬀentliche We-
banwendung von ITMViz momentan nicht voll funktionstüchtig, stattdessen werden Fehler-
meldungen angezeigt. Des Weiteren enthalten einige Arbeiten, die von [SHKJ15] referenziert
werden, nicht exakt das, wofür auf sie verwiesen wurde. Außerdem ist die Anzahl der Teil-
nehmer der Studien, die unternommen wurden, um die Eﬀektivität von Komponenten von
ITMViz zu evaluieren (z.B. ITM von [AZC09]), oft niedrig und somit nur begrenzt aussa-
gekräftig.

Andere Aspekte von ITMViz sind möglicherweise verbesserungswürdig. So wählen [SHKJ15]

die Parameterwerte selbst und justieren sie dann anhand der visualisierten Ergebnisse nach.
Es könnte interessant sein, zu untersuchen, ob eine automatisierte Festlegung der Parameter
mit dem genetischen Algorithmus von [PDO+13] nicht bessere Ergebnisse liefert.

Außerdem begegnen [PDO+13] dem Problem, dass Themen aus Quellcode nicht immer
sinnvoll sind, damit, dass der Nutzer diese Themen eigenständig verbessert. Allerdings ent-
hält die Struktur des Quellcodes selbst noch mehr Informationen, die allerdings von LDA
nicht verarbeitet werden können. Hier bleibt Potential ungenutzt, das möglicherweise von
Erweiterungen von LDA ausgenutzt werden könnte. Um die Arbeit der Nutzer zu erleichtern,
könnten zudem sinnvolle Constraints vorgeschlagen werden, wie [HBGS11] es tun.

25

A Abbildungsverzeichnis

2.1 Das Integrierte Program Comprehension Modell (Quelle: [vMV94]) . . . . . .
2.2 Code-Beispiel in FORTRAN für Delokalisierung bei Program Interleaving

(Quelle: [RSW96])

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.3 Code-Beispiel in FORTRAN für geteilte Ressourcen bei Program Interleaving

(Quelle: [RSW96])

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.4 Links das gesamte Programm, rechts die Slice in Abhängigkeit von Statement

5

7

7

8

s (heller Kasten) (Quelle: [BG96])

. . . . . . . . . . . . . . . . . . . . . . . .

3.1 Themen von Artikeln aus dem Yale Law Journal mit ihren häuﬁgsten Wör-

tern (Quelle: [Ble11]) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.2 Generierung der Dokumente (Quelle: [Ble11]) . . . . . . . . . . . . . . . . . . 11
3.3 News-Artikel mit seinen Themen (Quelle: [BNJ03]) . . . . . . . . . . . . . . . 12
3.4 LDA angewendet auf Artikel des Science-Magazins (Quelle: [Ble11])
. . . . . 13
3.5 Enkodierung von Constraints in Bäumen (Quelle: [HBGS11])
. . . . . . . . . 14
3.6 Ablauf des interaktiven Topic Modeling (Quelle: [HBGS11]) . . . . . . . . . . 15
. . . . . . . . . . . . . . . . . . . . . 16
3.7 Screenshot von LDAvis (Quelle: [SS14])
4.1 TopicXP Screenshot (Quelle: [SDGP10])
. . . . . . . . . . . . . . . . . . . . . 18
4.2 Zusammenhang zwischen Themen und Changelists (Quelle: [GCS12]) . . . . . 19
4.3 Automatisierte Verschiebung von Klassen in ein anderes Paket mit R3(Quelle:

[BGO+14])
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
5.1
ITMViz Architektur (Quelle: [SHKJ15]) . . . . . . . . . . . . . . . . . . . . . 22
5.2 Screenshot der Dokumenten-Ansicht von ITMViz (Quelle: [SHKJ15]) . . . . . 24

26

B Literaturverzeichnis
[AZC09] David Andrzejewski, Xiaojin Zhu, and Mark Craven.

Incorporating domain
knowledge into topic modeling via dirichlet forest priors. In Proceedings of the
26th Annual International Conference on Machine Learning, ICML ’09, pages
25–32, New York, NY, USA, 2009. ACM.
David W Binkley and Keith Brian Gallagher. Program slicing. Advances in
Computers, 43:1–50, 1996.

[BG96]

[BGO+14] Gabriele Bavota, Malcom Gethers, Rocco Oliveto, Denys Poshyvanyk, and An-
drea de Lucia.
Improving software modularization via automated analysis of
latent topics and dependencies. ACM Trans. Softw. Eng. Methodol., 23(1):4:1–
4:33, February 2014.

[BHLO14] David Binkley, Daniel Heinz, Dawn Lawrie, and Justin Overfelt. Understanding
LDA in source code analysis.
In Proceedings of the 22Nd International Con-
ference on Program Comprehension, ICPC 2014, pages 26–36, New York, NY,
USA, 2014. ACM.
David Blei. Probabilistic topic models. In Proceedings of the 17th ACM SIGKDD
International Conference Tutorials, KDD ’11 Tutorials, pages 5:1–5:1, New York,
NY, USA, 2011. ACM.

[Ble11]

[BLLB08] Pierre F. Baldi, Cristina V. Lopes, Erik J. Linstead, and Sushil K. Bajracharya.
A theory of aspects as latent topics. In Proceedings of the 23rd ACM SIGPLAN
Conference on Object-oriented Programming Systems Languages and Applicati-
ons, OOPSLA ’08, pages 543–562, New York, NY, USA, 2008. ACM.

[BNJ03] David M. Blei, Andrew Y. Ng, and Michael I. Jordan. Latent dirichlet allocation.

[Boe81]

[GC14]

[GCS12]

[Gla02]
[GS04]

J. Mach. Learn. Res., 3:993–1022, March 2003.
Barry Boehm. Software engineering economics, volume 197. Prentice-hall Engle-
wood Cliﬀs (NJ), 1981.
Steven Grant and James R Cordy. Examining the relationship between topic
model similarity and software maintenance.
In Software Maintenance, Reen-
gineering and Reverse Engineering (CSMR-WCRE), 2014 Software Evolution
Week-IEEE Conference on, pages 303–307. IEEE, 2014.
Scott Grant, James R Cordy, and David B Skillicorn. Using topic models to
support software maintenance.
In Software Maintenance and Reengineering
(CSMR), 2012 16th European Conference on, pages 403–408. IEEE, 2012.
Robert L. Glass. Facts and fallacies of software engineering, 2002.
Thomas L Griﬃths and Mark Steyvers. Finding scientiﬁc topics. Proceedings of
the National Academy of Sciences, 101(suppl 1):5228–5235, 2004.

27

[HBGS11] Yuening Hu, Jordan Boyd-Graber, and Brianna Satinoﬀ. Interactive topic mo-
deling. In Proceedings of the 49th Annual Meeting of the Association for Compu-
tational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages
248–257, Stroudsburg, PA, USA, 2011. Association for Computational Lingui-
stics.

[HH01]

[HBS+12] Abram Hindle, Earl T. Barr, Zhendong Su, Mark Gabel, and Premkumar Devan-
In Proceedings of the 34th International
bu. On the naturalness of software.
Conference on Software Engineering, ICSE ’12, pages 837–847, Piscataway, NJ,
USA, 2012. IEEE Press.
Mark Harman and Robert Hierons. An overview of program slicing. Software
Focus, 2(3):85–92, 2001.
Jürgen Koenemann and Scott P. Robertson. Expert problem solving strategies
for program comprehension. In Proceedings of the SIGCHI Conference on Hu-
man Factors in Computing Systems, CHI ’91, pages 125–130, New York, NY,
USA, 1991. ACM.

[KR91]

[MaL15] Roberto Minelli, Andrea Mocci and, and Michele Lanza. I know what you did last
summer: An investigation of how developers spend their time. In Proceedings
of the 2015 IEEE 23rd International Conference on Program Comprehension,
ICPC ’15, pages 25–35, Piscataway, NJ, USA, 2015. IEEE Press.

[PDO+13] Annibale Panichella, Bogdan Dit, Rocco Oliveto, Massimiliano Di Penta, Denys
Poshyvanyk, and Andrea De Lucia. How to eﬀectively use topic models for soft-
ware engineering tasks? an approach based on genetic algorithms. In Proceedings
of the 2013 International Conference on Software Engineering, ICSE ’13, pages
522–531, Piscataway, NJ, USA, 2013. IEEE Press.
Nancy Pennington. Comprehension strategies in programming. In Empirical stu-
dies of programmers: second workshop, pages 100–113. Ablex Publishing Corp.,
1987.

[Pen87]

[RSW95] Spencer Rugaber, Kurt Stirewalt, and Linda M Wills. The interleaving problem
in program understanding. In Reverse Engineering, 1995., Proceedings of 2nd
Working Conference on, pages 166–175. IEEE, 1995.

[RSW96] Spencer Rugaber, Kurt Stirewalt, and Linda M Wills. Understanding interleaved

code. In Reverse engineering, pages 47–76. Springer, 1996.
Elliot Soloway, Beth Adelson, and Kate Ehrlich. Knowledge and processes in the
comprehension of computer programs. In Chi et al, volume 123, pages 129–152,
1988.

[SAE88]

[SDGP10] Trevor Savage, Bogdan Dit, Malcom Gethers, and Denys Poshyvanyk. Topic
xp: Exploring topics in source code using latent dirichlet allocation. In Software
Maintenance (ICSM), 2010 IEEE International Conference on, pages 1–6. IEEE,
2010.

28

[SHKJ13] Amir Saeidi, Jurriaan Hage, Ravi Khadka, and Slinger Jansen. Gelato: Generic
language tools for model-driven analysis of legacy software systems. In Reverse
Engineering (WCRE), 2013 20th Working Conference on, pages 481–482. IEEE,
2013.

[SHKJ15] Amir M. Saeidi, Jurriaan Hage, Ravi Khadka, and Slinger Jansen. Itmviz: In-
teractive topic modeling for source code analysis.
In Proceedings of the 2015
IEEE 23rd International Conference on Program Comprehension, ICPC ’15, pa-
ges 295–298, Piscataway, NJ, USA, 2015. IEEE Press.

[SS14]

[SKA+13] Janet Siegmund, Christian Kästner, Sven Apel, André Brechmann, and Gunter
Saake. Experience from measuring program comprehension—toward a general
framework. 2013.
Carson Sievert and Kenneth E Shirley. Ldavis: A method for visualizing and
interpreting topics. In Proceedings of the workshop on interactive language lear-
ning, visualization, and interfaces, pages 63–70, 2014.
Margaret-Anne Storey. Theories, methods and tools in program comprehensi-
on: Past, present and future. In Program Comprehension, 2005. IWPC 2005.
Proceedings. 13th International Workshop on, pages 181–191. IEEE, 2005.

[Sto05]

[vML99] Anneliese von Mayrhauser and Stephen Lang. A coding scheme to support
systematic analysis of software comprehension. Software Engineering, IEEE
Transactions on, 25(4):526–540, 1999.

[vMV94] Anneliese von Mayrhauser and A Marie Vans. Program Unterstanding: A Survey.

Colorado State Univ., 1994.

[Wei81] Mark Weiser. Program slicing. In Proceedings of the 5th International Conference
on Software Engineering, ICSE ’81, pages 439–449, Piscataway, NJ, USA, 1981.
IEEE Press.
Steven Woods and Qiang Yang. The program understanding problem: Analysis
and a heuristic approach. In Proceedings of the 18th International Conference
on Software Engineering, ICSE ’96, pages 6–15, Washington, DC, USA, 1996.
IEEE Computer Society.

[WY96]

[YMM09] Limin Yao, David Mimno, and Andrew McCallum. Eﬃcient methods for topic
model inference on streaming document collections. In Proceedings of the 15th
ACM SIGKDD International Conference on Knowledge Discovery and Data Mi-
ning, KDD ’09, pages 937–946, New York, NY, USA, 2009. ACM.

29

