Der Effekt von Qualifiern in 
Mitarbeiterbefragungen 
Haben Qualifier im Itemstamm einen Einfluss auf die 
Antwortverteilung? 

Masterarbeit im Fachgebiet Arbeits-und Organisationspsychologie 
Lisa Maria Brockmann 
Betreuer: Prof. Dr. Karsten Müller 

Inhalt 

1. Relevanz der Thematik 
2. Bisherige Forschung 
3. Effekte von Qualifiern 
4. Methode 

Stichprobe & Design 

a.
b. Messinstrumente 
c. Vorstudie 
d. Demographische Variablen 
e. Analysen 
Literatur 

5.

 

2 

1. Relevanz der Thematik 

Bedeutung von Mitarbeiterbefragungen: 
 

• Mitarbeiterbefragungen (MABs) sind eines der meist genutzten 

Führungs- und Organisationsentwicklungsinstrumente in 
Unternehmen (Borg & Mastrangelo, 2008) 
• Studie von Hossiep & Frieg (2008):  

• 80% der Unternehmen im deutschsprachigen Raum führen MABs durch 
• 64% davon „regelmäßig“ 

• USA: Anzahl vergleichbar mit deutschspr. Raum; Verbreitung schon rund 

20 Jahre früher 

 

• MABs werden auch in Zukunft nicht an Bedeutung verlieren        

(Hossiep & Frieg, 2013; Liebig, 2006) 

• wichtige Funktion: internes & externes Benchmarking                    

(Domsch & Ladwig, 2006) 

3 

1. Relevanz der Thematik 

Eigenschaften von MABs: 
 

• Definition MAB: „Schriftliche, anonym durchgeführte Vollerhebungen 
mit einem standardisierten Erhebungsinstrument, das hauptsächlich 
geschlossene Items enthält“ (Müller et al.,2007, S.6) 
 
 
 
 
 

 
• Ziel: „Einstellungen, Wünsche und Erwartungen“ gezielt erheben 

(Bungard & Jöns, 2005, S.163) 

 
• Zweck: „measurement and change“ (Borg & Mastrangelo, 2008, S. 6) 

4 

1. Relevanz der Thematik 

Eigenschaften von MABs: 
 
Meist genutztes Itemformat in MABs  Likert-Skala (Borg & Mastrangelo, 2008) 
 
• Typisches Item: Statement mit einer ‚stimme zu - stimme nicht zu‘ 

Antwortskala (Borg & Mastrangelo, 2008) 

• Sonderform der Ratingskala 
• Vorteile von Ratingskalen:  

•

 
 
 

leicht zu administrieren, für TN einfacher zu vervollständigen, leichter 
auszuwerten (McCarty & Shrum, 2000) 

Der Herbst ist die schönste Jahreszeit. 
 
 
Stimme            Stimme eher        Weder noch            Stimme            Stimme zu 
nicht zu               nicht  zu                                               eher zu 
 
 

X 

5 

1. Relevanz der Thematik 

Welche Konstrukte werden in MABs gemessen? 
 Arbeits-
zufriedenheit 

Locke (1976): „ a pleasurable or positive emotional state 
resulting from the appraisal of one‘s job or job 
experiences“ (S.1300) 
 

Commitment  Mowday, Steers & Porter (1979): „the relative strength of 

an individual‘s identification with and involvement in a 
particular organization“ (S. 226) 
 

Engagement 

Schaufeli et al. (2002): „a positive, fulfilling, work related 
state of mind that is characterized by vigor, dedication and 
absorption“ (S.74) 
 

94% 

 

83% 

55% 

 Diese Konstrukte werden in der Literatur am häufigsten genannt, wenn es 
um die Inhalte einer Mitarbeiterbefragung geht… 

Prozentwerte aus: Dievernich & Hermann (2007)  

6 

1. Relevanz der Thematik 

1. Zentrale Beobachtung bei MABs: 
 

 

 

Abb. aus Peterson & Wilson (1992), S. 62 

 Häufig Deckeneffekte und mangelnde Differenzierung zwischen den Items bei 

Wertemessungen (z.B. Braunscheidel, Suresh & Boisnier, 2010; McCarty & Shrum, 2000) 

 
 Bei Wichtigkeitsratings werden häufig nahezu alle Aspekte als wichtig bewertet                   

(z.B. Brake, 2009; Bungard, Müller & Niethammer, 2007; Kornmeier, 2007) 

 
 Schuman & Presser (1981): Statements mit einer Zustimmungs-Ablehnungs-Skala 

unterliegen häufig einem Akquieszenzbias 

 
 Instrumente zur Erfassung von AZ und COM unterliegen häufig einer linksschiefen 

Verteilung 
• Weaver (1980): AZ in den USA 

•

zwischen 85,8 % und 89,2 % äußern sich als ››zufrieden‹‹ oder ››sehr zufrieden‹‹  

• Peterson & Wilson (1992): Kundenzufriedenheit  

•

“To what extent do satisfaction self-reports reflect ‘true’ satisfaction?” (S.62) 

• Kunin-Skala (Kunin, 1955): 

Die gestellten Fragen ermöglichen 
keine präzise Differenzierungen der 

arbeitenden Bevölkerung! 

7 

1. Relevanz der Thematik 

2. Zentrale Beobachtung bei MABs: 

 

 Unterschiedlicher Gebrauch von „Qualifiern“ 

 = Adverb oder (meist adverbiell verwendetes) Adjektiv, das die Bedeutung eines Wort genauer 

bestimmt oder einschränkt 

 

 

 

• Organizational Commitment Qestionnaire (OCQ) 

•

•

“I find that my values and the organization‘s values are very similar.’’ 
“I am extremely glad that I chose this organization to work for over others I was considering at that time 
I joined.” 
 

• Affective Commitment Scale (ACS)  

•

•

“I would be very happy to spend the rest of my career with this organization.“ 
“I really feel as if this organization's problems are my own.” 

 
Job Satisfaction Survey (JSS) 

•

•

•

“I feel () satisfied with my chances for salary increase.” 
“ My supervisor is quite competent in doing his/her job.” 

Wenn sich die Anker bereits innerhalb ein und desselben 
Instruments unterscheiden, wie vergleichbar sind dann 

die Ergebnisse der Instrumente untereinander? 

8 

1. Relevanz der Thematik 

Zentrale Fragestellung der Masterarbeit: 

 

Problem 

 
 
 

• Wenn sich die Qualifier im Itemstamm bereits innerhalb ein und desselben 
Instruments unterscheiden, wie vergleichbar sind dann die Ergebnisse der 
Instrumente untereinander? 

• Die gestellten Fragen ermöglichen keine präzise Differenzierungen der 

arbeitenden Bevölkerung! 

• Qualifier im Itemstamm spielen eine große Rolle!  
• Haben Qualifier einen Effekt auf die Antwortverteilung und somit auf die 

Vergleichbarkeit der Befragungen? 

• Könnten extremer formulierte Items die schiefen Verteilungen in AZ, COM und 

ENG Fragebögen reduzieren? 

Idee 

• Kann man sich Qualifier in den Itemstämmen zunutze machen, um die Ergebnisse 

einer Erhebung an eine Normalverteilung anzunähern, die Varianz zu erhöhen 
und den Mittelwert zu verschieben, um zu aussagekräftigeren und besser 
vergleichbaren Ergebnissen zu gelangen? 

Forschungs-

frage 

9 

2. Bisherige Forschung  
     – Item- und Fragebogendesign allgemein 

Einige Beispiele… 
 
• Rating vs. Ranking Skalen (z.B. McCarty & Shrum, 2000) 
• Prozess der Fragebeantwortung (z.B. Strack & Martin, 1987; Sudman et al., 1996; Tourangeau & 

Rasinski, 1988, Tourangeau et al., 2000) 

• Formulierung von Items / Regeln zur Formulierung (z.B. Borg & Mastrangelo, 2008; 

Bungard, Müller & Niethammer, 2007; Lietz, 2010) 

• Positionierung von Fragen im Fragebogen (z.B. Kraut, 1996) 
• Skalendesign: Likert-Skala 

• Anzahl an Kategorien: sehr inkonsistente Befunde (z.B. Weng 2004) 
• Mittelkategorie 
• „Weiß nicht“- Kategorien 
• Verbales Labeling der Kategorien: alle Kategorien vs. Endpunkte         

(z.B. Weijters et al., 2010; Weng, 2004) 

10 

2. Bisherige Forschung – Ankereffekte in Items 

Bisher viele Untersuchungen zu Ankern im Antwortformat… 
 
• Rohrmann (1978): Antwortskalen, die äquidistant messen, hinreichend 

differenzieren und von allen Probanden verstanden werden 

 
• Weijters et al. (2010): Evidenz für den Einfluss des Skalenformats (Anzahl an 

Antwortkategorien + Labelung) auf NARS, ERS und MR 

 
• Kontextfaktoren: 

• Schwarz et al.,1985: Befragung zum TV Konsum – je nach Höhe der 

Antwortvorgaben wurde unterschiedlich geurteilt  

• Sudman, Bradburn & Schwarz, 1996: z.B. gleiches Quadrat wird je nach Größe       

der Vergleichsquadrate unterschiedlich groß beurteilt 

 

 
 

11 

2. Bisherige Forschung – Ankereffekte in Items 

…und spezielle Befunde zu verbalen Ankereffekten: 
 

•

Item-wording Effekte: schon kleine Veränderungen in der Wortwahl können zu sehr 
unterschiedlichen Ergebnissen führen  (z.B. Schuman & Presser, 1996; Schwarz, 1999) 
• Bsp. Studie (Rugg, 1941): „Do you think the US should allow/forbid public speeches against 

democrazy?“ 

 

• Rohrmann (2007): Äquidistante verbale Skalenlabels 

•

„Wording is the main reason for measurement deficiencies“ (S.2) 

 
• French-Lazovik & Gibson (1984): Mittelwerte und Schiefe-Maße sind beeinflusst von 

den verbalen Labels 
•

“the degree of negative skew in distributions of behavioral rating measures can be altered by 
the verbal labels used as anchors” (S.53)  

 

• Wyatt & Meyers (1987): absolute Endpunkte 

• weniger absolut formulierte Antwortanker produzieren größere Variabilität in den 

Antworten und führen zu einer ausgeglicheneren Verwendung aller Antwortmöglichkeiten 
als absolut formulierte Antwortanker 

12 

2. Bisherige Forschung – verbale Ankereffekte 

…und spezielle Befunde zu verbalen Ankereffekten: 
 
• French-Lazovik & Gibson (1984): Mittelwerte und Schiefe sind beeinflusst von 

den verbalen Labels 
 

 

höhere  Indizes = positivere Labels 

höhere (= schlechtere) Mittelwerte 

13 

3. Effekte von Qualifiern 

…aber nach umfassender Literaturrecherche wurde bisher wenig 
Aufmerksamkeit auf einen möglichen Einfluss von Ankern (Qualifiern) im 
Itemstamm gelegt: 
 
 Dedrick et al. (2007):  
• Wording-Effekte bei Instrumenten zur Messung von Lehrer-Einstellungen zur Inklusion; 
Manipulation der Adjektive (“mild disabilities”, “severe disabilities”, “disabilities”)          
 Einfluss auf das Level (M)  

 
 
 
 
 Spector et al. (1997) und McPherson & Mohr (2005): 
•

Testen die Interaktion von invertierten Items und extrem formulierten Items mit 
modifizierten Itemstämmen 

• Die moderate Skala war deutlich eindimensionaler 
•

"For the LOT, skewness coefficients indicated that positively keyed items were less 
negatively skewed" (McPherson & Mohr, 2005, S. 127) 

 

14 

3. Effekte von Qualifiern 

Warum können Qualifier im Itemstamm  von Bedeutung sein? 
 

 

 Effekt auf das Level (z.B. Dedrick et al., 2007; Schuman & Presser, 1977) 
 
 
 Effekt auf Verteilung  von bisherigen linksschiefen Kurven hin zu einer eher 

normalverteilten Kurve  (z.B. French-Lazovik & Gibson,1984)  

 
 

 Effekt auf Standardabweichung/Varianz (z.B. McCarty & Shrum, 2000, S. 273) 
 
 

 

 Effekt auf Interkorrelation der Items/Subskalen (z.B. Dedrick et al., 2007; McCarty & Shrum, 2000; van 

Vaerenbergh, 2013)  (& Korrelationen mit externen Variablen) 
 

 

 

15 

3. Effekte von Qualifiern 

Praktische Konsequenzen eines Effekts auf das Level / Mehrwert der 
Studie: 
 

 Benchmarking: externer und interner Vergleich 

 Keine gemeinsame Vergleichsbasis bei unterschiedlichen Qualifiern 
 dabei werden MABs sehr häufig zum Benchmarking verwendet                  

(z.B. Borg & Mastrangelo, 2008) 

 
 

  Follow-up Prozesse 

 falsche Schlussfolgerungen der Unternehmen (könnte kostenspielig 

werden etc.) 

  … 
 

16 

3. Effekte von Qualifiern 

H1 

Mittelwerte der Items mit starker Formulierung sind 
niedriger als die der Items mit moderater Formulierung 

H2 

Die Verteilung der Items mit starker Formulierung 
entspricht eher einer Normalverteilung als die Verteilung 
bei moderater Formulierung 

H3 

Standardabweichungen der Items mit starker Formulierung 
sind größer als die der Items mit moderater Formulierung 

H4 

Bei starker Itemformulierung sind die Interkorrelationen 
der Items auf Grund der deutlicheren Differenzierungen 
höher als bei moderater Itemformulierung 

17 

4. Methode 

 

Stichprobe: Berufstätige Personen (Vollzeit & Teilzeit)  
 
 
Datenerhebung: Online-Umfrage via Unipark 
 
 
Design:   3 Fragebögen mit je 3 Abstufungen  3 Gruppen randomisiert 
 

 
 

Intensität 

der Items / Qualifier 

Gruppe 1 

Gruppe 2 

Gruppe 3 

Moderat Q  
(moderater 
Qualifier) 

Moderat O                  

Extrem 

(ohne Qualifier) 

Ablauf 

Fragebogen COMM 
Fragebogen AZ 
Fragebogen ENG 

1.
2.
3.
4. Demographische Daten 

18 

4. Methode 

Messinstrumente/Fragebögen: 
 
Welches sind die meist genutzten zum Thema? 

Konstrukt 

Fragebogen 

Beispiel Item 

Commitment   OCQ 

 
Mowday, Steers & Porter 
(1979) 

„I talk up this organization to my friends 
as a great organization to work for.“ 

Arbeits-
zufriedenheit 

JSS 
 
Spector(1985) 

„There is really too little chance for 
promotion in my job.“ 

Engagement 

UWES 
 
Schaufeli & Bakker (2003) 

„I am enthusiastic about my job.“ 

Englische Skalen  deutsche Version bzw. Übersetzung 

19 

4. Methode 

Beispiel für Manipulation der Fragebögen: 

20 

4. Methode 

Bearbeitung der Fragebögen im Vorfeld: 
 
1.

JSS: Übersetzung ins Deutsche 
1. Übersetzung der englischen JSS Items in Deutsche 
2. Rückübersetzung der deutschen Items ins Englische von bilingualer 

Person/Übersetzerin 

3. Überprüfung der  Übereinstimmung 

2. Umformulierung von invertierten Items 



Grund dafür: invertierte Items stellen häufig einen methodischen Artekfakt dar, indem sie 
einen zweiten Faktor bilden (z.B. Kanning & Hill, 2013; Jonkisz, Moosbrugger & Brandt, 
2012; Weijters & Baumgartner, 2012) 

3. Erstellen von Qualifier-Listen & Bewertung der Qualifier 

 Qualifier angelehnt an Cliff (1959) und Rohrmann (1978) 

4. Modifikation der Originalitems 



Einbauen der zuvor bewerteten Qualifier bzw. Entfernen von Qualifiern  

21 

4. Methode 
Vorstudie: 

 

 

Qualifier 
sammeln 

 

Rating der 
Qualifier 

 

Kategorisierung 

der Items 

• Erstellen von Qualifier Listen 
• Inspiration durch Studien von Cliff (1959) und Rohrmann (1978) 

• Bewerten der Qualifier auf einer Ratingskala von 1 (sehr 

schwacher Ausdruck) bis 9 (sehr starker Ausdruck) durch Rater 

• Einsortieren der Qualifier in 3 Kategorien durch Rater 
• Qualifier aussortieren 

• Urteiler ordnen alle Items (inkl. Qualifier) einer Kategorie zu 

(schwach/moderat oder stark)  

• Interrater-Reliabilität bestimmen 

22 

Geschlecht 

4. Methode 

Demographische Variablen: 
 
 
 
 
 
 
 
 
 
 
 

Branche des 

Unternehmens 

Wie lange 
insgesamt 
arbeitstätig? 

Alter 

Größe des 

Unternehmens 

Wie lange in 

derzeitigem Job 

tätig? 

Ernsthafte Absichten/Wunsch den Job in den nächsten 6 Monaten zu 
wechseln?   Turnover Intention – Scale 

23 

5. Literatur 

•

•

•

•

•

Borg, I., & Mastrangelo, P. M. (2008). Employee surveys in management: Theories, tools, and practical applications. 
Hogrefe & Huber Publishers. 
Brake, A. (2009). Schriftliche Befragung. In Handbuch Methoden der Organisationsforschung (pp. 392-412). VS Verlag für 
Sozialwissenschaften. 
Braunscheidel, M. J., Suresh, N. C., & Boisnier, A. D. (2010). Investigating the impact of organizational culture on supply 
chain integration. Human Resource Management, 49(5), 883-911. 
Bungard, W., & Jöns, I. (2005). Mitarbeiterbefragungen. Feedbackinstrumente im Unternehmen. Grundlagen, 
Gestaltungshinweise, Erfahrungsberichte, 161-176. 
Bungard, W., Müller, K., & Niethammer, C. (2007). Mitarbeiterbefragung-was dann...?: MAB und Folgeprozesse erfolgreich 
gestalten. Berlin: Springer. 
Cliff, N. (1959). Adverbs as multipliers. Psychological Review, 66(1), 27. 

•
• Dedrick, R. F., Marfo, K., & Harris, D. M. (2007). Experimental Analysis of Question Wording in an Instrument Measuring 

Teachers’ Attitudes Toward Inclusive Education. Educational and Psychological Measurement, 67(1), 116–131.  

• Dievernich, F., & Hermann, M. (2007). Die aktuellen Trends bei Mitarbeiterbefragungen – Vom Stimmungsbarometer zum 

strategischen Informations- und Steuerungsinstrument. Zeitschrift für Betrieb und Personal, 03/2007, 159-163. 

• Domsch, M. E., & Ladwig, D. H. (2006). Handbuch Mitarbeiterbefragung. Springer. 
•

French-Lazovik, G., & Gibson, C. L. (1984). Effects of verbally labeled anchor points on the distributional parameters of 
rating measures. Applied Psychological Measurement, 8(1), 49-57. 

• Hossiep, R., & Frieg, P. (2008). Der Einsatz von Mitarbeiterbefragungen in Deutschland, Österreich und der Schweiz. 

planung & analyse, 6(2008), 55-59. 

• Hossiep, D. R., & Frieg, P. (2013). Mitarbeiterbefragungen in den 2000er Jahren: Eine Bestandsaufnahme. In M. E. Domsch 

•

•

& D. Ladwig (Hrsg.), Handbuch Mitarbeiterbefragung (S. 57–75). Springer Berlin Heidelberg.  
Jonkisz, D. E., Moosbrugger, P. D. H., & Brandt, D.-P. H. (2012). Planung und Entwicklung von Tests und Fragebogen. In U.-P. 
D. H. Moosbrugger & P. D. A. Kelava (Hrsg.), Testtheorie und Fragebogenkonstruktion (S. 27–74). Springer Berlin 
Heidelberg. Abgerufen von http://link.springer.com/chapter/10.1007/978-3-642-20072-4_3 
Kanning, U. P., & Hill, A. (2013). Validation of the Organizational Commitment Questionnaire (OCQ) in six Languages. 
Journal of Business and Media Psychology, 4(2), 11-22. 

24 

5. Literatur 

•

•

•

Kraut, A. I. (1996). Organizational surveys: Tools for assessment and change. Jossey-Bass Publishers. 
Krosnick, J. A., & Alwin, D. F. (1988). A Test of the Form-Resistant Correlation Hypothesis Ratings, Rankings, and the 
Measurement of Values. Public Opinion Quarterly, 52(4), 526–538. 
Kunin, T. (1955). The Construction of a New Type of Attitude Measure1. Personnel Psychology, 8(1), 65–77. 
Locke, E. A. (1976). The Nature and Causes of Job Satisfaction1. Hand book. 

•
• McCarty, J. A., & Shrum, L. J. (2000). The measurement of personal values in survey research: A test of alternative rating 

procedures. Public Opinion Quarterly, 64(3), 271-298. 

• McPherson, J., & Mohr, P. (2005). The role of item extremity in the emergence of keying-related factors: an exploration 

with the life orientation test. Psychological methods, 10(1), 120. 

• Mowday, R. T., Steers, R. M., & Porter, L. W. (1979). The measurement of organizational commitment. Journal of 

Vocational Behavior, 14(2), 224–247. 

• Müller, K., Bungard, W., Jöns, I., & Liebig, C. (2007). Mitarbeiterbefragungen planen und durchführen. In 

•

•

•

•

•

•

•

Mitarbeiterbefragung—was dann…? (pp. 5-67). Springer Berlin Heidelberg. 
Peterson, R. A., & Wilson, W. R. (1992). Measuring customer satisfaction: Fact and artifact. Journal of the Academy of 
Marketing Science, 20(1), 61–71. 
Rohrmann, B. (1978). Empirische Studien zur Entwicklung von Antwortskalen für die sozialwissenschaftliche Forschung. 
Zeitschrift für Sozialpsychologie, 9(1), 222-245. 
Rohrmann, B. (2007). Verbal qualifiers for rating scales: Sociolinguistic considerations and psychometric data. Project 
Report. University of Melbourne, Australia. 
Rugg, D. D. (1941). Experiments in wording questions: II. Public Opinion Quarterly, 5 91-92. doi:10.1086/265467 
Schaufeli, W. B. (2012). Work engagement: What do we know and where do we go. Romanian Journal of Applied 
Psychology, 14(1), 3-10. 
Schaufeli,W. B.,& Bakker, A. B. (2003). Test manual for the UtrechtWork Engagement Scale. Unpublished manuscript, 
Utrecht University, the Netherlands. Retrieved from http://www.schaufeli.com 
Schaufeli, W. B., Salanova, M., González-Romá, V., & Bakker, A. B. (2002). The Measurement of Engagement and Burnout: 
A Two Sample Confirmatory Factor Analytic Approach. Journal of Happiness Studies, 3(1), 71–92. 

25 

5. Literatur 

•

•

•

•

•

•

•

•

•

•

Schuman, H., & Presser, S. (1977). Question Wording as an Independent Variable in Survey Analysis. Sociological Methods & 
Research, 6(2), 151–170.  
Schwarz, N. (1999). Self-reports: How the questions shape the answers. American Psychologist, 54(2), 93–105. 
Schwarz, N., Hippler, H.-J., Deutsch, B., & Strack, F. (1985). Response categories: Effects on behavioral reports and comparative 
judgements. Public Opinion Quarterly, 49, 388-395. 
Spector, P. E. (1985). Measurement of human service staff satisfaction: Development of the Job Satisfaction Survey. American 
journal of community psychology, 13(6), 693-713. 
Spector, P. E., Van Katwyk, P. T., Brannick, M. T., & Chen, P. Y. (1997). When two factors don't reflect two constructs: How item 
characteristics can produce artifactual factors. Journal Of Management, 23(5), 659-677. doi:10.1177/014920639702300503 
Strack, F., & Martin, L. L. (1987). Thinking, Judging, and Communicating: A Process Account of Context Effects in Attitude Surveys. 
In H.-J. Hippler, N. Schwarz, & S. Sudman (Hrsg.), Social Information Processing and Survey Methodology (S. 123–148). Springer 
New York. 
Sudman, S., Bradburn, N. M., & Schwarz, N. (1996). Thinking about answers:  The application of cognitive processes to survey 
methodology (Bd. xiv). San Francisco,  CA,  US: Jossey-Bass. 
Tourangeau, R., & Rasinski, K. A. (1988). Cognitive processes underlying context effects in attitude measurement. Psychological 
Bulletin, 103(3), 299–314. 
Tourangeau, R., Rips, L. J., & Rasinski, K. (2000). The psychology of survey response. Cambridge University Press. 
Van Vaerenbergh, Y., & Thomas, T. D. (2013). Response styles in survey research: A literature review of antecedents, 
consequences, and remedies. International Journal of Public Opinion Research, 25(2), 195-217. 

• Weaver, C. N. (1980). Job satisfaction in the United States in the 1970s. Journal of Applied Psychology, 65(3), 364–367. 
• Weijters, B., & Baumgartner, H. (2012). Misresponse to reversed and negated items in surveys: A review. Journal of Marketing 

Research, 49(5), 737-747. 

• Weijters, B., Geuens, M., & Schillewaert, N. (2010). The Individual Consistency of Acquiescence and Extreme Response Style in 

Self-Report Questionnaires. Applied Psychological Measurement, 34(2), 105–121. 

• Weng, L. J. (2004). Impact of the number of response categories and anchor labels on coefficient alpha and test-retest reliability. 

Educational and Psychological Measurement, 64(6), 956-972. 

• Wyatt, R. C., & Meyers, L. S. (1987). Psychometric properties of four 5-point Likert type response scales. Educational and 

psychological measurement, 47(1), 27-35. 

26 

 

Vielen Dank für die 
Aufmerksamkeit! 

 

27 

