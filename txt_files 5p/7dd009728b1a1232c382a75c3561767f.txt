Udo Kuckartz

Einführung in die computergestützte Analyse
qualitativer Daten

Udo Kuckartz

Einführung in die 
computergestützte 
Analyse qualitativer 
Daten
3., aktualisierte Auflage

Bibliografische Information der Deutschen Nationalbibliothek
Die Deutsche Nationalbibliothek verzeichnet diese Publikation in der 
Deutschen Nationalbibliografie; detaillierte bibliografische Daten sind im Internet über
<http://dnb.d-nb.de> abrufbar.

.
.

3., aktualisierte Auflage 2010

Alle Rechte vorbehalten
© VS Verlag für Sozialwissenschaften | GWV Fachverlage GmbH, Wiesbaden 2010

Lektorat: Frank Engelhardt

VS Verlag für Sozialwissenschaften ist Teil der Fachverlagsgruppe 
Springer Science+Business Media.
www.vs-verlag.de 

Das Werk einschließlich aller seiner Teile ist urheberrechtlich geschützt.
Jede Verwertung außerhalb der engen Grenzen des Urheberrechtsgesetzes
ist ohne Zustimmung des Verlags unzulässig und strafbar. Das gilt insbeson -
dere für Vervielfältigungen, Übersetzungen, Mikroverfilmungen und die Ein-
speicherung und Verarbeitung in elektronischen Systemen.

Die Wiedergabe von Gebrauchsnamen, Handelsnamen, Warenbezeichnungen usw. in diesem
Werk berechtigt auch ohne besondere Kennzeichnung nicht zu der Annahme, dass solche
Namen im Sinne der Warenzeichen- und Markenschutz-Gesetzgebung als frei zu betrachten
wären und daher von jedermann benutzt werden dürften.

Umschlaggestaltung: KünkelLopka Medienentwicklung, Heidelberg
Druck und buchbinderische Verarbeitung: Ten Brink, Meppel
Gedruckt auf säurefreiem und chlorfrei gebleichtem Papier
Printed in the Netherlands

ISBN 978-3-531-16661-2

Inhalt

Vorwort zur dritten Auflage ................................................................. 8 
1  Software für die qualitative Datenanalyse: Leistungen, 

Anwendungsfelder, Arbeitsschritte ............................................... 12 
1.1  Was leistet QDA-Software .............................................................................. 12 
1.2  Anwendungsfelder und methodische Orientierungen ................................. 15 
1.3  Arbeitsschritte mit einem QDA-Programm.................................................. 20 
2  Die Texte: Transkription, Vorbereitung und Import ................... 29 
2.1  Allgemeines zu Texten und ihrer Formatierung ........................................... 29 
2.2  Texte im Textverarbeitungsprogramm (Word)............................................. 32 
2.3  Textvorbereitung............................................................................................... 34 
2.4  Texte einscannen............................................................................................... 37 
2.5  Texte transkribieren, Transkriptionsregeln und Transkriptionssysteme ... 38 
2.6  Analyseeinheiten und Textgestaltung ............................................................. 48 
2.7  Vorstrukturierte Textformen ........................................................................... 49 
2.8  Zusammenfassung: Die Vorbereitung von Texten ...................................... 50 
2.9  Praktische Hinweise für MAXQDA .............................................................. 53 
3  Die Kategorien und das Codieren von Texten ............................. 57 
3.1  Über Kategorien ............................................................................................... 57 
3.2  Kategorientypen ................................................................................................ 60 
3.3  Codieren mit QDA-Software .......................................................................... 64 
3.4  Praktische Hinweise für MAXQDA .............................................................. 68 

4  Sozialwissenschaftliche Ansätze für die kategorienbasierte 

Textanalyse ................................................................................... 72 
4.1  Theoretisches Codieren: Die Grounded Theory .......................................... 73 
4.2  Thematisches Codieren .................................................................................... 84 
4.3  Zusammenfassende qualitative Inhaltsanalyse .............................................. 92 
4.4  Typenbildung und typologische Analyse ....................................................... 97 
5  Text-Retrieval: codierte Textstellen wiederfinden ...................... 108 
5.1  Das Grundprinzip des Text-Retrievals ........................................................ 108 
5.2  Text-Retrieval und Modelle der Interviewauswertung............................... 109 

 

6 

Inhalt 

5.3  Einfaches Retrieval: Alle Segmente einer Kategorie zusammenstellen ... 111 
5.4  Kontrastierendes Retrieval: Segmente ausgewählter Kategorien 

gegenüberstellen .............................................................................................. 112 

5.5  Verknüpfendes Retrieval: Suche nach gemeinsamem Vorkommen 

von Codes ........................................................................................................ 113 
5.6  Code-Hierarchien im Retrieval ..................................................................... 114 
5.7  Code-Übersichten und Häufigkeiten ........................................................... 116 
5.8  Praktische Hinweise für MAXQDA ............................................................ 119 
6  Textexploration: Volltext-Recherche ........................................... 121 
6.1  Stichworte im Kontext ................................................................................... 121 
6.2  Texte explorieren ............................................................................................ 123 
6.3  Automatisches Codieren von Fundstellen ................................................... 127 
6.4  Stärken und Schwächen der lexikalischen Suche ........................................ 128 
6.5  Praktische Hinweise für MAXQDA ............................................................ 130 
7  Die Memos: Eigene Ideen aufzeichnen und organisieren .......... 133 
7.1  Notizen und Aufzeichnungen im Forschungsprozess ............................... 133 
7.2  Systematisches Arbeiten mit Memos in der Grounded Theory ............... 134 
7.3  Memos im QDA-Programm ......................................................................... 140 
7.4  Praktische Hinweise für MAXQDA ............................................................ 142 
8  Die Fallvariablen: Strukturierte Übersicht .................................. 146 
8.1  Sinn und Zweck von Fallvariablen ............................................................... 146 
8.2  Forschungsbeispiel: Adult Attachement Interviews .................................. 148 
8.3  Forschungsbeispiel: Strukturierende Inhaltsanalyse ................................... 150 
8.4  Weiterarbeit mit Fallvariablen in SPSS......................................................... 151 
8.5  Praktische Hinweise für MAXQDA ............................................................ 154 
9  Komplexe Formen des Text-Retrievals ....................................... 157 
9.1  Subgruppen von Daten vergleichen ............................................................. 157 
9.2  Themenmatrix ................................................................................................. 159 
9.3  Die Suche nach Mustern von Codierungen ................................................ 161 
9.4  Sequenz- und Entfernungsoperatoren ......................................................... 162 
9.5  Überschneidungs- und Einbettungsoperatoren .......................................... 163 
9.6  Mengenoperatoren .......................................................................................... 166 
9.7  Hypothesenprüfung ........................................................................................ 166 
9.8  Praktische Hinweise für MAXQDA ............................................................ 173 
10  Daten-Display und Visualisierung .............................................. 178 
10.1 Sinn und Zweck von Visualisierungen ......................................................... 178 
10.2 Visualisierung bei der Arbeit mit der QDA-Software................................ 179 
10.3 Visualisierung von Analyseergebnissen ........................................................ 181 

Inhalt 

7 
 
10.4 Konzept Maps und Mapping Tools ............................................................. 184 
10.5 Visuelle Repräsentation von Zusammenhängen ........................................ 189 
10.6 Praktische Hinweise für MAXQDA ............................................................ 195 
11  Praktisches Arbeiten mit Kategoriensystemen ............................ 198 
11.1 Typen von Kategoriensystemen ................................................................... 198 
11.2 Konstruktion von Kategoriensystemen: induktiv oder deduktiv? ........... 200 
11.3 Wie viele Kategorien sind notwendig? ......................................................... 203 
11.4 Einfaches Kategoriensystem in einer leitfadenorientierten 

Interviewstudie ................................................................................................ 205 
11.5 Kategoriensystem einer Argumentationsanalyse ........................................ 207 
11.6 Kategoriensystem in einer Leitbildanalyse ................................................... 210 
11.7 Praktische Hinweise für MAXQDA ............................................................ 214 
12  Wortbasierte Analysefunktionen ................................................. 218 
12.1 Wortlisten und Diktionäre ............................................................................. 218 
12.2 Das Prinzip diktionärsbasierter Inhaltsanalyse ........................................... 220 
12.3 CUI und qualitative Datenanalyse ................................................................ 222 
12.4 Praktische Hinweise für MAXQDA ............................................................ 223 

13  Kombination mit statistischen Verfahren: Ähnlichkeiten, 

Muster und Typologien ............................................................... 227 
13.1 Über Klassifikationsverfahren ....................................................................... 227 
13.2 Ähnlichkeiten zwischen Personen ermitteln ............................................... 230 
13.3 Typenbildung durch Clusteranalyse ............................................................. 237 
13.4 Codemuster erkennen: Faktorenanalyse von Codierungen ....................... 243 

14  Die Zukunft der computergestützten qualitativen 

Datenanalyse ............................................................................... 247 
Anhang .............................................................................................. 251 
Übersicht QDA-Software ....................................................................................... 251 
Interessante Internet-Seiten rund um QDA-Software und qualitative 

Datenanalyse .................................................................................................... 255 
Literatur ............................................................................................ 258 
Index ................................................................................................. 266 

 

 

Vorwort zur dritten Auflage 

Diese dritte Auflage des erstmals 1999 unter dem Titel „Computergestützte 
Analyse qualitativer Daten“ erschienenen Bandes ist an vielen Stellen aktua-
lisiert und erweitert worden. Die Struktur dieses Lehrbuchs und seiner Ka-
pitel  folgt  der  Logik  der  Datenauswertung  in  einem  empirischen  Projekt, 
d.h.  die  verschiedenen  Arbeitsschritte  der  Analyse  werden  nacheinander 
durchlaufen. Am Ende jedes Kapitels wird in einem Abschnitt „Praktische 
Hinweise“ eine Anleitung gegeben, wie die zuvor beschriebenen Verfahren 
mit dem Computerprogramm MAXQDA umgesetzt werden können. Auf 
MAXQDA habe ich dabei aus vier Gründen zurückgegriffen: Erstens weil 
es im deutschsprachigen Raum neben ATLAS.ti das am weitesten verbreite-
te  Programm  ist,  zweitens  weil  hierzu  auch  eine  deutsche  Version  mit 
deutschem Handbuch existiert, drittens weil der Einstieg in MAXQDA über 
ein online verfügbares Tutorial und regelmäßig angebotene E-Learning Kur-
se sehr leicht ist und viertens weil mir als Entwickler dieses Programm na-
türlich  besonders  gut  vertraut  ist.  Ferner  sind  rund  um  MAXQDA  eine 
Menge  Anwendungsbeispiele  in  deutscher  Sprache  verfügbar  (z.B. in  Ku-
ckartz/Grunenberg/Lauterbach 2004; Kuckartz/Grunenberg/Dresing 2007; 
Kuckartz u.a. 2008) und die Tagungsbände der jährlich stattfindenden Be-
nutzerkonferenzen CAQD1 enthalten zahlreiche Beiträge aus Forschungs-
zusammenhängen, die das Spektrum der Einsatzmöglichkeiten deutlich ma-
chen. 

Der  Ausgangspunkt  dieses  Buches  lässt  sich  gut  durch  ein  Zitat  der  
amerikanischen Sozialwissenschaftler Anselm Strauss und Juliet Corbin il-
lustrieren (1996: IX): 
„Wie aufregend Ihre Erfahrungen bei der Datenerhebung auch sein mögen, es kommt der 
Tag, an dem die Daten analysiert werden müssen.“ 

                                                           
 
1   Die Tagungsbände der CAQD-Konferenzen können kostenfrei unter www.caqd.de he-

runtergeladen werden. 

Vorwort 

9 

In diesem Zitat klingen zwei Dinge an, zum einen dass der qualitative 
Forschungsprozess  ein  sehr  interessanter,  ja  aufregender  und  abenteuerli-
cher  sein  kann  (man  denke  an  Feldstudien  in  prekären  Settings  oder  an 
ethnologische  Forschung  in  fremden  Kulturen),  zum  anderen,  dass  es  ir-
gendwann im Projektverlauf einen Zwang zur Datenanalyse, nämlich zu eher 
trockener  Schreibtischarbeit,  gibt,  die  nicht  selten  als  ein  Gegenstück  zur 
aufregenden Feldarbeit empfunden wird. Als Strauss den obigen Satz in der 
Zeit  seiner  aktiven  Forschungsarbeit  formulierte,  ist  ihm  sicherlich  noch 
nicht in den Sinn gekommen, Computersoftware für die Analyse seiner Da-
ten einzusetzen. In den Sozialwissenschaften fand die Frage einer Methodik 
zur Auswertung von qualitativen Daten ohnehin lange Zeit nur wenig Be-
achtung.  Man  interessierte  sich  vor  allem  für  die  Datenerhebung  und  für 
Probleme der Feldarbeit. Die dominanten Fragen lauteten etwa: Wie gestal-
tet man die Interviewsituation? Wie lockt man Erzählungen hervor? Wie ver-
meidet man es, als teilnehmender Beobachter zu sehr zum Teil des unter-
suchten Feldes zu werden? Dieser Text befasst sich nicht mit Fragen der 
Feldarbeit und der Datenerhebung, sondern nur mit der Datenauswertung, 
und zwar mit computergestützten Techniken des Datenmanagements und 
der Datenanalyse, die im letzten Jahrzehnt entwickelt worden sind. Für die 
einschlägigen EDV-Programme hat sich im englischen Sprachgebrauch die 
Bezeichnung „QDA-Software“ bzw. „CAQDAS“ durchgesetzt. QDA steht 
hierbei für „Qualitative Data Analysis“, CAQDAS für „Computer Assisted 
Qualitative  Data  Analysis  Software“.  Dieses  Buch  will  bewusst  einen 
schnellen Einstieg in diese Analysetechniken geben, d.h. die Leserinnen und 
Leser sollen in die Lage versetzt werden, die Basisfunktionen zu verstehen 
und selbst anzuwenden. Das Buch beschäftigt sich bewusst nicht mit wis-
senschaftstheoretischen Voraussetzungen oder methodologischen Kontro-
versen, sondern vertritt den Standpunkt der Pluralität von Methoden. Me-
thoden sollten in Abhängigkeit von der Fragestellung und den zur Verfü-
gung stehenden zeitlichen und finanziellen Ressourcen gewählt werden, ei-
ne beste oder einzig gültige Vorgehensweise gibt es nicht. 

Dieses Buches ist ein praktisches Arbeitsbuch für Leser und Leserinnen 
unterschiedlicher Disziplinen mit unterschiedlichen methodischen Ansätzen. 
Im Mittelpunkt steht das Problem, Textdaten methodisch kontrolliert aus-
zuwerten. Dabei werden sowohl aus den Sozialwissenschaften stammendes 
methodisches Background-Wissen als auch praktische Fertigkeiten vermit-
telt. Qualitative Datenanalyse, die lange Zeit eher nach dem Prinzip selekti-

 

10 

Vorwort 

ver  Plausibilisierung  und  episodischer  Evidenz  arbeitete,  kann  erheblich 
verbessert werden, wenn sie in systematischer Form organisiert wird. 

QDA-Software  ist  sehr  flexibel  und  unterstützt  beispielsweise  sowohl 
eine induktive als auch eine deduktive Codierung von Texten. Dieses Buch 
will  den  Leser  nicht  auf  bestimmte  Methoden  oder  wissenschaftstheore-
tische  Positionen  festlegen.  Dort,  wo  methodische  Ansätze  referiert  wer-
den, geschieht dies mit der Intention zu informieren und nicht zu bewerten. 
Nur  die  Forscherinnen  und  Forscher  selbst  können  entscheiden,  welche 
Analysestrategie ihrer Fragestellung adäquat ist. Das gleiche gilt auch für die 
Auswahl einer hierfür geeigneten QDA-Software. Es gibt kein bestes Pro-
gramm, das für alle Formen der Analyse in gleicher Weise geeignet ist. Die-
ses  Buch  will  kein  Ratgeber  zur  Auswahl  von  Software  sein  und  enthält 
auch keinerlei Vergleichstests. Solche Vergleiche stehen ohnehin immer vor 
dem  Problem,  dass  sie  wegen  des  großen  Innovationstempos  in  diesem 
Feld im Grunde schon überholt sind, wenn sie in gedruckter Form erschei-
nen. Mittlerweile gibt es von fast allen QDA-Programmen zeitlich limitierte 
Versionen zum Ausprobieren, so dass es leicht fällt, die Programme zu tes-
ten. Auch ist es ratsam Kolleginnen und Kollegen, die bereits mit QDA-
Software arbeiten, nach ihren Erfahrungen zu fragen. 

Die mit rasantem  Tempo  betriebene  Entwicklung von QDA-Software 
ist  in  beispielhafter  Weise  interdisziplinär  geschehen.  Die  Entwickler  der 
Programme entstammen sehr unterschiedlichen Disziplinen, unter anderem 
der Soziologie, Psychologie, Erziehungswissenschaft, Gesundheitsforschung 
und Informatik. Noch vielfältiger ist das Spektrum der Benutzer, das über 
die  genannten  Disziplinen  hinaus  u.a.  Sportwissenschaftler,  Mediziner, 
Kommunikationswissenschaftler,  Linguisten,  Historiker,  Literaturwissen-
schaftler,  Politikwissenschaftler,  Kriminologen,  Stadtforscher,  Sozialarbei-
ter,  Marktforscher,  Islamwissenschaftler,  Japanologen  und  andere  mehr 
umfasst. Die heutigen QDA-Programme können erheblich mehr leisten, als 
lediglich  Hilfsmittel  im  Prozess  traditioneller  qualitativer  Sozialforschung 
zu  sein:  Sie  ermöglichen  Textanalysen,  Inhaltsanalysen,  Medienanalysen,  Doku-
mentanalysen,  Aktenanalysen,  Diskursanalysen,  Argumentationsanalysen  und  viele 
weitere Formen der wissenschaftlichen Bearbeitung von Texten, wie sie in 
den vorgenannten Disziplinen anzutreffen sind. 

Dieses Buch richtet sich keineswegs nur an Sozialwissenschaftler, son-
dern an alle, die professionell mit der Auswertung von Texten befasst sind, 
d.h. auch an Leser außerhalb des Wissenschaftsbereiches. Der vorliegende 

Vorwort 

11 

Text ist als Studienbuch konzipiert und folgt im Aufbau der ersten  Kapitel 
der  Logik  des  Ablaufs  der  Datenbearbeitung  und  -auswertung  im  For-
schungsprozess: Ehe ein Text codiert werden kann, muss er zunächst trans-
kribiert,  formatiert  und  in  das  QDA-Programm  importiert  werden.  Und  ehe 
man nach Mustern von Kategorien oder Kategorienabfolgen suchen kann, 
muss der Text bzw. einzelne Passagen zuvor codiert werden – sei es durch 
automatische oder durch intellektuelle Codierung. An dieser Logik hinter-
einander  ablaufender  und  aufeinander  aufbauender  Arbeitsschritte,  die 
gleichwohl  in  zirkulärer  Weise  organisiert  werden  können,  ist  das  Buch 
orientiert.  In  den  meisten  Kapiteln  sind  Beispiele  und  praktische  Hinweise 
enthalten. Grundlegende Begriffe und Definitionen sind deutlich hervorge-
hoben. 

Software für die Datenanalyse verändert sich sehr schnell, wird weiter-
entwickelt und ist abhängig von der generellen Entwicklung der Software 
und  Betriebssysteme.  Deshalb  war  das  Leitprinzip,  möglichst  wenig  soft-
warespezifisch zu sein, aber dennoch hinreichend konkret zu werden, um 
die Leserinnen und Leser in die Lage zu versetzen, schnell in die Praxis der 
Textanalyse einsteigen zu können. 

Dieses  Buch  will  dazu  beitragen,  neue  Analysetechniken  und  Analyse-
möglichkeiten jenseits der alten Dualität von qualitativen und quantitativen 
Verfahren vorzustellen. Ich hoffe, dass dies bei vielen Forschern und in vie-
len Disziplinen gleichermaßen auf Interesse stößt. 

Viele  Anregungen  von  Kolleginnen  und  Kollegen  haben  zur  Verbes-
serung  und  Erweiterung  dieses  Buchs  beigetragen.  Thorsten  Dresing  und 
Heiko Grunenberg danke ich für die kritischen Kommentare zum Manusk-
ript, Claus Stefer für die Zusammenstellung der Webadressen im Anhang, 
Lena Lehmann, Thomas Ebert, Gabi Schwarz und Stefan Rädiker für die 
technische Mithilfe bei der Manuskriptgestaltung. 

 

 
Marburg im September 2009 

 Udo Kuckartz 

 

 

1  Software für die qualitative Datenanalyse: 

Leistungen, Anwendungsfelder, Arbeitsschritte 

1.1  Was leistet QDA-Software 

In  freier  Abwandlung  der  Aussage,  nichts  sei  praktischer  als  eine  gute 
Theorie, könnte man für die qualitative Datenanalyse formulieren: Nichts 
ist praktischer als eine einfach zu handhabende QDA-Software. Lange Zeit 
war  die  qualitative  Sozialforschung  nicht  unbedingt  ein  Feld,  in  dem  die 
Forscherinnen und Forscher mit dem Computer auf Du und Du standen. 
Dies hat sich in den letzten Jahren gründlich geändert, denn zu offensich-
tlich sind die Vorteile des computerunterstützten Arbeitens. Doch was leis-
ten  eigentlich  solche  EDV-Programme  wie  ATLAS.TI,  MAXQDA  oder 
NVivo? 

Beginnen wir mit einer (unvollständigen) Aufzählung dessen, was heuti-

ge QDA-Software kann: 
 

(cid:120)  Gleichzeitiges Verwalten der Texte eines Projektes, z.B. der transkri-

bierten Interviews, mit schnellem Zugriff auf jeden einzelnen Text 

(cid:120)  Organisieren der Texte in Form von Subgruppen nach benutzerge-

(cid:120)  Definition  von  Kategorien  und  Konstruktion  eines  Kategoriensys-

wählten Kriterien  

tems 

(cid:120)  Zuordnung von Kategorien zu ausgewählten Textabschnitten 
(cid:120)  Zusammenstellung aller zu einer Kategorie codierten Textsegmente 
(cid:120)  Gruppierung von Kategorien zu Hierarchien und Netzwerken 
(cid:120)  Visuelle Darstellung von Kategorienzuordnungen 
(cid:120)  Gezielte  Suche  nach  Überschneidungen  von  Kategorien  oder  nach 

komplexen Mustern von Kategorien 

(cid:120)  Visuelle Darstellung von Kategorienüberschneidungen 
(cid:120)  Möglichkeit, eigene Ideen und Anmerkungen an Textstellen, Codes, 

Texte u.a. wie Post-it Zettel anzuheften (Memos) 

Was leistet QDA-Software 

13 

(cid:120)  Verwaltungssystem für diese Memos 
(cid:120)  Lexikalische  Suche  nach  Worten  und  Wortkombinationen  in  den 

(cid:120)  Automatische Vercodung aufgrund des Vorkommens von bestimm-

ten Worten oder Wortkombinationen 

(cid:120)  Erstellen von Worthäufigkeitslisten und Wortindices 
(cid:120)  Erstellen von Baumstrukturen und Netzwerkansichten von Katego-

Texten 

rien 

(cid:120)  Definition von Variablen zu jedem Text 
(cid:120)  Nutzen der Variablen als Selektionskriterien für Texte 
(cid:120)  Import  und  Export  von  Ergebnistabellen  zu  Statistiksoftware,  z.B. 

(cid:120)  Unterstützen von Teamarbeit und konsensuellen Codierverfahren in 

(cid:120)  Verknüpfung  von  Text-Informationen  mit  räumlichen  Bezügen 

zu SPSS 

Arbeitsgruppen 

(Georeferenzierung) 

(cid:120)  Synchronisierung von Text mit Audio- und Videodateien 

 
Die  meisten  der  genannten  Funktionen  bieten  zwar  „nur“  Unterstützung 
für  die  intellektuelle  Auswertungsarbeit  und  führen  keine  automatische 
Analyse durch, doch wird durch die Schnelligkeit des Computers und die 
dadurch möglichen größeren Datensätze durchaus eine neue Stufe qualitati-
ver Datenanalyse erreicht. (Fast) alles, was das Computerprogramm macht, 
ließe  sich  auch  mit  althergebrachten  Paper-and-pencil  Techniken  realisie-
ren, aber es würde um einige Zehnerpotenzen mehr Zeit benötigen. Inso-
fern ist die Diskussion, ob QDA-Software nun etwas prinzipiell Neues dar-
stellt oder nur die Automatisierung alt bekannter Techniken ist, eigentlich 
müßig. 

QDA-Programme geben keine bestimmte Methode der Analyse vor, so 
wenig  wie  Textverarbeitungsprogramme  die  Art  (und  Qualität)  der  Texte 
determinieren,  die  mit  ihnen  geschrieben  werden.  Gleichwohl  verändern 
EDV-Programme  den  Arbeitsstil.  Mit  einem  Textverarbeitungsprogramm 
läuft der Prozess der Textproduktion in ziemlich anderer Weise ab als mit 
der guten alten Schreibmaschine oder gar mit dem Füllfederhalter. Techno-
logien generieren eine bestimmte Umgebung und dies gilt auch für QDA-
Software, die einen anderen Analysestil hervorruft, ohne aber die eingesetz-
te Methode selbst zu determinieren. 

 

14 

Software für die qualitative Datenanalyse  

Im Grunde haben beide Positionen Recht: QDA-Software steht für Me-
thodenpluralität  (auch  dann,  wenn  die  Entwickler  vielleicht  jeweils  be-
stimmte  Methoden  oder  Metaphern  im  Kopf  gehabt  haben  mögen)  und 
gleichzeitig  hat  sie  einen  homogenisierten  Arbeitsstil  zur  Folge,  jedenfalls 
dann, wenn man die Arbeitsvorgänge und die Arbeitsorganisation aus einer 
Position der Distanz betrachtet – auch die Waschmaschine hat den Alltag 
im Haushalt verändert und der Computer hat die Welt des Büros so verän-
dert, dass auf den ersten Blick alle Büros ein uniformes Aussehen aufwei-
sen. 

Die wissenschaftliche Auswertung von Texten besteht aus einer Reihe 

unterschiedlicher, aufeinander bezogener Akte mit den Kernbestandteilen 
 

(cid:120)  Exploration, 
(cid:120)  Interpretation, 
(cid:120)  Kategorisierung, 
(cid:120)  Klassifikation (teilweise auch Typenbildung), 
(cid:120)  Daten Display und Visualisierung 
(cid:120)  Theoriekonstruktion und 
(cid:120)  Ergebnispräsentation. 

 
Die methodisch kontrollierte Analyse von Texten unterscheidet sich prin-
zipiell von der Textrezeption und -produktion im Alltagsleben. Dort geht 
es eher um Erfahrung, Common-sense-Techniken und Inspiration: Eindrü-
cke, die sich beim Lesen von Texten einstellen, werden zum Anlass für ei-
genes  Nachdenken  und  vielleicht  zur  Formulierung  eines  neuen,  eigenen 
Textes genommen. Im Zentrum der Analyse mittels QDA-Software steht 
hingegen der systematische Umgang mit Texten, d.h. eine weitgehend codifi-
zierte Vorgehensweise, bei  der es nicht  nur um die selektive Plausibilisie-
rung eigener Hypothesen durch entsprechend gewählte Zitate geht. 

Die QDA-Software stellt für solche systematische Textarbeit verschie-
dene Werkzeuge zur Verfügung. Welche man davon nutzt und welche nicht, 
ist  ausschließlich  Angelegenheit  des  Programm-Nutzers  und  hängt  davon 
ab,  welchem  methodischen  Paradigma  bei  der  Auswertung  gefolgt  wird. 
Von QDA-Programmen werden in dieser Hinsicht keine Vorschriften ge-
macht.  Sie  beschränken  ihre  Benutzer  allenfalls  in  der  Hinsicht,  dass  be-
stimmte  Operationen  und  Prozeduren  mit  dem  Programm  nicht  möglich 
sind,  zwingen  sie  aber  nicht,  einer  bestimmten  Auswertungsmethodik  zu 
folgen. 

Anwendungsfelder und methodische Orientierungen 

15 

Die Stärke von QDA-Software liegt in der Unterstützung der oben dar-
gestellten Tätigkeiten von der Exploration und Interpretation bis zur Theo-
riekonstruktion. Moderne QDA-Software erlaubt zudem die Eingabe und 
Modifikation von Texten und offeriert fortgeschrittene Archivierungsfunk-
tionen.  QDA-Software  dient  hingegen  nicht  zur  Formatierung  und  gra-
phischen bzw. typographischen Gestaltung der Arbeitsergebnisse in Form 
von Forschungsberichten. 

Angesichts  der  immer  perfekter  werdenden  Textverarbeitungspro-
gramme  und  ihrer  stark  ausgeweiteten  Fähigkeiten  mag  die  Frage  gestellt 
werden, ob Textverarbeitungsprogramme denn nicht ausreichen, um quali-
tative Datenanalyse zu betreiben. Was unterscheidet QDA-Programme ei-
gentlich von Programmen wie Microsoft Word? Ließe sich denn nicht auch 
Word  zur  computergestützten  qualitativen  Datenanalyse  benutzen?  Die 
Antwort  lautet  „Ja,  aber  nur  sehr  eingeschränkt“.  Moderne  Textverarbei-
tungsprogramme sind in ihrem Leistungsspektrum mit jeder neuen Version 
verbessert und erweitert worden, doch sind sie für ein völlig anderes Auf-
gabenfeld als für die systematische und wissenschaftliche Auswertung von 
Textdaten konzipiert. Sie haben vor allem Formatierungs- und Layoutfunk-
tionen. Zwar verfügen Programme wie Word inzwischen über gute Index-
funktionen, doch sind sie für das Arbeiten mit Kategoriensystemen ebenso 
wenig konzipiert wie für die vergleichende und systematisierende Auswer-
tung eines Sets von Texten. 

1.2  Anwendungsfelder und methodische Orientierungen 

Die  Anwendungsfelder  von  QDA-Programmen  sind  sehr  vielfältig,  sie 
werden heute in einer Vielzahl von Wissenschaftsdisziplinen und Praxisfel-
dern  sowie  in  der  Marktforschung  eingesetzt.  Die  meisten  Anwendungen 
findet man in den klassischen sozialwissenschaftlichen Disziplinen, der So-
ziologie,  Psychologie  und  Politikwissenschaft.  Soziologen  analysieren  bei-
spielsweise  die  Biographien von Studenten  oder Lebensvorstellungen von 
Jugendlichen. In der Psychologie und Psychoanalyse geht es etwa um Be-
wältigungsstrategien in kritischen Lebenssituationen. Ein typisch politikwis-
senschaftliches Anwendungsfeld ist die Analyse von Dokumenten und Pro-
tokollen, beispielsweise von Politikerreden im Deutschen Bundestag. 

 

16 

Software für die qualitative Datenanalyse  

Zu  den  Hauptanwendungsfeldern  zählen  auch  die  Erziehungswissen-
schaft,  die  Sozialarbeit  und  Sozialpädagogik  sowie  die  Bildungsforschung. 
Inhaltlich geht es hier etwa um Berufsbiographien arbeitsloser Lehrer, um 
berufliche Einmündung von Diplompädagogen, um Experteninterviews in 
der  Jugendhilfeforschung  oder  um  die  subjektive  Bedeutung  des  Compu-
ters für Schülerinnen. 

Ein  stetig  wachsendes  Feld  ist  die  Kommunikations-  und  Medienwis-
senschaft. Die Inhaltsanalyse von Massenmedien (Printmedien und Fernse-
hen)  ist  dabei  ebenso  zu  nennen  wie  die  Analyse  von  Kommunikations-
formen, die mit den neuen Medien, Internet und Multimedia, assoziiert sind 
z.B. Kommunikation in Diskussionsforen und in Chat-Räumen. 

Auch  in  querschnittlich  angelegten  Disziplinen  werden  QDA-Pro-
gramme häufig eingesetzt, u.a. in der Genderforschung, den Gesundheits- 
und  Pflegewissenschaften,  den  Rehabilitationswissenschaften  und  den 
Umweltwissenschaften. 

Noch vergleichsweise selten sind Anwendungen in klassischen geistes-
wissenschaftlichen  Fächern,  den  Philologien  und  der  Geschichtswissen-
schaft. Häufiger werden QDA-Programme jedoch bereits in der Sportwis-
senschaft,  der  Theologie,  Ethnologie,  den  Wirtschaftswissenschaften  und 
der Marktforschung eingesetzt. Das Spektrum der Anwendungsfelder weitet 
sich stetig aus und es lässt sich begründet vermuten, dass all jene Diszipli-
nen, die es mit der systematischen Auswertung und Bearbeitung von Tex-
ten zu tun haben, in den nächsten Jahren QDA-Programme für sich ent-
decken werden. 

So unterschiedlich die QDA-Programme auch sein mögen, in der zen-
tralen Voraussetzung zu ihrer Benutzung sind sie sich relativ ähnlich: Die 
zu bearbeitenden Texte müssen digitalisiert vorliegen. Häufig fragen Inter-
essierte, die erstmals mit einem QDA-Programm konfrontiert sind, ob das 
in Frage stehende Programm auch mit eingescannten Texten arbeiten kann. 
Selbstverständlich ist dies der Fall, denn wie ein solcher digitalisierter Text 
zustande kommt, ob durch Eintippen, Einscannen oder Voice-Recorder, ist 
für das QDA-Programm völlig gleichgültig. Allerdings besitzen QDA-Pro-
gramme  keine  speziellen  Texterkennungs-  und  Digitalisierungsfunktionen, 
da muss schon auf einschlägige Programme wie beispielsweise OmniPage 
zurückgegriffen werden. 

Für QDA-Programme gilt, dass sie nicht mit einer bestimmten Wissen-
schaftsdisziplin, sondern mit einer bestimmten Klasse von Problemen as-

Anwendungsfelder und methodische Orientierungen 

17 

soziiert  sind,  nämlich  der  systematischen  Auswertung  von  Texten.  Diese 
Eigenschaft  der  Multidisziplinarität  teilen  sie  mit  Statistik-Programmsys-
temen. Auch diese werden in den verschiedensten Bereichen der Wissen-
schaft,  in  Verwaltungen,  Unternehmen  und  Forschungsinstituten  einge-
setzt. Im Fall der Statistikprogramme ist es ganz selbstverständlich, für wel-
che Datentypen sich diese eignen, nämlich für numerische Daten, die man 
mittels  statistischer  Algorithmen  zu  analysieren  beabsichtigt.  Im  Fall  der 
QDA-Programme  ist  die  Zuordnung  von  Datentypen  keineswegs  so 
selbstverständlich.  Für  welche  Datenarten  eignet  sich  QDA-Software? 
Schaut man sich empirisch im Kreis der Programmbenutzer um, so sind die 
ausgewerteten  Datenarten  außerordentlich  vielfältig.  Unter  anderem  kann 
man folgende Arten von Datenmaterial finden: 
 

(cid:120)  Transkripte  von  offenen  Interviews  aller  Art  (narrative  Interviews, 

problemzentrierte Interviews, Tiefeninterviews etc.) 

(cid:120)  Feldnotizen und Feldprotokolle aus der sozialwissenschaftlichen und 

ethnologischen Forschung 

(cid:120)  Aufzeichnungen von Gruppendiskussionen und Fokusgruppen 
(cid:120)  Vorstrukturierte  Texte,  beispielsweise  Resultate  von  Datenbankre-

cherchen 

(cid:120)  Daten der Onlineforschung, z.B. Chats, Foren, Online-Seminare und 
-konferenzen,  Texte  von  Webseiten,  Online-Gruppendiskussionen 
etc. 

(cid:120)  Dokumente  verschiedenster  Art  wie  beispielsweise  Lehrpläne,  Zei-

tungsartikel u. Ä. 

(cid:120)  Leitfadenstrukturierte Interviews, Expertengespräche 
(cid:120)  Akten (z.B. der Sozialverwaltung oder Jugendhilfe) 
(cid:120)  Aufsätze (z.B. Schüleraufsätze, Abituraufsätze), Briefe 
(cid:120)  Antworttexte auf offene Fragen aus standardisierten Fragebögen 
(cid:120)  Beobachtungsprotokolle,  Therapieprotokolle,  Protokolle 

von 

Anamnesegesprächen, protokollierte Träume 

(cid:120)  Literarische Texte, Zeitungsannoncen 

 
Außer  der  Grundvoraussetzung,  dass  es  sich  um  digitalisierten  Text  han-
deln  muss,  bestehen  im  Grunde  keine  weiteren  Vorbedingungen  für  das 
Arbeiten  mit  QDA-Programmen.  Ein  Charakteristikum  von  QDA-Pro-
grammen ist ihre Flexibilität hinsichtlich der Analysestile. Tesch (1990: 58) 
hat  bezogen  auf  die  Soziologie,  Psychologie  und  Erziehungswissenschaft 

 

18 

Software für die qualitative Datenanalyse  

Focus Group Research 
Grounded Theory 
Hermeneutics 
Heuristic Research 
Holistic Ethnography 
Imaginal Psychology 
Intensive Research 
Interpretive Evaluation 
Interpretive Interactionism 
Interpretive Human Studies 
Life History Research 
Naturalistic inquiry 
Oral History 
Panel Research 
Participant Observation 
Participative Research 
Phenomenography 
Phenomenology 
Qualitative Evaluation 
Structural Ethnography 
Symbolic Interactionism 
Transcendal Realism 
Transformative Research 

versucht,  die  Analyseformen  zu  systematisieren  und  folgende  Liste2  zu-
sammengestellt: 
 
Action Research 
Case Study 
Clinical Research 
Cognitive Anthropology 
Collaborative Inquiry 
Content Analysis 
Dialogical Research 
Conversation Analysis 
Delphi Study 
Descriptive Research 
Direct Research 
Discourse Analysis 
Document Study 
Ecological Psychology 
Educational Connoisseurship and Criticism 
Educational Ethnography 
Ethnographic Content Analysis 
Ethnography 
Ethnography of Communication 
Ethnomethodology 
Ethnoscience 
Experimental Psychology 
Field Study 
 
Die Liste zeigt, wie vielfältig die Methoden sind, in denen QDA-Software 
eingesetzt  werden  kann.  Die  von  Tesch  zusammengestellten  Analysefor-
men beziehen sich allerdings auf verschiedene Ebenen: Einige bezeichnen 
die Art des Forschungsprozesses (z.B. Action Research, Case Study), andere den 
theoretischen Ansatz (Symbolic Interactionism), wieder andere die Art des Ma-
terials (Document Study). Der Versuch, eine Art Typologie qualitativer For-
schung  auf  dieser  Basis  zu  erstellen,  ist  deshalb  zum  Scheitern  verurteilt. 
Tesch hat die Vielzahl der aufgeführten Methoden in Form einer Cognitive 

                                                           
 
2  Auf eine Übersetzung wird an dieser Stelle verzichtet, weil häufig ohnehin die englischen 
Bezeichnungen  wiederholt  werden  müssten  (Grounded  Theory,  Ethnomethodology) 
oder durch eine Übersetzung nur Unklarheit gestiftet würde, etwa, wenn Focus Group 
Research mit Kleingruppenforschung übersetzt würde. 

Anwendungsfelder und methodische Orientierungen 

19 

Map nach dem Gesichtspunkt des Forschungsinteresses geordnet, wobei sie 
danach  unterscheidet,  ob  das  Forschungsinteresse  auf  die  Charakteristika 
von  Sprache,  die  Entdeckung  von  Regelmäßigkeiten,  das  Verstehen  der 
Bedeutung des Textes bzw. der Handlung oder auf Reflexion gerichtet ist 
(vgl. Tesch 1990: 63 ff.). 

Unter die erste Abteilung (Charakteristika von Sprache) werden u.a. die 
Diskursanalyse, die Ethnomethodologie, der symbolische Interaktionismus 
und die Inhaltsanalyse subsumiert. Der zweiten Abteilung (Entdeckung von 
Regelmäßigkeiten) wird die Grounded Theory, die Ethnographie, die Akti-
onsforschung und die qualitative Evaluation zugeordnet. Hermeneutik, Le-
benslaufforschung und Phänomenologie sind Beispiele für den dritten Typ 
von Forschungsinteressen, der sich primär auf Verstehen von Bedeutungen 
bezieht. 

Der Einsatz von QDA-Programmen ist keineswegs auf qualitative Para-
digmen beschränkt. Auch für die Auswertung von Mitarbeiterbefragungen, 
Onlinefragebögen (etwa zur Kundenzufriedenheit) sowie von Antworttex-
ten auf offene Fragen in Surveys lassen sie sich hervorragend nutzen. Be-
sonders  geeignet  sind  sie  für  Mixed-Methods-  und  Triangulationsansätze, 
weil sie die Kombination und Integration von qualitativen und quantitati-
ven Daten, etwa Text und standardisierten Befragungsdaten, gestatten. An-
dererseits wird man feststellen müssen, dass QDA-Software nicht für sol-
che Formen der Textanalyse konzipiert ist, die primär auf Textexegese aus-
gerichtet sind. Mikroskopische Analysen, die mit einer akribischen und zeit-
aufwändigen  Zeile-für-Zeile  Vorgehensweise  arbeiten  und  Stunden  oder 
Tage  für  die  sorgfältige  Analyse  weniger  Zeilen  Text  aufwenden,  werden 
naturgemäß von Computerunterstützung nur wenig profitieren können. 

Qualitative Datenauswertung ist zeitaufwändig und insofern teuer. Allzu 
berechtigt  ist  deshalb  die  Frage,  welcher  zusätzliche  Aufwand  durch  die 
Entscheidung für eine computergestützte Auswertung möglicherweise ent-
steht  und  welche  Gewinne  sich  hierdurch  erzielen  lassen.  QDA-Software 
steigert die Effizienz der Analyse in beträchtlichem Maße: Kategoriensys-
teme  lassen  sich  schnell  und  einfach  handhaben,  codierte  Textstellen  su-
chen, das Textmanagement wird vereinfacht und Übersichten lassen sich in 
Sekundenschnelle  erstellen.  Doch  ist  es  nicht  nur  die  Effizienzsteigerung 
vorhandener Auswertungstechniken als vielmehr die Eröffnung von neuen 
Analysemöglichkeiten,  die  durch  QDA-Programme  bewirkt  wird.  Neben 
diesem neuen Analysestil versprechen die QDA-Programme einen erhebli-

 

20 

Software für die qualitative Datenanalyse  

chen Zugewinn an Qualität: Kategoriensysteme, Memos und codierte Text-
segmente sind leicht zugänglich und machen es möglich, die Resultate qua-
litativer  Forschung nachzuprüfen.  Gerade  diese  mangelnde  Nachprüfbarkeit 
der Ergebnisse bei traditionellen Vorgehensweisen ist in der Vergangenheit 
der  qualitativen  Forschung  immer  wieder  zum  Vorwurf  gemacht  worden 
und hat nicht unerheblich zum einseitigen Reputationsgewinn quantitativer 
Verfahren beigetragen. 

Zurück  zur  Frage  des  zusätzlichen  Aufwandes,  der  durch  den  Einsatz 
von  QDA-Programmen  entsteht.  Heute  ist  es  zur  Regel  geworden,  alle 
Transkriptionen mittels Computer vorzunehmen. Damit ist die wesentliche 
Voraussetzung für den Einsatz eines QDA-Programms, nämlich das Vor-
handensein digitalisierter Texte, schon erbracht. Die darüber hinausgehen-
den  Vorleistungen  sind  denkbar  gering,  sie  bestehen  lediglich  im  Import 
der  Texte  in  das  QDA-Programm.  Dies  eröffnet  ein  ganzes  Arsenal  von 
Möglichkeiten, deren einfachste Variante im Kapitel „Textexploration“ be-
schrieben ist. Bei relativ geringen Investitionskosten dürfte somit der Ein-
satz von QDA-Software immer mit Gewinn, teilweise mit großem Gewinn 
im Hinblick auf Zeitersparnis, Qualität und Komplexität der Analyse ver-
bunden sein. 

1.3  Arbeitsschritte mit einem QDA-Programm 

Wie läuft nun der Auswertungsprozess mit einem QDA-Programm ab? Im 
Mittelpunkt stehen natürlich die Texte, die zunächst in das QDA-Programm 
importiert bzw. diesem zugeordnet werden müssen. Charakteristisch für die 
Arbeit  mit  QDA-Programmen  ist,  dass  gewöhnlich  nicht  nur  mit  einem 
Einzeltext gearbeitet wird, wie dies üblicherweise bei einem Textverarbei-
tungsprogramm der Fall ist, sondern mit einer gewissen Anzahl von Tex-
ten, die zu einem Projekt – eine Art Container – gehören und die man zu-
sammen  analysieren  will:  Man  will  die  Texte  miteinander  vergleichen,  sie 
kontrastieren, Gemeinsamkeiten herausarbeiten und Regelmäßigkeiten fest-
stellen. Es kommt also weniger auf den einzelnen Text in seiner Besonder-
heit, sondern vielmehr auf die Gesamtschau an. Dieser Fokus auf ein gan-
zes Set von  Texten  bedeutet  allerdings  keineswegs, dass detaillierte Zeile-
für-Zeile Analysen damit ausgeschlossen wären. Die Vielfalt der verschie-
denen Methoden der Text- und Inhaltsanalyse bedingt, dass keine allgemein 

Arbeitsschritte mit einem QDA-Programm 

21 

verbindliche Abfolge von Arbeitsabläufen und Analyseschritten angegeben 
werden kann. Es lassen sich allerdings Bearbeitungsphasen unterscheiden, 
die in den verschiedenen methodischen Paradigmen eine mehr oder weni-
ger große Rolle spielen. QDA-Programme lassen sich mit Werkzeugkästen 
vergleichen, die umfangreiche Sammlungen von Werkzeugen unterschiedli-
chen Typs enthalten. Natürlich sind nicht alle Werkzeugkästen quantitativ 
und  qualitativ  gleich  bestückt.  Manche  enthalten  nur  wenige  Werkzeuge, 
manche enthalten vielleicht sehr viele Dinge, die  aber  nur selten  benötigt 
werden. 

Die  folgenden  Arbeitsschritte  beschreiben  grundsätzliche  Arbeitsabläufe 
bei der computergestützten Analyse qualitativer Daten, die in unterschiedli-
cher Kombination und Schwerpunktsetzung in den verschiedenen metho-
dischen Paradigmen eine Rolle spielen. Diese Arbeitsschritte müssen nicht 
notwendigerweise  hintereinander  ablaufen.  Sie  können  parallel  bearbeitet 
oder auch in zirkulärer Reihenfolge durchlaufen werden. 

Arbeitsschritt – Projekt und Textgruppen einrichten 
Die erste Arbeitsaufgabe bei der Arbeit mit einem QDA-Programm besteht 
im Anlegen eines neuen Projektes, d.h. der Einrichtung von einer Art Lager-
haus für alle Daten, die jetzt oder im zukünftigen Projektverlauf im Rah-
men der Auswertung anfallen. Am besten wählt man einen aussagekräftigen 
Namen für das Projekt, beispielsweise haben wir in einer Feldstudie über 
Lokale Agenda 21-Initiativen3 der Projektdatei den Namen „Umweltkom-
munikation und Agenda 21“ gegeben. In der Projektdatei ist alles Wesentli-
che enthalten, was zu dem betreffenden Projekt gehört, d.h. alle Texte, Ka-
tegorien, codierten Textstellen und Hyperlinks, Memos, Anmerkungen und 
Variablen.  Audio-  und  Videodateien,  quasi  die  Rohdaten  eines  Projektes, 
werden wegen ihrer beträchtlichen Größe in der Regel nicht in der Projekt-
datei gespeichert. 

Im oben erwähnten Projekt „Umweltkommunikation und Agenda 21“ 
wurden einerseits die Akteure von Agenda 21-Initiativen interviewt, ande-
rerseits auch  Experten  aus dem Umfeld. Zum  Datenmaterial gehören die 

                                                           
 
3  Das  Forschungsprojekt  „Initiativen  für  eine  nachhaltige  Entwicklung:  Neue  Dialogfor-
men und Kommunikationsstile im Zusammenhang mit der Agenda 21“ wurde unter dem 
Förderkennzeichen 
de 
Haan/Kuckartz/Rheingans 2000). 

vom  Umweltbundesamt 

10107133 

gefördert 

(vgl. 

 

22 

Software für die qualitative Datenanalyse  

Sitzungsprotokolle  der  Initiativen,  ferner  wurden  Beobachtungsprotokolle 
über die Treffen der Initiativen und ihrer Arbeitsgruppen angefertigt. Sinn-
voll ist es, verschiedene Textgruppen zu unterscheiden und entsprechend zu 
benennen. Es empfiehlt sich dementsprechend vier Textgruppen zu bilden: 
 

1.  Interviews mit Akteuren 
2.  Interviews mit Experten 
3.  Beobachtungsprotokolle 
4.  Sitzungsprotokolle 

Ein Projekt besteht aus 
mehreren Texten und 
mehreren Textgruppen.

 

Abb. 1: Ausgangssituation: ein Projekt mit mehreren Texten 

Arbeitsschritt – Import von Texten 
Hat  man  ein  neues  Projekt  eingerichtet  und  den  ersten  Arbeitsschritt  be-
wältigt, kann der Import von Texten beginnen. Zuvor sollten diese entspre-
chend vorbereitet werden. In QDA-Programmen haben die Texte norma-
lerweise den Status von Dokumenten, d.h. sie werden während des Analy-
seprozesses nicht oder nur marginal verändert. Eine sorgfältige Korrektur 
von Texttranskriptionen ist in jedem Fall vor der Analyse empfehlenswert. 
Ebenso  sollten  die  Texte  vor  dem  Import  anonymisiert  werden.  Weitere 
Texte können auch später noch, zu jedem beliebigen Zeitpunkt des Analy-
seprozesses,  eingelesen  werden.  Man  ist  also  nicht  gezwungen,  gleich  alle 
Texte  bereits  zu  Beginn  der  Textauswertung  zu  importieren.  Häufig  wird 
eine  Arbeitsweise  praktiziert,  bei  der  zunächst  jeder  importierte  Text  mit 
Zeilen  bzw.  Absatznummern  ausgedruckt  wird.  Ein  solcher  Ausdruck  ist 
eine  gute  Grundlage  für  eine  in  der  Forschergruppe  gemeinsam  vorge-
nommene  Bearbeitung  und  Diskussion.  Der  Ausdruck  stellt  ferner  einen 
guten Ausgangspunkt für die Analyse- und Codierarbeit dar: Man kann No-
tizen  an  den  Rand  schreiben,  Themen  vermerken,  Relevantes  markieren 

Arbeitsschritte mit einem QDA-Programm 

23 

und Kategorien notieren. Ob man lieber am Bildschirm oder mit Papier ar-
beitet, ist letzten Endes eine Angelegenheit persönlicher Präferenzen. 

Arbeitsschritt – Texte explorieren 
QDA-Programme  beinhalten  Funktionen  zur  Exploration  von  Texten. 
Man  kann  gezielt  nach  Worten  und  Wortkombinationen  suchen,  das  se-
mantische  Umfeld  von  Begriffen  erkunden  und  Keyword-in-Context  Zu-
sammenstellungen anfertigen – und dies nicht nur für einen einzelnen Text, 
sondern für das gesamte Projekt.. Textstellen lassen sich in ähnlicher Weise 
wie  mit  einem  Text-Marker  markieren  und  so  für  die  zukünftige  genaue 
Interpretationen festhalten. Prägnante Formulierungen der Befragten lassen 
sich als solche kenntlich machen. 

Auch der direkte Zugriff auf den Originalton der Audio- bzw. Videoda-
tei  ist  möglich,  sofern  die  QDA-Software  eine  solche  Synchronisierungs-
funktion besitzt. 

Arbeitsschritt – Texte segmentieren und Codes zuordnen 
Ein zentraler Arbeitsschritt stellt die systematische Codierung von Textpas-
sagen  dar.  Relevante  Textsegmente  werden  markiert  und  aussagekräftigen 
Kategorien („Codes“) zugewiesen. 

Hinsichtlich  der  Festlegung  der  Grenzen  eines  Textsegmentes  ist  man 
bei moderner QDA-Software völlig frei. Ein Segment kann nur aus einem 
Wort, einem oder wenigen Sätzen oder auch aus längeren Textpassagen be-
stehen.  Die  gleichen  Textstellen  können  mehrmals  codiert  werden,  d.h. 
dem Segment können gleichzeitig mehrere Codes zugeordnet werden. Auf 
diese  Weise  werden  die  Texte  des  Projektes  systematisch  bearbeitet.  Dies 
stellt eine wesentliche Vorarbeit dar, um später alle Textstellen zu bestimm-
ten Themen zusammenstellen zu können oder um die Struktur des Textes, 
den Zusammenhang zwischen Kategorien zu erforschen. 
 

 

24 

Software für die qualitative Datenanalyse  

I: Mach mal so, bezogen jetzt rein auf die 
Initiative, da die ja noch relativ „jung“ ist, 
haben Sie dafür auch so ne Vision, was da 
noch machbar ist? 
 
Fr. Wenger: Also was ich mir insgesamt 
wünsche, ist daß so die Menschen wieder 
untereinander in Kontakt kommen, auch 
durch solche Aktionen. Auch wenn man 
seine Straße aufräumt, denn ist es ja nicht 
nur, daß die Straße sauber ist, wobei 
manche immer zusammenzucken, aber ich 
finde das einfach wichtig, ich denke, das 
gehört zum Wohlfühlen und Menschen 
kommunizieren wieder untereinander und 
außerdem merken sie, sie haben was 
geschafft. Und sie können - es ist zwar eine 
winzig kleine Sache, aber sie können was 
verändern. Und es sind so viele Menschen, 
die sich zurückgezogen haben und sagen, 
Ihr könnt mich mal und wir wollen uns nicht 
mehr beteiligen und vielleicht ist das 
irgendwo son kleiner Punkt, wo sie dann so 
anfangen sich wieder ein bißchen 
gemeinschaftlich zu betätigen. Also das ist 
so meine Vision der - ja - Aufleben des 
Kommunegedankens. 

Abb. 2: Text segmentieren und codieren 

Fr. Wenger: Also was ich mir insgesamt 
wünsche, ist daß so die Menschen wieder 
untereinander in Kontakt kommen, auch 
durch solche Aktionen. Auch wenn man 
seine Straße aufräumt, denn ist es ja nicht 
nur, daß die Straße sauber ist, wobei 
manche immer zusammenzucken, aber ich 
finde das einfach wichtig, ich denke, das 
gehört zum Wohlfühlen und Menschen 
kommunizieren wieder untereinander und 
außerdem merken sie, sie haben was 
geschafft. Und sie können - es ist zwar eine 
winzig kleine Sache, aber sie können was 
verändern. 

Code 

Wunschprojektion 

 

Arbeitsschritt – Textstellen über Hyperlinks miteinander verknüpfen 
Durch das Internet sind inzwischen  Hyperlinks allgemein  bekannt. Dabei 
handelt es sich um Verknüpfungen von Webseiten, d.h. Querverweise auf 
andere Internetseiten. Klickt man einen solchen Querverweis an, wird zum 
Zielpunkt  des  Verweises  gesprungen,  d.h.  die  entsprechende  Internetseite 
geladen. Diese Querverweistechnik steht auch für die Textanalyse zur Ver-
fügung:  Textstellen  können  mit  anderen  Textstellen  –  sei  es  im  gleichen 
oder in anderen Texten – verknüpft werden, so dass später durch einen ein-
fachen Mausklick auf das Ziel des Verweises gesprungen werden kann. 

Arbeitsschritt – Ideen, Hypothesen und Theorien in Form von Memos festhalten 
Ein weiteres wichtiges analytisches Werkzeug von QDA-Programmen stel-
len die Memos dar. Dabei handelt es sich zunächst um nichts anderes als um 
die Möglichkeit, Notizen zu verfassen und zusammen mit den Originalda-
ten  zu  speichern  und  zu  verwalten.  Etwas  Wichtiges  auf  eine  Karteikarte 
aufzuschreiben,  war  natürlich  auch  schon  vor  dem  Computerzeitalter  im 
Forschungsalltag ein ständig praktiziertes Verfahren, um z.B. Kategoriende-

Arbeitsschritte mit einem QDA-Programm 

25 

finitionen,  Hypothesen  oder  komplexe  Gedankengänge  festzuhalten.  Me-
mos können sich auf bestimmte Texte, Textstellen oder auf Codes bezie-
hen, sie können aber auch als „theoretische Memos“ frei von einer solchen 
Zuordnung sein. Memos sind ein wichtiges Hilfsmittel, um die eigenen Hy-
pothesen  zu  entwickeln.  Sie  können  wichtige  Meilensteine  auf  dem  Weg 
zum eigenen Text bzw. Forschungsbericht sein. 

Arbeitsschritt – Ein System von Kategorien entwickeln 
Das Arbeiten mit dem Kategoriensystem stellt einen wesentlichen Teil der 
analytischen Arbeiten dar. QDA-Programme leisten hier wirksame Unters-
tützung.  Die  Codes  wachsen  im  Verlauf  des  Analyseprozesses  zu  einem 
dichten, geordneten System von Kategorien zusammen. Dabei können ei-
nerseits verschiedene Codes zu einem neuen, übergreifenden Code zusam-
mengefasst  werden.  Andererseits  können  Codes  ausdifferenziert  werden. 
Es  mag  sich  beispielsweise  als  nützlich  herausstellen,  bei  einem  Code 
„Wunschprojektion“  zwischen  sozialen,  ökologischen  und  ökonomischen 
Wünschen zu unterscheiden. QDA-Programme ermöglichen es dann, ohne 
größeren Aufwand die bereits mit „Wunschprojektion“ codierten Textseg-
mente einer der drei neu gebildeten Subkategorien zuzuordnen. 

TEXT: Interviews Akteure / Wenger  
(Zeile 153-162) 
 
CODE: Wunschprojektion 
 
Fr. Wenger: Also was ich mir 
insgesamt wünsche, ist dass so die 
Menschen wieder untereinander in 
Kontakt kommen, auch durch solche 
Aktionen. Auch wenn man seine 
Straße aufräumt, denn ist es ja nicht 
nur, daß die Straße sauber ist, wobei 
manche immer zusammenzucken, 
aber ich finde das einfach wichtig, ich 
denke, das gehört zum Wohlfühlen 
und Menschen kommunizieren wieder 
untereinander und außerdem merken 
sie, sie haben was geschafft. Und sie 
können - es ist zwar eine winzig kleine 
Sache, aber sie können was 
verändern. 

CODE: 
Wunschprojektion
  - sozial 
  - ökologisch 
  - ökonomisch 

 

Abb. 3: Ausdifferenzierung des Kategoriensystems 

 

26 

Software für die qualitative Datenanalyse  

Arbeitsschritt – Memos verdichten und integrieren 
Je  weiter  der  Analyseprozess  fortschreitet,  desto  umfangreicher  werden 
normalerweise die Memos. Sie integrieren bereits vorhandene Memos oder 
halten die nun schon recht umfangreichen theoretischen Gedanken fest. In 
Form von Code-Memos werden Kategoriendefinitionen und Ankerbeispie-
le festgehalten. 

Mit der im Laufe des Forschungsprozesses entstehenden Sammlung von 
Memos verfügt man über einen Fundus von Ideen, Hypothesen und Aus-
wertungsteilen. All dies erleichtert die Anfertigung eines Forschungsberich-
tes.  Man  kann  in  Memos  gezielt  nach  Begriffen  suchen,  auch  lassen  sich 
den Memos wiederum Kategorien zuordnen, die das Auffinden bestimmter 
Ideen und Beschreibungen  ermöglichen.  Auf diese Weise lassen sich Me-
mos zu umfassenden Memos integrieren und zu Forschungsberichten aus-
bauen. 

Arbeitsschritt – Text-Retrieval: Fragen an das Material stellen 
Mit  dem  Mittel  des  Text-Retrievals  kann  eine  Synopse  aller  zu  einer  be-
stimmten  Kategorie  oder  Subkategorie  zugeordneten  Textstellen  des  ge-
samten Text-Sets erstellt werden. Die Segmente lassen sich in einer geord-
neten  Liste  zusammen  mit  der  Herkunftsangabe  ausgeben,  speichern,  zu 
Word exportieren und drucken. Dies stellt eine sehr einfache Möglichkeit 
zur Themenanalyse dar. Man erhält beispielsweise alle auf den Bereich „So-
ziales“  zielenden  Wunschprojektionen  der  Befragten  und  kann  zusätzlich 
zwischen verschiedenen  Textgruppen (Akteure und Experten) unterschei-
den. Anders als manuelle Karteisysteme machen gute QDA-Programme es 
möglich, nach Belieben in den Originaltext zurückzuspringen und den grö-
ßeren  Kontext  einer  codierten  Textpassage  einzusehen,  wann  immer  dies 
für sinnvoll erachtet wird. 

Fortgeschrittene  Formen  des  Text-Retrievals  sehen  beispielsweise  so 
aus, dass nach Überschneidungen von Kategorien bzw. Kategoriengruppen 
geforscht wird. Mittels spezieller Abfragewerkzeuge lassen sich Fragen an 
das Material stellen, z.B. „Existieren Textstellen, in denen Befragte ihre auf 
die  Initiativgruppe  bezogenen  Wünsche  beschreiben  (Code  „Wunschpro-
jektion/sozial“) und gleichzeitig „negative Emotionen“ äußern?“ 

Arbeitsschritte mit einem QDA-Programm 

27 

Arbeitsschritt – Fallvariablen definieren, Textmerkmale bewerten und klassifizieren 
Mit dem Werkzeug der Fallvariablen können einerseits a priori vorhandene 
Informationen  über  den  Text  festgehalten  werden,  z.B.  sozio-demogra-
phische Daten, Informationen über den Interviewer und den Interviewver-
lauf. Andererseits kann das Werkzeug der Fallvariablen auch dazu benutzt 
werden, um Klassifizierungen und Bewertungen, die auf der Grundlage der 
Textinterpretation  vorgenommen  werden,  in  Form  von  Variablenwerten 
festzuhalten. Die Fallvariablen können als Selektionskriterien für das Text-
Retrieval, d.h. das Wiederfinden codierter Textpassagen herangezogen wer-
den. Angenommen, man habe die Variablen Anzahl der Kinder und Einkom-
menshöhe als Fallvariable definiert, dann lässt sich bspw. die Frage „Wie se-
hen die sozialen Wunschprojektionen von Befragten mit Kindern und ei-
nem Monatseinkommen über 4000 Euro aus?“ beantworten. Auch lassen 
sich mit den Fallvariablen Übersichtstabellen erstellen und statistische Be-
rechnungen durchführen. 

I: Mach mal so, bezogen jetzt rein auf 
die Initiative, da die ja noch relativ 
„jung“ ist, haben Sie dafür auch so ne 
Vision, was da noch machbar ist? 
 
Fr. Wenger: Also was ich mir 
insgesamt wünsche, ist dass so die 
Menschen wieder untereinander in 
Kontakt kommen, auch durch solche 
Aktionen. Auch wenn man seine Straße 
aufräumt, denn ist es ja nicht nur, dass 
die Straße sauber ist, wobei manche 
immer zusammenzucken, aber ich 
finde das einfach wichtig, ich denke, 
das gehört zum Wohlfühlen und 
Menschen kommunizieren wieder 
untereinander und außerdem merken 
sie, sie haben was geschafft. Und sie 
können - es ist zwar eine winzig kleine 
Sache, aber sie können was 
verändern. 

Interviewte: Wenger 
Interviewer: Anke B. 
Geschlecht: w 
Alter: 
53 
Fam.Stand:  ledig 
Bezirk: 
Kinder: 
Status: 
...... 

Pankow 
2 
5 

 

Abb. 4: Mit dem Text assoziierte Fallvariablen 

Arbeitsschritt – Komplexe Analyse 
Komplexe  Formen  des  Text-Retrievals  ermöglichen  die  gezielte  Prüfung 
von  Hypothesen.  Es  wird  nicht  mehr  lediglich  nach  dem  gemeinsamen 
Auftreten  von  Kategorien  geforscht,  sondern  es  kann  z.B.  mit  Hilfe  von 

 

28 

Software für die qualitative Datenanalyse  

Entfernungsoperatoren überprüft werden, welche Themen im Umkreis be-
stimmter Fragen erörtert oder gerade nicht erörtert werden. 

Ferner besteht die Möglichkeit, Textinformationen in Form von Varia-
blenwerten  zu  vercoden  und  mit  diesen  Variablen  auch  quantitative  Aus-
wertungen durchzuführen. Statistische Verfahren wie die Faktorenanalyse, 
Clusteranalyse, Konfigurationsfrequenzanalyse oder Korrespondenzanalyse 
können eingesetzt werden, um nach Mustern zu suchen oder Typen zu bil-
den. Die Resultate lassen sich wiederum in Kombination mit Techniken des 
Text-Retrievals  nutzbar  machen.  Relevanz-Scores  ermöglichen  es,  die  Be-
deutsamkeiten  von  Textsegmenten  festzuhalten  und  ebenfalls  beim  Text-
Retrieval zu berücksichtigen. 

 

2  Die Texte: Transkription, Vorbereitung und 

Import 

2.1  Allgemeines zu Texten und ihrer Formatierung 

Welche  Textarten  lassen  sich  mit  QDA-Software  verwalten  und  analysie-
ren?  Müssen  die  Texte  ganz  bestimmte  Bedingungen  erfüllen,  gibt  es  Be-
schränkungen hinsichtlich der Anzahl der Texte und ihres maximalen Um-
fangs? Muss eine bestimmte Syntax eingehalten werden? Sind nur bestimm-
te Schriftzeichen und Schriftarten erlaubt? Darf der Text Bilder, Grafiken, 
Excel-Tabellen  oder  Ähnliches  enthalten?  Wie  viel  Vorarbeit  ist  erforder-
lich, um die Texte für eine computerunterstützte Auswertung vorzubereiten 
und lohnt sich ein solcher Aufwand überhaupt? Fragen wie diese werden 
häufig gestellt, wenn es um die Entscheidung geht, ob man QDA-Software 
bei der Textauswertung einsetzen soll oder nicht. Beginnen wir mit der Be-
antwortung der Fragen in chronologischer Reihenfolge: 

Textarten 
Prinzipiell lassen sich alle Texte, die in digitalisierter Form vorliegen oder 
sich  leicht  in  eine  solche  überführen  lassen,  mit  einem  QDA-Programm 
auswerten. Es kann sich also beispielsweise um Transkriptionen von Inter-
views,  Gruppendiskussionen  u.  Ä.  handeln,  aber  auch  um  Texte,  die  aus 
CD-ROM-Quellen oder aus dem Internet stammen, ferner um Texte, die 
zunächst nur in Papierform vorliegen und eingescannt werden müssen. 

Beschränkungen 
Wie sieht es mit Beschränkungen in Bezug auf die Anzahl der bearbeitba-
ren  Texte  und  der  Textlänge  aus?  Hier  gilt  es  zunächst  einmal  zwischen 
dem einzelnen Text und dem gesamten Text-Set, das gleichzeitig verfügbar 
sein  muss  und  ausgewertet  werden  soll,  zu  unterscheiden.  In  einem  For-
schungsprojekt  sind  dies  etwa  alle  transkribierten  Interviews,  Beobach-
tungsprotokolle, Dokumente, Feldnotizen u. Ä.,  also  die Gesamtheit aller 

30 

Die Texte: Transkription, Vorbereitung und Import 

Texte  die  zum  Projekt  gehören.  Betrachten  wir  zunächst  den  einzelnen 
Text: Was ist im Sinne eines QDA-Programms ein „normaler“ Text, was 
ein  „langer“  und  was  ein  „kurzer“  Text?  Ein  durchschnittliches  offenes 
Interview von circa einer Stunde Dauer ergibt in transkribierter Form etwa 
25 bis 60 Seiten. Das ist kein besonders langer Text, weder für diese Art der 
Datenerhebung  noch  für  die  Auswertung  mit  einem  QDA-Programm. 
Hingegen würde man einen mehr als 100 Seiten umfassenden Text durch-
aus als einen langen Text bezeichnen. Derartig lange Texte sind in der Pra-
xis  qualitativer  Sozialforschung  eher  selten  und  auch  bei  Medienanalysen 
keineswegs  als  normal  zu  betrachten,  denn  Texte  müssen  in  den  meisten 
Fällen transkribiert werden (was mit beträchtlichen Kosten verbunden ist) 
und natürlich von den Bearbeitern bei einer qualitativen Analyse auch gele-
sen werden. Den Prototyp eines kurzen Textes stellt ein Abstract von einer 
halben  Seite  dar.  Auch  Antworttexte  auf  offene  Fragen  in  Fragenbogen-
interviews umfassen selten mehr als etwa 20 Zeilen. Für heutige QDA-Soft-
ware stellen Texte mit einem Umfang bis zu 100 Seiten kein Problem mehr 
dar, praktisch wirksame Beschränkungen für die maximale Länge einzelner 
Texte existieren also nicht. 

Im  Hinblick  auf  das  gesamte  Text-Set  hat  man  es  in  der  qualitativen 
Forschung gewöhnlich mit relativ kleinen Fallzahlen zu tun, jedenfalls im 
Vergleich  zu  den  riesigen  Stichprobengrößen  in  der  Surveyforschung,  die 
häufig mehr als 1000 Personen umfassen. In qualitativen Interviewstudien 
arbeitet man in der Regel mit 20 bis 80, gelegentlich auch mit mehr als 100 
Interviews, aber nur sehr selten mit mehreren hundert oder gar mehreren 
tausend. Das sind beträchtliche Datenmengen, doch wird nicht erst seit der 
Existenz  von  QDA-Software  in  der  qualitativen  Forschung  mit  großen 
Mengen  von  Text  gearbeitet.  Hunderte  oder  gar  mehrere  tausend  Seiten 
von Feldprotokollen und Interviews mit Informanten gehörten auch bereits 
vor  der  Computerisierung  zum  Alltag  qualitativer  Forscher.  Autoren  wie 
Huberman  und  Miles  sprachen  in  diesem  Kontext  von  „data  overload“ 
(1983: 285), d.h. von „Daten-Überlastung“. In Bezug auf Zahl und Umfang 
des analysierten Materials sollte man stets daran denken, dass QDA-Soft-
ware ursprünglich als Hilfsmittel für qualitative Forschung konzipiert wur-
de und nicht etwa als Datenverwaltungs- oder Datenbankprogramm. 

Das typische Datenmaterial für QDA-Software stellen deshalb Textkor-
pora von etwa 20 bis 80 Texten mit jeweils 10 bis 60 Seiten dar. Wenn man 
von diesem Regelfall sehr stark abweicht, mag dies je nach QDA-Software 

Allgemeines zu Texten und ihrer Formatierung 

31 

und Rechnertyp zu Problemen führen, etwa dazu, dass die Ausführungsge-
schwindigkeit stark sinkt. 

Textgestaltung 
In QDA-Software, die das DOC oder Rich-Text-Format (RTF) unterstützt, 
können  Texte  im  Prinzip  so  importiert  werden,  wie  sie  im  Textverarbei-
tungsprogramm  formatiert  sind.  Das  heißt,  es  ist  keine  weitere  Vorarbeit 
notwendig, um die Texte für die Auswertung vorzubereiten, etwa weil die 
QDA-Software eine bestimmte Syntax verlangen oder bestimmte Textaus-
zeichnungen nicht unterstützen würde. 

Objekte im Text (Fotos, Grafiken, Word- und Excel-Tabellen etc.) 
Die neueste Programmgeneration von MAXQDA, NVivo und ATLAS.TI 
gestattet nun auch das Arbeiten mit Texten, die Fotos, Grafiken, Tabellen 
oder andere eingebettete Objekte enthalten. 

Notwendige Vorarbeit 
Den computergestützten Techniken zur Auswertung von Textdaten ist ge-
meinsam, dass die ersten Schritte – gleichgültig welches Softwareprogramm 
eingesetzt wird – weitgehend die gleichen sind. Ursprünglich waren QDA-
Programme primär für die Textauswertung und das Textmanagement kon-
zipiert und weniger für die Texteingabe bzw. Transkription. Inzwischen ge-
statten Programme das Erstellen und Editieren von Texten, teilweise wird 
auch die Transkription von Texten wirkungsvoll unterstützt. In den meisten 
Fällen wird allerdings die Erfassung bzw. die Eingabe des Textes mit einem 
Textverarbeitungsprogramm  oder  einem  Transkriptionsprogramm  reali-
siert.  Es  spielt  aber  eigentlich  keine  Rolle,  welches  Programm  verwendet 
wird,  entscheidend  ist,  ob  das  Programm  in  der  Lage  ist,  einen  Text  im 
RTF- oder DOC-Format zu speichern. Wenn eben möglich sollten bereits 
bei der Texterstellung die Spezifika von QDA-Programmen beachtet wer-
den, d.h. die Texte sollten schon im Hinblick auf den späteren Einsatz eines 
QDA-Programms  gestaltet  werden.  Die  entsprechenden  Anforderungen 
und Restriktionen von QDA-Programmen sind nicht sonderlich hoch, so 
dass auch bereits vorhandene Texte meist problemlos entsprechend präpa-
riert werden können. 

Die Frage, wie viel Zeit für die Vorbereitung der Texte notwendig ist, 
lässt sich nicht pauschal beantworten. In der Regel ist der Aufwand ziem-

 

32 

Die Texte: Transkription, Vorbereitung und Import 

lich gering, jedenfalls im Verhältnis zu den Kosten, die für die Transkrip-
tion eines Textes anfallen. Die folgenden Abschnitte dieses Kapitels befas-
sen  sich  mit  den  verschiedenen  Varianten  der  Textvorbereitung  und  ma-
chen eine genauere Abschätzung der im Einzelfall benötigten Zeit möglich. 

2.2  Texte im Textverarbeitungsprogramm (Word) 

Im  Feld  der  nicht-quantitativ  arbeitenden  Sozialwissenschaftler  war  es  – 
ebenso  wie  bei  Historikern  (vgl.  Greenstein  1994)  –  lange  Zeit  unüblich 
oder sogar verpönt, Computer im Forschungsprozess einzusetzen. Compu-
ter  wurden  mit  quantitativen  Methoden  und  statistischen  Verfahren  asso-
ziiert  und  aus  diesen  Gründen  war  man  nicht  sonderlich  willig,  sie  als 
Werkzeuge für die qualitative Analyse zu begreifen und in der eigenen Ar-
beit  einzusetzen.  Mit  dem  Aufkommen  preiswerter  Personal  Computer 
Ende der 1980er-Jahre änderte sich dies und ein Prozess der „Destigmati-
sierung“  des  Computers  setzte  ein.  Heute  ist  es  für  die  jüngeren  Wissen-
schaftlergenerationen  selbstverständlich  geworden,  Computer  in  der  eige-
nen Forschungspraxis zu benutzen. Man schreibt die Texte mit Textverar-
beitungsprogrammen  und  benutzt  den  Computer  für  die  unterschiedlich-
sten Aufgaben: Schriftverkehr, Seminarpläne, Literaturlisten, Datenbanken 
für  die  Literaturrecherche,  Internet  und  die  Erstellung  von  Camera-ready 
Manuskripten und Tagungsbänden.  

Betrachten wir etwas genauer, welche Formen von Textbearbeitung mit 
Textverarbeitungsprogrammen  auf  dem  derzeitigen  Stand  der  Technik 
möglich  sind.  Ein  Programm  wie  Microsoft  Word  vereinigt  in  sich  ver-
schiedene Programmroutinen: einen Editor, mit dem man Texte am Bild-
schirm eingeben und modifizieren kann, ein Formatierungsmodul, das die 
Darstellung  am Bildschirm und die Form des Ausdrucks steuert (z.B. die 
Seitenränder,  die  Zeilenabstände,  die  benutzten  Schriftarten  und  Schrift-
größen) und ein User Interface, das bestimmt, was der Benutzer am Bild-
schirm sieht, auf welche Weise er die Programmfunktionen steuert und das 
ihn  hierbei  wirkungsvoll  unterstützt,  beispielsweise  indem  es  so  genannte 
Assistenten  zur  Verfügung  stellt.  Textverarbeitungsprogramme  haben  die 
Art und Weise, wie wir Texte erstellen, vollständig verändert: Heute kann 
man an jede beliebige Stelle eines Textes springen und Abschnitte einfügen 
oder löschen, wobei die Programme automatisch alle folgenden Seiten neu 

Texte im Textverarbeitungsprogramm (Word) 

33 

formatieren.  Wörter  oder  Zeichenketten  lassen  sich  global  im  gesamten 
Text ersetzen – eine Funktion, die vor allem für die Anonymisierung von 
Interviews  oder  Beobachtungsprotokollen  außerordentlich  nützlich  ist, 
denn so lassen sich mit einem einzigen Befehl alle Erwähnungen einer Per-
son verändern: aus „Dr. Schulte“ wird überall „Dr. A“. Eine Vielzahl weite-
rer automatischer Funktionen steht zur Verfügung. So können Inhaltsver-
zeichnisse erstellt und Fußnoten verwaltet werden. 

Rich-Text-Format und DOC-Format 
Im Gegensatz zum  DOC-Format, das ein  proprietäres Format der  Firma 
Microsoft ist, stellt das Rich-Text-Format (RTF) ein Austauschformat für 
Texte  dar.  Es  dient  dazu,  formatierte  Texte  zwischen  Textverarbeitungs-
programmen  verschiedener  Hersteller  auszutauschen.  Dieses  Format  ist 
klar definiert und kann um neue Kommandos erweitert werden. Trifft ein 
Programm auf ein unbekanntes RTF-Kommando, so wird dieses ignoriert 
und übersprungen. Beim Austausch von RTF-Dateien bleiben die wesent-
lichen  Formatierungsmerkmale  erhalten,  z.B.  Schriftgröße  und  Schriftart, 
Farbe, Fettdruck, Kursivdruck und Unterstreichungen. 

Im Kern ist eine RTF-Datei eine Textdatei, in der die entsprechenden 
Formatierungsoptionen eingefügt sind, so sieht beispielsweise der obige Satz 
(mit dem fettgedruckten Wort Fettdruck) im RTF-Format wie folgt aus: 

{\insrsid11288219 Das Rich-Text-Format (RTF) ist ein von Microsoft eingef\'fchrtes Austauschformat 
f\'fcr Texte, das dazu dient formatierte Texte zwischen Textverarbeitungsprogrammen verschiedener 
Hersteller auszutauschen. Bei diesem Austausch bleiben wesentliche Formatierungsmerkmale erhalten, 
z.B.: Schriftgr\'f6\'dfe und Schriftart, Farbe, }{\b\insrsid11288219\charrsid293648 
Fettdruck}{\insrsid11288219 , Kursivdruck und Unterstreichungen\par } 
Abb. 5: Darstellung eines Textes im RTF-Format 

Sowohl das RTF- wie das DOC-Format unterstützen OLE (Object Linking 
and Embedding), d.h. Bilder, Grafiken, Microsoft Office Objekte wie Ex-
cel-Tabellen oder Powerpoint Präsentationen, ja sogar Audio- und Video-
dateien können in die Datei eingebettet werden. Es kommt allerdings dar-
auf an, ob das Programm, in welchem die RTF-Datei geöffnet wird, OLE-
Funktionen unterstützt, ansonsten werden diese OLE Objekte einfach igno-
riert.  In  Vergleichen  von  verschiedenen  QDA-Programmen  wird  häufig 
auch das unterstützte Textformat aufgeführt. Man sollte dann beachten, dass 
unter Rich-Text-Format durchaus verschiedenes verstanden werden kann, je 
nachdem  ob  und  welche  Art  von  eingebetteten  Objekten  erlaubt  ist.  Bei 

 

34 

Die Texte: Transkription, Vorbereitung und Import 

eingebetteten Grafiken und Fotos ist zu beachten, dass diese im Rich-Text-
Format als Bitmap gespeichert werden und so beträchtlich größer werden 
können als die ursprüngliche komprimierte Dateiform als JPG- oder GIF-
Datei. Hier kann es sich für die Arbeit als nützlich erweisen, wenn nicht die 
Dateien selbst eingebettet werden, sondern nur ein Link auf die Datei ver-
weist, so dass diese nur bei Bedarf aufgerufen wird. 

In  diesem  Buch  geht  es  vorrangig  um  die  computergestützte  Analyse 
von  Texten,  insofern  wird  an  dieser  Stelle  die  Vorbereitung  von  Dateien 
mit Multimedia-Elementen nicht weiter beschrieben. 

2.3  Textvorbereitung 

Bei der Vorbereitung von Texten für die Analyse mithilfe eines QDA-Pro-
gramms müssen folgende Punkte beachtet werden: 

Erstens, welches  Textformat von der  QDA-Software  unterstützt wird, 
z.B. RTF-, DOC- oder Nur-Text-Format. Zweitens, ob die Software auch 
spezielle  Textelemente  wie  Word-Tabellen  darstellen  und  codieren  kann. 
Drittens, ob die Definition von Texteinheiten erforderlich ist, d.h. ob eine 
bestimmte  Eingabesyntax  eingehalten  werden  muss.  Viertens,  welche  Art 
der Transkription und welche Transkriptionsregeln gewählt werden (dies ist 
nur  dann  relevant,  wenn  Texte  zunächst  verschriftlicht  werden  müssen). 
Fünftens, ob eine Vorstrukturierung der Texte und eine Vorab-Codierung 
vorgenommen  werden  soll  (vorausgesetzt  die  QDA-Software  unterstützt 
den Import solcher strukturierter Texte). 

Unterstütztes Textformat 
Wenn  das  QDA-Programme  lediglich  das  Nur-Text-Format  unterstützt. 
sind  die  Formatierungsmöglichkeiten  aufgrund  des  ASCII-Zeichensatzes 
stark  eingeschränkt.  Diese  Beschränkungen  sollte  man  bereits  bei  der 
Transkription  bzw.  der  Texterfassung  unbedingt  berücksichtigen.  Man 
kann bspw. keine speziellen Zeichenformatierungen verwenden (Fettdruck, 
Unterstrichen,  Kapitälchen  etc.)  und  nicht  mit  verschiedenen  Schriftarten 
und Schriftgrößen arbeiten. 

Zweifellos bereitet es die geringsten Probleme, wenn die QDA-Software 
das DOC- oder das RTF-Format mit OLE unterstützt. In diesem Fall lässt 
sich  der  Text  aus  dem  Textverarbeitungsprogramm  (fast)  ohne  Verände-

Textvorbereitung 

35 

rung übernehmen, auch Grafiken und Fotos bleiben erhalten. Zu bedenken 
ist  allerdings,  dass  hochauflösende  Fotos  im  RTF-Format  beträchtlichen 
Speicherplatz benötigen, so dass man sich tunlichst Beschränkungen in die-
ser Hinsicht auferlegen sollte. So kann ein Foto, das im hoch komprimier-
ten JPG-Format 200 Kilobyte groß ist, im RTF-Format leicht auf mehrere 
Megabyte anwachsen. Wenn Fotos benutzt werden, beispielsweise um Bil-
der von Befragten oder Gegebenheiten im Untersuchungsfeld zu dokumen-
tieren, ist es ratsam, die Bilder in einer bildschirmgerechten Auflösung (72 
dpi) und nicht als hoch auflösende Fotos zu speichern. 

Unicode 
Im  RTF-Format  ist  die  Verwendung  unterschiedlicher  Schriftarten  und 
Ländercodes unproblematisch, d.h. man kann auch ohne weiteres französi-
sche  oder  skandinavische  Texte  analysieren.  Weitaus  schwieriger  gestaltet 
sich die Auswertung von Texten mit nicht-westeuropäischem Zeichensatz, 
wie z.B. von arabischen, hebräischen, koreanischen oder chinesischen Tex-
ten.  Solche  Texte  können  zwar  von  vielen  Programmen  mit  RTF-  oder 
DOC-Unterstützung  dargestellt  werden,  sollen  aber  auch  die  Kategorien-
systeme und die Textsuche mit solchen Sprachen arbeiten, ist es erforder-
lich, dass die QDA-Software den Unicode-Zeichensatz unterstützt. Derzeit 
ist dies nur bei MAXQDA und NVivo uneingeschränkt der Fall. 

Definition von Text- bzw. Analyseeinheiten 
Leser, die mit der quantitativ orientierten sozialwissenschaftlichen Inhalts-
analyse (vgl. Merten 1995, Früh 2004, Wirth/Lauf 2001) vertraut sind, wis-
sen, dass dort vor Beginn der Analyse die Bestimmung von Texteinheiten 
erfolgen muss. Die Texteinheit entspricht der Analyseeinheit in der späte-
ren  statistischen  Auswertung,  d.h.  sie  ist  die  Bezugsgröße,  innerhalb  wel-
cher später codiert wird (vgl. Klein 1997) – technisch gesprochen handelt es 
sich um eine Zeile der späteren Datenmatrix. Die Wahl der Analyseeinheit 
stellt  also  eine  Vorab-Festlegung  der  möglichen  Anzahl  der  Codierzeilen 
und  damit  der  Codiertiefe  und  der  Differenziertheit  der  Auswertung  dar. 
Eine Texteinheit kann etwas sehr Verschiedenes bedeuten: ein Buch bei der 
Inhaltsanalyse von Büchern, eine Zeitschriftenausgabe, einen Zeitschriften-
artikel,  vielleicht  nur  einen  Absatz  in  einem  solchen  Artikel  oder  gar  nur 
einen einzelnen Satz. Texteinheiten können also verschieden definiert wer-
den und stark unterschiedlichen Umfang besitzen. Im Gegensatz zu den ri-

 

36 

Die Texte: Transkription, Vorbereitung und Import 

giden Vorschriften, die die Programme zur quantitativen Inhaltsanalyse auf-
weisen, sind QDA-Programme weitaus liberaler: MAXQDA und ATLAS.TI 
verlangen keine Vorab-Festlegung von Texteinheiten, d.h. ähnlich wie beim 
manuellen Markieren von Textstellen mit einem Text-Marker können An-
fang und Ende eines Segmentes frei bestimmt werden. 

Selbstverständlich kann es auch aus analytischen Gründen sinnvoll sein, 
Texteinheiten zu definieren, prototypisch bei der Analyse von Gruppendis-
kussion oder Fokusgruppen, wo jeder Sprechakt als eine Einheit betrachtet 
werden kann. In solchen Fällen ist es empfehlenswert, bereits vor dem Im-
portieren eines Textes in die QDA-Software die gewünschte Struktur des 
Textes herzustellen. 

Wie bereitet man die Daten für die Analyse mit QDA-Software vor? Die 
Antwort auf diese Frage hängt von zwei Faktoren ab, erstens von der Art 
der Daten, die man auswerten möchte, und zweitens von den Möglichkei-
ten der benutzten Software (bzgl. des unterstützten Formats, der einbettba-
ren  Objekte  und  der  Vorab-Strukturierung).  Idealtypisch  lassen  sich  vier 
Datenarten unterscheiden: 
 

Typ  A:  Vorhandene  Texte,  die  bereits  digitalisiert  sind  und  keine  be-
sondere Struktur aufweisen 
Typ B: Vorhandene Texte, die erst digitalisiert werden müssen, indem 
sie eingescannt werden 
Typ C: Texte, die nur als Audiodatei, als Tonband- oder Videoaufnah-
me vorliegen und transkribiert werden müssen 
Typ  D:  Texte,  die  formularähnlich  aufgebaut  sind  bzw.  eine  innere 
Gliederung aufweisen, wie etwa die Ergebnisse einer Literaturrecherche 
in Datenbanken oder Antworttexte auf offene Fragen in Interviews 

 
Texte des Typs A erfordern keine weitergehenden Überlegungen. Hier ist 
nur  eine  der  gewählten  Analysesoftware  entsprechende  Umformatierung 
erforderlich, also beispielsweise das Speichern als Dateityp RTF oder DOC. 
Typ  B-Texte  erfordern  zunächst  das  Einscannen.  Im  nächsten  Schritt 
der  Textvorbereitung  ist  dann  zu  entscheiden,  ob  es  sich  um  Texte  des 
Typs A oder D handelt. 

Typ C ist ein Texttyp, der in der qualitativen Sozialforschung besonders 
häufig auftritt. Vor allem offene Interviews werden sehr oft als Datenerhe-
bungsverfahren eingesetzt, sei es in Form von narrativen Interviews, fokus-
sierenden  oder  leitfadengestützten  Interviews.  Auch  die  Daten  aus  Grup-

Texte einscannen 

37 

penerhebungsverfahren  wie  der  Gruppendiskussion  oder  Fokusgruppen 
liegen meist nur als Tonbandmitschnitt vor. 

Texte des Typs D weisen eine innere Struktur auf, die für die Auswer-
tung von Belang ist. Solche Texte verlangen eine Reihe von vorbereitenden 
Maßnahmen, jedenfalls dann, wenn die QDA-Software dazu in der Lage ist, 
vorab strukturierte Dokumente einzulesen und automatisch Zuordnungen 
zu den Strukturelementen vorzunehmen. 

PDF-Dateien 
Mittlerweile  sind  QDA-Programme  auch  in  der  Lage,  Texte  im  PDF-
Format  zu  verarbeiten.  Das  PDF-Format  ist  ein  plattformunabhängiges 
Format, das ursprünglich für Zwecke des Layouts und Druckens entwickelt 
wurde. Dateien im PDF-Format lassen sich gleichgültig auf welchem Bild-
schirm und unter welchem Betriebssystem immer originalgetreu wiederge-
ben.  Für  die  qualitative  Sozialforschung,  wo  in  den  meisten  Fällen  durch 
eigene Erhebungen Daten neu erzeugt werden, spielt das PDF-Format ei-
gentlich keine Rolle, allenfalls wenn bereits in PDF vorhandene Dokumen-
te analysiert werden sollen. PDF basiert auf der Seitenbeschreibungssprache 
Postskript und dies zieht eine Reihe von Konsequenzen nach sich, u.a. dass 
jeweils nur eine Seite bearbeitet werden kann und damit auch alle  Codie-
rungen, die man vornimmt, Anfang und Ende auf der gleichen Seite haben 
müssen. Ferner ist es im Rahmen des Arbeitens mit QDA-Software nicht 
möglich,  PDF-Dokumente  zu  editieren  und  zu  verändern  bzw.  zu  ergän-
zen. Wenn man die Wahl hat, ist das Arbeiten mit Dateien im DOC- oder 
RTF-Format also vorzuziehen. Das gilt bspw. wenn man im Projekt selbst 
Interviews transkribiert: In diesem Fall wäre die Formatierung als PDF ganz 
und gar kontraproduktiv. Die PDF-Option macht es allerdings für neue An-
wendungsfelder interessant, QDA-Software bei der Analyse einzusetzen. 

2.4  Texte einscannen 

Texte, die  nur in Papierform und nicht  digitalisiert vorliegen, müssen zu-
nächst eingescannt werden. Eine dafür gut geeignete Software ist das Pro-
gramm OmniPage zur optischen Zeichenerkennung (Optical Character Re-
cognition, kurz: OCR). OmniPage liest Texte als Bilddatei ein und erkennt 
aus diesem Bild die einzelnen Zeichen, so dass sie anschließend in Textver-

 

38 

Die Texte: Transkription, Vorbereitung und Import 

arbeitungsprogrammen  bearbeitbar  sind.  Auch  PDF-Dateien  können  als 
Grundlage verwendet werden. Ferner können verschiedene Sprachen ein-
gestellt werden, so dass beispielsweise ein englischer Text ebenso erkannt 
werden kann wie ein deutscher. 

2.5  Texte transkribieren, Transkriptionsregeln und 

Transkriptionssysteme 

Unter Transkription versteht man in der empirischen Sozialforschung das 
Verschriftlichen verbaler und ggf. auch von nonverbaler Kommunikation. 
Grundlage ist in der Regel eine Audio- oder Videoaufzeichnung. Wie genau 
und  detailliert  man  transkribiert,  hängt  vom  Untersuchungszeck  und  den 
Forschungsfragen ab. 

Die  Weiterentwicklungen  im  Computerbereich  eröffnen  auch  für  die 
Transkription und die Zugänglichkeit der Originalaufzeichnung neue Mög-
lichkeiten.  Früher  wurden  bspw.  Interviews  zumeist  auf  Kassette  aufge-
nommen und mit einem üblichen Transkriptionsgerät und Fußschalter ab-
getippt.  Diese  Funktionalität  ist  heute  auch  mit  dem  Computer  möglich. 
Die  Aufnahme  kann  mit  geeigneten  digitalen  Aufnahmegeräten  vorge-
nommen werden, sofern diese ein Mikrofon integriert haben oder den An-
schluss  derselben  ermöglichen.  Die  Aufnahme  erfolgt  im  MP3-  oder 
WMA-Format,  die  Qualität  ist  allgemein  gut  bis  sehr  gut.  Natürlich  lässt 
sich auch klassisch aufgenommenes Material am Computer digital umwan-
deln,  dieser  Vorgang  dauert  aber  recht  lange  (entsprechende  Programme 
sind  kostenfrei  erhältlich).  Der  Vorteil  der  digitalen  Verfügbarkeit  der 
Interviewdaten ist dabei nicht nur die erleichterte Archivierung und Erhe-
bung  der  Daten,  sondern  auch  die  leichtere  Verbreitung  (via  Computer) 
und die stetige Verfügbarkeit des Originalmaterials.  

Für die Transkription des digitalen Tonmaterials am Computer existie-
ren eine Reihe von Tools, die das Abspielen der Tondokumente ermögli-
chen (z.B. Winamp oder den Mediaplayer von Microsoft). Allerdings fehlen 
hier  Funktionalitäten,  die  ansonsten  bei  Transkriptionsgeräten  üblich  und 
notwendig  sind,  beispielsweise  das  automatische  Zurückspulen  um  einige 
Sekunden, die Änderung der Abspielgeschwindigkeit oder die genaue zeitli-
che Verortung durch Zeitmarken. Solche Funktionalität findet sich in Spe-
zialsoftware  wie  f4,  Transana,  Transcriber,  ExpressScribe  u.a.  Die  an  der 

Texte transkribieren, Transkriptionsregeln und Transkriptionssysteme 

39 

Universität Marburg entwickelte kostenfreie Software f4 stellt alle notwen-
digen  Funktionen  bereit  und  vereinfacht  die  Transkription  von  digitalem 
Audio- und Videomaterial wesentlich4. Audiodaten, die mit f4 transkribiert 
werden, können mit Zeitmarken versehen werden. Nach dem Import des 
Transkriptes in MAXQDA kann durch einen Klick auf eine Zeitmarke di-
rekt die entsprechende Audiostelle abgespielt werden. So behält man einen 
einfachen Zugang zum Originalmaterial.  

Was machen Forscher, wenn sie ein Interview geführt und dies ggf. als 
Audiodatei  oder  auf  Kassette  aufgenommen  haben  und  mit  der  Analyse 
beginnen wollen? Es lassen sich vier Varianten der weiteren Vorgehenswei-
se bei der Interviewauswertung unterscheiden, die mit mehr oder weniger 
großem Arbeitsaufwand verbunden sind: 
 

1.  Gedächtnisbasierte  Auswertung,  d.h.  die  Analyse  geschieht  auf  der 
Basis  des  eigenen  Gedächtnisses  und  der  während  des  Interviews 
erstellten stichwortartigen Notizen 

2.  Protokollbasierte Analyse, d.h. es wird ein schriftliches summieren-

des Protokoll unmittelbar nach dem Interview erstellt 

3.  Bandbasierte Analyse, d.h. es wird ein abgekürztes Transkript ange-
fertigt, das nur einen Teil des Originaltextes enthält und ansonsten 
den Inhalt des Bandes paraphrasiert 

4.  Transkriptbasierte Analyse, d.h. es wird eine vollständige Transkription 

erstellt, wobei der Genauigkeitsgrad der Transkription variieren kann 

 
Die  erste  Variante,  die  gedächtnisbasierte  Auswertung,  ist  eher  für  den 
Journalismus als für die Wissenschaft charakteristisch. Die zweite Variante, 
das Arbeiten mit einem vom Interviewer erstellten Interviewprotokoll, war 
im  Vor-Computer-Zeitalter  die  Regel.  Diese  protokollbasierte  Form  der 
Auswertung ist heute – teilweise zu Unrecht – fast in Vergessenheit geraten. 
So  stellt  sich  in  der  qualitativen  Sozialforschung  heute  eigentlich  nur  die 
Entscheidung zwischen den beiden letzten Varianten, d.h. die Frage lautet: 
Soll  man  wirklich  alles  transkribieren  und  falls  ja,  in  welcher  Form,  nach 

                                                           
 
4  Diese Software ermöglicht sämtliche Funktionen eines klassischen Transkriptionsgerätes. 
Weitere  Informationen  dazu  und  den  Download  der  Software  findet  man  unter 
www.audiotranskription.de. Zusätzlich findet sich dort auch eine Aufnahmesoftware für 
Interviews  (z.B.  mit  dem  Laptop).  Digitale  Aufnahmegeräte  und  ein  Fußschalter  zur 
leichteren Bedienung sind gegen Gebühr erhältlich. 

 

40 

Die Texte: Transkription, Vorbereitung und Import 

welchen Transkriptionsregeln? Die Beantwortung der Frage hängt zualler-
erst von finanziellen Faktoren ab, denn Texte zu transkribieren ist zeitauf-
wändig und verursacht erhebliche Kosten. Wie viel Stunden genau anfallen, 
hängt in erster Linie vom gewählten Genauigkeitsgrad der Transkription ab. 
Auch für einfache Transkriptionen beträgt der benötigte Zeitaufwand etwa 
das  fünf-  bis  zehnfache  der  Interviewzeit.  Wenn  die  Gleichzeitigkeit  der 
Sprechenden  sowie  Dialektfärbung  und  Intonation  dokumentiert  werden 
sollen, können die Kosten sich weiter vervielfachen. Häufig wird man des-
halb  selektiv  vorgehen  und  nicht  das  gesamte  Material  transkribieren. 
Strauss/Corbin  (1996)  empfehlen  für  Projekte,  die  mit  der  Methode  der 
Grounded Theory arbeiten, die im folgenden Kasten wiedergegebene Vor-
gehensweise bei der Auswahl des zu transkribierenden Materials. 
 

TIPP: Besser zu viel als zu wenig 

„Die Vorgehensweise gemäß dem Analysestil der Grounded Theory ist normalerweise 
wie folgt: Die allerersten Interviews oder Feldnotizen sollten vollständig transkribiert und 
analysiert werden, bevor man das nächste Interview oder die nächste Feldbeobachtung 
durchführt. Das frühe Kodieren leitet die folgenden Feldbeobachtungen und/oder Inter-
views, wie später noch ausgeführt wird. 

Zu einem späteren Zeitpunkt, wenn die Theorie sich entwickelt, mag es sein, dass Sie 

die Tonbänder nur abhören und ausschließlich die Sätze, Abschnitte oder Textstellen 
transkribieren möchten, die mit der entstehenden Theorie in Zusammenhang steht. (Am 
Anfang der Studie ist man sich nicht sicher, was dazugehört und was nicht. Deshalb ist es 
besser, alles zu transkribieren, da sonst wichtige Daten verloren gehen könnten.) Das 
Transkribieren dieser ausgewählten Materialteile erspart einem allerdings nicht unbedingt 
späteres Transkribieren, falls eine zusätzliche oder detaillierte Analyse notwendig erscheint. 
(...) 

Letztendlich muß jeder selbst entscheiden, in welchem Umfang er die Interviews und 
Feldnotizen transkribiert, ausgenommen, ein Prüfungsausschuss oder Betreuer besteht auf 
etwas anderem. Sie müssen festlegen, was Sinn und Zweck Ihrer Studie ist und welchen 
zusätzlichen analytischen (sowohl theoretisch als auch „psychologisch“ sensiblen) Beitrag 
bereits transkribierte versus nicht transkribierte Teile des Materials zur gesamten Untersu-
chung leisten. Eine weitgehend vollständige Transkription mag notwendig sein, um die 
erwünschte Dichte einer Theorie zu erlangen. Darüber hinaus kann man eine vollständige 
Transkription anstreben, wenn man ausreichend Geld zur Verfügung hat, um die Trans-
kription der Bänder zu bezahlen. 

Unabhängig davon, ob man die Tonbänder vollständig oder nur teilweise transkribiert, 

ist es unerlässlich, sie abzuhören. Abhören und Transkribieren sind wesentlich für eine 
vollständige und vielfältige Analyse. Eine abschließende Bemerkung dazu: Besser zu viel 
als zu wenig! Letztendlich liegt aber die Verantwortung und Entscheidung bei jedem 
selbst.“ (Strauss/Corbin 1996: 14 f.) 

 

Texte transkribieren, Transkriptionsregeln und Transkriptionssysteme 

41 

In den Sozialwissenschaften ist es zwar weitgehend Standard, offene Inter-
views aufzuzeichnen, das dann folgende  Verfahren folgt bislang aber kei-
nen streng fixierten Regeln, so lässt sich insbesondere nicht von der Exis-
tenz von Transkriptionsstandards sprechen, vielmehr existieren verschiedene 
Transkriptionsregeln mit unterschiedlicher Genauigkeit nebeneinander. 

Transkriptionssysteme  sind  Regelwerke,  die  genau  festlegen,  wie  ge-
sprochene Sprache in eine fixierte Form übertragen wird. Dabei kommt es 
in jedem Fall zu Informationsverlusten. Je nach Ziel und Zweck der Analy-
se sind solche Verluste hinnehmbar oder aber nicht akzeptabel. Transkrip-
tionssysteme unterscheiden sich vor allem dadurch, ob und wie verschiede-
ne Textmerkmale in der Transkription berücksichtigt werden.  

 

Solche sind u.a.: 
 

(cid:120)  Sprachliche Tönungen und Betonungen 
(cid:120)  Lautstärke 
(cid:120)  Dehnungen 
(cid:120)  Sprechpausen und ihre Länge 
(cid:120)  Überlappungen zwischen den Äußerungen verschiedener Sprecher 
(cid:120)  Dialektfärbungen 
(cid:120)  Gestik,  Mimik  und  paraverbale  Äußerungen  wie  Lachen,  Hüsteln, 

Stöhnen 

(cid:120)  Nicht vollständig ausgesprochen Worte 
(cid:120)  Unverständliche bzw. nicht genau verständliche Äußerungen 

 
Auch  äußere  Merkmale  der  Interviewsituation  können  eine  Rolle  spielen 
und für die Auswertung von Belang sein, z.B. dass jemand den Raum betritt 
oder verlässt, dass das Telefon klingelt und dergleichen mehr. 

Die Methodenliteratur schenkt dem lange vernachlässigten Themenfeld 
Transkription  mittlerweile  mehr  Aufmerksamkeit  (vgl.  Kowall/O’Conell 
2000,  Flick  2007a:  379 ff.,  Lamnek  2005:  403 ff.,  Mayring  2002:  89 ff.). 
Dittmars 2002 verfasstes Lehrbuch „Transkription. Ein Leitfaden mit Auf-
gaben für Studenten, Forscher und Laien“, aus der Perspektive eines Sprach-
wissenschaftlers  geschrieben,  enthält  zahlreiche  auch  für  Sozialwissen-
schaftler  wertvolle  Hinweise.  Er  formuliert  folgende  Leitfragen  für  die 
Auswahl eines Transkriptionssystems (ebd.: 83-85): 
 

1.  Definiere  den  Untersuchungszielen  angemessene,  optimale  Ver-

schriftlichungskategorien. 

 

42 

Die Texte: Transkription, Vorbereitung und Import 

2.  Mache dein System zugänglich (z.B. so leicht und einfach lesbar wie 

möglich). 

3.  Wähle stabile und robuste Zeichen! 
4.  Wähle dein Zeicheninventar nach den Prinzipien der Ökonomie aus! 
5.  Gestalte dein System so, dass es für verschiedene Arbeitszusammen-

hänge und Funktionen anpassungsfähig ist! 

6.  Gestalte  dein  System  so,  dass  es  für  EDV-gestützte  Analysen  von 
sprachlichen und kommunikativen Funktionen leicht und angemes-
sen verwendet werden kann! 

 
Die von Dittmar ausführlich betrachteten Transkriptionssysteme fokussie-
ren  vornehmlich  Dialoge,  Diskurse  und  Konversationen.  Es  handelt  sich 
um folgende Systeme: 
 

(cid:120)  Transkriptionsdesign  der  formalen  Konversationsanalyse.  Ein  Sys-

tem, das die sequentielle Struktur von Redebeiträgen abbildet. 

(cid:120)  HIAT (HalbinterpretativeArbeitsTranskription)5. Hier ist die Trans-
kription  nach  dem  Muster  der  Partitur  als  eine  Endloszeile  organi-
siert, so dass die Synchronizität von Sprechakten erhalten bleibt. 

(cid:120)  Diskurs-Datenbank (DIDA)6. Ein am Institut für deutsche Sprache 
entwickeltes System, das ebenfalls die Aufzeichnung mehrerer Spre-
cher zum Ziel hat. 

(cid:120)  Diskurstranskription nach du Bois – ein System mit leicht erlernba-

ren Symbolen für die Wiedergabe von Diskursen. 

(cid:120)  Gesprächsanalytisches  Transkriptionssystem  (GAT)7  –  ein  linguis-

tisch orientiertes System. 

(cid:120)  Codes for human analysis of transcripts (CHAT)8 – im Kontext der 
Spracherwerbsforschung entwickelt, ebenfalls linguistisch orientiert. 
 
Drei dieser aus dem Bereich der Sprachwissenschaften und der Linguistik 
stammenden Systeme sind speziell für sehr genau umrissene Anwendungen 
konzipiert, nämlich für Diskurse. Die Systeme sind relativ aufwändig und 
auf  detailgenaue  Aufzeichnung  konzentriert.  In  der  qualitativen  Sozialfor-
schung sind  die Anforderungen in der  Regel deutlich geringer und derart 
                                                           
 
5  www.daf.uni-muenchen.de/HIAT/HIAT.htm 
6  www.ids-mannheim.de/prag/dida/ 
7  www.fbls.uni-hannover.de/sdls/schlobi/schrift/GAT/gat.pdf 
8  www.mpi.nl/ISLE/overview/overview_frame.html 

Texte transkribieren, Transkriptionsregeln und Transkriptionssysteme 

43 

genaue  Notationssysteme  werden  nur  relativ  selten  verwendet.  Im  Allge-
meinen verzichtet man etwa auf die genaue Protokollierung von Dialekten 
und sprachlichen Färbungen, auch muss nicht jedes „ähh“ und „mhm“ pro-
tokolliert werden. Der Text wird insgesamt geglättet. Mayring unterscheidet 
zwischen drei Techniken der wörtlichen Transkription (Mayring 2002: 91): 
 

(cid:120)  der Verwendung des internationalen phonetischen Alphabets, 
(cid:120)  der  literarischen  Umschrift,  bei  der  auch  Dialektfärbungen  im  ge-

bräuchlichen Alphabet wiedergegeben werden und 

(cid:120)  der Übertragung in normales Schriftdeutsch. 

 
Die erste Variante wird in den Sozialwissenschaften nur in Ausnahmefällen 
praktiziert. Den häufigsten Fall stellt die Übertragung in normales Schrift-
deutsch dar, wobei mitunter auch Dialektfärbungen mit protokolliert wer-
den. Man muss sich aber darüber im Klaren sein, dass ein so transkribierter 
Text weitaus schwieriger zu lesen ist. Wenn man etwa Sätze zu entziffern 
hat wie „Da ka ma ja, hör ma, da ka ma jarkeener sehn, wenn ick jetzt mit 
meiner Frau inner Ecke liege. Und deshalb bin ick dafür, dass die sechzig 
Matratzn. Is zu viel, Fritz, ja? Stimmt, die – alle, ick meine für die Menge, 
für  die  Größe  des  Raumes,  aba  angebracht  sin  se  trotzdem,  könn  ruhich 
rinnjehen.“ (vgl. Mayring 2002: 91), dürfte sich doch die Frage stellen, ob 
sich die für die Transkription und Auswertung entstehenden Zusatzkosten 
wohl rentieren werden.  

Speziell bei der computerunterstützten Auswertung von Interviewdaten 
haben sich allerdings einige, frühere Transkriptionsregeln als kontraproduk-
tiv erwiesen. Bspw. wird ein gedehnt gesprochenes Wort, dass nach älteren 
Transkriptionsregeln so geschrieben wird „W o r t“, also mit Leerzeichen 
zwischen den Buchstaben, von Suchfunktionen der Textanalyseprogramm 
nicht mehr erfasst.  

Für ein Evaluationsprojekt haben wir ein bewusst einfaches und schnell 
erlernbares  Set  von  Transkriptionsregeln  entworfen  (Kuckartz/Dresing/ 
Rädiker/Stefer 2007: 27), das die spätere Auswertungsarbeit am Computer 
berücksichtigt. Dabei wurden vorhandene und häufig genutzte Transkripti-
onssysteme als Basis verwendet und geeignet modifiziert: 
 

 

44 

Die Texte: Transkription, Vorbereitung und Import 

1.  Es  wird  wörtlich transkribiert, also nicht  lautsprachlich  oder zusammenfassend.  Vor-

handene Dialekte werden nicht mit transkribiert.  

2.  Die Sprache und Interpunktion wird leicht geglättet, d.h. an das Schriftdeutsch ange-
nähert. Bspw. wird aus „Er hatte noch so‘n Buch genannt“ -> „Er hatte noch so ein 
Buch genannt“.  

3.  Alle Angaben, die einen Rückschluss auf eine befragte Person erlauben, werden ano-

nymisiert.  

4.  Deutliche, längere Pausen werden durch Auslassungspunkte (...) markiert.  
5.  Besonders betonte Begriffe werden durch Unterstreichungen gekennzeichnet.  
6.  Zustimmende  bzw.  bestätigende  Lautäußerungen  der  Interviewer  (Mhm,  Aha  etc.) 
werden nicht mit transkribiert, sofern sie den Redefluss der befragten Person nicht un-
terbrechen.  

7.  Einwürfe der jeweils anderen Person werden in Klammern gesetzt.  
8.  Lautäußerungen der befragten Person, die die Aussage unterstützen oder verdeutli-

chen (etwa Lachen oder Seufzen), werden in Klammern notiert.  

9.  Absätze der interviewende Person werden durch ein „I“, die der befragte Person(en) 

durch ein eindeutiges Kürzel, z.B. „B4:“, gekennzeichnet.  

10. Jeder Sprecherwechsel wird durch zweimaliges Drücken der Enter-Taste, also einer 

Leerzeile zwischen den Sprechern deutlich gemacht, um die Lesbarkeit zu erhöhen.  

Abb. 6: Transkriptionsregeln für die computerunterstützte Auswertung 

Dieses Transkriptionssystem lässt sich ohne Probleme umsetzen, Resultat 
sind Transkripte mit einem Erscheinungsbild wie in der folgenden Abbil-
dung.  

I: Also Sie gehen montags in die Vorlesung und dienstags in die Übung und donnerstags 
ins Tutorium. (B3: Genau.) Also drei Tage der Woche gehören der Statistik schon mal, so 
ungefähr. 
 
B3: Genau. Also zumindestens dieses Jahr und letztes Jahr waren es eher zwei. 
 
I: Ja, es geht aber auch um dieses Jahr. Das Letzte brauchen Sie gar nicht (B3: Okay, al-
les  klar)  groß  sich  irgendwie  in  Erinnerung  rufen.  Also,  besuchen  Sie  Arbeitsgruppen? 
Selbst, haben Sie irgendwie einen Freundeskreis oder einen Bekanntenkreis, in dem Sie 
was lernen, sich treffen? 
 
B3:  Ja,  ja,  jetzt,  aber  jetzt  zur  Klausur  hin  eben.  (I:  Ah  ja)  Ja,  leider  vorher  auch  nicht 
(lacht). 
 
I: Treffen Sie sich regelmäßig? 
 
B3: Nee, eben jetzt drei oder vier Mal haben wir uns getroffen. 

Abb. 7: Für die computerunterstützte Auswertung optimiertes Transkript  

Texte transkribieren, Transkriptionsregeln und Transkriptionssysteme 

45 

Die Transkription von paraverbalen Äußerungen kann man so vornehmen, 
dass dafür bestimmte Zeichen benutzt werden, die sonst im Text nicht vor-
kommen,  wie  z.B.  die  Zeichen  „#  <Y$}“.  Da  viele  QDA-Programme  in 
der Lage sind, in den Texten nach Zeichenketten zu suchen, ist man bei ei-
nem so transkribierten Text in der Lage, sich später all jene Passagen zu-
sammenstellen zu lassen, bei denen Befragte etwa gestottert, gezögert oder 
gelacht haben. Sofern das QDA-Programm dies vorsieht, lassen sich solche 
Textstellen dann gleich automatisch vercoden. 

 (,) 
.. 
... 
(Pause) 
mhm 
(.) 
(–) 
(’) 
(?) 
(h) 
(k) 

sicher 
sicher 
(Lachen), 

=  ganz kurzes Absetzen einer Äußerung 
=  kurze Pause 
=  mittlere Pause 
=  lange Pause 
=  Pausenfüller, Rezeptionssignal 
=  Senken der Stimme 
=  Stimme in der Schwebe 
=  Heben der Stimme 
=  Frageintonation 
=  Formulierungshemmung, Drucksen 
=  markierte Korrektur (Hervorheben der endgültigen Version, insbesondere 

bei Mehrfachkorrektur) 

=  auffällige Betonung 
=  gedehnt 
=  Charakterisierung von nichtsprachlichen Vorgängen bzw. Sprechweise, 
Tonfall; (geht raus), die Charakterisierung steht vor den entsprechenden 
Stellen und gilt bis zum Äußerungsungsende, bis zu einer neuen Charakte-
risierung oder bis + 

=  auffällig schneller Anschluss 
=  unverständlich 

& 
(..), (...) 
(Kommt es?)  =  nicht mehr genau verständlich, vermuteter Wortlaut 
A: (cid:170)aber da kam ich nicht weiter 
B: (cid:172)ich möchte doch sagen 
 

=  gleichzeitiges Sprechen, u. U. mit genauer Kennzeichnung des Einsetzens 

Abb. 8: Transkriptionsregeln nach Kallmeyer/Schütze 

Das Notationssystem von Kallmeyer/Schütze (Mayring 2002: 93) ist bezüg-
lich  der  Transkription  von  sprachlichen  Besonderheiten  ausführlicher  als 

 

46 

Die Texte: Transkription, Vorbereitung und Import 

das  oben  dargestellte,  enthält  jedoch  keine  speziellen  Hinweise  für  die 
computerunterstützte Auswertung. Auch dieses Transkriptionssystem lässt 
sich für das Rich-Text-Format ohne Änderungen verwenden. 

Die Wahl des Transkriptionssystems hat sich nach der Art der geplanten 
Analyse zu richten. Plant man eine Konversationsanalyse, ist man viel stär-
ker an Details wie „ähs“ und „mhms“ und der genauen Transkription von 
Pausen interessiert als dies bei einer normalen Interviewstudie der Fall ist. 
Gut  beraten  ist  man  also,  sich  jeweils  die  Fragen  „Muss  das  unbedingt 
transkribiert  werden?“  und  „Will  ich  die  so  festgehaltenen  Phänomene 
überhaupt später interpretieren?“ zu stellen. 

In der qualitativen Sozialforschung beginnt die Auswertung eines Inter-
views  im  Grunde  bereits  vor  der  Transkription:  Man  entwickelt  bereits 
während des Interviews oder beim Abhören des Bandes Auswertungsideen 
und Hypothesen, hat die Interviewsituation und eventuelle Besonderheiten 
im  Kopf  oder  schon  bestimmte  Auffälligkeiten  im  Team  besprochen.  All 
dies ist es wert, festgehalten zu werden. Am besten aber nicht in der Trans-
kription selbst, sondern in Form eines Memos, das man über das Interview 
schreibt. 

Insgesamt sollten die Transkriptionsregeln so gewählt werden, dass man 
sich  bei  der  späteren  Arbeit  mit  dem  QDA-Programm  die  Stärken  des 
Computers zu Nutze machen kann, nämlich dessen Fähigkeiten, in Sekun-
denschnelle  bestimmte  Zeichen  oder  Zeichenketten  aus  Hunderten  von 
Textseiten  herausfinden  zu  können.  Deshalb  ist  es,  gleichgültig  welches 
Transkriptionssystem bevorzugt wird, von entscheidender Bedeutung, dass 
die Bezeichnungen – sei es zur Kennzeichnung des Sprechers, einer bestimm-
ten Frage des Leitfadens oder eines bestimmten Abschnittes der Befragung 
– immer durch den gesamten Text hindurch beibehalten werden: also bei-
spielsweise  zur  Kennzeichnung  des  Interviewers  „I:“.  und  nicht  das  eine 
mal „INTERV:“ oder „Interviewer:“  

Für die spätere lexikalische Suche ist diese Einheitlichkeit der Schreib-
weise  eine  unbedingte  Voraussetzung.  Ferner  muss  die  Sprecherbezeich-
nung für den Fall, dass diese auch im Text vorkommen kann, in Großbuch-
staben  transkribiert  werden,  also  „CARSTEN:“  anstelle  von  „Carsten:“. 
Am Ende eines Sprecherbeitrags sollte ein Zeilenumbruch und eine zusätz-
liche Leerzeile eingefügt werden (vgl. Abb. 7). Zeilenumbrüche sollten aber 
auf keinen Fall zwischen der Sprecherbezeichnung und dem folgenden Text 
platziert werden, ansonsten ist die automatische Zuordnung des Sprechers 

Texte t

transkribieren, 

Transkription

nsregeln und T

Transkriptionss

systeme

47 

n nicht mehr
ederung wege
narrativen  In
Zeilenumbrü
Notwendigkei
arbeitsökono
vorgenomm
nswert, weil d
Texte kann 
rview  vorkom
nd  Daten  ve
dass direkte 
Platzhalter er
deutungen tr
m  „Sommer“, 
de Überblicks

r möglich. A
en ist es auch
nterviews  vor
che einzufüg
it der Anonym
omischen  Gr
men  werden.  E
dies die Trans
die Anonym
mmenden  N
erfährt  man  ä
Rückschlüsse
setzen, welch
ransportieren
„Winter  des
stabelle für d

Aus optischen
h bei längere
rkommen  kö
gen. 
misierung vo
ründen  sollte
Eine  sofortig
skribierenden
isierung erfo
Namen  durch 
ähnlich.  Auc
e nicht mehr 
he noch einig
n, wie etwa „D
s  vorangegan
die eigene En

zu Te
besser
wie  si
wert, g
Fe
zu  be
zunäch
ist nic
der K
weise 
zen.  M
veränd
lassen 
nis we
oder  b
Eine e
erstell
Wa
dieser 
wenn 
fiehlt 
gramm
zu  ko
wünsc
ren  in
Speich

extabschnitten
ren Unterglie
ie  etwa  bei  n
gelegentlich Z
rner ist die N
achten.  Aus 
hst  wörtlich 
ht empfehlen
Korrektur der 
alle  im  Inter
Mit  Orten  un
dert werden, 
 sich durch P
esentliche Be
beim  Datum
entsprechend
t werden. 
as muss bei d
mit  einem 
das gewählte
es sich in de
m zu schreibe
orrigieren.  H
chten Import
n  das  RTF-F
hern unter“ u

n Gründen u
en Textabsch
önnen,  empfe

und der 
hnitten, 
ehlens-

on Forschung
e  die  Transk
ge  Anonymis
n überfordert
olgen, d.h. bei
Decknamen
ch  diese  müs
möglich sind
ge für das Ver
Dorf“, „Klein
ngenen  Jahre
ntschlüsselung

gsdaten 
kription 
sierung 
t. Nach 
ispiels-
n  erset-
ssen  so 
d. Orte 
rständ-
nstadt“ 
es“  etc. 
g sollte 

der Transkrip
QDA-Progr
e QDA-Prog
er Regel, die T
en und vor d
at  der  Text 
tformat der Q
Format  wählt
und stellt als D

ption von Te
ramm  analysi
gramm das E
Texte mit Hi
dem Import s
das  endgült
QDA-Softwa
t  man  in  Wo
Dateityp „Ric

xt noch beac
iert  werden 
ditieren von 
ilfe eines Tex
sehr sorgfälti
tige  Aussehe
are gespeicher
ord  den  Me
ch Text Form

chtet werden,
kann?  Auch
Text erlaubt
xtverarbeitun
ig zu lesen un
en,  wird  er  i
rt. Zum Kon
nübefehl  „D
mat (*.rtf)“ ein

, damit 
h  dann, 
t, emp-
ngspro-
nd ggf. 
im  ge-
nvertie-
Datei  > 
n.  

Abb. 9

: Text in Word

d als Dateityp R

Rich-Text-Form

mat speichern

 

 

48 

Die Texte: T

Transkription, Vo

orbereitung und

d Import 

2.6  A

Analyseeinh

heiten und 

Textgestal

ltung 

dem  man  die
Nachd
n  zu  verschri
Daten
en, nämlich w
werde
wird.  Vor  alle
ren  w
nderen Texte
von an
s  Problem  de
ist  das
möchte man
Regel 
haben und jew
cher h
an sollte sich
Ma
hauend mit D
aussch
twa  bei  der 
d.h.  e
Sprech
her gesonder
ntsprechende
eine en

e  Entscheidu
ftlichen  sind
wie hinsichtlic
em  bei  Trans
en, bei denen
er  Bestimmu
n später einen
weils schnell e
h bereits zum
Details des sp
Analyse  von
rt auszuwerte
e Vorab-Cod

ung  getroffen
d,  muss  noch
ch der Defin
skriptionen  v
n man es mit 
ung  von  Text
n Zugriff auf
erfahren kön
m Zeitpunkt d
päteren Ausw
n  Gruppendi
n sind. In die
dierung vorzu

n  hat,  nach  w
h  eine  zweite
nition von Te
von  Gruppen
mehreren Sp
teinheiten  vir
f die Sprecha
nnen, wer was
der Vorbereit
wertungsverfa
skussionen  e
esem Fall ist 
unehmen.  

welchen  Rege
  Frage  entsc
exteinheiten v
ndiskussionen
prechern zu tu
rulent,  denn 
akte einzelner
s gesagt hat. 
tung der Tex
ahrens beschä
entscheiden, 
es empfehlen

eln  die 
chieden 
verfah-
n  oder 
un hat, 
in  der 
r Spre-

te vor-
äftigen, 
ob  die 
nswert, 

Abb. 10

0: Text als Flie

eßtext mit Eint

teilung in Para

agraphen (im P

Programm MAX

 
XQDA) 

Ferner
Zeilen

r stellt sich d
nnummerieru

die Frage, ob
ung arbeiten w

b man mit ei
will oder ob d

iner fixierten 
diese wie bei 

Zeilenstrukt
Textverarbe

tur mit 
itungs-

Vorstrukturierte Textformen 

49 

programmen flexibel gehandhabt werden soll, d.h. mit der Einstellung der 
Fenster  und  der  Schriftgröße  variieren  kann.  Feste  Zeilenlängen  mit  der 
entsprechenden Zeilennummerierung haben zwar den Vorteil, dass das Zei-
len-Layout ein für allemal festliegt, so dass eine Zeile 523 auch zukünftig 
immer die Zeile 523 bleibt. Diesen Vorteil erkauft man sich mit einer man-
gelnden Flexibilität, die dazu führen kann, dass der Text bei einer veränder-
ten  Fenstergröße  nicht  mehr  vollständig  sichtbar  ist  bzw.  unerwünschte 
Zeilenumbrüche  stattfinden,  die  dem  Text  eine  Art  Zick-Zack-Aussehen 
geben. Heute wird der Text in der Regel so gestaltet, dass nur die Absatz-
zeichen unveränderlich sind und der Text zwischen den Absatzzeichen als 
Fließtext flexibel umgebrochen werden kann. Ein solcher Text (siehe Abb. 
10) enthält eine Absatznummerierung, die als Ortsangabe bei Zitaten die-
nen kann. Der Text innerhalb eines Absatzes ist – wie aus Word gewöhnt – 
Fließtext, der sich den jeweiligen Gegebenheiten des Bildschirms (Fenster-
größe, Bildschirmauflösung) anpasst. Auch das spätere Kopieren von Text-
passagen, z.B. in einen Forschungsbericht, wird so nicht von Zeilenumbrü-
chen gestört. 

2.7  Vorstrukturierte Textformen 

Nicht selten hat man es bei der Textanalyse mit vorstrukturierten Textfor-
men zu tun, d.h. der Text weist von vornherein eine Gliederung in Sektio-
nen, Sprecher, Sinnabschnitte oder Ähnliches auf. Dazu folgende Beispiele: 
 
(cid:120)  Antworttexte auf offene Fragen: Hier hat man es mit verschiedenen 
Befragten und Antworten auf mehrere Fragen zu tun, so dass gleich 
vermerkt werden kann, zu welcher offenen Frage welchen Fragebo-
gens ein Antworttext gehört. 

(cid:120)  Forenbeiträge im Internet: Diese lassen sich eindeutig verschiedenen 
Autoren zuordnen. Bei Onlineseminaren liegen zudem jeweils weite-
re Informationen zu den Autoren vor. 

(cid:120)  Protokolle von Gruppendiskussionen: Hier kann zwischen verschie-

denen Sprechern unterschieden werden. 

(cid:120)  Leitfadenstrukturierte Interviews: Hier kann festgehalten werden, auf 

welchen Punkt des Leitfadens sich eine Antwort bezieht. 

(cid:120)  Abstracts wissenschaftlicher Tagungen: Diese weisen meist eine ähn-
liche Struktur auf: Angaben zu den Autoren, zum Titel des Vortrags, 

 

50 

Die Texte: Transkription, Vorbereitung und Import 

zu der Sitzung, in der dieser gehalten wird, sowie das eigentliche Ab-
stract. 

(cid:120)  Rechercheergebnisse  aus  Literatur-  und  Forschungsdatenbanken 
(z.B. den sozialwissenschaftlichen Datenbanken SOLIS und FORIS): 
Diese  enthalten  eine  vorgegebene  Strukturierung,  z.B.  bei  FORIS 
folgender  Art:  Titel  des  Projektes,  Erhebungszeitraum,  Primärfor-
scher, Datenerhebung, Inhalt, Grundgesamtheit und Auswahl. 

 
Diese Beispiele zeigen, dass es nicht nur wünschbar, sondern teilweise auch 
unumgänglich ist, zwischen den verschiedenen Strukturebenen des Textes 
zu  unterscheiden:  Bei  der  Themenanalyse  von  Kongressabstracts  möchte 
man beispielsweise nur den Teil des Textes inhaltsanalytisch auswerten, der 
den  eigentlichen  inhaltlich  bedeutsamen  Text  des  Abstracts  enthält.  Bei 
Gruppendiskussionen  wird  man  häufig  sprecherspezifisch  auswerten  wol-
len.  Bei  der  Analyse  von  transkribierten  Antworttexten  aus  Fragebogen-
interviews interessieren zunächst nur die auf eine bestimmte Frage gegebe-
nen Antworten und nicht gleichzeitig die Antworten auf alle anderen Fra-
gen. 

Antworttexte  auf  offene  Fragen  auszuwerten,  ist  wohl  das  Muster-
beispiel  für  die  Analyse  strukturierter  Texte.  Diese  Textart  unterscheidet 
sich erheblich von einem Set von qualitativen Interviews oder einer Samm-
lung von Beobachtungsprotokollen: Man hat es mit vergleichsweise vielen, 
aber relativ kurzen Texten zu tun. Während eine durchschnittliche qualita-
tive Studie eine durchschnittliche Populationsgröße von vielleicht 20 bis 80 
Interviews hat, sind es hier gleich mehrere hundert Probanden, deren Texte 
auszuwerten sind. Schon angesichts der großen Zahl erweisen sich die übli-
chen  Einleseprozeduren  der  QDA-Programme  als  ziemlich  unpraktisch, 
denn  bei  einer  Stichprobengröße  von  N=200  müssen  200  Primärdateien 
erstellt und in das QDA-Programm importiert werden. Dies wäre eine recht 
zeitraubende Angelegenheit. Deshalb ist es ratsam, die Möglichkeit zur Vor-
ab-Strukturierung wie sie etwa MAXQDA bietet, bei der Textvorbereitung 
zu nutzen. 

2.8  Zusammenfassung: Die Vorbereitung von Texten 

Fassen wir zusammen: Bevor ein Text mit einem QDA-Programm bearbei-
tet  werden  kann,  sind  eine  Reihe  von  Schritten  zu  durchlaufen  und  Ent-

Zusammenfassung: Die Vorbereitung von Texten 

51 

scheidungen  zu  fällen.  Dabei  erweisen  sich  QDA-Programme,  die  das 
DOC-  oder  Rich-Text-Format  unterstützen,  als  weitgehend  unproblema-
tisch, während bei QDA-Programmen, die lediglich das Nur-Text-Format 
vorsehen,  umfangreichere  Vorarbeiten  erforderlich  sind.  Dies  gilt  insbe-
sondere dann, wenn die Definition von Texteinheiten oder sogar eine feste 
Zeilenlänge verlangt wird. 

Der  Weg  eines  Textes  bis  zum  Import  in  das  QDA-Programm  ist  in 
Abb. 11 dargestellt. Üblicherweise wird nach den vorbereitenden Schritten 
eine Datei im DOC- oder Rich-Text-Format erstellt, von der auch eine Si-
cherheitskopie  angefertigt  werden  sollte.  Eine  andere  Import-Möglichkeit 
besteht  darin,  den  Text  im  Textverarbeitungsprogramm  in  die  Windows-
Zwischenablage zu kopieren und direkt in die QDA-Software einzufügen, 
ohne  dass  der  Umweg  über  eine  zwischengespeicherte  Datei  genommen 
wird. Einige Programme bieten auch die Möglichkeit, Texte über Drag-and-
drop direkt in das Textfenster der QDA-Software einzufügen. 
 

 

digitalisierter 

Text 

digitalisierter 

nicht 

Text 

scannen 

ggf. Struktur- und 
Formatänderungen 

Band-

aufnahme 

digitale 

Aufnahme 

Transkriptionsregeln 

Transkription erstellen mit Word 

korrigieren und anonymisieren 

Backup 

Als DOC/RTF-Datei 

speichern 

Windows 

Zwischenablage

Abb. 11: Der Weg eines Textes in das QDA-Programm 

Import QDA Software 

 

 

52 

Die Texte: Transkription, Vorbereitung und Import 

Vor dem Import von Texten sind im Hinblick auf drei Problemkreise Ent-
scheidungen zu fällen: 
 

(cid:120)  Es muss entschieden werden, ob Texteinheiten definiert werden sollen. 
(cid:120)  Es  muss  entschieden  werden,  ob  ein  fixiertes  Zeilenlayout  sinnvoll 

(cid:120)  Bei Texten, die noch verschriftlicht werden müssen, sind die Trans-

kriptionsregeln zu bestimmen. 

 
Die folgende Checkliste gibt einen schnellen Überblick über die zu treffen-
den Entscheidungen. 

ist. 

Checkliste für die Textaufbereitung 

1.  Bei  gesprochener  Sprache:  Art  der  Transkription  bestimmen,  d.h. 
vollständige Transkription oder nur Teile des Textes verschriftlichen. 

2.  Transkriptionsregeln festlegen. 
3.  Transkribierte Texte Korrektur lesen, ggf. Fehler verbessern. 
4.  Texte falls erforderlich anonymisieren. 
5.  Entscheidung über eingebettete Objekte  (z.B. Grafiken, Fotos etc.) 
treffen, Fotos ggf. so umwandeln, dass sie weniger Speicherplatz be-
nötigen. 

6.  Bei  bereits  digitalisierten  Texten:  Den  Text  in  das  Textverarbei-
tungsprogramm laden und auf spezielle Formatierungen durchsehen. 
Gibt es Zeichenformatierungen und Absatzformatierungen, die un-
günstig für die Analyse sind? 

7.  Ggf. Leerzeilen einfügen, z.B. vor Sprecherwechsel oder zwecks bes-

serer Lesbarkeit des Textes. 

8.  Text im DOC- oder Rich-Text-Format speichern. 
9.  Backup des Textes erstellen und auf externes Medium sichern. 
10. Text in die QDA-Software importieren. 

 
Wer zum ersten Mal mit einer QDA-Software arbeitet, sollte in jedem Fall 
ein oder zwei Texte in das QDA-Programm importieren, einige Probeco-
dierungen  vornehmen  und  unterschiedliche  Suchprozeduren  durchführen, 
bevor  das  gesamte  Textmaterial  transkribiert  wird,.  Vielleicht  wird  man 
dann  entdecken,  dass  bestimmte  Optionen  des  QDA-Programms,  vor  al-
lem die lexikalische Suche und die automatische Codierung, sich nur bei ei-
ner bestimmten Transkriptionsweise nutzen lassen. In einem so frühen Sta-
dium  der  Texttranskriptionen  ist  man  dann  noch  leicht  in  der  Lage,  die 

Praktisc

che Hinweise f

für MAXQDA
A

Transk
siehe d
kriptio

kriptionsrege
die oben dar
onssystems n

eln  entsprech
rgestellten Le
nach den Ziele

hend  zu  mod
eitfragen von 
en der Analy

difizieren.  Ge
Dittmar – d
se richten. 

enerell  muss 
die Wahl des 

53 

sich  – 
Trans-

2.9  P

Praktische 

Hinweise f

für MAXQD

DA 

In MA
denen
könne
gruppe
Text-S
zwei  T
gruppe

AXQDA lass
n die Texte zu
en zudem Tex
en  enthalten 
Sets werden im
Textgruppen 
e „Akteure“ s

sen sich versc
ugeordnet we
xt-Sets gebild
können.  All
m Fenster „L
namens „Ak
sind vier Text

chiedene Ord
erden können
det werden, di
le  importierte
Liste der Texte
kteure“ und „
te (Interview1

dner („Textgr
n. Für tempo
ie Texte aus v
en  Texte,  alle
e“ dargestellt
„Experten“ e
1 bis Interview

ruppen“) defi
oräre Auswer
verschiedenen
e  Textgruppe
. Abb. 12 zeig
existieren, der
w4) zugeordn

inieren, 
rtungen 
n Text-
en  und 
gt, dass 
r  Text-
net. 

 

Abb. 12

2: Definierte T

Textgruppen in

n der Liste der T

Texte 

Texte 
dows 
„Liste
Textgr
einfüg
einzug
könne
len,  P
Da die
standa
Anwe
Windo
prakti

werden  imp
Explorer  au
e  der  Texte“ 
ruppe  mit  de
gen“ gewählt 
geben  bzw.  T
en alle Arten v
owerpoint  Fo
ese Objekte u
ardmäßig unt
ndungsprogr
ows-Zwische
sch, einen ne

portiert,  indem
uf  die  gewün
gezogen  we
er  rechten  M
wird. Die Op
Transkription
von Window
olien,  Forme
u.U. viel Plat
erbunden we
rammen könn
enablage  imp
euen Text mit

m  sie  einfach
nschte  Textgr
erden.  Altern
Maustaste  ang
ption „Texte 
nen  direkt  in 
s OLE Objek
el-Editor  Obj
tz benötigen, 
erden. Texte 
nen direkt pe
portiert  werd
t dem Tasten

h  mit  der  M
ruppe  bzw.  a
ativ  kann  au
geklickt  und 
erstellen“ erla
MAXQDA
kten enthalten
ekte,  Fotos  u
kann der Im
aus dem Int
er Drag-and-
den.  Dabei  e
nkürzel Strg+

Maus  aus  dem
auf  die  Wurz
uch  die  gewü
die  Option 
aubt es, selbst
zu  erstellen.
n, z.B.: Excel 
und  Anderes
mport von Ob
ternet oder an
drop oder üb
erweist  es  si
T zu erzeuge

m  Win-
zel  der 
ünschte 
„Texte 
t Texte 
.  Texte 
Tabel-
s  mehr. 
bjekten 
nderen 
ber die 
ich  als 
en. 

 

54 

Die Texte: Transkription, Vorbereitung und Import 

Vorab-strukturierte Texte können entweder in Form einer Tabelle oder 
mit  Hilfe  des  Text-Preprozessors  importiert  werden.  Einfacher  ist  die 
Textvorbereitung als Tabelle, in welcher die Texte die Zeilen und zu codie-
renden Segmente die Spalten bilden. Mit Excel lassen sich Tabellen dieser 
Art einfach erstellen und als CSV-Datei speichern. Für den prototypischen 
Anwendungsfall von Antworttexten auf offene Fragen ist eine Tabelle nach 
folgendem Muster verlangt: 

Textgruppe 

Textname 

Frage 1 

Frage 2 

Bürger 

Bürger 

I1 

I2 

Hier steht der Antworttext 
von I1 auf Frage 1 

Hier steht der Antworttext 
von I1 auf Frage 2 

Hier steht der Antworttext 
von I2 auf Frage 1 

Hier steht der Antworttext 
von I2 auf Frage 2 

Abb. 13: Vorab-strukturierte Texte als Tabelle importieren 

Die Tabelle enthält zwei Texte – I1 und I2 – und die Antworten beider Per-
sonen auf zwei Fragen. Die Überschriften in der Kopfzeile – hier „Frage 1“ 
und „Frage 2“ werden von MAXQDA als Kategorienname verwendet. 

Eine  weitere  Funktion  für  vorab-strukturierte  Textformen  stellt  der 
Text-Preprozessor dar: Hiermit können beispielsweise viele Texte hinterei-
nander in einer einzigen Datei eingegeben werden. Jeder Text muss dann 
mit einem Identifikator #TEXT beginnen, hinter dem der Textname anzu-
geben  ist.  Auch  können  die  Texte  automatisch  nummeriert  werden.  Auf 
diese  Weise  lassen  sich  Hunderte  von  Einlesevorgängen  erheblich  abkür-
zen.  

Weiterhin  ermöglicht  der  Text-Preprozessor  eine  Vorab-Zuordnung 
von Kategorien. Dies kann bspw. auch für die Auswertung von Antwort-
texten auf offene Fragen genutzt werden. Angenommen, in einem Frage-
bogen seien drei offene Fragen enthalten, die für die Auswertung transkri-
biert werden sollen. Die Antworttexte werden nun schon bei der Transkrip-
tion durch Einfügen eines entsprechenden Deskriptors den jeweiligen Fra-
gen  zugeordnet.  Dies  erspart  die  Mühe,  erst  nach  dem  Einlesen  in  allen 
Texten  diese  Zuordnung  manuell  vornehmen  zu  müssen.  Dazu  muss  in 
MAXQDA  eine  bestimmte  Eingabesyntax  beachtet  werden.  Vor  jedem 
Antworttext ist eine Zeile mit dem Schlüsselwort #CODE einzufügen, da-
hinter folgt das jeweilige Codewort, z.B. „Frage 1“, oder ein entsprechendes 
Kürzel (z.B. nur „1“), das später leicht durch die komplette Kategorienbe-

Praktische Hinweise für MAXQDA 

55 

zeichnung ersetzt werden kann. Der Antworttext wird jeweils mit einer Zei-
le, die nur das Schlüsselwort #ENDCODE enthält, abgeschlossen. 

#TEXTtextname 
#CODEcodename 
hier folgt der Text zu Frage 1 
#ENDCODE 
#CODEcodename 
hier folgt der Text zu Frage 2 
#ENDCODE 
#TEXTtextname 
… 
hier folgt der zweite Text nach dem gleichen Schema 
… 
#TEXTtextname 
… 
hier folgt der dritte Text nach dem gleichen Schema 
... 

Abb. 14: Beispiel für die Eingabe von vorab codierten Texten 

MAXQDA offeriert in den Suchfunktionen die Möglichkeit zur automati-
schen Codierung von Fundstellen. Dies kann genutzt werden, um Textab-
schnitte  automatisch  bestimmten  Sprechern  zuzuordnen  (z.B.  bei  Grup-
pendiskussionen). In diesem Fall muss die Transkription so gestaltet wer-
den, dass jeder Beitrag eines Sprechers mit der Sprecherbezeichnung – zur 
besseren Unterscheidung am besten in Großbuchstaben – beginnt. Der je-
weilige Sprechakt selbst darf nur ein Absatzzeichen am Ende und sonst kei-
ne Absatzzeichen enthalten. 

Übungen (mit MAXQDA) 
Vorab ein Hinweis zu den Übungsaufgaben in diesem Buch: Um die Auf-
gaben  bearbeiten  zu  können,  muss  aus  dem  Internet  (ww.maxqda.de)  die 
Demoversion  von  MAXQDA  heruntergeladen  werden.  Diese  ist  für  30 
Tage uneingeschränkt funktionsfähig. Sie erlaubt nicht nur die Bearbeitung 
der Übungen, sondern ermöglicht es auch, mit eigenen Daten zu arbeiten.9 

                                                           
 
9  Ein  MAXQDA-Tutorial,  das  die  technische  Handhabung  des  Programms  Schritt  für 

Schritt erklärt, ist ebenfalls auf der Webseite verfügbar. 

 

56 

Die Texte: Transkription, Vorbereitung und Import 

Am Ende dieses Kapitels sollten Sie in der Lage sein, Ihre Texte für die 
computergestützte Analyse aufzubereiten, d.h. die Texttranskription zu pla-
nen, ein sinnvolles Textlayout zu bestimmen und die Frage der Definition 
von Texteinheiten zu entscheiden. 
 

1.  Wählen Sie einen bei Ihnen vorhandenen Text oder den in der De-
moversion von MAXQDA im Unterordner „Examples/Ger“ enthal-
tenen Beispieltext „interview1.rtf“ aus. Öffnen Sie den Text mit Ih-
rem Textverarbeitungsprogramm. Überlegen Sie, welche verschiede-
nen Gestaltungsmöglichkeiten es für die Transkription gibt.  

2.  Ist es sinnvoll, bei diesem Text Texteinheiten für die spätere Codie-
rung zu definieren? Versuchen Sie die Vor- und Nachteile abzuwägen. 
3.  Starten Sie nun MAXQDA und tragen Sie ihren Namen in das Be-
nutzerfeld  ein.  Erstellen  Sie  ein  neues  Projekt  mit  dem  Namen 
„test1“. Nach der Bestätigung erscheint das Feld „Tipps und Tricks“, 
lesen Sie die Information, schauen Sie sich auch die nächsten zwei 
Tipps an und schließen danach das Feld. 

4.  Fügen Sie eine neue Textgruppe mit dem Namen „Bürger“ ein. 
5.  Importieren Sie die Texte „interview1“ bis „interview4“ in die Text-
gruppe  „Bürger“.  Diese  Beispieltexte  befinden  sich  im  Ordner  der 
deutschen Beispieldateien von MAXQDA im Unterordner „Examp-
les/Ger“. 

6.  Erzeugen  Sie  einen  neuen  leeren  Text,  indem  Sie  in  der  Liste  der 

Texte die Tastenkombination Strg+t drücken. 

7.  Markieren  Sie  einen  Abschnitt  (inklusive  Grafik)  im  Internet-
Browser und fügen Sie ihn durch Kopieren direkt in MAXQDA ein. 
Was passiert? 

8.  Kopieren Sie nun den Abschnitt zuerst in Word und speichern ihn 
dort als RTF-Datei ab. Jetzt importieren Sie die Datei in MAXQDA 
(Word vorher schließen). Nennen Sie den Text „Webseite“. Achten 
Sie darauf, die Optionen so einzustellen (Projekt > Optionen), dass 
auch Objekte importiert werden. 

 

3  Die Kategorien und das Codieren von Texten 

 

3.1  Über Kategorien 

Alle  qualitativen  Verfahren  der  Textanalyse  beginnen  mit  Textarbeit,  d.h. 
der  sorgfältigen  Lektüre  des  Textmaterials.  Auch  bei  der  computerunter-
stützten  Analyseform  ziehen  Wissenschaftler  es  meist  vor,  diesen  ersten 
Arbeitsschritt  nach  dem  Importieren  eines  Textes  in  die  QDA-Software 
nicht  am  Bildschirm  vorzunehmen.  In  der  Forschungspraxis  hat  es  sich 
bewährt,  zunächst  eine  Arbeitsfassung  der  einzelnen  Texte  mit  Absatz-
nummerierung  zu  erstellen  und  auszudrucken.  Diese  Papierfassung  des 
Textes ist es, mit der zunächst gearbeitet wird. Vor allem dann, wenn man 
mit Kolleginnen und Kollegen im Team zusammen arbeitet, ist es von Vor-
teil über eine solche sequentiell nummerierte Textfassung zu verfügen. So 
kann man sich bei der gemeinsamen Diskussion von Textpassagen besser 
verständigen  und  unter  Angabe  der  Absatznummer  Textstellen  leicht  fin-
den. 

Auch während der computerunterstützten Analyse qualitativer Daten ist 
es nicht der Computer, der denkt, interpretiert und codiert, sondern immer 
noch der Mensch. Qualitative Daten sind gegenüber der datenbankmäßigen 
Erfassung und automatischen Codierung ein sehr resistentes Material. Des-
halb ist es trotz der gestiegenen Möglichkeiten von automatischen Codier-
verfahren die intellektuelle Codierung, die im Zentrum von QDA-Programmen 
steht. Wenn hier von Codieren die Rede ist, so wird darunter zunächst ganz 
allgemein die Zuordnung von Kategorien zu relevanten Textpassagen bzw. 
die Klassifikation von Textmerkmalen verstanden. Unter einem Code oder 
einer Kategorie ist dabei ein Bezeichner, ein Label, zu verstehen, der Text-
stellen  zugeordnet  wird.  Es  kann  sich  dabei  um  ein  einzelnes  Wort  (z.B. 
„Einstellungen“,  „Helfersyndrom“),  sogar  nur  um  ein  einzelnes  Zeichen 
oder um eine Mehrwortkombination handeln (z.B. „Mutterbindung in der 
frühen Kindheit“). 

58 

Die Kategorien und das Codieren von Texten 

Die Codierung geschieht in der Regel also nicht automatisch, z.B. auf-
grund  bestimmter  Worte  oder  Wortkombinationen  im  Text,  sondern  ist 
Resultat einer menschlichen Interpretationsleistung, welche natürlich zwin-
gend  die  Lektüre  und  die  Durcharbeitung  des  Textes  voraussetzt.  In  der 
sozialwissenschaftlichen Methodenliteratur wird dem Thema Kategorien und 
Kategorienfindung  keine  sonderliche  Aufmerksamkeit  gewidmet.  Was  über-
haupt  eine  Kategorie  ist  und  wie  man  Kategorien  bildet,  wird  in  Me-
thodentexten  meist  nicht  weiter  problematisiert,  sondern  stillschweigend 
vorausgesetzt, d.h. man unterstellt, dass die Fähigkeit zum Bilden von Ka-
tegorien  als  Alltagstechnik  bei  jedem  vorhanden  ist.  Im  Methodenlexikon 
von Kriz und Lisch heißt es etwa: „Patentrezepte für die Kategorienbildung 
im engeren Sinne gibt es nicht; je nach Untersuchungsgegenstand müssen 
dazu immer wieder neue Entscheidungen gefällt werden“ (Kriz/Lisch 1988: 
134). In den Inhaltsregistern der bekannten deutschsprachigen Methoden-
lehrbücher sucht man meist vergeblich nach dem Stichwort Kategorie (so bei 
Diekmann 2007). Wenn man überhaupt einen Eintrag findet, wird häufig 
auf Textseiten verwiesen, in denen von speziellen Analyseverfahren die Re-
de ist und in diesem Kontext dann auch von Kategorien, etwa von Beobach-
tungskategorien,  Kategoriensystemen  in  der  klassischen  Inhaltsanalyse  u.ä.  (Schnell/ 
Hill/Esser  2005:  394).  Der  Kategorienbegriff  und  die  Kategorienbildung 
selbst werden indes nicht zum Gegenstand gemacht. Häufig wird der Be-
griff Kategorie synonym mit Variable, Merkmal oder Merkmalsausprägung 
benutzt. Im Forschungskonzept des Kritischen Rationalismus werden Ka-
tegorien als Operationalisierungen der in den Hypothesen enthaltenen Be-
griffe aufgefasst. Sie haben hier also den Charakter von Nominaldefinitio-
nen. Das Gegenstück zu dieser deduktiven Vorgehensweise stellt die induk-
tive Kategorienbildung dar, bei welcher der kategoriale Bezugsrahmen aus 
den  Daten  selbst  konstruiert  wird.  Bei  genauerem  Hinschauen  zeigt  sich 
allerdings oft, dass das Vor- und Kontextwissen des Forschers dabei einen 
nicht zu unterschätzenden Einfluss hat (vgl. etwa die protokollierte Semi-
narsitzung „Umgang mit Schmerz“ in Strauss 1991: 74 ff.). 

Hier soll es nicht um die allgemeine Betrachtung von Vorgehensweisen 
bei der Kategorienbildung in der sozialwissenschaftlichen Forschung gehen, 
sondern um die spezifische Perspektive der qualitativ orientierten Text- und 
Inhaltsanalyse. Kategorie bedeutet hier nichts anderes als einen Begriff, ein 
Label, das vom Bearbeiter der Texte definiert wird, d.h. ein Wort, mehrere 
Wörter oder eine Kurzsatz, die nicht notwendigerweise auch im Text vor-

Über Kategorien 

59 

kommen müssen. Als Beispiel mag man sich die der Maslowschen Bedürf-
nishierarchie entnommene Kategorie „Grundbedürfnis“ vor Augen führen. 
Die Kategorie kann benutzt werden, um verschiedene in einem Interview-
text  präsente  Bedürfnisse  zu  differenzieren  –  möglicherweise  nimmt  ein 
Interviewter aber an keiner Stelle des Interviews das Wort Bedürfnisse selbst 
in  den  Mund.  Andere  Beispiele  für  Kategorien  sind  ethnische  Identität  oder 
autoritärer  Umgangsstil.  Es  sind  analytische  Kategorien,  die  benutzt  werden, 
um bestimmte Phänomene im Text zu identifizieren und gegebenenfalls im 
späteren  Auswertungsprozess  wieder  zu  finden.  Kategorien  müssen  also 
keineswegs Begriffe der Akteure sein, die sich im Interviewtext finden las-
sen. 

In der Methodenliteratur und in der Praxis der Sozialforschung sind un-
terschiedliche Vorschläge für das Codieren gemacht worden. Es lassen sich 
u.a.  folgende  Formen  des  Codierens  in  der  qualitativen  Forschung  unter-
scheiden: 
 

(cid:120)  Paraphrasierendes Codieren 
(cid:120)  Thematisches Codieren 
(cid:120)  Theoretisches Codieren 
(cid:120)  Episodisches Codieren 
(cid:120)  Codieren von Fakten 
(cid:120)  Bewertendes Codieren 

 
Das Codieren von Fakten und das bewertende Codieren sind eher Gegen-
stand einer quantitativ orientierten Inhaltsanalyse  (vgl. Merten 1995). Das 
episodische Codieren, bei dem nur besonders auffällige Stellen eines Textes 
codiert werden, ist kein Verfahren systematischer qualitativer Datenanalyse. 
Es geschieht entweder im  Rahmen einer mehr  an Alltagstechniken  orien-
tierten Herangehensweise, z. B. im Journalismus, oder ist eingebettet in um-
fassendere  Auswertungsstrategien  wie  etwa  die  Suche  nach  so  genannten 
natürlichen Codes in einem an der Grounded Theory orientierten Arbeits-
stil. Eine gewisse Rolle spielt es im Marketing und in der Marktforschung, 
wo Kreativität und die Generierung von Ideen häufig eine größere Bedeu-
tung haben als Systematisierung und Zusammenfassung. 

Die  im  Kapitel  4  vorgestellten  methodischen  Ansätze  spiegeln  die  in 
den Sozialwissenschaften entwickelten Hauptstile des Codierens wider: Die 
Vorgehensweise der Grounded Theory kann als Beispiel für theoretisches 
Codieren  dienen,  die  zusammenfassende  Inhaltsanalyse  nach  Mayring  als 

 

60 

Die Kategorien und das Codieren von Texten 

Beispiel für das paraphrasierende Verfahren und die Vorgehensweise von 
Hopf u.a. als Beispiel für thematisches Codieren. 

3.2  Kategorientypen 

Der Vorgang des Codierens lässt sich aus zwei Perspektiven betrachten, die 
analytisch als deduktive und induktive Vorgehensweise bezeichnet werden 
können: 

Die  erste  Perspektive  entspricht  der  deduktiven  Variante:  Ein  Phäno-
men des Textes wird als Indikator für einen theoretischen Tatbestand ge-
nommen. Neben dem Text entsteht so quasi eine Sequenz von Codes, die 
das wiedergibt, was unter theoretischen Gesichtspunkten, unter den analyti-
schen Perspektiven der definierten Kategorien, von diesem Text zu halten 
ist.  Die  Perspektive  ist  der  quantitativen  Inhaltsanalyse  nicht  unähnlich: 
Nach  dem  Codiervorgang  steht  dann  die  Analyse  der  Kategorien,  ihrer 
Korrelationen und Beziehungsmuster im Mittelpunkt. 

Die andere, mehr induktiv orientierte Perspektive entwickelt die Kate-
gorien erst im Laufe der Analyse aus den Texten. Aus dieser Blickrichtung 
werden Textabschnitte ausgeschnitten und vorläufigen Kategorien zugewie-
sen,  gewissermaßen  hinter  diese  Karteireiter  der  Kategorien  eingeordnet. 
Hier  wird  der  Text  nicht  durch  die  Codierung  überflüssig,  sondern  dient 
dazu, im nächsten Schritt des Analyseprozesses Kategorien weiterzuentwi-
ckeln, zusammenzufassen, zu dimensionalisieren und auszudifferenzieren. 
In  Abhängigkeit  von  der  jeweiligen  Forschungsmethode  und  der  Wis-
senschaftsdisziplin existieren unterschiedliche  Bezeichnungen für das, was 
hier als Kategorien bezeichnet wird. Mitunter spricht man von Stichworten, 
von Schlagworten, von Codes oder wie in der Tradition der Inhaltsanalyse von 
Kategorien.  Mit  Ausnahme  der  Grounded  Theory  gibt  es  in  der  Literatur 
über qualitative Methoden nur wenige Beiträge, die sich mit dem grundle-
genden Vorgang des Codierens im Detail befassen. Unter dem Begriff Co-
dieren werden sehr verschiedene Vorgehensweisen mit differenten Gütekri-
terien subsumiert: 

Eine  erste  Variante  begreift  Codieren  als  eine  eher  explorierende  und 
organisierende Tätigkeit: Ein Text wird intensiv bearbeitet, wichtige Text-
stellen  werden  angestrichen  und  Bemerkungen  an  den  Rand  geschrieben. 
Hier werden im Grunde explorative Hinweisschilder gesetzt, was eine völlig an-

Kategorientypen 

61 

dere Arbeitsweise darstellt als das Codieren im Sinne der quantitativen In-
haltsanalyse, an das Maßstäbe von Reliabilität und Validität angelegt werden 
müssen. 

Eine zweite Variante von Codieren identifiziert ein Textsegment als ei-
nen Indikator für das Vorliegen einer bestimmten, genau definierten Kate-
gorie  eines  u.U.  sehr  komplexen  Kategoriensystems.  Es  handelt  sich  um 
eine sorgfältige, kontrollierte Tätigkeit, bei der sich auch Probleme der Re-
liabilität,  etwa  in  Bezug  auf  die  Übereinstimmung  von  unterschiedlichen 
Codierern,  stellen.  Hier  geht  es,  anders  als  bei  der  ersten  Variante  nicht 
darum, Ideen festzuhalten und Begriffe und Formulierungen des Textes für 
die spätere Auswertung zugänglich zu machen, sondern um die theoretische 
Durchdringung und Bewertung der Daten. 

Wenn man die Charakteristika von Codes betrachtet, lassen sich drei Ar-

ten von Codes unterscheiden: 

1. Faktencodes 
Codes,  die  eine  bestimmte  „objektive“  Gegebenheit  zum  Ausdruck  brin-
gen:  Jemand  ist  männlich.  Jemand  kennt  Person  X  oder  Y.  Jemand  sagt, 
dass  er  hauptsächlich  an  Verkehrspolitik  interessiert  ist.  Bei  Faktencodes 
existieren Kriterien für Reliabilität – sowohl für Inter-Coder- wie für Intra-
Coder-Reliabilität.  Inter-Coder-Reliabilität  meint,  dass  mehrere  Codierer 
unabhängig  voneinander  zum  gleichen  Urteil  kommen;  Intra-Coder-
Reliabilität, dass die gleiche codierende Person im hypothetischen Fall, dass 
sie die Stelle zweimal codieren würde, zum gleichen Ergebnis kommt. 

2. Thematische Codes 
Codes dienen als Zeiger auf bestimmte Themen im Text. Ähnlich wie Ver-
kehrsschilder an der Landstraße gelten die Codes nur  als Hinweis darauf, 
dass man an einer bestimmten Stelle die so benannten Themen, Phänome-
ne, Ereignisse, Argumente etc. findet. Es gibt wenig Gütekriterien für ein 
solches Hinweisschild, außer, dass die Richtung stimmt, und dass man tat-
sächlich zu dem Versprochenen hinkommt, wenn man dem Hinweis folgt. 
Niemand wird aber erwarten, dass das Schild mit einer Abweichung von 0,0 
Grad auf den gesuchten Ort zeigt. 

 

62 

Die Kategorien und das Codieren von Texten 

3. Bewertende Codes 
Diese ähneln Faktencodes, sind aber komplexer und stärker auf extern vor-
gegebene  Bewertungsmaßstäbe  bezogen.  Während  Faktencodes  noch  ge-
wissermaßen dem Alltagswissen und dem Common-sense-Urteilsvermögen 
zugänglich sind – man muss nicht Sozialwissenschaftler sein um die oben 
genannten Angaben zu codieren – kommt es hier auf die Bewertung an. Je-
mand wird über sein Verhältnis zu Organisationsformen befragt, und man 
ordnet  diese  Äußerungen  als  „Befragter  bevorzugt  das  Netzwerkmodell“ 
ein. Nur auf der Basis von Hintergrundwissen und speziellem Codierertrai-
ning sind solche Einstufungen verlässlich möglich. 
 
Die unterschiedlichen Funktionen von Codes spiegeln sich in der Grounded 
Theory  in  den  verschiedenen  Bezeichnungen  wider,  die  dort  für  Codes 
verwendet werden. So findet man etwa die Begriffe Code, Kategorie, Konzept, 
Subkategorie,  Dimension  und  Merkmal.  Allerdings  kann  die  gegenseitige  Ab-
grenzung dieser Begriffe, wie sie etwa bei Strauss und Corbin (1996: 43 ff.) 
vorgenommen wird, nicht überzeugen. Die Verwendung unterschiedlicher 
Bezeichnungen führt eher zur Verwirrung, als dass sie Klarheit schafft. Es 
soll deshalb hier auf den Versuch verzichtet werden, je nach Abstraktions-
niveau  unterschiedliche  Namen  für  Kategorien  einzuführen.  Hier  sollen 
Kategorien als Werkzeuge zur Phänomenklassifizierung mit der Möglichkeit der Bil-
dung von Unterklassen begriffen werden. Für die Arbeit mit QDA-Software ist 
es  unerheblich,  ob  die  Kategorienbildung  deduktiv  oder  induktiv  erfolgt. 
Die Gleichsetzung von qualitativer Methodik mit induktiver Kategorienbil-
dung und quantitativer Methodik mit deduktiver Kategorienbildung greift 
zu kurz, denn in der Praxis hat man es auch in der qualitativen Forschung 
meist mit Mischformen zu tun. Auf der Basis von Vorinformationen, die 
man über den Untersuchungsgegenstand besitzt, wird häufig für die Erhe-
bung ein Interviewleitfaden konstruiert, der auch als Grundgerüst für das 
Kategoriensystem dient. Dieses wird dann anhand des Untersuchungsmate-
rials induktiv ausdifferenziert und präzisiert. Oft ist es ein Set von (forma-
len)  Grobkategorien  wie  im  Falle  des  Codierparadigmas  von  Glaser  und 
Strauss,  das  die  Art  von  Fragen  vorgibt,  die  man  an  das  Datenmaterial 
stellt. 

Mit  der  Codierung  von  Textsegmenten  und  der  späteren  Zusammen-
stellung von Textsegmenten der gleichen Kategorie geht notwendigerweise 
ein Prozess der Dekontextualisierung einher. Schon in ihren Anfängen wurde 

Kategorientypen 

63 

gegen die quantitative Inhaltsanalyse von den Kritikern – so von Kracauer 
(1952) – das Argument vorgebracht, sie sei zu „atomistisch“, weil sie Texte 
lediglich  auf  der  Basis  von  Worten  und  Worthäufigkeiten  analysiere.  Ein 
Stück  Atomismus  ist  auch  der  qualitativen  Vorgehensweise  der  Seg-
mentierung und Codierung von Textpassagen inhärent. Zwei entscheidende 
Unterschiede zwischen dieser Technik und der quantitativ orientierten In-
haltsanalyse sind aber hervorzuheben: 

Erstens  stellen  die  codierten  Segmente  etwas  anderes  dar  als  codierte 
Worte oder Zeichenketten: Sie sind codierte Sinneinheiten und keine forma-
len Einheiten wie ein Wort oder eine Zeichenkette.  Die Codierung ist se-
mantischer und nicht syntaktischer Art. In der quantitativen Inhaltsanalyse sind 
die  Kategorien  das  Messinstrument,  mit  dem  ein  Text  „gemessen“  wird. 
Nach vollzogener Messung wird mit den Zahlenwerten der so entstandenen 
Datenmatrix weitergearbeitet. Zusammenhänge in der Datenmatrix werden 
nicht mit interpretativen, sondern mit statistischen Methoden analysiert. 

Zweitens ist mit der Codierung in der klassischen quantitativen Inhalts-
analyse der Text quasi abgearbeitet: Man greift nicht mehr auf ihn zurück 
und kann dies während des weiteren Auswertungsprozesses auch gar nicht 
mehr ohne weiteres tun. Anders im Fall des Arbeitens mit QDA-Software, 
wo jederzeit wieder vom codierten Segment in den größeren Kontext des 
Originaltextes zurückgesprungen werden kann. 

Anselm Strauss bezeichnet eine neue Kategorie als „the may be tonight 
promise of a possible theory“. Kategorien sind also keineswegs nur deskrip-
tiv und keinesfalls ohne Effekte auf den Analyseprozess. Sie engen einer-
seits  ein  und  eröffnen  andererseits  neue  Perspektiven.  Insofern  ist  es 
selbstverständlich, dass Kategoriensysteme nicht nur Freude bereiten, son-
dern auch Kritiker auf den Plan rufen, die die Einengung des Blicks (nega-
tiv formuliert das Schubladendenken) kritisieren und jene Blickperspektiven 
einklagen, die durch die Brille des Kategoriensystems nicht mehr zu sehen 
sind. Meistens emergieren Kategorien nicht „von selbst“ aus dem Material 
– jedenfalls nicht mehr als Melodien und Sonaten aus dem deutschen Wald. 
Gleichwohl  mag  es  dem  Komponisten  helfen,  durch  Wald  und  Flur  zu 
streifen, auf dass sich die Melodien von selbst einstellen. Ebenso mag das 
vorurteilslose genaue Studieren eines Textes bewirken, dass man analytische 
Kategorien (er)findet. In der Regel steckt hinter  brauchbaren Kategorien-
systemen  aber  eher  harte  Arbeit,  denn  die  Kategorien  fallen  nicht  vom 
Himmel wie das biblische Manna in der Wüste. 

 

64 

Die Kategorien und das Codieren von Texten 

3.3  Codieren mit QDA-Software 

Für das Codieren der Texte mit Hilfe von QDA-Software haben sich un-
terschiedliche Arbeitsweisen herausgebildet: 
 

(cid:120)  Eher  traditionell  und  zunehmend  seltener  anzutreffen  ist  eine  Ar-
beitsweise,  die  als  „Two-step-Codieren“  bezeichnet  wird:  Man  er-
stellt einen Papierausdruck des Textes und markiert dort die relevan-
ten  Stellen  mit  einem  Textmarker.  Am  Rand  macht  man  Notizen 
und  vermerkt  den  Code,  den  man  der  Textstelle  zuordnen  will.  In 
einem  gesonderten  Arbeitsgang  werden  anschließend  diese  Codie-
rungen mit Hilfe der QDA-Software in den Computer eingegeben. 

(cid:120)  Die  zweite,  heute  in  der  Regel  praktizierte  Variante  verzichtet  auf 
den Zwischenschritt des Markierens und Codierens auf dem Papier-
ausdruck. Die Texte werden direkt am Bildschirm codiert. Man blät-
tert den Text von vorne nach hinten durch, markiert und codiert so-
fort alle Textstellen. 

 
Die Segmentierung und Kategorisierung hat sich zu einer Art Basistechnik 
der  computergestützten  Analyse  qualitativer  Daten  entwickelt:  Inhaltlich 
bedeutsame  Textpassagen  werden  identifiziert  und  es  wird  ein  Code  zu-
geordnet. Hat man beispielsweise eine Textpassage identifiziert, in der eine 
Befragte sich über ihre Wunschvorstellungen äußert, so weist man diesem 
Textsegment den Code „Wunschprojektion“ zu. 

Dieses Grundmuster der Erschließung von Textinhalten wird im Engli-
schen als „Cut-and-paste-Technik“ bezeichnet. Es orientiert sich an der im 
Vor-Computer-Zeitalter betriebenen handwerklichen Auswertung von Tex-
ten: Mit Schere, Kleber und Karteikarten ausgestattet, bearbeitet man den 
Textkorpus und schneidet jene Stellen aus, die zu einem bestimmten The-
ma  relevant  sind  (vgl.  Lofland/Lofland  1984:  134).  Auf  die  Karteikarte 
schreibt man zuoberst das Stichwort, vermerkt die Herkunft des Abschnitts 
und klebt den Textabschnitt auf. Eine solche Karteikarte hat dann etwa fol-
gendes Aussehen: 

Codieren mit QDA-Software 

65 

KARTE NNN 
Stichwort: Wunschprojektion 
Herkunft: Interview mit Frau Wenger, S.3: Absatz 15-17 
Auch wenn man seine Straße aufräumt, denn ist es ja nicht nur, dass die Straße sauber ist, 
wobei manche immer zusammenzucken, aber ich finde das einfach wichtig, ich denke, das 
gehört zum Wohlfühlen und Menschen kommunizieren wieder untereinander und außerdem 
merken sie, sie haben was geschafft. Und sie können - es ist zwar eine winzig kleine Sache, 
aber sie können was verändern. Und es sind so viele Menschen, die sich zurückgezogen ha-
ben und sagen, Ihr könnt mich mal und wir wollen uns nicht mehr beteiligen und vielleicht ist 
das irgendwo son kleiner Punkt, wo sie dann so anfangen sich wieder ein bisschen gemein-
schaftlich zu betätigen. Also das ist so meine Vision der - ja - Aufleben des Kommunegedan-
kens. 
Abb. 15: Grundprinzip des Cut-and-paste (Textausschnitt auf Karteikarte) 

Die in den QDA-Programmen implementierte elektronische Variante die-
ses Ausschneidens und Aufklebens funktioniert meist ein wenig anders: Die 
Textsegmente werden nicht ausgeschnitten, sondern es wird mit elektroni-
schen Zeigern gearbeitet, die auf einen bestimmten  Textabschnitt verwei-
sen.  Im  Laufe  des  Codierungsprozesses  entsteht  eine  lange  Liste  von  co-
dierten Segmenten , die den Code sowie Angaben über den Herkunftstext 
und die Position des Segmentes in diesem Text enthält. Die Positionsanga-
be erfolgt in Form einer Absatz- und Byteangabe für Anfang und Ende des 
Segmentes. 

Code 

Text 

Absatznummern: 
Beginn-Ende 

Wunschprojektion 

Erfolgskriterien 

Erfolgskriterien 

Machbarkeit 

... 

Interviews/Wenger 

Interviews/Wenger 

Interviews/Wenger 

Interviews/Wenger 

… 

15-16 

21-23 

41-44 

49-51 

… 

Abb. 16: Liste der codierten Segmente eines Textes 

Diese  Grundform  der  QDA-Textbearbeitung  basiert  auf  menschlicher 
Interpretations- und Klassifikationsleistung. Beim Codieren der Textpassa-
gen stellt sich natürlich die Frage: Wie lang soll ein codiertes Segment ei-
gentlich sein? Das folgende Beispiel wurde von einem Codierer im Projekt 
„Umweltkommunikation  und  Lokale  Agenda  21“  als  „Wunschprojekti-

 

66 

Die Kategorien und das Codieren von Texten 

on/sozial“  codiert,  weil  im  Textabschnitt  soziale  Aspekte  (Motivation, 
Freude, freudlos) angesprochen werden: 

„Dazu  gehört  eben  ganz  klar  Motivation  auch  Freude,  dass  ein  Prozess  – 
wenn  der  Agenda  Prozess  freudlos  abliefe,  das  wäre  für  mich  überhaupt 
kein Wunsch.“ 

Auf diese Weise aus dem Kontext gerissen, ist das Segment nicht mehr oh-
ne  weiteres  verständlich,  insbesondere  weiß  der  Leser  nicht,  worauf  sich 
das einleitende „dazu” bezieht. Dies wird erst dann klar, wenn der größere 
Kontext  der  Textstelle  hinzugezogen  wird,  und  der  sieht  folgendermaßen 
aus: 

„Dennoch  heißt  das  natürlich  auch,  sich  selber  Ziele  zu  setzen  und  diese 
Ziele abzufragen. Das heißt für mich, dass sozusagen ne Art Projektmana-
gement mit Controlling sozusagen da ein Bestandteil ist, um ne Zufrieden-
heit auch gewährleisten zu können. Ich denke, dass das Abfragen oder abge-
fragt werden, wo stehen wir jetzt eigentlich, heute, wo wollen wir eigentlich 
morgen hin, ein immerwährender Prozess ist. Wie gesagt, konkrete Ergeb-
nisse anstreben, aber auch den Prozess für wichtig nehmen. Dazu gehört eben 
ganz klar Motivation auch Freude, dass ein Prozess – wenn der Agenda Prozess freudlos 
abliefe, das wäre für mich überhaupt kein Wunsch. Und ein Kriterium ist natürlich 
aber auch die Frage der Überprüfbarkeit jetzt von Ergebnissen.” 

Aus  diesem  Beispiel  lässt  sich  gut  ersehen,  dass  die  Größe  von  Textseg-
menten  so  gewählt  werden  sollte,  dass  die  entsprechenden  Äußerungen 
auch  außerhalb  ihres  Kontextes  noch  gut  verständlich  bleiben.  Mit  Aus-
nahme  des  Codierens  von  Fakten-Codes,  geschieht  das  Codieren  bei  der 
qualitativen Datenanalyse ja nicht als Selbstzweck, sondern als gezielte Vor-
arbeit für das spätere Wiederfinden und Interpretieren von Textstellen. Na-
türlich  ist  es  in  den  führenden  QDA-Programmen  möglich,  jederzeit  den 
größeren  Kontext  eines  codierten  Segmentes  einzusehen,  doch  wird  dies 
dann lästig, wenn es mehr oder weniger zum Regelfall wird. Gerade Anfän-
ger tendieren dazu, zu kleine Segmente zu codieren. 

Bei der praktischen Arbeit am Text können verschiedene Varianten des 

Codierens praktiziert werden: 

Text farbig markieren 
Dies  entspricht  dem  Unterstreichen  einer  Textstelle  mit  einem  farbigen 
Text-Marker bei der Lektüre eines Buches. Damit wird die Textstelle nur 
als  irgendwie  wichtig  vorgemerkt,  ohne  dass  ein  Code  zugeordnet  wird. 
Durch Verwendung unterschiedlicher Farben, können bereits grobe inhalt-

Codieren mit QDA-Software 

67 

liche Zuordnungen vorgenommen werden. Die Textstelle lässt sich später 
leicht wieder finden, genauer inspizieren und codieren. 

Offenes Codieren 
Eine  Textstelle  wird  mit  der  Maus  markiert  und  anschließend  wird  ein 
neuer Code in ein entsprechendes Textfeld eingegeben. Die Technik kann 
während des gesamten Auswertungsprozesses angewendet werden, beson-
ders typisch ist sie beim ersten, explorativen Durchgang durch das Daten-
material. 

Codieren mit Codes aus dem Kategoriensystem 
Dies setzt voraus, dass bereits Codes definiert wurden und diese Teil des 
Kategoriensystems  sind.  Die  Technik  ist  typisch  bei  deduktiver  Vorge-
hensweise, d.h. ein bestehendes Kategoriensystem wird auf die Texte ange-
wendet.  Auch  in  späteren  Phasen  einer  induktiven  Kategorienbildung, 
wenn  sich  Kategorien  herauskristallisiert  haben  und  sich  ein  ausdifferen-
ziertes  Kategoriensystem  entwickelt  hat,  wird  diese  Form  des  Codierens 
praktiziert. 

Ein Kategoriensystem besteht nun allerdings gewöhnlich aus weit mehr 
als aus einer Kategorie mit Subkategorien. Will man nicht für jede Katego-
rie bzw. jeden Kategorienbereich die Texte erneut lesen, so wird man „in 
einem Rutsch“ gleich alle Kategorisierungen vornehmen wollen. Bei kom-
plexen Kategoriensystemen kann dies die Codierer vor nicht unerhebliche 
Probleme stellen. 

Zuordnen eines ausgewählten Codes 
Hier wird eine andere Arbeitsform praktiziert als bei der zuvor genannten 
Variante. Es werden nicht gleich alle Kategorisierungen beim sequentiellen 
Durchgang durch den Text vorgenommen, sondern man bearbeitet immer 
nur einzelne Kategorienbereiche oder eine Teilmenge der Kategorien. Auf 
den ersten Blick scheint dies mit mehr Arbeit verbunden zu sein, denn man 
muss  schließlich  mehrere  Durchgänge  durch  die  Texte  bewältigen.  Ande-
rerseits  ergeben  sich  u.U.  dadurch  Zeitersparnisse,  dass  man  die  lexikali-
schen  Suchfunktionen  benutzen  kann,  um  Textstellen  zu  finden.  Dies 
hängt allerdings von der Art der Kategorien ab. In einer biographisch orien-
tierten Studie ist es z.B. sehr leicht möglich mittels der Suchworte „Mutter“ 
oder „Vater“  genau solche  Textstellen zu finden (und dann zu codieren), 

 

68 

Die Ka

ategorien und da

as Codieren von

n Texten 

die sic
ohne w
die Te

ch auf die Elt
weiteres mög
extpassagen f

tern beziehen
glich, die rich
für bestimmte

n. In den mei
htigen Suchw
e Kategorien 

isten Fällen is
wörter zu find
in den Texte

st es hingegen
den, mit dene
en finden lass

n nicht 
en sich 
sen. 

In-Viv
Hierbe
treffen
Textst
um ei
forsch
schers

vo-Codieren 
ei wird ein W
nd  oder  char
telle gleichzei
nen „natürlic
hten  vorhand
s darstellt. 

Wort oder ein
rakteristisch 
itig mit diese
chen Code“, 
den  ist  und  d

n Ausdruck d
erscheint,  al
em Code cod
eine Katego
die  nicht  etw

der Befragten
ls  neuer  Cod
diert. Es han
orie, die in de
wa  eine  Kon

n, der als bes
de  erzeugt  u
ndelt sich also
en Köpfen d
nstruktion  de

onders 
und  die 
o quasi 
der Be-
es  For-

3.4  P

Praktische 

Hinweise f

für MAXQD

DA 

In MA
Es las
struktu
sich d
durch 
Maust
gorien

AXQDA wer
sen sich hier
ur visualisiert
urch Anklick
Anklicken  v
taste). Nach d
n bis hin zu z

rden alle Cod
archische Ka
t werden. Co
ken der Wurz
von  bereits 
diesem Prinz
ehn Ebenen 

des im Fenst
ategoriensyste
odes auf der o
zel des Codes
definierten  C
ip können au
gebildet werd

ter „Liste der
eme konstrui
obersten Hie
systems einfü
Codes  (jewei
uch Subkateg
den. 

r Codes“ ver
ieren, die als 
erarchieebene
ügen, Subkate
ils  mit  der  r
gorien von Su

rwaltet. 
Baum-
e lassen 
egorien 
rechten 
ubkate-

 

Abb. 17

7: Der Bildschi

irm in MAXQD

DA beim Codie

eren 

Praktische Hinweise für MAXQDA 

69 

Alle fünf oben erwähnten Formen des Codierens lassen sich praktizieren, 
wobei zunächst immer die Textstelle, die man codieren will, mit der Maus 
markiert werden muss. Das Codieren geht dann folgendermaßen vonstat-
ten: 

Text farbig markieren 
Diese Funktion heißt „Color Coding“ und wird durch Anklicken von einem 
Farbbutton der „Color-Toolbar“ ausgelöst. Dies bewirkt einerseits, dass die 
Textstelle entsprechend eingefärbt wird, andererseits dass im Codesystem der 
Codiervorgang festgehalten wird, so dass sich später beispielsweise alle blau 
markierten Textstellen leicht wieder finden lassen. 

Offenes Codieren 
Nach Eingabe der Tastenkombination Strg+W öffnet sich ein Textfeld, in 
das man den neuen Code eintippen kann. Der Code wird in die Liste der 
Codes eingefügt und die Textstelle codiert. 

Codieren mit Codes aus dem Kategoriensystem 
Bei dieser Form des Codierens werden der Text und das Kategoriensystem 
am besten nebeneinander platziert (Abb. 17). Nun kann per Drag-and-drop 
codiert  werden,  d.h.  die  Textstelle  wird  mit  der  Maus  zum  gewünschten 
Code hingezogen oder umgekehrt der Code zur Textstelle. 

Zuordnen eines ausgewählten Codes 
Bei dieser Form des Codierens steht der Code, den man zuordnen will, von 
vornherein  fest  und  der  Text  wird  sukzessive  auf  Textstellen  durchsucht, 
die mit diesem speziellen Code codiert werden sollen. Zunächst ist der ge-
wünschte Code in der Liste der Codes anzuklicken, dadurch erscheint er im 
Codefenster über dem zu codierenden Text. Um Codierungen mit diesem 
Code vorzunehmen, ist auf das Symbol „Codieren“ zu klicken. Alternativ 
kann das Tastenkürzel Strg+Q eingegeben werden. 

In-Vivo-Codieren 
Mit Hilfe des In-Vivo-Codierens wird ein Begriff (oder Halbsatz) eines Be-
fragten als Code in das Kategoriensystem aufgenommen und die entspre-
chende Textstelle hiermit codiert. Um In-Vivo-Codierungen vorzunehmen, 

 

70 

Die Kategorien und das Codieren von Texten 

ist auf das Symbol „In-Vivo-Codieren“ zu klicken. Alternativ kann das Tas-
tenkürzel Strg+I eingegeben werden. 

MAXQDA  zeigt  die  vorgenommene  Codierung  in  Form  eines  „Co-
dierstreifens“ in der Spalte vor dem Text an. Jedem Code kann ein Farbat-
tribut  zugeordnet  werden,  der  Codierstreifen  wird  dann  in  der  Farbe  des 
jeweiligen Codes dargestellt. 
 
Bewegt man die Maus über die Visualisierung der Codierung, erscheint der 
zugeordnete Code als Tooltipp10 auf dem Bildschirm. Gleichzeitig wird an-
gezeigt, wer wann diese Codierung vorgenommen hat. 

Codierungen  lassen  sich  an  Ort  und  Stelle  löschen  und  verändern.  In 
der „Liste der Codes“ wird hinter jedem Code angegeben, wie viele codierte 
Segmente zu dieser Kategorie vorhanden sind. 

Übungen 

1.  Definieren  Sie  vier  neue  Codes  „Wissen“,  „Intentionen“,  „Einstel-
lungen“ und „Verhalten“. Lassen Sie danach die Codes alphabetisch 
sortieren. 

2.  Definieren Sie zu „Einstellungen“ die Subkategorien „politisch“ und 
„religiös“  und  zum  Code  „Verhalten“  die  Subkategorien  „Familie“ 
und „Beziehungen“. 

3.  Verschieben Sie das Kategoriensystem so, dass „Einstellungen“ und 
„Verhalten“  in  der  Liste  zuoberst  stehen  und  die  Subkategorien 
alphabetisch sortiert sind. 

4.  Öffnen Sie den Text „interview2“ in der Textgruppe „Bürger“, mar-
kieren Sie den sechsten Absatz und codieren Sie diesen mit dem Code 
„Einstellungen/politisch“. 

5.  Codieren Sie den zehnten Absatz mit dem gleichen Code und außer-

dem mit dem Code „Intentionen“. 

6.  Löschen Sie die erste Codierung in Absatz 6 wieder. 
7.  Markieren Sie im Absatz 12 alles ab „Lokale Agenda …“ und nutzen 

Sie die In-Vivo-Codieren Funktion. Was passiert? 

                                                           
 
10 Ein Tooltipp ist ein kleines Informationsfenster, das am Mauszeiger erscheint, wenn er 

sich über einem bestimmten Bildschirmelement befindet. 

Praktische Hinweise für MAXQDA 

71 

8.  Markieren  Sie  den  14.  Absatz  und  nutzen  Sie  den  Button  „Codie-
ren“,  um  den  Textabschnitt  dem  gleichen  Code  zuzuordnen.  Ver-
kürzen Sie den Namen des Codes in „Lokale Agenda“. 

9.  Öffnen Sie das „interview3“, lesen und codieren sie die ersten sieben 

Absätze. Gehen Sie dabei Zeile für Zeile vor. 

 

 

4  Sozialwissenschaftliche Ansätze für die 

kategorienbasierte Textanalyse 

Systematische, methodisch kontrollierte Textauswertung ist zwar eine Auf-
gabe,  die  sich  in  vielen  Disziplinen  und  Praxisfeldern  stellt,  doch  verfügt 
man  meist  nicht  über  einen  Kanon  von  präzise  beschriebenen  Auswer-
tungsmethoden. Im Bereich der Sozialwissenschaften sind eine Reihe von 
Verfahren entwickelt worden, die auch für andere Disziplinen sehr interes-
sant sind. Im Folgenden werden vier solcher Ansätze skizziert, und zwar: 
 

(cid:120)  Theoretisches Codieren (orientiert an der Grounded Theory) 
(cid:120)  Thematisches Codieren 
(cid:120)  Zusammenfassende qualitative Inhaltsanalyse 
(cid:120)  Typenbildung und typologische Analyse 

 
Diese methodischen Ansätze praktizieren verschiedene Formen des Codie-
rens  und  basieren  auf  unterschiedlichen  wissenschaftstheoretischen  An-
nahmen,  deren  Darstellung  den  Rahmen  dieses  Buches  sprengen  würde. 
Zur Vertiefung seien ausdrücklich die beiden umfassenden Monographien 
von Kelle empfohlen (Kelle 1994 und 2008). Die große Bandbreite der An-
sätze verdeutlicht, dass QDA-Software nicht nur für einen ganz bestimm-
ten Ansatz geeignet ist. Alle vorgestellten Verfahren basieren allerdings auf 
dem Arbeiten mit Kategorien: Die Vorgehensweise der Grounded Theory 
dient  als  Beispiel  für  theoretisches  Codieren,  die  zusammenfassende  In-
haltsanalyse nach Mayring als Beispiel für das paraphrasierende Verfahren, 
die Vorgehensweise von Hopf u.a. als Beispiel für thematisches Codieren 
und  die  Typenbildung  als  Beispiel  für  einen  Ansatz,  der  quantitative  und 
qualitative Verfahren integriert.  

Intention dieses Kapitels ist es, Grundzüge der verschiedenen Verfahren 
zu skizzieren. Eine erschöpfende Darstellung ist nicht beabsichtigt, die ein-
gefügten  Hinweise  auf  die  relevante  Literatur  ermöglichen  hier  ggf.  eine 
weitergehende Beschäftigung mit einzelnen Verfahren. Das Kapitel ist vor 
allem für solche Anwender von QDA-Software gedacht, die ihre Texte bis-

Theoretisches Codieren: Die Grounded Theory 

73 

lang nach Common-sense-Prinzipien auswerten und wenig über die in den 
Sozialwissenschaften entwickelten Techniken wissen. 

4.1  Theoretisches Codieren: Die Grounded Theory 

Nicht nur in der amerikanischen Feldforschung, sondern zunehmend auch 
in  der  deutschen  Sozialforschung  hat  der  Ansatz  der  auf  Anselm  Strauss 
und Barney Glaser zurückgehenden Grounded Theory (Empirisch begrün-
dete  Theoriebildung)  vielfache  Beachtung  gefunden.  Strauss,  Glaser  und 
später  Corbin  haben  in  verschiedenen,  alleine  und  gemeinsam  verfassten 
Schriften dieses Konzept einer Forschungsstrategie, in welcher Kategorien 
und  das  Codieren  eine  zentrale  Rolle  spielen,  ausgearbeitet  (vgl.  Glaser/ 
Strauss  1998;  Glaser  1978;  Strauss  1991;  Strauss/Corbin  1996;  Strauss/ 
Corbin 2007). Im Laufe von drei Jahrzehnten hat sich das Konzept aller-
dings kontinuierlich weiter entwickelt und ausdifferenziert. In den Anfän-
gen war der Ansatz stark induktivistisch formuliert und schien auf den ers-
ten  Blick  eine  weitgehend  theorielose  Herangehensweise  zu  propagieren: 
Alle vor der Analyse beim Forscher vorhandenen Theorien („preconceived 
theories“) wurden als eher wahrnehmungshemmend denn -fördernd apost-
rophiert. Strauss und Corbin haben nach und nach verschiedene Elemente 
klassischer  Forschungskonzepte  integriert.  Vermutlich  waren  die  Anfänge 
der Grounded Theory Mitte der 1960er Jahre dadurch gekennzeichnet, dass 
Strauss und Glaser primär eine wissenschaftspolitische Manifestation gegen-
über  dem  Behaviorismus  und  dem  quantitativen  Mainstream  vornehmen 
wollten, der in der politisch konservativen Nachkriegszeit in den USA die 
interaktionistischen Ansätze ziemlich an den Rand gedrängt hatte. Strauss 
selbst hat in einer rückblickenden Betrachtung diese Vermutung bestärkt: 

„Wir  entschieden  Mitte  60,  ein  Buch  über  Methoden  zu  schreiben.  Wir 
spürten schon, dass Veränderungen in der Luft lagen, denn wir wollten für 
die  „Kids“  schreiben  –  Leute  über  30  schienen  uns  schon  zu  festgelegt. 
Barney hatte das bessere Gefühl, dass ein solches Buch ankommen würde, 
ich war skeptischer, weil ich älter war. Der Titel „The Discovery of Groun-
ded Theory“ (1967), zeigt schon, worauf es uns ankam: Nicht wie in den üb-
lichen Methodenlehrbüchern die Überprüfung von Theorie, sondern deren 
Entdeckung aus den Daten heraus. Grounded Theory ist keine Theorie, son-
dern  Methodologie,  um  in  den  Daten  schlummernde  Theorien  zu  entde-
cken.“ (Legewie/Schervier-Legewie 1995: 70) 

 

74 

Sozialwissenschaftliche Ansätze für die kategorienbasierte Textanalyse 

Die  sukzessive  Präzisierung  der  Grounded  Theory  als  Analyseverfahren 
durch Strauss und Corbin hat auch zu Kontroversen zwischen den beiden 
Begründern der Grounded Theory11 geführt, deren Kern von Kelle (2005) 
treffend beschrieben wird. Die Übersetzung des Begriffs Grounded Theory 
ins Deutsche ist nicht unproblematisch. Noch am ehesten lässt er sich mit 
„gegenstandsbezogene Theorie“ oder „empirisch basierte Theorie(bildung)“ 
übersetzen,  wobei  mit  Theorie  hier  eine  Theorie  mittlerer  Reichweite  und 
keine Gesellschaftstheorie („Grand Theorie“) gemeint ist. Anselm Strauss 
zufolge  besteht  eine  Grounded  Theory  aus  Kategorien,  ihren  theoretisch 
bedeutsamen Merkmalen und Hypothesen, d.h. aus verallgemeinerten Be-
ziehungen zwischen Kategorien und ihren Merkmalen. Obwohl weit vom 
Konzept  der  traditionellen  Inhaltsanalyse  entfernt,  teilt  Strauss  mit  dieser 
die zentrale Stellung, die den Kategorien und dem Vorgang des Codierens 
eingeräumt wird. Strauss formuliert „Codieren ist der Prozess der Daten-
analyse“ und  bringt damit  zum Ausdruck, dass der Begriff „Codieren“ in 
der Grounded Theory etwas anderes meint als in klassischen Forschungs-
ansätzen, in denen „Codieren“ wesentlich enger als Klassifizierung von Da-
ten in der Auswertungsphase eines Projektes begriffen wird. 

Im Zentrum des Analysestils der Grounded Theory steht das sorgfältige 
Codieren der Daten, d.h. die Formulierung von Konzepten und die Zuord-
nung  von  Codes  zu  bestimmten  Phänomenen  im  Datenmaterial12.  Dabei 

                                                           
 
11 Die Grundideen der Grounded Theory lassen sich anhand folgender Originaltexte stu-
dieren: a) Glaser, B. G./Strauss, A. L. (1998): Grounded Theory. Strategien qualitativer 
Forschung. Bern u. a. Es handelt sich um die erste, 1967 erstmals erschienene umfassen-
de Darstellung der Grounded Theory – einschließlich aller Missverständnisse. b) Strauss, 
A., 1998: Grundlagen qualitativer Sozialforschung. Datenanalyse und Theoriebildung in 
der empirischen soziologischen Forschung. München. Dieser Studientext macht anhand 
von Seminarprotokollen die Vorgehensweise von Strauss praktisch nachvollziehbar. Der 
Text weist allerdings viele Wiederholungen auf und oft mangelt es an begrifflicher Klar-
heit. c) Strauss, A./Corbin, J., 1996: Grundlagen qualitativer Sozialforschung. Weinheim. 
Dieses Buch stellt eine Art Komplement zu dem vorgenannten Text dar. Strauss und sei-
ne  Mitautorin  haben  hier  versucht,  die  verschiedenen  Werkzeuge  und  Verfahren  der 
Grounded Theory systematisch zu definieren und zu beschreiben. 2007 hat Corbin die 
überarbeitete dritte Auflage dieses Lehrbuchs publiziert. Zu Anselm Strauss vgl. Strübing 
(2007). 

12 Eine Zusammenfassung der Grundideen des Codierens nach der Methode der Grounded 
Theory findet man bei: Böhm (2000), Flick (2002: 258 ff.). Sehr empfehlenswert ist auch 
der von Mey und Mruck zusammengestellte Reader zur Grounded Theory (2007). 

Theoretisches Codieren: Die Grounded Theory 

75 

werden von Strauss und Corbin drei Haupttypen des Codierens unterschie-
den: offenes Codieren, axiales Codieren und selektives Codieren. 

Offenes Codieren 
Das offene Codieren ist als der Prozess des Aufbrechens, Untersuchens, Ver-
gleichens, Konzeptualisierens und Kategorisierens von Daten definiert. Of-
fenes  Codieren  „eröffnet“  die  Forschungsarbeit:  Das  Datenmaterial  wird 
sorgfältig  durchgearbeitet,  vorläufige  Konzepte  und  deren  Dimensionen 
werden entwickelt. Den Daten werden normalerweise zahlreiche Codes zu-
gewiesen (vgl. Flick 2007a: 391). Verwendet werden konzeptuelle Katego-
rien („conceptual codes“), die auf theoretischen Konzepten basieren oder 
In-Vivo-Codes, alsoBegriffe, die von den Akteuren selbst verwendet wer-
den.  In-Vivo-Codes  ermöglichen  laut  Strauss  einen  unmittelbaren,  durch 
keine  Theorie verstellten Zugang zu den Sichtweisen  der Akteure.  Solche 
Begriffe fallen bei der Dateninterpretation sofort ins Auge: Beispielsweise 
bezeichnet  in  einer  medizinsoziologischen  Studie  von  Strauss  eine  Ober-
schwester eine andere Stationsschwester als „Traditionsträger der Station“, 
weil ihr die Aufgabe zufällt, alle neuen Beschäftigten einzuarbeiten und in 
die Regeln und Abläufe der Station einzuführen. 

Unter Konzepten verstehen Strauss/Corbin (1996): „Konzeptuelle Be-
zeichnungen  oder  Etiketten,  die  einzelnen  Ereignissen,  Vorkommnissen 
oder anderen Beispielen für Phänomene zugeordnet werden.“ Ein weiteres 
Beispiel hierfür ist die Bezeichnung „Einschätzung des sozialen Verlustes“. 
Ergebnis des ersten Analyseschrittes ist eine Liste von Konzepten, die im 
nächsten Schritt zu Kategorien zusammengefasst werden. Kategorie ist für 
Strauss ein unabhängiges begriffliches Element einer Theorie, eine Klassifi-
kation von Konzepten. Diese Klassifikation wird erstellt, wenn Konzepte 
miteinander verglichen werden und sich offenbar auf ein ähnliches Phäno-
men  beziehen.  So  werden  die  Konzepte  unter  einem  Konzept  höherer 
Ordnung zusammengruppiert – ein abstrakteres Konzept, genannt Katego-
rie, beispielsweise „Pflegehandeln des Personals“. 

Kategorien  besitzen  Eigenschaften  und  Merkmale,  die  theoretisch  be-
deutsame Aspekte darstellen. Die Kategorie „Pflegehandeln des Personals“ 
besitzt beispielsweise die Merkmale „professionelle Gelassenheit“ und „Ein-
schätzung  des  sozialen  Verlustes“.  Die  Begriffe  Merkmal  und  Subkategorie 
werden von Strauss allerdings weitgehend synonym verwendet. Auch Sub-
kategorien  können  wiederum  Merkmale  besitzen,  beispielsweise  kann  die 

 

76 

Sozialwissenschaftliche Ansätze für die kategorienbasierte Textanalyse 

Subkategorie „Einschätzung des sozialen Verlustes“ das Merkmal „Verlust-
rationalisierungen“ aufweisen. 

Eine wichtige Tätigkeit bei der Entwicklung von Kategorien ist das Di-
mensionalisieren.  Kategorien  besitzen  Attribute  und  diese  lassen  sich  auf  ei-
nem  Kontinuum  beschreiben:  Die  „Professionelle  Gelassenheit“  kann, 
ebenso  wie  die  „Einschätzung  des  sozialen  Verlustes“  groß  oder  gering 
sein: 

professionelle Gelassenheit

gering 

gering 

Einschätzung des sozialen Verlustes 

groß 

groß 

 

Der Arbeitsschritt des offenen Codierens besteht also neben dem Konzept-
ualisieren  der  Daten  im  Identifizieren  und  Dimensionalisieren  der  Eigen-
schaften von Kategorien. Offenes Codieren kann auf verschiedene Art und 
Weise  durchgeführt  werden,  wobei  Strauss  empfiehlt,  zunächst  Zeile-für-
Zeile vorzugehen (Strauss 1991: 57 ff.). 

Codes können sich auf einzelne Worte beziehen – wie oben auf „Tradi-
tionsträgerin“ – auf Sätze, Abschnitte oder den gesamten Text. Im letzten 
Falle geht es darum, Dokumente miteinander zu vergleichen, Ähnlichkeiten 
und  Unterschiede  bezogen  auf  das  gesamte  Dokument  zu  klassifizieren. 
Hier  haben  Codes  dann  den  Charakter  von  Fallvariablen  (vgl.  Kapitel  7). 
Als Beispiel für eine dimensionalisierte Kategorie sei eine Darstellung von 
Strauss wiedergegeben, die er in einer Studie für den Arbeitstyp „Beobach-
ten“ entwickelt hat (Strauss/Corbin 1996: 53). 

Kategorie 

Eigenschaften 

Beobachten 

Häufigkeit 
Ausmaß 
Intensität 
Dauer 

Dimensionale Ausprägung 
(pro Ereignis) 

oft 
viel 
hoch 
lang 

----------------   nie 
----------------   wenig 
----------------   niedrig 
----------------   kurz 

Abb. 18: Dimensionalisierung der Kategorie „Beobachten“ 

Hierauf basierend lassen sich fallbezogene Profile für Kategorien herstellen, 
indem die Merkmale auf einem Kontinuum abgetragen werden. 

Theoretisches Codieren: Die Grounded Theory 

77 

Axiales Codieren 
Als spezielle fortgeschrittene Technik des Codierens, die am Anschluss an 
das offene Codieren betrieben wird, beschreibt Strauss das axiale Codieren. 
Darunter versteht er „eine Reihe von Verfahren, mit denen durch das Er-
stellen von Verbindungen zwischen Kategorien die Daten nach dem offe-
nen Codieren auf neue Art zusammengesetzt werden. Dies wird durch den 
Einsatz  eines  Codier-Paradigmas  erreicht,  das  aus  Bedingungen,  Kontext, 
Handlungs-  und  interaktionalen  Strategien  und  Konsequenzen  besteht.“ 
(Strauss/Corbin 1996: 75) Das axiale Codieren richtet sich also gezielt auf ei-
ne  bestimmte  fokussierte  Kategorie  und  ihre  Beziehungen.  Heuristischer 
Rahmen ist ein allgemeines Handlungsmodell, aufgrund dessen die Katego-
rien auf die Zugehörigkeit zu sechs Klassen hin untersucht werden: 
 

1.  Phänomene, auf die sich das Handeln richtet 
2.  Kausale Bedingungen für diese Phänomene 
3.  Eigenschaften des Handlungskontextes 
4.  Intervenierende Bedingungen 
5.  Handlungs- und Interaktionsstrategien 
6.  deren Konsequenzen 

 
Auf  diese  Weise  erreicht  der  Analyseprozess  eine  abstraktere  Ebene  und 
bewegt sich hin zur dritten Form des Codierens, dem selektiven Codieren. 

Selektives Codieren 
Dieses ist definiert als „Der Prozess des Auswählens der Kernkategorie, des 
systematischen In-Beziehung-Setzens der Kernkategorie mit anderen Kate-
gorien, der Validierung dieser Beziehungen und des Auffüllens von Katego-
rien,  die  einer  weiteren  Verfeinerung  und  Entwicklung  bedürfen.“  (ebd.: 
94).  In  dieser  Phase  wird  die  gesamte  interpretative  Arbeit  integriert.  Die 
einzelnen  Handlungsmodelle  werden  in  ein  umfassendes  theoretisches 
Konzept, eine Theorie über das typische Handeln typischer Akteure im Un-
tersuchungsfeld,  verdichtet.  Die  Kernkategorie(n)  werden  systematisch  zu 
anderen Kategorien in Beziehung gesetzt. Die Daten werden gruppiert, Ziel 
ist das Aufdecken von Mustern durch Betrachtung der dimensionalen Aus-
prägungen  der  Kategorien.  Das  entspricht  der  multivariaten  statistischen 
Analyse  im  Fall  der  quantitativen  Inhaltsanalyse,  anders  als  dort  geht  es 
aber nicht um Koeffizienten und Signifikanzen, sondern um die Konstruk-
tion  einer  analytischen  Geschichte.  Diese  muss  einen  roten  Faden  aufweisen, 

 

78 

Sozialwissenschaftliche Ansätze für die kategorienbasierte Textanalyse 

sequentiell  und  logisch  geordnet  sein.  (vgl.  hierzu  Strauss/Corbin  1996: 
198 ff.) 

Wie funktionieren das Codieren und die Generierung von Codes nach dem 
Stil der Grounded Theory denn nun genau? Anselm Strauss neigt zu allem 
anderen als zu Dogmatismus, wenn er den Analysestil der Grounded Theo-
ry als einen unter vielen möglichen Analysestilen betrachtet. Ebenso betont 
er, dass es wichtig sei, die Methode immer an die je konkrete Fragestellung 
anzupassen.  Entscheidend  ist  weniger  ein  ganz  bestimmtes  Procedere  als 
vielmehr das Ziel, nämlich Theorie – und zwar sowohl Theoriegenerierung 
als auch Theorieüberprüfung. Hiermit sind deutliche Differenzen markiert, 
erstens  zu  einer  vornehmlich  auf  Deskription  und  dichte  Beschreibungen 
zielenden qualitativen Analysestrategie und zweitens zu einer Position, die 
qualitative  Forschung  auf  Exploration  und  Theoriegenerierung  festlegen 
will  und  der  quantitativen  Forschung  das  Recht  auf  Theorieüberprüfung 
vorbehält. Als zentrales Merkmal des Codierens nach Strauss ist also fest-
zuhalten: 

Codieren im Rahmen der Grounded Theory ist theoretisches Codieren, d.h. auf eine 

Theorie hin arbeitendes Codieren. 

 
Mit diesem Merksatz wird ein Problem deutlich, das die Grounded Theory 
als Auswertungsverfahren besitzt, nämlich eine inhärente Vagheit und Un-
bestimmtheit. Wie, so lässt sich fragen, kann man auf der Basis derselben 
Daten  eine  Theorie  generieren  und  gleichzeitig  überprüfen?  Bedarf  eine 
noch  so  plausible  Deutung  nicht,  will  sie  allgemeine  Gültigkeit  bean-
spruchen,  doch  der  Überprüfung  mittels  statistischer  Tests?  Theoriegene-
rierung ist zudem kein codifizierbarer und genau beschreibbarer Vorgang. 
Es handelt sich nicht um ein Procedere, das man Schritt für Schritt als quasi 
technischen Prozess erlernen könnte, sondern der Forscher ist weitgehend 
auf sich selbst verwiesen. Wer mit den Erwartungen an präzise Verfahrens-
beschreibungen, wie sie in der quantitativen Methodik üblich sind, an die 
Grounded  Theory  herangeht  und  ganz  genau  gesagt  bekommen  möchte, 
was er zu tun hat, der wird recht unbefriedigt zurückbleiben. Theoriekon-
struktion ist eine Mischung aus Intuition, harter Arbeit, Kreativität, solidem 
Vorwissen und nicht zuletzt Zufälligkeiten und Glück. Diese Charakteristi-
ka von Theoriebildung infizieren gewissermaßen die Auswertungsmethode 
der Grounded Theory  mit einer  Dosis  Vagheit und  Unbestimmtheit. Co-

Theoretisches Codieren: Die Grounded Theory 

79 

dieren nach der Grounded Theory ist eine Kunstlehre und in solcher spie-
len Meister immer eine bedeutende Rolle. Ihnen schaut man gewisserma-
ßen über die Schulter und erlernt so ihre Handwerkskunst. Der Eindruck 
einer  solchen  Meister-Lehrlings-Konstellation  drängt  sich  auch  geradezu 
auf, wenn man die in Strauss’ zentraler Arbeit „Grundlagen qualitativer So-
zialforschung.“  (Strauss  1991)  dokumentierten  Seminarsitzungen  des 
„Meisters“ liest (insbes. 124 ff.). 

Der Analyseprozess nach der Grounded Theory unterliegt also keinem 
streng  fixierten  Ablauf.  Strauss  hat  sich  bewusst  gegen  eine  Systematisie-
rung von methodischen Regeln ausgesprochen. Die Grounded Theory gibt 
nur Leitlinien und Orientierungshilfen. Codieren ist laut Strauss Datenana-
lyse und Analyse ist gleichbedeutend mit der Interpretation von Daten, d.h. 
Codieren ist damit eine Tätigkeit, die während des gesamten Forschungs-
prozesses stattfindet und nicht nur zu einem bestimmten Zeitpunkt, in ei-
ner bestimmten Phase des Forschungsprozesses. 

Die Vorgehensweise der Grounded Theory 
Im Folgenden wird versucht, die einzelnen Bestandteile und Leitlinien des 
Vorgehens nach der Grounded Theory in eine der Logik des Forschungs-
prozesses  folgende  Ordnung  zu  bringen,  wohl  wissend,  dass  gerade  die 
Vorgehensweise der Grounded Theory stark auf zirkuläre Vorgehensweise 
abstellt. Bei den zwölf Schritten, die unten beschrieben werden, sind also 
jeweils auch (mögliche) „Rückschritte“ von unten nach oben mitzudenken. 
Trotz aller Zirkularität: Auch die Grounded Theory beginnt mit der Lektü-
re  des  ersten  Textmaterials  (z.B.  eines  Interviewtranskripts,  eines  Proto-
kolls,  einer  Gruppendiskussion  oder  einer  Feldnotiz)  und  endet  mit  der 
Erstellung  eines  Forschungsberichts.  Auch  findet  eine  Evolution  des  Co-
dierens,  vom  offenen  Codieren,  das  die  Arbeit  eröffnet  und  die  Daten 
„aufbricht“ hin zum komplexen axialen und selektiven Codieren statt. Die 
drei  verschiedenen  Formen von Codes  bezeichnen gleichzeitig bestimmte 
aufeinander folgende Phasen im Forschungsprozess, wobei Phase hier nicht 
im  Sinne  des  streng  sequentiellen  Ablaufs  klassischer  Sozialforschung  zu 
verstehen ist, sondern durchaus zirkuläre Elemente beinhalten kann. Klar 
ist aber, dass kein selektives Codieren in der ersten Phase des Forschungs-
prozesses stattfinden kann, ohne dass man eine Phase des offenen Codie-
rens durchschritten hätte. 

 

80 

Sozialwissenschaftliche Ansätze für die kategorienbasierte Textanalyse 

1.  Zunächst wird der gesamte Text gelesen – bei einer Forschergruppe von allen Mitglie-

dern des Teams, die an der Interpretation beteiligt sind. 

2.  Vorwissen über den Gegenstandsbereich der Forschung ist sehr wichtig und durchaus 
willkommen. Viele Forschungsfragen lassen sich auf der Basis von Vorwissen und all-
gemeinem Weltwissen bereits stellen, ehe man das erste Interview gelesen und ausge-
wertet hat. Zwar ist eine Analyse nach dem Verfahren der Grounded Theory prinzipiell
auch  ohne  Vorwissen  möglich,  doch  würden  die  Resultate  wahrscheinlich  schlechter
sein  und  Gefahr  laufen,  Ergebnisse  zu  produzieren,  die  Experten  als  Trivialitäten  er-
scheinen. 

3.  Die  eigentliche  Analyse  und  Interpretation  erfolgt  als  Detailanalyse  auf  dem  Hinter-

grund des gesamten Textes. 

4.  Mit dem offenen Codieren beginnt die Analyse, dabei sind gezielt Fragen an das Materi-

al zu stellen (vgl. Böhm u.a. 1994): 
WAS? (cid:570) Worum geht es hier? Welches Phänomen wird angesprochen? 
WER? (cid:570) Welche Personen sind beteiligt, welche Rollen, wie interagieren sie? 
WIE? (cid:570) Welche Aspekte des Phänomens werden (nicht) angesprochen? 
WANN? WIE LANGE? WO? WIE VIEL? WIE STARK? 
WARUM? (cid:570) Welche Begründungen werden gegeben oder lassen sich erschließen? 
WOZU? (cid:570) Mit welcher Absicht, zu welchem Zweck? 
WOMIT? (cid:570) Welche Mittel werden zur Zielerreichung verwendet? 

5.  Die Vorgehensweise bei der Auswertung ist flexibel. Es kann sowohl mit einer Zeile-
für-Zeile Analyse am Anfang des Textes begonnen werden, als auch ein ausgewählter
Aspekt, der natürlich für das Interview zentral sein sollte, systematisch betrachtet wer-
den (Sehen wir uns die ersten vier Seiten des Textes an. Was sagen sie uns zum Thema
„xy“?). Auch dann beginnt man die Interpretation vorne im Text und führt eine Zeile-
für-Zeile Analyse durch. Man eilt nicht der Geschichte voraus. Die Analyse besteht aus
der Interpretation des Gesagten, auf dem Hintergrund von Wissen (Alltagswissen, For-
scherwissen,  wissenschaftliches  Wissen)  und  von  Kenntnis  des  übrigen,  „noch  kom-
menden“  Interviewtextes.  Die  sehr  ausführliche  Interpretation  auf  dem  Hintergrund
von  Vorwissen  lässt  sich  am  besten  in  einer  Forschergruppe  vornehmen.  So  kommt
zum einen mehr Wissen auf den Tisch, zum anderen stellt die Gruppe ein Korrektiv dar,
so dass Fehldeutungen eher vermieden werden. 

6.  Zu achten ist auch auf „natürliche Codes“, d.h. auffällige Formulierungen des Befragten
(Beispiel: Eine Patientin erzählt über eine Routineuntersuchung auf Krebs, die sie hat 
durchführen  lassen.  Urplötzlich  teilte  man  ihr  eine  sehr  negative  Diagnose  mit.  Im
Interview heißt es: „… ich flippte aus“. 

7.  Die  Interpretation  führt  zur  Entdeckung  von  Codes  (Beispiel  hierfür:  „diagnostische

Karriere“, „medizinische Stationen“). 

Theoretisches Codieren: Die Grounded Theory 

81 

Die Codes in dieser Phase können einen sehr unterschiedlichen Abstraktionsgrad auf-
weisen. So bildet Strauss den Code „medizinischer Trichter“ und bezeichnet damit das
Phänomen, das man während einer Krankheitskarriere Entscheidungsmöglichkeiten hat. 
Man kann Medikamente nehmen oder nicht, einer Operation zustimmen oder nicht etc.
Die Entscheidungsmöglichkeiten engen sich zunehmend ein, bis man die Entscheidung
dem Arzt überlässt. 
Anders  als  beim  Codieren  der  quantitativen  Forschung  kann  eine  Textpassage  hier 
durchaus mehreren Codes zugewiesen werden. 

8.   Alle Ideen, die über die Textstelle hinaus auf andere Stellen weiter hinten im Text wei-
sen (an die man sich aufgrund der Lektüre des gesamten Textes erinnert), werden als
Memo festgehalten, quasi als ein Erinnerungsposten für die Interpretation der entspre-
chenden Seiten im Interview, zu denen man dann erst später kommen wird. Man setzt
die Analyse Zeile-für-Zeile und Absatz für Absatz fort. 

9.  Bei der Deutung sollte man stets in Vergleichen denken und sich bspw. fragen: „Was 
sagt  uns  die  erste  Hälfte  der  Seite?  Welche  Phänomene  sind  hier  angesprochen?  Wie
könnten diese noch sein? Was könnte stattdessen passieren?“ 

10.  Mit Fortgang der Analyse werden die Codes endgültiger und verlieren ihren vorläufigen 
Charakter, der noch für die Phase des offenen Codierens typisch ist. Das impliziert, dass
man Codes umbenennt, löscht, zusammenfasst, unter ein übergeordnetes Konzept sub-
sumiert etc. 

11.  In den mittleren und fortgeschrittenen Stadien des Analyseprozesses beginnt auch das 
axiale Codieren, bei dem einzelne Codes in den Mittelpunkt der Analyse gerückt werden. 
Auf der Basis der oben unter 4) genannten Fragen, die in systematischer Weise an das
Material  zu  stellen  sind,  schematisiert  Strauss  das  Codierparadigma  wie  folgt  (Böhm 
2000: 479): 
 

Kontext und 

intervenierende 
Bedingungen 

ursächliche 
Bedingungen 

Phänomen 

Konsequenzen 

 

Handlungsstrategien 

 

 

82 

Sozialwissenschaftliche Ansätze für die kategorienbasierte Textanalyse 

12.  Mit jedem Schritt der Analyse schreitet die Theoriebildung fort. Die analytische Arbeit
ist darauf ausgerichtet, die Schlüsselkategorie(n) herauszuarbeiten. Um diese herum wird 
dann die Theorie aufgebaut. Möglicherweise ist auch eine der Achsenkategorien die ent-
scheidende Schlüsselkategorie. Dann wird um sie herum unter Einbeziehung der bislang
geschriebenen Memos etc. der Forschungsbericht geschrieben. 

Das Erlernen der Grounded Theory ist nicht einfach, gerade weil sie dem 
Forscher viel Freiheit lässt. Ein Problem stellt gewiss dar, dass Begriffe wie 
„Code“, „Konzept“, „Kategorie“ oder „Dimension“ nicht sehr präzise de-
finiert und gegeneinander abgegrenzt sind. Schließlich bedeutet die Anwen-
dung der Grounded Theory dem Anspruch nach auch, das Wichtige in den 
Daten  zu  erkennen,  das  ist  nun  gewiss  nichts,  was  man  leicht  erlernen 
könnte. Kritik an der Grounded Theory richtet sich auf die wenig kontrol-
lierte Datensammlung, die möglicherweise ausufernde Codierung, die Ge-
fahr der vorschnellen Festlegung durch Theoriebildung auf der Basis von 
noch sehr wenigen Daten und die mangelnde Intersubjektivität. 

Umsetzung der Methode mit QDA-Software 
Die Umsetzung des Analysestils der Grounded Theory mit QDA-Software 
stellt kein Problem dar, denn häufig ist es gerade die Grounded Theory, die 
bei  den  Entwicklern  der  Programme  als  Leitbild  im  Hintergrund  präsent 
war und insofern ist die Software genau für diesen Typ der Analyse konzi-
piert. Die führenden QDA-Programme offerieren alle Werkzeuge, die für 
das Arbeiten nach dem Stil der Grounded Theory benötigt werden: 
 
(cid:120)  Man kann Textstellen mit der Maus markieren und codieren. 
(cid:120) 

Jede  Codierung  wird  ähnlich  wie  beim  Arbeiten  mit  Papier  und 
Bleistift neben dem Text angezeigt. Man sieht jederzeit, wo man et-
was codiert hat und um welchen Code es sich handelt. 

(cid:120)  Alle Codes werden in einer Liste geführt, die nach den Bedürfnissen 

des Nutzers geordnet werden kann. 

(cid:120)  Codes können jederzeit umbenannt, d.h. präziser formuliert werden. 
(cid:120)  Codes können umorganisiert, d.h. zu abstrakteren Konzepten grup-

piert oder in mehrere Codes ausdifferenziert werden. 

(cid:120)  Verschiedene Dimensionen und Subdimensionen eines Codes kön-
nen gebildet und codiert werden. Es wird angezeigt, ob und wie häu-
fig die Dimensionen im Material vorhanden sind. Dies kann wertvol-
le Hinweise für die vergleichende Analyse liefern oder Basis für ein 
Theoretical Sampling sein. 

Theoretisches Codieren: Die Grounded Theory 

83 

(cid:120)  Natürliche  Codes  („In-Vivo-Codes“)  können  identifiziert  und  mar-
kiert werden. Sie werden automatisch in die Liste der Codes aufge-
nommen. 

(cid:120)  Memos  können  geschrieben,  verändert  und  integriert  werden,  und 
zwar Memos unterschiedlicher Art, z.B. Text-Memos, Code-Memos, 
theoretische Memos etc. 

(cid:120)  Über  die  von  Strauss  und  Corbin  beschriebenen  Techniken  hinaus 
bietet die computergestützte Auswertung noch Möglichkeiten an, die 
bei  einer  handwerklichen  Arbeitsweise  nicht  bestanden:  Es  lassen 
sich Übersichten erstellen, z.B. als Übersicht über alle Codierungen 
eines Textes, als Übersicht über alle Stellen, an denen man einen be-
stimmten Code zugewiesen hat. 

(cid:120)  Es lassen sich Überschneidungen von Codes ermitteln und die ent-

sprechenden Textstellen listen. 

(cid:120)  Die Nähe von Codierungen zueinander lässt sich als Suchkriterium 

formulieren, ebenso die Abfolge von Codes. 

(cid:120)  Memos lassen sich wie in einem Karteikasten verwalten und durch-

suchen. 

(cid:120)  Verschiedene  Memotypen  (Theorie-Memos,  Code-Memos,  etc.) 
können  selektiert  werden  und  gezielt  betrachtet  werden,  etwa  alle 
Memos, die sich auf ein Theoretical Sampling beziehen, so lässt sich 
die nächste Feldphase gezielter planen. 

 
Zusammenfassend  lassen  sich  aus  der  Grounded  Theory  eine  Reihe  von 
wertvollen Hinweisen und Maßregeln für den Umgang mit Kategorien ge-
winnen. An erster Stelle ist hier die zentrale Bedeutung, die dem Codieren 
überhaupt eingeräumt wird, zu nennen. Ferner zeigt die Praxis der Grounded 
Theory, dass Kategorien sehr verschiedene Grade an Dichte und Abstrakti-
on  aufweisen  können.  Von  Bedeutung  ist  drittens  die  im  Analyseprozess 
kontinuierlich stattfindende Arbeit an den Kategorien, etwa die Kategorien 
auszudifferenzieren und zu dimensionalisieren. Schließlich führt der Analy-
sestil der Grounded Theory auch deutlich vor Augen, dass es jenseits eines 
einfachen  Konzeptes  von  „Indikator(cid:111)  Kategorie(cid:111)  statistische  Analyse“ 
auch solche Forschungskonzepte gibt, die auf unterschiedliche Formen des 
Codierens in verschiedenen Phasen des Forschungsprozesses zielen und die 
die Entdeckung von Schlüsselkategorien in den Mittelpunkt stellen. 

 

84 

Sozialwissenschaftliche Ansätze für die kategorienbasierte Textanalyse 

4.2  Thematisches Codieren 

Thematisches  Codieren  ist  eine  Methode,  die  bei  sehr  vielen  qualitativen 
Projekten zur Datenauswertung eingesetzt wird. Meist geschieht dies eher 
im  Sinne  einer  Common-sense-Technik,  ohne  dass  man  sich  gezwungen 
sieht, hierzu besondere methodischen Begründungen und Rechtfertigungen 
zu  geben.  Das  heißt,  dass  in  solchen  Studien  das  thematische  Codieren 
nicht  selbst  zum  Gegenstand  methodischer  Überlegungen  gemacht  wird 
und  meist  in  seinem  Ablauf  auch  nicht  genauer  beschrieben  wird.  Still-
schweigend wird vorausgesetzt, dass jeder Wissenschaftler in der Lage ist, 
das zu bestimmten Themen Wichtige aus den Daten herauszuarbeiten, dazu 
bedarf es keiner fixierten Vorgehensweise. Auch in Methodenlehrbüchern 
war über das thematische Codieren lange Zeit wenig zu finden, es gehörte 
eher zu einer Art „Folklore“ der Datenanalyse, die vom wissenschaftlichen 
Nachwuchs erlernt wurde, indem den erfahrenen Forschern über die Schul-
ter geschaut wurde. Von Meistern zu lernen bzw. aus vorliegenden Studien 
die Vorgehensweise qualitativer Datenanalyse „abzugucken“, ist auch heute 
noch ein gangbarer und durchaus produktiver Weg, sich qualitative Metho-
dik anzueignen. Dies erfordert aber einerseits viel Zeit, andererseits bleibt 
dennoch eine gehörige Portion Unsicherheit hinsichtlich der methodischen 
Korrektheit zurück. 

Im  Folgenden  wird  eine  explizite,  gut  ausgearbeitete  und  methodisch 
kontrollierte Form des thematischen Codierens vorgestellt, nämlich die von 
Christel Hopf u.a. in verschiedenen Projekten eingesetzte Methodik. Hopf 
ist unter den qualitativen Methodikern und Forschern in Deutschland seit 
langem eine der profiliertesten. Sie hat eine Reihe einschlägiger qualitativer 
Studien durchgeführt, die durch ihre sorgfältige methodische Anlage über-
zeugen und in denen – durchaus selbstkritisch – die qualitative Methodik 
reflektiert  wird  (vgl.  Hopf/Nevermann/Schmidt  1985,  Hopf  u.a.  1995, 
Hopf/Hopf  1997,  Hopf/Hartwig  2001).  Teilweise  sind  zu  den  Studien 
auch methodische Begleitmaterialien verfügbar, aus denen sich das regelge-
leitete Vorgehen der Autorinnen im Detail nachvollziehen lässt.13 
                                                           
 
13 Vgl.  Hopf,  C./Schmidt,  C.  (Hrsg.),  1993.  In  diesem  Text  geben  die  Autorinnen  einen 
detaillierten  Einblick  in  die  Methoden  ihrer  Untersuchung.  Die  Interviewleitfäden, 
Transkriptionsregeln und Interviewanweisungen sind ebenso abgedruckt wie die Anwei-
sungen für die technische Vorgehensweise bei der Auswertung. 

Thematisches Codieren 

85 

Die methodische Vorgehensweise bei Hopf und Mitarbeiterinnen 
Am  besten  lässt  sich  die  Vorgehensweise  von  Hopf  u.a.  am  Beispiel  des 
Projekts „Familie und Rechtsextremismus“ nachvollziehen. Im Mittelpunkt 
dieser Studie steht die familiale Sozialisation von rechtsextrem orientierten 
jungen Männern (Hopf u.a. 1995). Ziel der Forschung ist es, Erkenntnisse 
über  den  Zusammenhang  von  rechtsradikaler  Orientierung  und  persönli-
chen Erlebnissen in Kindheit und Jugend zu gewinnen. Mit der Anknüpf-
ung an die psychologische Bindungstheorie wählen Hopf u.a. eine explizit 
theorieorientierte Vorgehensweise. Das Auswertungsverfahren basiert also 
wesentlich stärker als das in der Grounded Theory der Fall ist auf Vorwis-
sen,  vor  allem  theoretischem  Vorwissen.  Folglich  geht  es  in  der  empiri-
schen  Studie  auch  nicht  um  Theoriegenerierung,  wie  in  der  Grounded 
Theory üblich, sondern um die Überprüfung und Weiterentwicklung einer 
als aussichtsreich eingeschätzten Theorie, dies allerdings nicht in generali-
sierender Weise, sondern als fallbezogene Überprüfung der Gültigkeit einer 
Theorie mittlerer Reichweite. Hopf vertritt die unter qualitativ Forschenden 
nicht unumstrittene Position, dass qualitative Forschung durchaus auch zur 
Überprüfung von Theorien geeignet ist, jedoch nicht in dem Sinne dass die 
Allgemeingültigkeit einer Theorie getestet werden könne. Hierzu bedarf es, 
so  Hopf,  selbstverständlich  repräsentativer  Stichproben,  doch  fallbezogen 
lässt sich durchaus ermitteln, ob der betreffende Fall eine Theorie bestätigt 
oder widerlegt. 

Das von Hopf und Mitarbeiterinnen ausgearbeitete Auswertungsverfah-

ren unterscheidet vier hintereinander angeordnete Schritte: 
 

1.  Entwickeln der Auswertungskategorien 
2.  Codieren des Materials 
3.  Erstellen von Fallübersichten 
4.  Vertiefende Analyse von ausgewählten Fällen 

 
Ähnlich wie in der Grounded Theory gilt, dass alle Schritte unmittelbar am 
Material  vorgenommen  werden,  alle  Kategorien  sind  in  den  empirischen 
Daten verankert und das Material wird durch das Codieren nicht überflüs-
sig,  weil  danach  nur  noch  mit  den  Kategorien  und  Codierungen  weiter 
gearbeitet wird. Voraussetzung der Hopfschen Vorgehensweise ist, dass ei-
ne vollständige Transkription des Materials erstellt wird. Zusätzlich und er-
gänzend zum Transkript wird ein Protokoll zum Ablauf des Interviews und 
zur Interviewsituation erstellt. 

 

86 

Sozialwissenschaftliche Ansätze für die kategorienbasierte Textanalyse 

Im Folgenden werden die vier Schritte des Auswertungsprozesses näher 

erläutert: 

Erster Schritt: Entwickeln der Auswertungskategorien 
Dieser erste Schritt beginnt bereits mit der Planung der Datenerhebung, al-
so nicht erst dann, wenn die Daten erhoben, d.h. die Interviews schon ge-
führt sind. Die Entwicklung von Auswertungskategorien beginnt etwa zeit-
gleich  mit  der  Entwicklung  des  Interviewleitfadens.  Hintergrund  ist  eine 
möglichst präzise Formulierung der Forschungsfrage. Dazu kann auch ge-
hören, dass Theorien und auf die Theorie bezogene Begriffe und Katego-
rien schon vor der Erhebung festgelegt werden. Dies gilt aber in jedem Fall 
nur für einen Teil der Kategorien, welche ansonsten aus dem Material he-
raus  entwickelt  werden.  Die  Vorgehensweise  ist  theoriegeleitet,  aber  zu-
gleich  offen,  denn  es  wird  darauf  geachtet,  dass  die  Befragten  selbst  zu 
Wort kommen und man ist sensitiv in Bezug auf theoretische Widersprü-
che und Ungereimtheiten. Die auf den theoretischen Vorannahmen basie-
renden Kategorien werden als „Entwürfe“ verstanden, die durch die empi-
rische Realität verändert werden können und nicht als vorab fixierter una-
bänderlicher  Interpretationsrahmen.  Entwickelt  werden  die  Kategorien  in 
intensiver Auseinandersetzung mit den Texten, die u.U. mehrmals gelesen 
werden. 

Kategorien repräsentieren Themen, sie ähneln Überschriften, die mehr 
oder weniger präzise sein können und ggf. im Zuge des Auswertungspro-
zesses  ausdifferenziert  werden  müssen,  wie  im  folgenden  Zitat  erläutert 
wird: 

„Als  Beispiel  soll  hier  die  Auswertungskategorie  ‚Auseinandersetzung  mit 
der nationalsozialistischen Vergangenheit’ herangezogen werden. Aufgrund 
von Erfahrungen während des Interviews sowie während der Codierung der 
Probeinterviews und der ersten Interviews schien sich zu ergeben, dass die 
Differenzierung  zwischen  den  Interviews  sehr  gering  sind:  In  fast  allen 
Interviews fanden sich Abwehr und Unlust, sich kritisch mit der faschisti-
schen  Vergangenheit  auseinanderzusetzen.  Betrachtet  man  jedoch  die  Be-
gründungen,  zeigten  sich  wichtige  Unterschiede  zwischen  den  Interviews: 
Während  einige  die  nationalsozialistische  Vergangenheit  relativieren,  baga-
tellisieren und verleugnen und sogar positive Seiten darin sehen, finden sich 
solche Argumente bei anderen nicht. Es war also wichtig die Auswertungs-
kategorie entsprechend auszudifferenzieren.“ (Schmidt 1997: 551) 

Thematisches Codieren 

87 

Auf der Basis des Materials werden in der Studie fünf Ausprägungen der 
Kategorie  „Einstellung  zum  Nationalsozialismus“  unterschieden  (vgl. 
Schmidt 1997: 556): 

1.  Der Befragte neigt zur Verherrlichung des Nationalsozialismus. 
2.  Der Befragte meint, dass ein Schlussstrich unter diesen Teil der deut-
schen Geschichte gezogen werden sollte, und meint, dass auch an-
geblich positive Seiten dieser Zeit gesehen werden müssten. 

3.  Der Befragte meint, dass ein Schlussstrich unter diesen Teil der deut-
schen Geschichte gezogen werden sollte, negative Seiten dieser Zeit 
werden gleichwohl gesehen, vermeintlich positive Seiten werden nicht 
hervorgehoben. 

4.  Der Befragte hält es für wichtig, sich weiter kritisch mit der Vergan-

genheit auseinanderzusetzen. 

5.  Keine Angabe, nicht gefragt o.ä., Zuordnung zu einer der vorhande-

nen Kategorien trotz vorhandener Information nicht möglich. 

 
Die Kategorienbildung verläuft folgendermaßen: 

(cid:120)  In  Auseinandersetzung  mit  der  Theorie  und  aufgrund  der  ersten 
Felderkundungen  werden  Kategorien  gebildet,  die  gleichzeitig 
Grundlage des Leitfadens sind. 

(cid:120)  Aufgrund  von  Probeinterviews  und  weiteren  Erfahrungen  im  Feld 
werden die bereits präziser werdenden Kategorien zu einem „Codier-
leitfaden“ zusammengestellt. 

(cid:120)  Gemeinsame  Diskussionen  im  Team  führen  zu  einer  Überprüfung 
der Anwendbarkeit der Kategorien und ggf. zu ihrer Überarbeitung, 
es entsteht der endgültige Codierleitfaden: „Nach Abschluss der Be-
fragung haben wir erste Entwürfe unseres Codierleitfadens zunächst 
mehrfach  erprobt  und  überarbeitet.  In  interpretativer  Auseinander-
setzung  mit  Textpassagen  aus  Probeinterviews  und  aus  den  ersten 
verschrifteten Interviews wurden die Kategorien ausdifferenziert und 
verändert. (...)“ (Hopf u.a. 1995: 29). 

Zweiter Schritt: Codieren des Materials 
Der Codierleitfaden stellt das Instrumentarium dar, mit dem in der zweiten 
Analysephase alle Interviews durchgearbeitet werden: 

„In jedem einzelnen Interview sollten damit Passagen, die explizit oder im-
plizit Informationen zu diesen Kategorien enthielten identifiziert und – im 
Vergleich  mit  anderen  Interviews  –  nach  ihrer  Relevanz  und  Ausprägung 

 

88 

Sozialwissenschaftliche Ansätze für die kategorienbasierte Textanalyse 

bewertet  werden.  (...)  Mit  dem  überarbeiteten  Codierleitfaden  vercodeten 
jeweils  zwei  Projektmitarbeiter  bzw.  -mitarbeiterinnen  die  einzelnen  Inter-
views  zunächst  unabhängig  voneinander,  verglichen  dann  gemeinsam  ihre 
Einschätzungen und versuchten bei diskrepanten Bewertungen eine diskur-
sive  Einigung.  Auf  diese  Weise  haben  wir  das  gesamte  Interviewmaterial 
codiert.  Einzelne  Fälle,  die  besondere  Interpretationsprobleme  aufwarfen, 
wurden zusätzlich in der Gesamtprojektgruppe diskutiert.“ (Hopf u.a. 1995: 
29 f.) 

Dieses Verfahren, von Hopf u.a. als „konsensuelles Codieren“ bezeichnet, 
verlangt  zunächst,  dass  alle  Textstellen,  die  über  eine  Kategorie  (z.B.  die 
Einstellung zum Nationalsozialismus) Auskunft geben können, identifiziert 
werden. Im nachfolgenden Schritt wird eine der fünf oben beschriebenen 
Ausprägungen zugeordnet, und zwar pro Fall insgesamt eine Ausprägung, 
die für den Fall als dominant angesehen wird. 

Dritter Schritt: Erstellen von Fallübersichten 
Der  dritte  Schritt  der  Auswertung  ist  ein  Schritt  der  Materialzusammen-
schau  und  des  quantitativen  Überblicks.  Erstens  lässt  sich  nun  ein  Über-
blick über die Personen und ihre Merkmalskonstellationen schaffen, in dem 
zu ausgewählten Kategorien tabellarische Übersichten erstellt werden (vgl. 
Abb. 19). Die Funktion solcher Tabellen wird darin gesehen, „zur Transpa-
renz der Untersuchung beizutragen, die Materialbasis ein Stück weit offen-
zulegen  und  damit  zur  intersubjektiven  Überprüfbarkeit  beizutragen.“ 
(Schmidt 1997: 562). 

Rechtsextreme 
Orientierungen 

Norm-
bindung 

Fähigkeit/      
Bereitschaft zu 
Empathie 

Autoritaris-
mus-Index 

Attachment  
Klassifikation 

 

Udo 

Uwe 

Volker 

Wilfried 

.. 

 

nicht 
eingeordnet 

eher   
vorhanden 

eher   
vorhanden 

eher   
vorhanden 

eher 
gegeben 

eher 
gegeben 

gering 

eher   
gering 

 

eher          
gegeben 

eher         
gegeben 

eher nicht 
gegeben 

eher nicht 
gegeben 

 

Zwischen-
variante 

abwehrend-
bagatellisierend 

nicht 
eingeordnet 

verstrickt 

Autoritär/ 
klassisch 

Autoritär/ 
klassisch 

 

abwehrend-
bagatellisierend 

abwehrend-
bagatellisierend 

 

Abb. 19: Auszug aus einer Fallübersicht (Schmidt 1997: 562) 

 

 

 

 

 

 

Thematisches Codieren 

89 

Aufbauend  auf  einer  solchen  Materialübersicht  kann  eine  Häufigkeitsaus-
zählung erfolgen: Quantitative Fallübersichten können wie in der Deskrip-
tivstatistik auf einzelne Merkmale bezogen sein („univariate Auswertung“) 
oder den Zusammenhang zwischen zwei Kategorien („bivariate Analyse“) 
oder von drei und mehr Kategorien darstellen („multivariate Auswertung“). 
Einfache  Auswertungen  stellen  nur  die  Verteilung  eines  bestimmten 
Merkmals in der Studie dar und verdeutlichen, wie die Merkmalskonstella-
tion in der gesamten Studie genau aussieht. Stellt sich hier etwa heraus, dass 
das  Bindungsmuster  „verstrickt“  nur  bei  wenigen  Befragten  angetroffen 
wurde, ist dies eine wertvolle Information für die Rezipienten einer Studie. 
Eine  weitergehende  Funktion  können  Kreuztabellen  haben,  in  denen 
die Zusammenhänge zwischen zwei Kategorien sichtbar werden. Hierzu ein 
Beispiel (Hopf u.a. 1995: 131), in dem der Zusammenhang von rechtsex-
tremer Orientierung und Erfahrungen mit liebevoller persönlicher Zuwen-
dung durch die Mutter dargestellt ist: 

Deutlich rechtsex-
trem bzw. eher 
rechtsextrem 

Deutlich nicht 
rechtsextrem bzw. 
eher nicht rechtsex-
trem orientiert 

Nicht               
eingeordnet  

Insgesamt 

4 

2 

3 

1 

10 

- 

- 

1 

- 

1 

5 

7 

11 

2 

25 

 

Viel 

Mittel 

Wenig 

1 

5 

7 

Nicht eingeordnet  1 

insgesamt 

14 

Abb. 20: Beispiel einer Kreuztabelle 

Die in der Tabelle erkennbaren Konstellationen der Stichprobe haben meh-
rere Funktionen für die Analyse: 

(cid:120)  Sie geben einen Überblick, der in dieser Form auch für die Forscher-
gruppe eine neue und zusätzliche Information darstellt und sie davor 
bewahrt, aufgrund selektiver Wahrnehmung (fälschlicherweise) eine 
andere Konstellation zu unterstellen und zu berichten. 

(cid:120)  Sie  lenken  die  Aufmerksamkeit  auf  Zusammenhänge,  die  vielleicht 
so noch gar nicht im Blick waren und motivieren hierdurch dazu, das 
Material  in  Bezug  auf  diesen  in  der  Tabelle  vorhandenen  Zusam-

 

90 

Sozialwissenschaftliche Ansätze für die kategorienbasierte Textanalyse 

menhang qualitativ auszuwerten. Das bedeutet, es wird in die Texte 
zurückgegangen,  um  genau  nachzuvollziehen,  wie  sich  der  Zusam-
menhang fallbezogen darstellt. 

(cid:120)  Sie erlauben es, Ausnahmen zu identifizieren und gezielt auf die dort 
möglicherweise gegebenen Sonderbedingungen hin zu analysieren. In 
der obigen Tabelle sieht man etwa dass  von insgesamt fünf Perso-
nen, die in der Kindheit liebevolle Zuneigung durch die Mutter er-
fahren haben, heute vier nicht rechtsextrem orientiert sind, eine Per-
son  hingegen  doch.  Hier  kann  es  also  besonders  interessant  sein, 
noch einmal nachzufassen und den betreffenden Text genau zu ana-
lysieren. 

(cid:120)  Sie dienen als eine Folie, auf deren Basis Fälle für eine vertiefende 

Analyse ausgewählt werden. 
„Diese Quantifizierungen auf der Ebene des Gesamtmaterials bildeten eine 
wichtige  Grundlage  für  den  nächsten  Auswertungsschritt:  die  qualitative 
Analyse  von  Einzelfällen.  Mit  Hilfe  der  Fallübersichten  ließen  sich  die 
Interviews hierfür begründet anhand der durch die Codierung aufgedeckten 
Konstellationen auswählen.  Aus bestimmten  Konstellationen  z.B. von  Be-
ziehungserfahrungen und Ausprägungen rechtsextremer Orientierungen lie-
ßen sich Vermutungen zu den uns interessierenden Zusammenhängen ablei-
ten  und  dann  anhand  der  ausgewählten  Fälle  vertiefend  interpretieren.“ 
(Hopf u.a. 1995: 29 f.) 

Vierter Schritt: Vertiefende Analyse von ausgewählten Fällen 
In diesem letzten Auswertungsschritt steht die Einzelfallanalyse im Mittel-
punkt. Nah am Text werden Hypothesen aufgestellt oder überprüft, d.h. die 
vertiefende  Fallinterpretation  erfolgt  bei  Hopf  theoriebezogen.  Aufgrund 
der Fallübersichten werden Personen ausgewählt, wobei es sich oft als pro-
duktiv erweisen kann, solche Fälle auszuwählen, auf die die Hypothesen ge-
rade nicht zutreffen (vgl. Schmidt 1997: 564). Die Aufbereitung der Fallbei-
spiele geschieht so, dass in detaillierter Weise, möglichst mit Bezugnahme 
auf  den  Interviewtext,  Zusammenhänge  aufgezeigt  werden,  z.B.  zwischen 
der  rechtsextremen  Orientierung  und  einer  abwehrend-bagatellisierenden 
Umgangsweise mit Bindungserfahrungen (vgl. Hopf u.a. 1995: 138 ff.). Die 
Fallbeispiele  machen  einen  gefundenen  Zusammenhang  nachvollziehbar 
und damit verständlich. Es sind keine tiefenpsychologisch angelegten, breit 
argumentierenden Falldarstellungen – was bei mehreren Stunden Interview 
leicht zu einer mehr als 100-seitigen Darstellung führen könnte – sondern 
sehr konzentrierte, auf die Beantwortung theoretischer Fragen fokussierte 

Thematisches Codieren 

91 

Analysen, in denen die ausgewählte Person nicht als Persönlichkeitsstudie 
betrachtet wird, sondern als „Fall von …“. 

Resümierend lässt sich feststellen, dass sich das thematische Codieren in 
der von Hopf u.a. ausgearbeiteten Form sehr gut für Material eignet, das 
theoriebezogen mit einem Leitfaden erhoben wurde. Es ist also besonders 
adäquat für strukturierte Formen qualitativer Forschung. Hopf u.a. haben 
sich schon frühzeitig mit dem Problem der Qualität qualitativer Forschung 
befasst und versucht die Arbeit im Forschungsteam so zu organisieren, dass 
eine möglichst hohe Güte erreicht wird. Dazu gehört auch das in der For-
schergruppe  praktizierte  konsensuelle  Codieren,  bei  dem  jedes  Interview 
prinzipiell  von  zwei  Mitarbeitern  unabhängig  voneinander  codiert  wird. 
Dass bei Differenzen diese in der Gruppe diskutiert werden und man ge-
meinsam versucht, eine Lösung zu finden. Dies ist der Qualität der Ergeb-
nisse  sicherlich  förderlicher  als  die  Berechnung  eines  Übereinstimmungs-
koeffizienten. 

Festzuhalten ist, dass der Begriff Codieren bei Hopf und Schmidt bzw. 
generell beim thematischen Codieren eine andere Bedeutung hat als in der 
Grounded  Theory.  Dort  meint  Codieren  vor  allem  das  Arbeiten  an  den 
Codes,  d.h.  eine  Entwicklung  von  Kategorien  bis  hin  zum  Finden  von 
Schlüsselkategorien. Bei Hopf bedeutet Codieren hingegen eher traditionell 
wie beim Codierbegriff in der quantitativen Forschung die Zuordnung des 
Materials zu Auswertungskategorien. 

Umsetzung der Methode mit QDA-Software 
Das thematische Codieren lässt sich prinzipiell gut mit QDA-Software be-
treiben, allerdings werden spezielle Techniken, wie das „konsensuelle Co-
dieren“ häufig nicht unterstützt: 
 

(cid:120)  Die in der ersten Phase entwickelten Auswertungskategorien werden 
als  Codes  definiert.  Sie  lassen  sich  später  jederzeit  präzisieren  und 
ausdifferenzieren. 

(cid:120)  Die zu jedem Interview erstellten Protokolle zur Interviewsituation 
und zum Interviewablauf werden als zum gesamten Text gehöriges 
Text-Memo gespeichert. 

(cid:120)  Die Bedeutungen und inhaltlichen Definitionen der Auswertungska-

tegorien werden in Form von Code-Memos festgehalten. 

(cid:120)  Textpassagen, die implizit oder explizit Informationen zu den Kate-

gorien enthalten, werden entsprechend codiert. 

 

92 

Sozialwissenschaftliche Ansätze für die kategorienbasierte Textanalyse 

(cid:120)  Die Ausdifferenzierung und Weiterentwicklung der Kategorien kann 
durch  die  Zusammenstellung  aller  zu  einem  Code  vorhandenen 
Textstellen wirksam unterstützt werden. 

(cid:120)  Die Ausprägungen der Kategorien, beispielsweise die oben beschrie-
benen Ausprägungen der „Einstellungen zum Nationalsozialismus“, 
werden als Subcodes definiert. Die Bedeutungen werden wiederum 
als Code-Memos formuliert. 

(cid:120)  Konsensuelles  Codieren  kann  in  MAXQDA  so  realisiert  werden, 
dass unterschiedliche Codierer mit unterschiedlichen Codefarben ar-
beiten.  Beim  Codieren  sind  zunächst  nur  die  eigenen  Codierungen 
sichtbar.  Im  zweiten  Schritt,  bei  der  Zusammenschau,  werden  die 
Codierungen beider Codierer eingeblendet, so dass Differenzen so-
gleich erkennbar sind und mit dem Ziel, einen Konsens zu finden, 
diskutiert werden. (vgl. Kuckartz u.a. 2008: 40 ff.) 

(cid:120)  Der Codierleitfaden kann erstellt werden, in dem alle Code-Memos 

zusammengestellt werden. 

(cid:120)  Die  Häufigkeiten  der  Ausprägungen  von  Kategorien  stehen  ohne 

weitere Suche und Auszählen zur Verfügung. 

(cid:120)  Fallübersichten lassen sich leicht automatisiert erstellen. 
(cid:120)  Kreuztabellen, die eine mehrdimensionale Zuordnung des Materials 
vornehmen,  sind  ebenfalls  leicht  zu  erstellen  (in  MAXQDA  emp-
fiehlt sich in diesem Fall die Nutzung der Möglichkeit, Codes in dy-
namische Variablen umzuwandeln). 

4.3  Zusammenfassende qualitative Inhaltsanalyse 

Ein  weiterer  Ansatz  kategorienbasierter  Auswertung  ist  die  von  Mayring 
beschriebene  zusammenfassende  Inhaltsanalyse.  Mayrings  Entwurf  einer 
qualitativen  Inhaltsanalyse  (Mayring  2003)  ist  in  Auseinandersetzung  mit 
der  klassischen,  aus  der  Kommunikationsforschung  stammenden  Inhalts-
analyse entstanden, aus der wesentliche Momente übernommen werden. So 
ist die Inhaltsanalyse auch bei Mayring durch vier Merkmale gekennzeich-
net, die ebenso für die klassische Inhaltsanalyse gelten, nämlich durch Ein-
ordnung  in  ein  Kommunikationsmodell,  Regelgeleitetheit,  Gütekriterien 
und vor allem durch die zentrale Rolle von Kategorien. Die qualitative In-
haltsanalyse will sprachliches Material systematisch analysieren, indem sie 
 

Zusammenfassende qualitative Inhaltsanalyse 

93 

(cid:120)  das Material zergliedert und schrittweise bearbeitet, 
(cid:120) 
(cid:120)  die Analyseaspekte vorher festlegt. 

theoriegeleitet am Material ein Kategoriensystem entwickelt und 

 
Mayring  (2003: 58)  unterscheidet  drei  Grundformen  des  Interpretierens: 
Zusammenfassung,  Explikation  und  Strukturierung.  Bei  der  Auswertung 
von Forschungsdaten, so auch bei der von Mayring als Beispiel herangezo-
genen eigenen Untersuchung über Lehrerarbeitslosigkeit, wird zunächst die 
Technik der zusammenfassenden Inhaltsanalyse mit induktiver Kategorien-
bildung eingesetzt. Die Zielsetzung der zusammenfassenden Inhaltsanalyse 
ist es „das Material so zu reduzieren, dass die wesentlichen Inhalte erhalten 
bleiben, durch Abstraktion einen überschaubaren Corpus zu schaffen, der 
immer noch Abbild des Grundmaterials ist“ (ebd.). 

Anders als bei der Grounded Theory und beim thematischen Codieren 
versteht Mayring die Inhaltsanalyse als Instrumentarium einer im traditio-
nellen Verständnis des Forschungsprozesses als gesondert definierten Aus-
wertungsphase.  Die  gebildeten  Kategorien  haben  also  keine  Rückwirkung 
auf die Datenerhebung und deren Gestaltung: Die Daten sind alle bereits 
erhoben,  wenn  die  qualitative  Inhaltsanalyse  beginnt.  Die  Methode  ließe 
sich aber theoretisch durchaus auch bei einem stärker zirkulär organisierten 
Forschungsprozess verwenden. Das Wissen um die Mayringsche Konzep-
tion einer gesonderten Analysephase ist allerdings als Hintergrund notwen-
dig, um das folgende, aus sieben Schritten bestehende Ablaufmodell der zu-
sammenfassenden Inhaltsanalyse14 richtig zu verstehen. 
 

1.  Bestimmung der Analyseeinheiten 
2.  Paraphrasierung der inhaltstragenden Textstellen (Z1-Regeln) 
3.  Bestimmung  des  angestrebten  Abstraktionsniveaus,  Generalisierung 

der Paraphrasen unter diesem Abstraktionsniveau (Z2-Regeln) 

4.  Reduktion  durch  Selektion,  Streichen  bedeutungsgleicher  Paraphra-

sen (Z3-Regeln) 

                                                           
 
14 Mayring beschreibt in seinem Buch zur qualitativen Analyse noch zwei weitere inhalts-
analytische Ansätze: die explizierende Inhaltsanalyse, die eher an der klassischen Herme-
neutik  orientiert  ist  und  Textstellen  durch  Hinzuziehung  weiteren  Materials,  Hinter-
grundwissens  etc.  zu  verstehen  sucht  sowie  die  strukturierende  Inhaltsanalyse,  die  das 
Textmaterial unter bestimmten Kriterien strukturiert und meist auch quantifizierend un-
tersucht. Dieser Ansatz wird in Kapitel 8.3 aufgegriffen und skizziert. 

 

94 

Sozialwissenschaftliche Ansätze für die kategorienbasierte Textanalyse 

5.  Reduktion durch Bündelung, Konstruktion, Integration von Paraph-

rasen auf dem angestrebten Abstraktionsniveau (Z4-Regeln) 
6.  Zusammenstellung der neuen Aussagen als Kategoriensystem 
7.  Rücküberprüfung  des  zusammenfassenden  Kategoriensystems  am 

Ausgangsmaterial 

 
Die Richtung der Analyse ist klar vorgegeben, nämlich Reduktion des Ma-
terials auf einem vorab möglichst genau fixierten Abstraktionsniveau. Nach 
der Festlegung des Materials und der Bestimmung von Codiereinheiten, er-
folgt eine Phase der Paraphrasierung der inhaltlich interessanten Abschnit-
te, bei der laut Mayring (2003: 62) drei Regeln zu beachten sind: 
 

1.  Streiche alle nicht (oder wenig) inhaltstragenden Textbestandteile wie 

ausschmückende, wiederholende, verdeutlichende Wendungen! 

2.  Übersetze die inhaltstragenden Textstellen auf eine einheitliche Sprach-

ebene! 

 

3.  Transformiere sie auf eine grammatikalische Kurzform! 

Paraphrase 

Nr. 
A 1  Keine psychische Belastung durch 

Praxisschock gehabt 

A 2 

Im Gegenteil, ganz begierig auf 
Praxis gewesen 

Generalisierung  
Kein Praxisschock, als 
großen Spaß erlebt wegen

Eher auf Praxis gefreut 

A 3  Uni = reines Fachstudium, hat mit 

Leben wenig zu tun 

An Uni keine 
Lehrerfahrung vermittelt 

A 4  Konnte aber vorher schon 

Praxiserfahrungen sammeln 

Schon vorher 
Lehrerfahrung 

A 5  Praxis hat großen Spaß gemacht 

Praxis hat Spaß gemacht 

A 6  War stofflich einfach und 

faszinierend für die Schüler 

Gut vermittelbarer Stoff 
als Bedingung 

A 7  Darauf gewartet, endlich zu 

unterrichten 

Auf Praxis gefreut  

A 8  Es gibt schon Enttäuschungen, 

dass die Schüler nicht so sind, wie 
man meint 

Schon auch 
Enttäuschungen 

A 9  Praxisschock war es bestimmt 

nicht 

Kein Praxisschock 

Reduktion 
K1 
Praxis nicht als Schock, 
sondern als großen Spaß 
erlebt wegen 
- vorheriger Lehrerfahrung 
- Landschule ohne 
Disziplinschwierigkeiten 
- keine unrealistischen 
Erwartungen gehabt 
- gute Beziehungen zu 
Schülern gehabt 
 
K2 
Ohne diese Bedingungen 
Praxisschock schon denkbar 

Abb. 21: Von der Paraphrase zur Kategorienbildung (Mayring 2003: 64 ff., auszugs-

weise) 

Zusammenfassende qualitative Inhaltsanalyse 

95 

Mayring  demonstriert  den  Ablauf  der  Phasen  3  bis  6  an  Beispielmaterial, 
das unter der Fragestellung „Was sind die hauptsächlichen Erfahrungen der 
arbeitslosen Lehrer mit dem ‚Praxisschock’“ ausgewertet wird. 

Schritt für Schritt wird das Material nach genau festgelegten Regeln, den 
so  genannten  Z-Regeln  (Mayring  2003:  62),  reduziert  und  das  Abstrakti-
onsniveau erhöht. Die Paraphrasierung ist zeitaufwändig und bei größeren 
Textmengen kaum mehr möglich, so dass ein abgekürztes Verfahren ange-
wandt wird: Bei jeder neuen generalisierten Paraphrase wird vor dem He-
rausschreiben geprüft, ob sie nicht schon vorhanden ist bzw. mit einer an-
deren Aussage gebündelt werden kann. 

Die in Abb.  21 dargestellte Kategorienbildung geschieht zunächst fall-
bezogen. Nachdem alle Fälle auf diese Weise bearbeitet sind, wird in einem 
weiteren  Integrationsschritt  fallübergreifend  vorgegangen.  Das  Abstrakti-
onsniveau wird weiter erhöht und nun sind es die Kategorien, die reduziert, 
gebündelt und integriert werden. Endresultat sind Kategorien wie die fol-
genden von Mayring beschriebenen Kategorien K1 und K3: 

„K1 Kein Praxisschock tritt auf, wenn man 
- vorher Lehrerfahrung macht; 
- gute Referendariatsbedingungen hat; 
- flexibel und anpassungsfähig ist; 
- offen mit Kollegen redet; 
- keine ‚unrealistischen’ pädagogischen Erwartungen hat  
(…) 
K3 In jedem Fall ist eine gute Beziehung zu Schülern erreichbar.“ (ebd.: 72) 

Man  erkennt  sogleich,  dass  diese  Kategorien  einen  anderen  Charakter  als 
die  Codes  der  Grounded  Theory  oder  die  thematischen  Kategorien  bei 
Hopf u.a. haben. Sie sind keine kurzen Bezeichnungen wie „Apparat-Kör-
per-Anschlüsse“  oder  thematische  Codes  wie  „Einstellungen  zum  Natio-
nalsozialismus“,  sondern  relativ  komplexe  inhaltliche  Aussagen.  Das 
Grundmodell der zusammenfassenden qualitativen Inhaltsanalyse lässt sich 
sehr gut für die induktive Bildung von Kategorien verwenden, die dann im 
weiteren Verlauf der Auswertung, z. B. bei der strukturierenden Inhaltsana-
lyse, deduktiv angewendet werden. 

Vom  Analysestil  der  Grounded  Theory  unterscheidet  sich  Mayrings 
Konzeption der qualitativen Inhaltsanalyse dadurch, dass sie weitaus stärker 
regelgeleitet  ist  und  methodisch  kontrollierter  vorgeht.  Auch  die  Auswer-
tung großer Textcorpora ist mit dieser Methode möglich, jedenfalls dann, 
wenn man nur eine eingeschränkte Form der Paraphrasierung wählt. 

 

96 

Sozialwissenschaftliche Ansätze für die kategorienbasierte Textanalyse 

Im Vergleich zur Grounded Theory und auch zum thematischen Codie-
ren  erscheint  die  zusammenfassende  qualitative  Inhaltsanalyse  wesentlich 
stärker beschreibend und weniger theorieorientiert zu sein. Theorieentwick-
lung  und  erst  recht  Theorieüberprüfung  spielen  hier  eine  weit  geringere 
Rolle als bei den zuvor dargestellten Ansätzen. Das Verfahren der zusam-
menfassenden Inhaltsanalyse hält sich sehr eng an die Texte und zielt auf 
eine sorgfältige und methodisch kontrollierte Zusammenfassung und Kate-
gorienbildung.  Diese  Strategie  steht  durchaus  im  Spannungsverhältnis  zur 
Grundorientierung der Grounded Theory, deren Autoren ja explizit emp-
fehlen, sich von den Texten und ihrer bloßen Wiederholung oder Verdopp-
lung möglichst schnell zu entfernen. Die zusammenfassende Form der qua-
litativen Inhaltsanalyse ist unter den in diesem Kapitel vorgestellten Ansät-
zen der am stärksten induktiv vorgehende und insofern für solche Frages-
tellungen besonders geeignet, bei denen das Vorwissen gering ist und die 
Exploration im Vordergrund steht. 

Umsetzung der Methode mit QDA-Software 
Die  qualitative  Inhaltsanalyse  ist  mit  den  meisten  QDA-Programmen  gut 
umsetzbar,  wenngleich  diese  nicht  unbedingt  für  das  Paraphrasieren  von 
Textstellen konzipiert sind. Mehrspaltige Tabellenlayouts wie oben in Abb. 
21  lassen  sich  in  keinem  QDA-Programm  erzeugen,  allerdings  kann  man 
die Daten gleich so vorbereiten, dass sie sich in einer mehrspaltigen Tabelle 
befinden,  in  welcher  die  entsprechenden  Spalten  für  die  Paraphrasierung 
und Generalisierung zunächst noch leer sind. Das Arbeiten mit Tabellen ist 
zweifellos  ein  komfortabler  Weg  der  Umsetzung  der  qualitativen  Inhalts-
analyse, es lassen sich aber auch ersatzweise andere Vorgehensweisen wäh-
len, die mit QDA-Software besser zu realisieren sind: 
 

(cid:120)  Die Paraphrasierungen können so vorgenommen werden, indem die 
betreffende  Textstelle  markiert  und  die  Paraphrase  als  Code  zuge-
wiesen wird. Da Paraphrasen üblicherweise recht kurz sind, ist diese 
Technik  recht  effektiv,  weil  die  Paraphrasen  immer  direkt  neben 
dem Text angezeigt werden. 

(cid:120)  Die  so  als  Codes  organisierten  Paraphrasen  können  gruppiert,  ge-
bündelt und integriert werden. Sie lassen sich im Kategoriensystem 
unter eine abstraktere Kategorie gruppieren, ebenso können Dopp-
lungen gelöscht werden. 

Typenbildung und typologische Analyse 

97 

(cid:120)  Der Materialbezug bleibt auch so erhalten, denn von jeder Paraphra-
se kann sofort zu der Textstelle gesprungen werden, auf die sich die 
Paraphrase bezieht. 

 
Weitere methodische Charakteristika der qualitativen Inhaltsanalyse  lassen 
sich mit QDA-Software folgendermaßen realisieren: 
 

(cid:120)  Die Definitionen von Einschätzungsdimensionen können als Code-
Memos eingegeben werden. Ankerbeispiele lassen sich dort einfügen. 
(cid:120)  Informationen  über  den  Text,  seine  Herkunft  und  sein  Zustande-

kommen lassen sich als Text-Memo formulieren. 

(cid:120)  Als  quantitative  Information  sind  die  Häufigkeiten  von  Code-

Zuordnungen vorhanden. 

(cid:120)  Für die Darstellung der zusammenfassenden Inhaltsanalyse in einem 
Forschungsbericht  lassen  sich  die  Zusammenstellungen  von  Text-
stellen zu ausgewählten Kategorien nutzen. 

(cid:120)  Die  von  der  QDA-Software  vorgenommene  Dokumentation,  wel-
ches  Mitglied  der  Forschergruppe  welche  Codierungen  vorgenom-
men hat, dient der Transparenz und fördert die Güte der Untersu-
chung. 

4.4  Typenbildung und typologische Analyse 

In  zahlreichen  qualitativen  Studien  werden  Verfahren  der  Typenbildung 
eingesetzt15  und  auch  in  der  sozialwissenschaftlichen  Methodenliteratur 
lässt  sich  eine  Reihe  von  Vorschlägen  zur  systematischen,  empirisch  be-
gründeten Typenbildung bei der Analyse qualitativer Daten finden16 . Weit-
hin  bekannt  ist  die  klassische  Studie  „Die  Arbeitslosen  von  Marienthal“, 
deren wichtigstes Ergebnis in der Herausarbeitung einer Typologie von vier 
Haltungstypen  (die  Ungebrochenen,  die  Resignierten,  die  Verzweifelten  und  die 
Apathischen) bestand17. Kaum einen Begriff findet man im Sachregister von 

                                                           
 
15 Z.B. Herwartz-Emden 1986, Schründer-Lenzen 1995 und 1996, Gerhardt 1986. 
16 Z.B. Gerhardt 1995, Kluge 1999, Kelle/Kluge 1999, Kuckartz 1988, 1995, 1996, Schrün-

der-Lenzen 1999. 

17 Vgl. die interessante Webseite des Psychologischen Instituts der Universität Hannover: 

www.sozpsy.uni-hannover.de/marienthal/ 

 

98 

Sozialwissenschaftliche Ansätze für die kategorienbasierte Textanalyse 

Lamneks Lehrbuch „Qualitative Sozialforschung“ so häufig wie den Begriff 
„Typ“  und  dessen  Derivate  („Typenbildung“,  „Typisierung“,  „Typologie“ 
etc.). In der Methodenliteratur kursieren zahlreiche Typenbegriffe, so ist die 
Rede von Ideal-, Real-, Proto-, Durchschnitts- und Extremtypen (vgl. Klu-
ge 1999: 25 ff.). Den unterschiedlich akzentuierten Begriffen ist gemeinsam, 
einen Typ als Kombination spezifischer Merkmale zu beschreiben. Wichtig 
ist zwischen der Ebene der Typologie und der Ebene des einzelnen Typs zu 
unterscheiden. Ein Typ ist das Grundelement einer Typologie, diese ist aber 
mehr als eine Summe von Typen, denn sie strukturiert einen Gegenstands-
bereich. 

Methodische Traditionen 
Eine  methodisch  kontrollierte  Typenbildung  knüpft  an  die  Überlegungen 
von Max Weber und Alfred Schütz an: Alfred Schütz, der das Alltagswissen 
und Alltagsbewusstsein einer eingehenden Analyse unterzog, kam zu dem 
Ergebnis, dass „das Alltagswissen des Einzelnen von der Welt ein System 
ihrer typischen Aspekte ist“ (1972, Bd. 1: 8). Das gesamte Erfahrungswis-
sen ist in Form von typischer Erfahrung organisiert, die Umwelt wird nicht 
„als eine Anordnung diskreter, einmaliger Gegenstände, die in Raum und 
Zeit verteilt sind, erfahren, sondern als ‚Berge’, ‚Bäume’, ‚Tiere’, ‚Mitmen-
schen’.“  (ebd.:  8 f.).  Die  Vermittlung  von  Alltagswissen  durch  Lehrer,  El-
tern, Freunde etc. im Verlauf des Sozialisationsprozesses umfasst nicht nur 
Definitionen  der  Umwelt,  sondern  auch  Konstruktionen  intersubjektiver 
gedanklicher  Gegenstände.  „Diese  Konstruktionen  umfassen  die  Lebens-
weise,  umfassen  Methoden,  in  der  Umwelt  zurechtzukommen,  also 
brauchbare Anleitungen zur Benutzung typischer Mittel, um typische Ziele 
in typischen Situationen zu erreichen (ebd.: 15). Für Schütz ist also Typen-
bildung  zum  einen  eine  anthropologische  Basistechnik,  zum  anderen  Ziel 
sozialwissenschaftlicher Analyse, die eben auf das Verstehen des Typischen 
und  nicht  psychologisch  auf  das  Verstehen  des  Einzelnen  abzielt.  Damit 
befindet  sich  Schütz  in  der  Tradition  Max  Webers,  der  die  Konstruktion 
von  verständlichen  Handlungstypen  zum  zentralen  Ziel  empirischer  Sozialwis-
senschaft erklärte. Sie sind eine Art Bindeglied zwischen einer hermeneuti-
schen Methodik, die auf das Verstehen des Einzelfalls abzielt, und einer auf 
gesetzesartige  Zusammenhänge  fixierten  sozialwissenschaftlichen  Statistik. 
(vgl. Weber 1964, Hopf/Weingarten 1979, Kuckartz 1991, Lazarsfeld 1972). 

Typenbildung und typologische Analyse 

99 

In der Praxis empirischer Sozialforschung sind verschiedene Konzepte 
empirisch  begründeter  Typenbildung  herausgearbeitet  worden.  Susann 
Kluge vergleicht in ihrem umfänglichen Band „Empirisch begründete Ty-
penbildung“ drei Verfahren der Typenbildung in detaillierter Weise: die Ty-
pologische Operation der Reduktion nach Barton und Lazarsfeld, die Prozessstruk-
turanalyse nach Gerhardt und die typologische Analyse nach Kuckartz. 

Die weitere Darstellung in diesem Kapitel konzentriert sich auf die typo-
logische Analyse nach Kuckartz, in der sich wesentliche Punkte der Konzepti-
on von Barton und Lazarsfeld wieder finden18.  

Die typologische Analyse 
Das Modell der typologischen Analyse hat der Autor an den Begriff „Merkmals-
raum“  und  die  Webersche  Methodologie  anknüpfend  entwickelt  und  in 
empirischen  Projekten  angewendet  (Kuckartz  1988,  1995,  de  Haan/Ku-
ckartz/Rheingans 2000). Das Verfahren war von Anfang an mit der Ent-
wicklung  von  QDA-Software  verknüpft,  deren  Möglichkeiten  die  Chance 
eröffneten, eine wirklich transparente, methodisch kontrollierte und inter-
subjektiv  nachvollziehbare  Typenbildung  vorzunehmen  (vgl.  Kuckartz 
1988). Seit Ende der 1980er Jahre entstanden mit den Programmen MAX 
und  winMAX  Softwaretools,  die  speziell  auf  die  Umsetzung  des  typolo-
gischen Ansatzes hin konzipiert waren. Im Unterschied zu den in den vor-
angehenden Abschnitten dargestellten Ansätzen der Grounded Theory, des 
thematischen Codierens und der zusammenfassenden Inhaltsanalyse ist die 
typologische  Analyse  von  vornherein  als  computergestütztes  Verfahren 
entwickelt  worden,  während  die  anderen  Ansätze  von  ihren  Autoren  als 
handwerkliche  Techniken  beschrieben  und  teilweise  im  Nachhinein  um 
Überlegungen der Computerisierung ergänzt wurden (vgl. Kap. 6 in May-
                                                           
 
18 Die Prozessstrukturanalyse ist ein von Uta Gerhardt (1986, 1991) entwickeltes Verfahren, 
das  an  die  idealtypische  Begriffsbildung  von  Max  Weber  anknüpft.  Die  Gerhardtsche 
Vorgehensweise zielt dabei nicht auf die Bildung einer (Real-)Typologie, die in den empi-
rischen Daten „gründet“, als vielmehr auf die Bildung eines zugespitzten idealtypischen 
Konstrukts. Dieser detailliert entwickelte Ansatz arbeitet in der Forschungspraxis nicht 
mit Computerunterstützung, sondern hat einen eindeutig hermeneutischen Schwerpunkt. 
Kluge, die den Gerhardtschen Ansatz umfassend darstellt (vgl. Kluge 1999: 110 ff.) kriti-
siert  die  „weltfremde“  idealtypische  Vorgehensweise.  „  Bei  der  Bildung  von  wenigen 
Ideal- und Extremtypen besteht jedoch die Gefahr, dass die Vielfalt und Differenz sowie 
die Widersprüchlichkeit der untersuchten Realität verloren geht, weil der Blick nur noch 
auf die idealtypische Zuspitzung bzw. die Extreme gelenkt wird.“ (ebd.: 280) 

 

100 

Sozialwissenschaftliche Ansätze für die kategorienbasierte Textanalyse 

ring  2003).  Aus  diesem  Grund  enthält  dieses  Kapitel  keinen  gesonderten 
Abschnitt, in dem die Umsetzbarkeit mit QDA-Software beschrieben wird, 
sondern die Darstellung beschreibt von vornherein die Schritte der compu-
terunterstützten  Auswertung.  Die  typologische  Analyse  besteht  aus  vier 
hintereinander angeordneten Hauptphasen: 

Phase A) Thematisches Codieren und Themenanalyse 
Phase B) Dimensionalisieren und Feincodierung (das „Wie“ Codieren“) 
Phase C) Typenbildung und Charakterisierung der Typologie 
Phase D) Typenbasierte Fallanalyse 

Phase A) Thematisches Codieren und Themenanalyse 
Diese erste Phase setzt sich aus sechs Auswertungsschritten zusammen: 
 

1.  Einzelfallanalyse – die Interpretation einzelner Texte 
2.  Vergleichende Einzelfallanalyse 
3.  Entwicklung von thematischen Kategorien 
4.  Zuordnung von Codes zu Textsegmenten 
5.  Themenanalyse  (Zusammenstellung  und  Interpretation  aller  Text-

segmente, die dem gleichen Code zugeordnet sind) 

6.  Vergleichende  Themenanalyse  (Analyse  des  Zusammenhangs  zwi-

schen Codes) 

 
In ihren ersten Schritten arbeitet die Methode hermeneutisch: Es geht zu-
nächst darum, den subjektiv gemeinten Sinn eines Textes herauszuarbeiten. 
Erst auf dieser Grundlage kann die Frage nach Gleichförmigkeiten und Re-
gelmäßigkeiten gestellt werden. Begonnen wird deshalb mit einer „Gesamt-
schau” von Einzelfällen. Die Codes, die in den folgenden Schritten entwi-
ckelt und Textsegmenten zugeordnet werden, bezeichnen das Was. Sie die-
nen  dazu,  Themen  und  Fragestellungen  in  den  Interviews  zu  identifizieren. 
Die  Codierung  ist  die  notwendige  Voraussetzung  für  die  folgende  quer-
schnittliche Auswertung, bei der die zu den gleichen Kategorien gehören-
den Textsegmente in vergleichender Weise bearbeitet werden. Die techni-
sche Vorgehensweise entspricht der oben im Abschnitt „Thematisches Co-
dieren“ beschriebenen. Je nach Fragestellung und Theoriebezug der Studie 
können die Codes induktiv oder deduktiv generiert werden. 

Die  vergleichende  Themenanalyse  hat  das  Ziel,  durch  kontrastierende 
Vergleiche Ähnlichkeiten zwischen den  einzelnen Personen,  Besonderhei-
ten  einzelner  Fälle  und  Zusammenhänge  von  Kategorien  zu  finden.  Am 

Typenbildung und typologische Analyse 

101 

Ende dieser  Phase ist die  Analyse bereits weit vorangekommen:  Das Da-
tenmaterial ist strukturiert worden, d.h. in eine überschaubare thematische 
Ordnung gebracht worden. Es gleicht nun den geordneten Arzneimitteln in 
einer Apotheke, die sich wohl sortiert in Schubladen- oder Regalschränken 
befinden. In diesen einzelnen Schubladen befinden sich die Textsegmente 
der  Interviews,  die  man  durch  Codierung  entsprechend  zugeordnet  hat. 
Diese Segmente lassen sich im Weiteren deskriptiv auswerten, indem gewis-
sermaßen der Schubladeninhalt ausgebreitet und zu einem neuen Text ver-
dichtet und montiert wird, der einen bestimmten umgrenzten thematischen 
Aspekt  behandelt.  Sofern  das  Datenmaterial  überschaubar  ist,  lassen  sich 
durch sorgfältige Inspektion und Interpretation Muster erkennen, und man 
ist in der Lage, „dichte Beschreibungen“ zu verfassen. 

Phase B) Dimensionalisieren und Feincodierung („Wie“-Codieren) 
Die erste Analysephase bringt an ihrem Ende nicht nur eine Rekontextuali-
sierung des Materials hervor, in dem z.B. Zusammenhänge zwischen Codes 
analysiert  werden,  sondern  sie  kann  als  Resultat  der  Interpretationsarbeit 
auch  Differenzierungen  nahe  legen,  so  wie  bei  der  Hopfschen  Kategorie 
„Einstellung  zum  Nationalsozialismus“,  wo  zwischen  verschiedenen 
Grundrichtungen  („Ausprägungen“)  unterschieden  wird.  In  der  jetzt  fol-
genden  zweiten  Phase  der  Typologischen  Analyse  geht  es  nach  der  noch 
recht groben Codierung der ersten Analysephase nun um eine „Feincodie-
rung“,  die  in  der  Regel  einen  erneuten  Materialdurchlauf  erforderlich 
macht. Ziel dieser Phase ist die Dimensionalisierung, d.h. es werden Aus-
prägungen  einer  Kategorie  zunächst  herausgearbeitet,  dann  definiert  und 
schließlich codiert. 

Diese  Feincodierung  des  Materials  kann  sowohl  textstellenbezogen  als 
auch  fallbezogen  geschehen.  Bei  der  ersten  Alternative  werden  die  neuen 
Dimensionen als Subkategorien definiert und die codierten Textstellen neu 
zugeordnet.  Die  alten  Codierungen  werden  damit  überflüssig.  Bei  dieser 
Variante wird zunächst nicht auf der Ebene des Falls codiert, es kann sich 
also herausstellen, dass Personen sich nicht nur in homogener Weise geäu-
ßert haben, also nicht nur Textstellen zu einer Dimension aufweisen. Die 
Aggregation  zu  einer  für  die  Person  charakterisierenden  Merkmalsausprä-
gung erfolgt hier erst am Ende der Feincodierung. Diese kann so erfolgen, 
dass durch die Codierer eine abschließende Bewertung der – möglicherwei-
se kontradiktorischen – Textstellencodierungen vorgenommen wird. MAX-

 

102 

Sozialwissenschaftliche Ansätze für die kategorienbasierte Textanalyse 

QDA  ermöglicht  auch  eine  automatische  Umwandlung  von  Kategorien-
häufigkeiten in fallbezogene Variablen. 

Bei der zweiten Alternative, der fallbezogenen Feincodierung, wird auf-
grund der Inspizierung aller die Kategorie betreffenden Textsegmente eine 
Gesamtbewertung aller das Thema betreffenden Äußerungen einer Person 
vorgenommen und jeder Person nur eine bestimmte Merkmalsausprägung 
zugeordnet.  Hier  haben  die  Dimensionen  die  Bedeutung  von  Variablen 
(Attributen)  –  Mayring  bezeichnet  sie  als  „Einschätzungsdimensionen“ 
(Mayring  2003:  92 ff.).  In  MAXQDA  lässt  sich  hierzu  das  Werkzeug  der 
Fallvariablen  nutzen.  Durch  sorgfältige  Klassifikation  des  Datenmaterials 
und durch Einstufung der individuellen Aussagen auf Merkmalsdimensio-
nen  wird  eine  Voraussetzung  für  das  Erkennen  von  komplexen  Zusam-
menhängen in den Daten geschaffen. In der gesamten Phase der Codierung 
des Wie finden Interpretations-, Klassifizierungs- und Bewertungsvorgänge 
statt, die häufig mit einem mehrmaligen Durchgang durch das Datenmate-
rial verbunden sind. Es ergibt sich folgender Ablauf: 
 
1.  Durchsicht aller Textsegmente zu einem Code 
2.  Dimensionsanalyse,  d.h.  systematische  Auswertung  des  empirisch 

vorgefundenen Antwortspektrums zu den betreffenden Themen 

3.  Definition von Dimensionen (Merkmalsausprägungen) 
4.  Formulierung eines Codierleitfadens mit prototypischen Beispielen 
5.  Fallbezogene Bewertung und Codierung 

 
Wenn das Datenmaterial sehr umfangreich ist bzw. der Analyseprozess im 
Projekt schon so weit fortgeschritten ist, dass die Dimensionen bereits fest-
stehen, lassen sich die Phasen A „Thematisches Codieren und Themenana-
lyse“ und B „Dimensionalisieren und Feincodierung“ auch zusammenzie-
hen, indem den Textstellen direkt eine Subkategorie zugewiesen und keine 
gesonderte Grobcodierung vorgenommen wird. Bezüglich der Anzahl der 
Dimensionen, die man unterschieden will, sollte man pragmatisch vorgehen 
und den Sample-Umfang beachten. Es macht wenig Sinn, bei relativ weni-
gen  Probanden  sehr  viele  Merkmalsausprägungen  zu  unterscheiden,  denn 
im  nächsten  Schritt  der  Analyse  geht  es  um  die  Bildung  von  Typen,  um 
Ähnlichkeiten und Differenzen von Probanden – und dies macht zwingend 
erforderlich, dass nicht jeder Einzelfall ein Sonderfall ist, sondern sich die 
definierten  Merkmalsdimensionen  auch  bei  mehreren  Fällen  des  Samples 
finden lassen. 

Typenbildung und typologische Analyse 

103 

Phase C) Typenbildung und Charakterisierung der Typologie 
Basis der Typenbildung ist die Definition eines „Merkmalsraums“ („proper-
ty pace“ bzw. „attribute space“). Typologien beruhen nicht auf einem einzi-
gen, sondern auf mehreren, mindestens auf zwei Merkmalen. Diese Merk-
male konstituieren einen n-dimensionalen Merkmalsraum. Hempel und Op-
penheim, auf die der Begriff „Merkmalraum“19 zurückgeht, zogen den Ver-
gleich zur Physik, die die räumliche Lage von Punkten mittels abstufbarer 
Koordinatenbegriffe bestimmt. 

„Auf diese Weise wird das Individuum nicht einfach klassifizierend in einen 
Typus eingeordnet, sondern es erhält (...) einen Ort im typologischen Merk-
malraum  individuell  zugewiesen.  (...)  So  bestimmt  also  jede  typologische 
Theorie  einen  besonderen  Merkmalraum,  und  die  Typbegriffe  ordnender 
Form haben, (...), eine ähnliche Funktion wie der Begriff ‚Ort (eines Masse-
punkts)’ in der Physik: sie dienen zur Charakterisierung der Lage eines Indi-
viduums im Merkmalraum der betreffenden typologischen Theorie.“ (Hem-
pel/Oppenheim 1936: 67) 

Die Typenbildung besteht aus vier Kernpunkten: 
 

(cid:120)  der Definition des der Typenbildung zugrunde liegenden Merkmals-

raums, 

(cid:120)  der eigentlichen Konstruktion der Typologie, 
(cid:120)  der Beschreibung der einzelnen Typen der gebildeten Typologie 
(cid:120)  der Zuordnung der Personen des Samples zu den gebildeten Typen 

 
Im ersten Schritt der Typenbildung ist zu entscheiden, welche Merkmale als 
relevant für die Typologie betrachtet werden. Wie viele Merkmale man über-
haupt einbeziehen kann, hängt von der Art der Konstruktion der Typologie 
ab. Es lassen sich drei Haupttypen von Typologiekonstruktion unterschei-
den. 

Bildung einer monothetischen Typologie 
Eine Typologie, in der alle Elemente eines Typs identische Merkmale besit-
zen,  bezeichnet  man  als  monothetisch.  Einfachstes  Beispiel  ist  eine  Vier-
Felder-Tafel auf der Basis von zwei dichotomen Merkmalen: 
                                                           
 
19  Bei  Hempel/Oppenheim  (1936),  wie  auch  in  der  seinerzeitigen  Physik,  ist  immer  von 
Merkmalraum die Rede und nicht wie heute meistens vom Merkmalsraum. Hier wird im 
Weiteren  der  heute  häufiger  benutzte  Begriff  „Merkmalsraum“  verwendet,  es  sei  denn 
Hempel/Oppenheim werden zitiert. 

 

104 

 

 

Einkommen 

Sozialwissenschaftliche Ansätze für die kategorienbasierte Textanalyse 

 

 

Hoch 

niedrig 

                   Geschlecht 

Männlich 

Typ 1 

Typ 3 

Weiblich 

Typ 2 

Typ 4 

Die Zugehörigkeit zu Typ 2 „Frauen mit hohem Einkommen“ ist dann und 
nur dann gegeben, wenn die beiden Merkmale Geschlecht und Einkommen 
die verlangten Werte haben. Solche Typologien erlauben aber nur, mit rela-
tiv  wenigen  Merkmalen  und  wenigen  Merkmalsausprägungen  zu  arbeiten. 
Schon bei drei Merkmalen mit jeweils vier Ausprägungen entstehen theore-
tisch 4 mal 4 mal 4 = 64 monothetische Typen. 

Typenbildung durch Reduktion 
Monothetische Typen lassen sich durch die von Lazarsfeld beschriebenen 
Verfahren  der  funktionalen  und  pragmatischen  Reduktion  auf  eine  hand-
habbare Anzahl verringern. Dazu folgendes Beispiel, in dem die Bildungs-
abschlüsse der Eltern in einer 4 mal 4 Tabelle (16 Typen) dargestellt sind. 

 
Bildungsabschluss der 
Mutter 

Kein Abschluss 

Haupt-/Realschulabschluss 

Abitur 

FH/Universität 

                             Bildungsabschluss des Vaters 
Kein  
Abschluss 

Abitur 

Haupt-/Real-
schulab-
schluss 

Typ 5 

Typ 4 

Typ 3 

Typ 2 

Typ 4 

Typ 4 

Typ 3 

Typ 2 

Typ 3 

Typ 3 

Typ 3 

Typ 2 

FH/Uni 

Typ 2 

Typ 2 

Typ 2 

Typ 1 

Um die schwer überschaubare Anzahl von 16 möglichen Typen zu verrin-
gern,  definiert  man  eine  Ordnungsrelation  und  führt  eine  Reduktion  des 
Merkmalsraums  herbei,  so  dass  die  Typologie  nur  mehr  aus  5  Typen  be-
steht: 
 
Typ 1: Beide Elternteile besitzen einen Hoch- o. Fachhochschulabschluss 
Typ 2: Ein Elternteil besitzt einen Hoch- oder Fachhochschulabschluss 
Typ 3: Ein Elternteil besitzt das Abitur 
Typ 4: Ein Elternteil besitzt einen Haupt- oder Realschulabschluss 
Typ 5: Beide Eltern verfügen über keinen Abschluss 
 

Typenbildung und typologische Analyse 

105 

Durch diese Reduktion werden aus den monothetischen teilweise polytheti-
sche Typen, d.h. sie weisen Varianz auf, denn nicht alle einem Typ zuge-
rechneten  Probanden  besitzen  die  gleichen  Bildungsmerkmale  der  Eltern. 
Die gilt für die Typen 2, 3 und 4, während die Typen 1 und 5 weiter mono-
thetisch sind, denn der Zugang zu ihnen ist nur bei einer einzigen Merk-
malskombination der beiden Klassifikationsvariablen möglich. 

Bildung einer polythetischen Typologie 
Die vorgenannten Formen der Typenbildung werden in der Literatur auch 
als „künstliche Typologien“ bezeichnet, weil sie ohne direkte Bezugnahme 
auf  die  empirische  Existenz,  rein  auf  der  Basis  theoretischer  Kombinati-
onen, konstruiert werden. Es mag aber sein, das bestimmte Kombinationen 
(„Mutter  Uni-Abschluss“/“Vater  ohne  Schulabschluss“)  in  der  Realität 
überhaupt nicht vorkommen. Als „natürliche Typologien“ bezeichnet man 
hingegen solche, die induktiv aus den empirischen Daten gebildet werden, 
d.h. die Probanden werden so zu Typen gruppiert, dass die Typen intern 
möglichst  homogen  und  extern  möglichst  heterogen  sind.  Solche  Typen 
sind faktisch immer polythetisch, d.h. die zu einem Typ gehörenden Indivi-
duen  sind  bezüglich  der  Merkmale  des  Merkmalsraums  nicht  alle  völlig 
identisch. Natürliche Typologien lassen sich sowohl intellektuell, d.h. durch 
systematisches geistiges Ordnen, als auch mit dem Hilfsmittel statistischer 
Algorithmen bilden. Für letzteres sind clusteranalytische Verfahren beson-
ders gut geeignet (vgl. Kap. 13). 

Welche der drei Möglichkeiten der Typenbildung man wählt, hängt von 
der Samplegröße und der Dimensionalität des angestrebten Merkmalsraums 
ab.  Die  monothetische  Typenbildung  lässt  sich  im  Grunde  nur  bei  zwei 
oder  drei  Merkmalen  mit  relativ  wenigen  Ausprägungen  realisieren.  Die 
Typenbildung durch Reduktion ist in dieser Hinsicht schon erheblich fle-
xibler,  doch  ermöglicht  nur  die  polythetische  Typenbildung  einen  vieldi-
mensionalen  Merkmalsraum.  Mit  Ausnahme  der  monothetischen  Typolo-
gie, die quasi selbst erklärend ist, verlangen die anderen Konstruktionsprin-
zipien, dass die Typen hinsichtlich ihrer Lage im Merkmalsraum beschrie-
ben werden. Bei der durch Reduktion entstandenen Typologie reicht hierzu 
in der Regel eine Aufzählung der in einem Typ zusammengefassten Merk-
malskombinationen,  so  wie  dies  oben  bei  der  Typologie  der  Bildungsab-
schlüsse der Eltern geschehen ist. Die Charakterisierung natürlicher Typo-
logien gestaltet sich demgegenüber schwieriger. Weithin bekannte Beispiele 

 

106 

Sozialwissenschaftliche Ansätze für die kategorienbasierte Textanalyse 

für solche Beschreibungen sind die Lebensstiltypologien bzw. Milieutypo-
logien aus der Lebensstilforschung. 

Alle  drei  Formen  der  Typenbildung  lassen  sich  durch  QDA-Software 
sehr wirksam unterstützen. In MAXQDA lassen sich die als Fallvariablen 
verwalteten Merkmale zu SPSS exportieren, so dass dort Kreuztabellen als 
Basis für eine Typenbildung durch pragmatische Reduktion erstellt werden 
können oder mit Hilfe clusteranalytischer Verfahren eine natürliche Typo-
logie  gebildet  werden  kann.  Die  Zugehörigkeit  von  Personen  zu  Typen 
kann durch SPSS vorgenommen werden und für die nächste Phase der ty-
pologischen Analyse wieder in MAXQDA importiert werden. 

Phase D) Typenbasierte Fallanalyse 
Die letzte Phase der typologischen Analyse lässt sich mit „Zurück zu den 
Texten“ überschreiben. In ihrem Mittelpunkt steht eine typologisch hinter-
leuchtete Textinterpretation. Ähnlich wie die Fallübersichten bei Hopf u.a. 
stellt die Typologie den Hintergrund dar, auf dem Einzelfälle eingeordnet 
und interpretiert werden können. Umgekehrt ist es so, dass die Verteilun-
gen in einer Fallübersicht ebenso wie die zahlenmäßige Übersicht über Ty-
pen und ihre Merkmalsverteilungen für sich noch wenig Aussagekraft besit-
zen. Erst durch den Rückgriff auf den einzelnen Fall und den dort ermittel-
baren subjektiven Sinn lassen sich Typen und Konstellation verstehen und 
nachvollziehen,  ansonsten  blieben  sie  recht  blutleere  Konstruktionen  und 
schieres Werk von Kombinatorik. 

Nach welchen Kriterien wählt man nun Fälle für eine solche Darstellung 
aus? Denn eine Auswahl ist notwendig, weil man nicht alle Fälle einer quali-
tativen Studie in aller Ausführlichkeit in einem Forschungsbericht darstellen 
kann. Man kann bei der Auswahl zwei Strategien folgen: 

Die  repräsentative  Fallinterpretation  zieht  einen  möglichst  geeigneten  Ein-
zelfall,  einen  „Prototypen“,  für  die  Interpretation  heran  und  stellt  diesen 
stellvertretend  für  alle  Probanden  dieses  Typs  in  der  gebotenen  Ausführ-
lichkeit dar. Sofern man das statistische Verfahren der Clusteranalyse einge-
setzt  hat,  erhält  man  eine  Information  über  die  Nähe  jeder  Person  zum 
Clusterzentrum und besitzt so ein formales Kriterium für die Auswahl. An-
sonsten gilt, dass durch sorgfältige Lektüre der Textsegmente, die der Ty-
penbildung zugrunde liegen, der bestgeeignete Fall (es kann sich auch um 
mehrere Fälle handeln) identifiziert werden muss. Die Techniken der com-

Typenbildung und typologische Analyse 

107 

putergestützten Analyse, z.B. das unten beschriebene kontrastierende Text-
retrieval (Kap. 5.4), stellen hier effektive Hilfen bereit. 

Die zweite Möglichkeit besteht in der Konstruktion eines Modellfalls aus der 
Zusammenschau und der Montage der am besten geeigneten Textsegmen-
te. Dieses Verfahren löst sich vom Einzelfall und weist gewisse Ähnlichkei-
ten mit der Weberschen Idealtypenbildung auf. Es werden allerdings keine 
wirklichen Idealtypen gebildet, denn die polythetischen Typen und ihre Po-
sition im Merkmalsraum liegen ja bereits vor der typologischen hinterleuch-
teten Textinterpretation fest, d.h. sie existieren real, denn es lassen sich In-
dividuen des Samples bezeichnen, die zu dem Typ gehören. Es werden le-
diglich einschlägige Textsegmente nach dem Kriterium der Plausibilität für 
den zu beschreibenden Typ ausgewählt und fallübergreifend montiert. 

 

5  Text-Retrieval: codierte Textstellen wiederfinden 

 

5.1  Das Grundprinzip des Text-Retrievals 

Ähnlich wie das Anlegen von Karteikarten beim manuellen Arbeiten ist das 
Codieren von Textsegmenten eine Systematisierungsleistung, die zwar ihren 
Eigenwert besitzt, aber auch eine mühevolle Vorarbeit im Vorgriff auf die 
spätere detaillierte Analyse darstellt, die hierdurch wesentlich leichter von-
statten geht. Die Grundform der computergestützten Auswertung codierter 
Textsegmente wird als Text-Retrieval bezeichnet. Es  handelt sich quasi um 
die elektronische Variante des Griffs in den Karteikasten: 

Abb. 22: Text Retrieval für Code A 

 

Alle  zu  einer  Kategorie  gehörenden  Karteikarten  werden  gewissermaßen 
aus dem Karteikasten herausgezogen und in einer Liste zusammengestellt. 
Diese in der obigen Abbildung dargestellte Grundform der Zusammenstel-
lung  codierter  Segmente  lässt  sich  in  verschiedene  Richtungen  erweitern: 
Das  Text-Retrieval kann nicht nur für einen, sondern  für mehrere  Codes 
durchgeführt  werden,  es  kann  zudem  nach  Überschneidungen  und  Über-

Text-Retrieval und Modelle der Interviewauswertung 

109 

lappungen von Codes gesucht werden, es kann nach bestimmten Kriterien 
eine Teilmenge von Texten für das Retrieval ausgewählt werden und ande-
res mehr. Diese Techniken sind Gegenstand dieses Kapitels und der Kapi-
tel 8 und 9. Bevor die verschiedenen Varianten des Text-Retrievals vorge-
stellt werden, soll ein kurzer Blick auf die Methodik der Interviewauswer-
tung geworfen werden, um zu verdeutlichen, an welchen Stellen des Analy-
seprozesses  die  Zusammenstellung  codierter  Textsegmente  eine  Rolle 
spielt. 

5.2  Text-Retrieval und Modelle der Interviewauswertung 

Die computergestützte qualitative Datenanalyse fing Mitte der 1980er-Jahre 
methodisch nicht als Tabula rasa an, sondern knüpfte an den State-of-the-
art qualitativer Analyse an. Modelle zur Auswertung qualitativer Interviews, 
der  häufigsten  Aufgabenstellung  qualitativer  Datenanalyse,  findet  man  als 
explizite  Darstellung  in  den  Lehrbüchern  der  qualitativen  Methoden  oder 
als  implizite  Methodik  in  den  empirischen  Studien  qualitativer  Sozialfor-
scherinnen und Sozialforscher. Lamnek versucht im Lehrbuch „Qualitative 
Sozialforschung“  (2005: 402 ff.)  eine  allgemeine  Handlungsanweisung  für 
die Auswertung von Interviews zu formulieren, in der vier Phasen unter-
schieden werden, und zwar Transkription (1), Einzelanalyse (2), generalisie-
rende Analyse (3) und Kontrollphase (4). Die Kernpunkte der analytischen 
Phasen 2 bis 4 werden in Abb. 23 dargestellt. Dieses Modell lässt sich pro-
blemlos  in  den  Arbeitsablauf  von  QDA-Software  übersetzen.  Die  Suche 
nach  prägnanten  Textstellen  und  ihre  Entnahme  (Phase  2)  entsprechen 
dem  Vorgang  des  Codierens  in  der  computergestützten  Auswertung,  das 
Schreiben  von  Kommentaren  und  die  Charakterisierung  des  Interviews 
dem Schreiben von Memos. 

Das Text-Retrieval dient als zentrales Hilfsmittel für die in Phase 3 an-
gestrebte generalisierende Analyse: Die Suche nach Gemeinsamkeiten und 
Unterschieden in den Interviews basiert darauf, dass zuvor dekontextuali-
sierte  Textstellen  nun  einer  vergleichenden  Betrachtung  unterzogen  wer-
den.  Die  „typisierende  Generalisierung“,  für  Lamnek  das  Hauptziel  der 
Interviewanalyse,  setzt  natürlich  voraus,  dass  relevante  Merkmale  in  den 
Interviews  identifiziert  und  für  eine  solche  Typenbildung  herangezogen 
werden. 

 

110 

Text-Retrieval: codierte Textstellen wiederfinden 

Einzelanalyse 

Ziel ist es, das Material zu konzentrieren, dabei geschieht folgendes: 
a) Hervorhebung zentraler Passagen  
b) Prägnante Stellen dem Text entnehmen (Resultat: gekürzter Text) 
c) Schreiben eines Kommentars und einer Charakterisierung des Interviews 
d) Interpretation der Besonderheiten und der Allgemeinheit des Interviews 

Generalisierende Analyse 

a) Suche nach Gemeinsamkeiten in den Interviews, Schritt zu einer typisierenden Generalisie-
rung 
b) Herausarbeiten der Differenzen zwischen den Interviews 
c) Erarbeiten der Gemeinsamkeiten und Unterschiede  
d) Typen von Befragten bilden, die unter Bezugnahme auf konkrete Einzelfälle dargestellt wer-
den 

Kontrollphase 

a) Immer wieder die vollständige Transkription heranziehen  
b) gegebenenfalls das Originalband noch einmal anhören 
c) Austausch der Befunde und Interpretationen im Team 

Abb. 23: Phasen bei der Auswertung von Interviews (nach Lamnek 2005: 402 ff.) 

Ganz ähnlich wie bei Lamnek sieht das von Spöhring vorgestellte Auswer-
tungsmodell aus, das in acht Schritten vorgeht (Spöhring 1995). 

1  Genaue Aufzeichnung des Gesprächstextes 
2  Ganzheitliche Betrachtung der Äußerungen des Befragten, seine persönlichen Relevanzen, seine 

Deutungsmuster, sein Weltbild 

3  Sorgfältige detaillierte Satz-für-Satz Interpretation auch scheinbar unwichtiger Äußerungen 
4  Thematische Analyse, Äußerungen zu einzelnen Themen/Fragen des Leitfadens 
5  Zuordnung von Interviewpassagen zu einzelnen inhaltlichen Kategorien, um die Interviews ver-

gleichen zu können 

6  Suche nach Auffälligkeiten, neuen Phänomenen, abweichenden Fällen 
7  Reduktion des Materials (thematische Beschränkung, Beschränkung der Fälle) 
8  Entdeckung von Regelmäßigkeiten, bei denen zwischen sozialen (quasi-statistischen Häufigkeits-) 

Typen und kulturell wirksamen, objektiven Regeln und Normen zu unterscheiden ist 

Abb. 24: Vorgehensweise bei der Auswertung offener Interviews – Acht Schritte nach 

Spöhring (1995) 

Auch in diesem Modell sind an entscheidenden Stellen Schritte des Codie-
rens  und  Wiederfindens  von  Textpassagen  enthalten:  In  Phase  4  und  5 
werden die Texte thematisch codiert und in den Phasen 6 bis 8 werden auf 
dieser Basis vergleichende Analysen vorgenommen. 

Den Modellen von Lamnek und Spöhring ist gemeinsam, dass sie in me-
thodisch kontrollierter Weise das Material verdichten mit dem Ziel, zu Aus-
sagen  über  Regelmäßigkeiten  zu  gelangen.  Gegenüber  anderen,  stärker 
hermeneutisch orientierten Verfahren, dominiert hier das Ziel der Material-
verdichtung, der Konzentration auf das Wesentliche im Sinne der jeweili-

Einfaches Retrieval: Alle Segmente einer Kategorie zusammenstellen 

111 

gen Forschungsfrage mit dem Ziel quasi-statistischer Aussagen. Der einzel-
ne Fall interessiert hier nicht in seiner Besonderheit sondern als Manifesta-
tion eines Musters. 

5.3  Einfaches Retrieval: Alle Segmente einer Kategorie 

zusammenstellen 

Die einfachste Form des Text-Retrievals besteht darin, aus dem Datenma-
terial alle codierten Textsegmente zusammenzustellen, die einer bestimmten 
Kategorie zugeordnet wurden. Ähnlich wie aus einem Karteikasten werden 
die  betreffenden  Segmente  dem  elektronischen  Karteikasten  entnommen 
und hintereinander in einer Liste zusammengestellt. Technisch sind mit ei-
nem  QDA-Programm  zwei  Dinge  zu  tun,  um  ein  solch  einfaches  Text-
Retrieval durchzuführen: 
 

(cid:120)  erstens muss der gewünschte Code aus dem Codesystem ausgewählt 

werden und 

(cid:120)  zweitens  muss  eine  Auswahl  von  Texten  getroffen  werden  oder  es 

werden die Segmente aller vorhandenen Texte zusammengestellt 

 
Der  Einfachheit  halber  wollen  wir  zunächst  annehmen,  dass  mit  der  Ge-
samtheit der Texte gearbeitet wird, dass also alle Texte ausgewählt werden. 
Die Logik des Text-Retrievals funktioniert dann nach folgendem Muster: 

DATENMATERIAL 

Das sind alle codierten  
Textsegmente aller Texte 

zu allen Kategorien 

ZUSAMMENSTELLUNG 
der vorhandenen codierten 

 Segmente für eine oder mehrere 

ausgewählte Kategorien 

 

Resultat  des  Text-Retrievals  ist  eine  Zusammenstellung  aller  zum  ausge-
wählten Code vorhandenen Segmente. Zu jedem aufgelisteten Segment ge-
hört eine Herkunftsangabe, d.h. die Information darüber, aus welchem Text 
die  Passage  stammt  und  welche  Position  die  Stelle  im  betreffenden  Text 
einnimmt (z.B. durch Angabe der Absatznummer oder Zeilennummer).  

 

112 

Text-Retrieval: codierte Textstellen wiederfinden 

5.4  Kontrastierendes Retrieval: Segmente ausgewählter 

Kategorien gegenüberstellen 

Beim kontrastierenden Retrieval geht es nicht nur um die Auswertung einer 
einzelnen Kategorie, sondern um die Gegenüberstellung von Aussagen zu 
zwei oder mehr Kategorien, zum Beispiel um die Frage: Was hat ein Be-
fragter zu Thema A geäußert und was sagt er zu Thema B? Wie sehen die 
Wünsche  aus  und  was  hält  jemand  für  machbar?  Die  Logik  des  Text-
Retrievals ist die gleiche wie beim oben beschriebenen einfachen Retrieval, 
doch werden beim kontrastierenden Retrieval die gefundenen Textsegmen-
te in einer bestimmten Reihenfolge benötigt, die bei zwei zu kontrastieren-
den Kategorien wie in Abb. 25 aussieht. 

Die Segmente in einer solchen Liste müssen nach Texten sortiert sein, 
d.h.  alle  Textpassagen  aus  Text  A  folgen  hintereinander  und  dann  folgen 
erst die Segmente aus Text B. Auf diese Weise lassen sich die Aussagen ei-
ner Person, z.B. ihre Wunsch- und Machbarkeitsvorstellungen, direkt mit-
einander vergleichen. 

Text A 
 
 
Text B 
 
 
Text C 
 
 
usw. 

 

 
Segmente zum Code Wunschprojektion 
Segmente zum Code Machbarkeitsprojektion 

Segmente zum Code Wunschprojektion 
Segmente zum Code Machbarkeitsprojektion 

Segmente zum Code Wunschprojektion 
Segmente zum Code Machbarkeitsprojektion 

Abb. 25: Codierte Segmente – nach Texten sortiert 

Selbstverständlich kann sich die Kontrastierung auch auf mehr als zwei Ka-
tegorien beziehen. Bedeutsam ist, dass mit der Kontrastierung ein Weg be-
schritten wird, der nach dem Schritt der Segmentierung und Dekontextuali-
sierung nun wieder auf die Suche nach Zusammenhängen und Querbezü-
gen geht. Übereinstimmungen werden ebenso deutlich wie Differenzen und 
schärfen den analytischen Blick für die Beziehungen zwischen den einzel-
nen Kategorien. 

Verknüpfendes Retrieval: Suche nach gemeinsamem Vorkommen von Codes 

113 

5.5  Verknüpfendes Retrieval: Suche nach gemeinsamem 

Vorkommen von Codes 

Zu  den  Basistechniken  des  Text-Retrievals  gehört  ferner  die  Suche  nach 
Überschneidungen von Kategorien, d.h. es wird nach solchen Textpassagen 
gesucht, denen sowohl ein Code A (z.B. „Wunschprojektion“) wie ein Code 
B  (z.B.  „Machbarkeitsprojektion“)  zugeordnet  ist.  Um  die  Bedingung  des 
gemeinsamen  Vorkommens  zu  erfüllen,  ist  es  nicht  notwendig,  dass  die 
Segmente exakt gleich groß sind, es reicht aus, wenn sich zwei Codierungen 
überlappen. 

Abb. 26: Textabschnitt mit gleichzeitiger Codierung von Wunsch- und Machbar-

keitsprojektion 

 

Im obigen Beispiel findet sich eine Textstelle, der gleichzeitig beide Katego-
rien zugeordnet sind. Hier spricht der Befragte also im gleichen Abschnitt 
über seine Wünsche und über das, was er für machbar hält. 

Um gezielt alle bzw. alle ausgewählten Texte eines Projektes daraufhin 
zu durchsuchen, ob es Überschneidungen von Codes gibt, muss eine Such-
anfrage folgender Art gestellt werden: „Finde Textpassagen, denen Code A 
UND  Code  B  zugeordnet  sind.“  Auch  die  einfache  UND-Verknüpfung 
lässt  sich  natürlich  von  zwei  auf  drei  und  mehr  Codes  erweitern,  d.h.  es 
wird nicht nur nach dem gemeinsamen Vorkommen von A und B gesucht, 
sondern nach solchen Textpassagen, die gleichzeitig mit drei spezifizierten 
Codes A, B und C codiert worden sind. Dieses Prinzip lässt sich auf belie-
big viele Codes erweitern. 

Als Resultat werden wie beim einfachen Text-Retrieval alle Textstellen, 
bei denen sich die spezifizierten Codes überschneiden, in einer Liste zusam-
mengestellt.  Anders  als  beim  einfachen  Retrieval,  wo  die  in  Frage  kom-

 

114 

Text-Retrieval: codierte Textstellen wiederfinden 

menden codierten Segmente immer vollständig ausgegebenen werden, ist es 
beim nach Überschneidungen suchenden Retrieval nicht selbstverständlich, 
welche Textstelle als Resultat ausgegeben wird. 

Im folgenden Beispiel überschneiden sich Code A und Code B. Es kann 
nun nur der direkte Überschneidungsbereich oder der gesamte von den bei-
den Segmenten umfasste Bereich ausgegeben werden. 

 

Abb. 27: Code A und B überschneiden sich 

Die Suche nach sich überschneidenden Kategorien kann weitaus komplexer 
als bei diesem einfachen Beispiel gestaltet werden. So lassen sich Abfolgen 
von Codes überprüfen (Code A gefolgt von Code B) oder Codes auf ihre 
Nähe  hin  untersuchen  (Code  A  in  maximal  x  Absätzen  Entfernung  von 
Code B). Diese komplexeren Formen des Text-Retrievals sind Gegenstand 
von Kapitel 9. 

5.6  Code-Hierarchien im Retrieval 

Kategoriensysteme bestehen in den meisten Fällen nicht nur aus einer ein-
fachen sequentiellen Liste von Codes, sondern sie weisen eine innere Struk-
tur  im  Sinne  von  unter-  und  übergeordneten  Kategorien  auf.  Angenom-
men, man habe eine Kategorie „Einstellungen“ mit den Subkategorien „po-
sitiv“  und  „negativ“  definiert.  In  jedem  Zweig  der  Einstellungskategorie 
können dann, wie die folgende schematische Darstellung zeigt, weitere Un-
terkategorien definiert werden. 

Code-Hierarchien im Retrieval 

115 

Einstellungen 

positiv 

negativ

Liebe 

Sympathie

Hass

Antipathie

 

Wenn man nun nach Überschneidungen mit der  Kategorie  „Erfolgskrite-
rien“ sucht, ist man daran interessiert, auch alle denkbaren Überschneidun-
gen von „Erfolgskriterien“ mit den Subkategorien von „Einstellungen“ zu 
erfassen, beispielsweise Textpassagen in den Daten zu finden, die zum ei-
nen  mit  „Erfolgskriterien“  und  zum  anderen  mit  „Einstellungen/posi-
tiv/Sympathie“ codiert sind. Man benötigt also Retrieval-Prozeduren, die in 
der Lage sind, die Baumstruktur des Kategoriensystems zu berücksichtigen. 
Anderenfalls wäre man gezwungen, alle denkbaren Überschneidungen von 
„Erfolgskriterien“  mit  den  sechs  Subkategorien  der  Einstellungen  geson-
dert zu explorieren. Dies wäre vom Arbeitsaufwand her zumindest theore-
tisch noch denkbar, doch wird die Angelegenheit dann schwieriger, wenn 
auch die zweite Kategorie Unterkategorien besitzt. 

Erfolgskriterien 

sozial 

ökonomisch

ökologisch

 

Schon dann, wenn die Kategorie „Erfolgskriterien“, wie im obigen Schema 
nur 3 Subkategorien besitzt, wären 6 mal 3, d.h. 18 denkbare Überschnei-
dungen  zu  überprüfen.  Die  Möglichkeit  zur  automatischen  Berücksichti-
gung von hierarchischen Strukturen im Retrieval ist also von großer Bedeu-
tung, vor allem dann, wenn die Struktur auf drei oder mehr Codes erweitert 
wird. 

 

116 

Text-Retrieval: codierte Textstellen wiederfinden 

5.7  Code-Übersichten und Häufigkeiten 

Die vorgenommenen Codierungen von Textsegmenten lassen sich auf ver-
schiedene Weise auswerten: 
 

1.  als Zusammenstellung der zu einem Code gehörenden Textsegmen-
te, meist in Form einer Liste, die die Textpassagen der Originaltexte 
mit Angabe der zugeordneten Kategorien enthält 

2.  als  Tabelle  der  Referenzen  der  Codes,  d.h.  als  tabellarische  Über-
sicht,  welche  Kategorien  und  Subkategorien  welchen  Texten  zuge-
wiesen sind 

3.  als  textbezogene  Häufigkeitsauswertung  von  Codes  und  Subcodes, 

ggf. aufgegliedert nach verschiedenen Teilgruppen von Texten 

 
Die  bisher  in  diesem  Kapitel  vorgestellten  Verfahren  des  Text-Retrievals 
produzieren  alle  Auswertungen  des  ersten  Typs,  d.h.  man  erhält  jeweils 
nach  bestimmten Kriterien  zusammengestellte Textpassagen der Original-
texte. Nun lassen sich auch interessante Auswertungen einzig auf der Basis 
der Codierungen durchführen, d.h. man ist weniger an einem Rückgriff auf 
die Textsegmente selbst interessiert als an der Information über die Codie-
rungen  –  eine  Vorgehensweise  also,  die  mehr  der  klassischen,  quantitativ 
orientierten Inhaltsanalyse entspricht. Formen von Auswertungen, die hier 
in Betracht kommen, sind: 
 

1.  die Auswertung der Codierungen einzelner Texte 
2.  ein Index der Codierungen für das gesamte Text-Set 
3.  Häufigkeitsauswertungen  der  Codierungen  für  einzelne  Texte  oder 

speziell selektierte Gruppen von Texten 

4.  Vergleich der Code-Häufigkeiten von Texten oder Textgruppen 

Auswertung der Codierungen eines einzelnen Textes 
Ob und wie oft ein bestimmter Code Texten zugeordnet ist, kann eine sehr 
nützliche  Information  darstellen.  Die  Auswertung  der  Codierungen  eines 
einzelnen Textes in Form einer chronologischen Liste der Codezuweisun-
gen gibt einen guten Überblick über den Interviewverlauf. Wenn man nach 
der Methode des thematischen Codierens vorgegangen ist, lassen sich Fra-
gen beantworten wie: Welche Themen wurden in welcher Reihenfolge be-
arbeitet?  Welche  Themen  wurden  besonders  ausführlich  und  welche  nur 
am Rande behandelt? Ergebnis ist ein Summary des Interviews, das unmit-

Code-Übersichten und Häufigkeiten 

117 

telbar Aufschluss über die Themen und theoretischen Konzepte gibt, wel-
che Gegenstand des Interviews sind. Einzelnes Element dieser Liste ist ein 
codiertes Segment, angegeben werden der zugeordnete Code und die Loka-
lisierung des Segmentes im Text. Abb. 28 zeigt, dass in dem hier ausgewer-
teten  Interview  insgesamt  8  Textstellen  zum  Thema  „Wunschprojektion“ 
vorhanden sind. 7 Textstellen hiervon beziehen sich auf den sozialen Be-
reich  –  an  erster  Stelle  handelt  es  sich  um  „gesellschaftliche  Visionen“  – 
und lediglich eine auf den Bereich Ökologie. Wunschprojektionen, die sich 
auf Ökonomie beziehen, werden im gesamten Interview gar nicht geäußert. 

 

CODE 
 

Wunschprojektion >sozial >gesellsch. Visionen 

Wunschprojektion >sozial >gesellsch. Visionen 

Wunschprojektion >sozial >gesellsch. Visionen 

Wunschprojektion >sozial >LA 21-Initiative 

Wunschprojektion >sozial >Öffentlichkeit 

Wunschprojektion >sozial >Partizipation/Politik 

Wunschprojektion >sozial >Umgest. d. lok. Lebensraumes 

Wunschprojektion >ökologisch 

Abb. 28: Tabellen mit den Code-Referenzen eines Textes 

     Absatznr. 
Beginn 

Ende 

14 

26 

47 

3 

31 

12 

16 

14 

15 

26 

49 

3 

32 

12 

17 

15 

Ähnlich  aussehende  Übersichten  lassen  sich  auch  für  die  Gesamtheit  der 
Texte erstellen. Wie das Sachregister eines Fachbuches enthält ein solcher 
Code-Index Hinweise darauf, an welchen Stellen welcher Texte Textpassa-
gen zum jeweiligen Thema bzw. zum jeweiligen Code zu finden sind. Auch 
hier verweist jede Zeile der Liste auf ein codiertes Textsegment. 

Code-Häufigkeiten 
Häufigkeitsauswertungen von Codes basieren auf dem oben beschriebenen 
Index der Codierungen. Zwar lässt sich aus den Häufigkeiten des Auftre-
tens einer Kategorie nicht ohne weiteres auf ihre Relevanz schließen, doch 
ist es  heuristisch durchaus  von Interesse, ob bestimmte Kategorien  in ei-
nem Text oder einer Gruppe von Texten sehr häufig oder überhaupt nicht 
vorkommen.  Häufigkeitsauswertungen,  die  für  Teilgruppen  der  Befragten 

 

118 

Text-Retrieval: codierte Textstellen wiederfinden 

durchgeführt werden, lenken den Blick auf Unterschiede und Auffälligkei-
ten  im  Datenmaterial.  Im  Projekt  „Umweltkommunikation  und  Lokale 
Agenda 21“ zeigte bereits die Verteilung der Häufigkeit der Codierung für 
die  Kategorie  „Wunschprojektion“  einige  Eigentümlichkeiten  auf.  Einer-
seits fiel die relativ geringe Häufigkeit der auf den lokalen Lebensraum be-
zogenen Wünsche auf, ferner war die Disparität zwischen den Häufigkeiten 
für „Gesellschaftliche Visionen“ bei den Wünschen und bei den Machbar-
keitsprojektionen augenfällig, d.h. in den Interviews fand man viele Wün-
sche,  die  auf  eine  Veränderung  der  Gesellschaft  zielen,  aber  nur  wenige 
Textpassagen, die sich mit deren Machbarkeit befassen. 

Häufigkeitsvergleiche  dieser  Art  sind  zudem  nützlich,  um  Subgruppen 
von  Texten  miteinander  zu  vergleichen.  Bei  der  genannten  Studie,  in  der 
Akteure aus verschiedenen Berliner Bezirken interviewt wurden, lässt sich 
eine Matrix erstellen, in der die Frequenzen der verschiedenen Subkatego-
rien von Wunschprojektionen für die bezirklichen Initiativen in aggregierter 
Form miteinander verglichen werden (Abb. 29). 

Wunschprojektion 

Sozial >gesellsch. Visionen 

Sozial >LA 21-Initiative 

sozial >Öffentlichkeit 

sozial >Partizipation/Politik 

sozial >Umgestaltung d. lokalen Lebensraums  1 

ökologisch 

ökonomisch 

Total 

1 

1 

22 

Charlotten-
burg 

Steglitz 

Lichten-
berg 

Köpenick 

5 

7 

2 

5 

5 

27 

6 

10 

0 

10 

5 

63 

2 

10 

1 

5 

2 

1 

3 

24 

14 

15 

3 

11 

3 

4 

1 

51 

Abb. 29: Häufigkeit der Wunschprojektionen im Vergleich der Bezirke 

Solche Tabellen haben zunächst einen explorativen und heuristischen Wert: 
Man erkennt, dass in der Steglitzer und der Köpenicker Initiative weitaus 
mehr Wunschprojektionen geäußert werden als in den beiden anderen Ini-
tiativen.  Auffallend  ist  zudem,  dass  sich  in  Köpenick  sehr  viele  Wünsche 
auf den Bereich gesellschaftlicher Visionen erstrecken. 

Praktische Hinweise für MAXQDA 

119 

5.8  Praktische Hinweise für MAXQDA 

In MAXQDA funktioniert das Text-Retrieval mittels des Prinzips der Akti-
vierung,  d.h.  sowohl  Texte  als  auch  Codes  werden  für  ein  Text-Retrieval 
ausgewählt.  Ergebnis  ist  eine  Zusammenstellung  aller  für  diese  Selektion 
vorhandenen  Textsegmente  in  einem  Resultatfenster,  der  „Liste  der  Co-
dings“.  Zur  Durchführung  eines  Text-Retrievals  ist  also  nichts  weiter  zu 
tun, als die gewünschten Texte und Codes zu aktivieren. Texte können in-
dividuell aktiviert werden, es lassen sich aber auch eine gesamte Textgrup-
pe, ein Text-Set oder gleich alle Texte des Projektes auswählen. Alle Akti-
vierungsvorgänge für Texte werden im Fenster „Liste der Texte“ getätigt, 
alle Aktivierungsvorgänge für Codes im Fenster „Liste der Codes“. An der 
Darstellung der Textsymbole bzw. Codesymbole lässt sich sofort erkennen, 
welche  Texte  und  Codes  in  das  Retrieval  einbezogen  sind.  Als  Resultat 
werden alle betreffenden Segmente in der „Liste der Codings“ hintereinan-
der präsentiert, links neben jedem Segment findet sich eine Info-Box, die 
über die Herkunft des Segmentes (u.a. die Textgruppe, den Text und den 
Absatz im Text) Auskunft gibt. Wird die Info-Box eines Segmentes ange-
klickt, so wird der Originaltext geladen und genau an diese Stelle positio-
niert. Auch können Aktionen mit dem Segment durchgeführt werden: Das 
Segment  kann  z.B.  gelöscht,  die  Segmentgrenzen  können  verändert  oder 
das Segment kann zusätzlich einem weiteren Code zugeordnet werden. 

Das faszinierende bei der Arbeit mit QDA-Programmen ist, dass anders 
als bei Karteisystemen althergebrachter Art der Originaltext nicht weit ent-
fernt ist – nämlich abgeheftet in einem Ordner – sondern dass der Original-
text jederzeit hinzugezogen werden kann: Ein Anklicken genügt, um zu je-
dem codierten Segment den umgebenden Kontext sofort einzusehen. 

Diese einfache Art des Text-Retrievals kann auf zweierlei Weise nützlich 
sein: bei der Analyse eines Einzelfalles bzw. des einzelnen Interviews und 
bei der Analyse von Themen, d.h. bei der fallübergreifenden Analyse von 
inhaltlichen Aspekten. 

Für  die  themenorientierte  Einzelfallanalyse  bietet  das  einfache  Text-
Retrieval eine wirkungsvolle Unterstützung, denn nun lassen sich alle über 
das  Interview  verteilten  Textstellen  zu  einem  bestimmten  Thema  zusam-
menstellen, so dass sich Inkonsistenzen und Unklarheiten leicht entdecken 
lassen. 

Fallübergreifende Analysen erleichtern es natürlich, das gesamte Material zu 

einem bestimmten Thema zu sichten und die Ergebnisse zusammenzufassen. 

 

120 

Text-Retr

rieval: codierte T

Textstellen wied

erfinden 

 

Abb. 30

0: Zusammens
in MAXQDA

stellung codier
A (Code: Mach

rter Segmente m
hbarkeitsprojek

mit Herkunftsa
ktion>ökologis

angabe vor dem
sch) 

m Text 

„test1“, das Si
haben. 
te  der  Textgr
h“. 
lick aus der „
llen. 
te  Ergebnis 

ie in den Übu

ungen der vo

orange-

ruppe  „Bürg

ger“  und  den

n  Code 

„Liste der Co

odings“ zu de

en ein-

mit  dem  neu

uen  Code  „E

Einstel-

Übun
ngen 
1. 

Ihr Projekt „
Öffnen Sie I
pitel erstellt h
henden Kap
Sie  alle  Text
Aktivieren  S
gen\politisch
„Einstellung
e per Mauskl
Springen Sie
erten Textste
zelnen codie
ie  das  gesam
Codieren  Si
“. 
lungen_neu“
n Sie die aktu
Exportieren
in Microsof
ft Word. Exp
. Wo liegt der
mat HTML.
ie  die  Codin
Sortieren  Si
und anschlie
(Textbaum) 
Erstellen Sie
e für „intervi
r vorhandene
wertung der

2. 

3. 

4. 

5. 

6. 

7. 

uelle Liste de
r Codings un
portieren sie e
es ein zweite
d? 
r Unterschied
in  der  Reih
ngs  zunächst 
dem Codebau
eßend nach d
iew1“ und „i
nterview2“ e
en. Drucken 
n Codierunge

nd öffnen Sie
es Mal im Da

e diese 
ateifor-

Texte 

henfolge  der 
um. 
eine Häufigke
Sie die Liste 

eitsaus-
aus. 

6  Textexploration: Volltext-Recherche 

 

6.1  Stichworte im Kontext 

Die Techniken des Codierens und des darauf aufbauenden Text-Retrievals 
eröffnen viele Möglichkeiten, sie haben aber den Nachteil, relativ zeitauf-
wändig zu sein. Nicht immer steht in einem Projekt genügend Zeit zur Ver-
fügung, um das Textmaterial in seiner vollen Breite zu kategorisieren und 
zu  codieren.  Eine  Hilfe  können  dann  Verfahren  der  lexikalischen  Suche 
darstellen, d.h. die Möglichkeit, in den Texten oder in ausgewählten Grup-
pen von Texten nach dem Vorkommen bestimmter Stichworte und Wort-
kombinationen  zu  suchen.  Die  lexikalische  Suche  ist  generell  zur  Textex-
ploration gut geeignet. Auch dann, wenn man eine Kategorisierung des Da-
tenmaterials ins Auge fasst, macht es Sinn, sich in der Phase der Textexplo-
ration der Fähigkeiten des  Computers zu bedienen:  Mit Hilfe von QDA-
Software  ist  eine  schnelle  und  effiziente  Volltext-Recherche  in  großen 
Textmengen möglich. So kann man gewissermaßen im Textkorpus surfen 
und  (ungeplante)  Entdeckungen  machen.  Solche  überraschenden  Entde-
ckungen von ursprünglich nicht Gesuchtem kann man auch mit dem Be-
griff  „Serendipity“  bezeichnen.  Nicht  nur  die  Entdeckung  Amerikas  ver-
dankt sich dem Serendipity-Prinzip, sondern auch innerhalb der Sozialwis-
senschaften spielt es eine nicht zu unterschätzende Rolle20. 

Als besonders nützlich erweisen sich so genannte Keyword-in-Context 
(KWIC) Zusammenstellungen. Solche KWIC-Listen enthalten ein Stichwort 
und den umgebenden Kontext in einem vom Benutzer bestimmbaren Um-
fang. 

                                                           
 
20 In der Soziologie hat sich vor allem Robert Merton mit Serendipity beschäftigt (vgl. Mer-

ton 2004a und 2004b). 

122 

Textexploration: Volltext-Recherche 

Beispiel: Die Verwendung des Begriffs „Öffentlichkeit“ in Interviews mit Akteuren von 
LA 21-Initiativen 
In der Studie über Akteure in Lokalen Agenda 21-Initiativen interessierte in 
der ersten Phase der Auswertung, in welchem Kontext der Begriff „Öffent-
lichkeit“  verwendet  wird.  Was  stellen  sich  die  Akteure  unter  Öffentlich-
keitsarbeit vor? In welcher Weise wollen sie aktiv werden? Was wollen sie 
auf keinen Fall tun? Wie ist ihre Haltung zur Presse? 

Ohne  dass  man  bereits  bestimmte  Auswertungskategorien  vor  Augen 
haben  muss,  lohnt  es  sich,  zunächst  einmal  eine  Suchrecherche  durchzu-
führen. 

Vorgehensweise 
a)  Man  suche  in  allen  vorhandenen  Interviews  nach  dem  Wort  „Öffent-
lichkeit“  oder  nur  nach  dem  Wortstamm  „öffentlich“.  Bei  der  Suche 
werden alle Worte, die diese Zeichenkette enthalten, gefunden, z.B. Öf-
fentlichkeit,  Öffentlichkeitsarbeit,  öffentliche  Veranstaltung.  Allerdings 
kann  man  auf  diese  Weise  auch  Unerwünschtes  wie  „öffentliche  Ge-
bäude“ als Suchresultat erhalten. 

b)  Man lasse sich alle Fundstellen im Kontext, d.h. Absätze, in denen der 
Suchbegriff vorkommt, heraus suchen und in einer Liste zusammenstel-
len. 

Resultat 
Ergebnis dieser einfach zu realisierenden explorativen Analyse ist eine Zu-
sammenstellung der entsprechenden Textstellen (Abb. 31), mit der schnell 
ein Überblick über das Bedeutungsumfeld des Begriffs „Öffentlichkeit“ zu 
gewinnen ist. Es lässt sich leicht erkennen, in welchen Kontexten in dieser 
Studie von Öffentlichkeit die Rede ist.  

Die lexikalische Suche findet natürlich nur solche Textpassagen, in de-
nen  der  gesuchte  Begriff  bzw.  die  gesuchte  Zeichenkette  manifest  auf-
taucht.  Textpassagen  hingegen,  in  denen  sehr  wohl  über  die  öffentliche 
Wirksamkeit der Initiative gesprochen wird, die aber keines der Suchworte 
enthalten, lassen sich so nicht finden. 
 

Texte explorieren 

123 

 

 

 

Position:  62 – 62 

Position:  68 – 68 

Position:  118 – 118 

Interviews\interview4  

Interviews\interview1        

Text: 
Fr. Berkempers: Also man müsste schon an die Medien gehen. Und sich eben noch mal darstellen. 
Wir waren ja zu Anfang stark in den Medien, als wir uns gegründet haben und da haben auch ganz 
viele  angerufen  und  sind  über  die  Medien sozusagen zu  uns  gekommen, das  war  unser einziges 
Transportmittel, um an die Öffentlichkeit zu kommen. Und das hat eigentlich funktioniert. Wenn wir 
jetzt noch mal so ne Aktion starten, dann denke ich, könnten wir es auch wieder über die Medien 
machen. 
 
Text: 
Herr Bellmann: Ja, da wird von der Xxxxxxxxxx aus ein Projekt vorgegeben für die nächste Zeit, so 
bis einem Jahr, das hat sich auch meines Erachtens bewährt, was man hier begonnen hat ähm, ich 
würde auch empfehlen, dass man eben auch mehr die Behörden mit einbezieht um hier die ganze 
Präsenz der Problematik mit bewusst zu machen. Und viele Dinge, die so am Schreibtisch durch-
dacht werden, dass die also mehr Öffentlichkeit erfahren. 
 
Text: 
Herr Bellmann: Na, wie ich schon sagte, das müssten Transformatoren sein, die Mitglieder der Bür-
gerinitiativen, ne, die dann auch in die Schulen gehen, die dort also mehr Öffentlichkeit herbeiführen. 
Abb. 31: Keyword-in-Context zum Begriff Öffentlichkeit (Kontextumfang: 1 Absatz) 

Interviews\interview4 

Giegler  (1992)  empfiehlt,  in  dieser  ersten  explorativen  Auswertungsphase 
keine Scheu davor zu haben, auch quantitative Aspekte zu eruieren: Welche 
Worte kommen vor, in welchen Texten? Wie häufig? Eventuell empfiehlt 
es sich auch, zusätzlich Techniken der quantitativen Inhaltsanalyse21 einzu-
setzen,  Wortbestände  auszuzählen  und  gegebenenfalls  zu  vergleichen.  Bei 
kurzen  Texten  lassen  sich  u.U.  gleich  automatische  Codierungen  vorneh-
men und dann weiter statistisch bearbeiten. Entsprechende Analysen lassen 
sich beispielsweise mit MAXDictio durchführen (vgl. Kapitel 12). 

6.2  Texte explorieren 

Die  Explorationsmöglichkeiten  stehen  in  engem  Zusammenhang  mit  der 
Art des analysierten Textes. In Anlehnung an Giegler (1992: 350) lässt sich 
zwischen  extern-strukturierten  und  nicht  extern-strukturierten  Texten  un-
terscheiden. Extern-strukturiert bedeutet, dass die Texte von außen vorge-
gebenen  Strukturierungsprinzipien  unterworfen  sind.  Prototypisch  ist  dies 
                                                           
 
21 Giegler rät, gezielt die Wortbestände von Texten mit Mitteln der quantitativen Analyse zu 
untersuchen. Dies scheint zwar zunächst den Ansprüchen interpretativer Analyse zuwi-
derzulaufen, doch lässt sich begründet vermuten, dass eine solche Vorgehensweise, wenn 
sie eher spielerisch denn als eigentliche Textanalyse begriffen wird, einen heuristischen 
Wert hat: Man wird etwa auf die besonders häufige Verwendung bestimmter Worte hin-
gewiesen oder auf die im Text verwendeten Metaphern aufmerksam. 

 

124 

Textexploration: Volltext-Recherche 

bei Leitfadeninterviews der Fall. Der Interviewer spricht immer vorab fest-
gelegte, für die Forschungsfrage wichtige Themen an bzw. stellt bei noch 
stärker strukturierten Interviewformen immer die gleichen vorformulierten 
Fragen. In der späteren Transkription ist zu jedem Leitfadenpunkt jeweils 
ein mehr oder weniger ausführlicher Antworttext vorhanden. Beispielsweise 
haben wir bei den mit Patienten geführten Interviews im Projekt „Rehabili-
tation  und  Pädagogik“  einen  umfangreichen  Leitfaden  eingesetzt,  dessen 
einleitende Fragen im folgenden Kasten wiedergegeben sind. 

BEREICH 1: Generelle Einschätzungen zur Reha-Maßnahme – Erwartungen und Konsequenzen 

FRAGELEITFADEN 

1.  Waren Sie der Meinung, dass Sie eine Kur brauchten? 

Warum? Was versprachen/erhofften Sie sich von der Kur? 

2.  Haben Sie rückblickend den Eindruck, dass bei Beginn der Reha-Maßnahme von Seiten der 

Klinikleitung gut über den Ablauf und die Zielsetzung der Kur informiert wurde? 
(Grob fragen: Welche Infos enthielt die Erstinformation? Gab es eine schriftliche Information, die 
wir einsehen/kopieren können?) 
Wenn nein, warum nicht? 

3.  Gibt es etwas in Ihrem alltäglichen Leben, das Sie infolge der Kur anders machen als vorher? 

Wenn ja: was? (Nur kurz abfragen, keine längeren Erklärungen) 

Abb. 32: Auszug aus einem Interviewleitfaden zu Reha-Maßnahmen 

Ein mit Hilfe eines solchen Leitfadens erhobenes Interview lässt sich auch 
in der Transkription noch deutlich diese Struktur des Leitfadens erkennen. 
Man kann in der folgenden Abbildung deutlich erkennen, dass der transkri-
bierte  Text  weitgehend  der  Leitfadenstruktur  folgt22.  Natürlich  weist  ein 
Interviewtext nicht nur diese äußere, sondern auch eine innere Struktur auf. 
Dieser innere Zusammenhang wird durch die Persönlichkeit des Befragten 
generiert: Bestimmte Arten der Problemwahrnehmungen, bestimmte Wer-
te, Vorurteile und Leitbilder kommen an verschiedenen Stellen des Inter-
views immer wieder zum Ausdruck. 

                                                           
 
22 Ein anderes gutes Beispiel für einen Interviewleitfaden und das auf diese Weise generierte 

Datenmaterial findet sich in Hopf u.a. 1995. 

Texte explorieren 

125 

I: Warst du der Meinung, dass du eine Kur brauchst? Was hast du dir davon versprochen, erhofft? 
 
P: Ja, also wie gesagt, mehr Zeit für mich zu haben, mehr Zeit fürs Kind zu haben. Ja und einfach 
einmal mich auf mich zu besinnen, Zeit haben, nichts tun, einfach mal gar nichts tun. 
I: Hast du rückblickend den Eindruck, dass du vor der Reha-Maßnahme, also von Seiten der Re-
haklinik gut über den Ablauf und die Zielsetzung der Kur informiert wurdest? 
 
P: Nee, da war ich nicht informiert, also der Kurablauf, ich wusste gar nichts, weder von der Kur, 
wie sie läuft, was da stattfindet, gar nichts. Die haben dann was zugeschickt, ungefähr 14 Tage 
vorher, aber mehr oder weniger nur zur Anreise, mehr zur Organisation, also was mitzubringen ist, 
aber da war nichts vom Ablauf der Kur zu erfahren, also vom inhaltlichen her gar nichts, da war 
auch teilweise über Ärzte nichts zu erfahren, die wussten das auch nicht. 
 
I: Weil das im Prinzip so ein Pilotprojekt war? 
 
P: Erstens sowieso, also ich sag mal im Osten ist es die erste Mutter-Kind überhaupt fast das ers-
te Heim was es überhaupt gibt, zumindestens im neuen Stil, was nach der Wende irgendwie auf-
gebaut worden ist, insofern wusste man wirklich nicht, auf was man sich einlässt. 

Abb. 33: Ausschnitt aus dem Transkript eines Leitfadeninterviews 

Eine ähnliche Strukturierung wie bei dem in Abb. 33 auszugsweise wieder-
gegebenen  Transkript  lässt  sich  auch  dann  erreichen,  wenn  das  Interview 
selbst  nicht  strikt  an  der  sequentiellen  Ordnung  des  Leitfadens  orientiert 
war. Der Text lässt sich auch ex post in die extern vorgegebene Ordnung 
des Leitfadens umsortieren – was oft allerdings nur unter erheblichen Mü-
hen  gelingt.  Für  die  praktische  Bearbeitung  eines  solchen  extern-struk-
turierten Textes mit einem QDA-Programm gibt es zwei alternative Vorge-
hensweisen. Die erste Variante wurde oben im Abschnitt 2.7 („Strukturierte 
Texte“)  beschrieben.  Sie  erfordert  die  Beachtung  bestimmter  Formatie-
rungsregeln bei der Texterfassung: Es ist jeweils anzugeben, wo ein zu ei-
nem bestimmten Leitfadenpunkt gehörender Textabschnitt beginnt und wo 
er endet. Diese Vorab-Zuordnung von Textabschnitten zu Leitfadenpunk-
ten wird dann beim Einlesen des Textes von der QDA-Software bearbeitet. 
Die zweite, zeitaufwändigere Variante arbeitet mit der Zuordnung von 
Leitfadenpunkten  durch  manuelle  Codierung  der  entsprechenden  Textab-
schnitte.  Hier  muss  jeder  Text  nach  dem  Import  im  QDA-Programm 
durchgearbeitet  werden,  die  entsprechenden  Textabschnitte  müssen  mar-
kiert und mit den Leitfadenpunkten codiert werden. 

Wie läuft nun die explorative Auswertung einer empirischen Studie mit 
solchen vorab strukturierten Texten ab? Giegler spricht von Komparatistik, 
d.h. die Antworten  auf einzelne Fragen  des Leitfadens werden in verglei-
chender  Weise  analysiert.  Basis  aller  Exploration  ist  eine  gedachte  Text-
Matrix nach folgendem Muster. 

 

126 

Textexploration: Volltext-Recherche 

Interview  Bedürfnis nach Kur  Erwartungen 

Hoffnungen 

Information durch 
Klinikleitung 

Person 1 

Person 2 

Person 3 

Person 4 

... 

Text 

Text 

Text 

Text 

... 

Person X 

Text 

Text 

Text 

Text 

Text 

... 

Text 

Text 

Text 

Text 

Text 

... 

Text 

Text 

Text 

Text 

Text 

... 

Text 

Abb. 34: Textmatrix der Leitfadenthemen 

Diese Matrix ähnelt einer rechteckigen Variablenmatrix, die Ausgangspunkt 
der  meisten  Auswertungen  der  sozialwissenschaftlichen  Statistik  ist.  Hier 
wie dort werden die Zeilen durch die Fälle, d.h. durch die Interviewten, ge-
bildet. Während in der quantitativen Datenmatrix die Variablen die Spalten 
bilden, sind es bei der hier dargestellten qualitativen Datenmatrix die Themen 
des Leitfadens. Die Exploration einzelner Spalten der Matrix entspricht quasi 
univariaten  statistischen  Auswertungen:  Man  verschafft  sich  einen  Über-
blick über das Antwortspektrum und die Häufigkeit verschiedener Antwor-
ten, gruppiert die Antworten nach Ähnlichkeit und identifiziert verschiede-
ne Dimensionen. 

Unschwer lassen sich in eine solche explorative Matrix der Antworten 
weitere Merkmale, etwa sozio-demographische Variablen, einbeziehen. Bei 
der Untersuchung über den Erfolg der Rehabilitation wurde hierzu ein er-
gänzender Fragebogen zur Erfassung dieser „objektiven Daten“ eingesetzt. 
Der simultane Blick in mehrere mit Text gefüllte Spalten ähnelt der Logik 
der  statistischen  Korrelationsanalyse.  Zwei  oder  mehrere  Antworten  des 
gleichen Probanden werden jeweils zueinander in Beziehung gesetzt. Selek-
tionen und gruppenspezifische Auswertungen werden möglich, wenn man 
weitere Variable hinzuzieht. 

Es  besteht  auch  die  Möglichkeit,  die  lexikalische  Suche  auf  einzelne 
Punkte des Leitfadens zu beschränken. So lassen sich einerseits die zuvor 
beschriebenen Keyword-in-context-Zusammenstellungen gezielt einsetzen: 
Die Frage „Welche spezifischen Erwartungen richten sich an Ärzte?“ lässt 
sich bearbeiten, indem man eine lexikalische Suche nach den Suchworten 
„Arzt“  und  „Ärztin“  in  den  codierten  Textpassagen  zum  Leitfadenpunkt 
„Erwartungen“ startet. 

Automatisches Codieren von Fundstellen 

127 

Unstrukturierte Texte zu explorieren gestaltet sich etwas mühsamer als 
die lexikalische Suche beim strukturierten Texttyp, bei dem man sofort in 
der  Lage  ist,  sich  über  bestimmte  Forschungsfragen  einen  Überblick  zu 
verschaffen. Die Daten einer Textmatrix wie in Abb. 34 lassen sich syste-
matisieren  und  für  einen  Forschungsbericht  zusammenzustellen,  inklusive 
etwaiger Statistiken oder Quasi-Statistiken. Wenn man hingegen erst müh-
sam zusammensuchen muss, wo ein Interviewter in einem längeren Inter-
viewtranskript über ein bestimmtes Thema spricht, beträgt der Zeitaufwand 
ein Zigfaches. 

6.3  Automatisches Codieren von Fundstellen 

Das  automatische  Codieren  macht  es  möglich,  eine  lexikalische  Suche 
durchzuführen und allen Fundstellen („Treffern“) automatisch einen Code 
zuzuweisen. Wird ein Suchausdruck in einem Text gefunden, dann wird die 
entsprechende  Textstelle  codiert,  d.h.  die  gewählte  Kategorie  wird  zu-
geordnet. Während die quantitative Inhaltsanalyse nur an einer Auszählung 
der  Kategorien  interessiert  ist  und  die  Texte  selbst  nach  dem  Codiervor-
gang nicht mehr von Interesse sind, verfolgt die qualitative Analyse andere 
Zwecke. Zwar ließe sich auch hier eine solche, auf Kategorienhäufigkeiten 
zielende  Codierung  vornehmen,  doch  ist  die  Logik  der  Analyse  geradezu 
gegenläufig. Der Text wird durch die Codierung nicht überflüssig, sondern 
besser erschlossen und organisiert. Codiert wird ein Bereich um die Fund-
stelle  des  Suchbegriffs  herum,  wobei  die  Größe  des  Kontextes  frei  be-
stimmt  werden  kann,  sie  richtet  sich  nach  formalen,  syntaktischen  Anga-
ben, beispielsweise ein Absatz vor und nach dem gefundenen „Treffer“. 

Die automatische Codierung ist gewiss nicht der Königsweg der compu-
tergestützten  Analyse  qualitativer  Daten,  aber  sie  ist  eine  außerordentlich 
nützliche Funktion nicht nur mit heuristischem Wert. Zum Beispiel erhält 
man  inzwischen  als  Teilnehmer  einer  wissenschaftlichen  Konferenz  übli-
cherweise  die  Abstracts  auf  CD-ROM.  Man  kann  diese  nun  sehr  einfach 
auswerten,,  etwa  lassen  sich  die  Abstracts  eines  Soziologiekongresses  auf 
diese Weise sehr schnell in Bezug auf die Vortragsthemen (Umwelt, Fami-
lie, Soziales etc.) und die theoretischen Bezüge (Luhmann, Habermas, We-
ber, System, Konstrukt etc.) automatisch codieren und mit den in Kapitel 5 

 

128 

Textexploration: Volltext-Recherche 

dargestellten  Mitteln  des  Text-Retrievals  Zusammenhänge  eruieren  und 
Bedeutungsfelder analysieren. 

Die automatische Codierung ist vor allem bei großen Textmengen eine 
wirksame Auswertungsstrategie. Wenn man es mit mehreren hundert Tex-
ten zu tun hat, lässt sich konkurrenzlos schnell herausfinden, ob sich Sozio-
loginnen und Soziologen bei ihrer Jahrestagung stärker mit Habermas oder 
Luhmann befassen, welche Klassiker in der Diskussion eine Rolle spielen 
und  in  welchen  inhaltlichen  Kontexten  diese  rezipiert  werden.  Besondere 
Stärke erhält die automatische Codierung dadurch, dass man sie mit den in 
Kapitel 9 beschriebenen Techniken des komplexen Text-Retrievals kombi-
nieren kann. 

6.4  Stärken und Schwächen der lexikalischen Suche 

Gegenüber der im vorangehenden Kapitel beschriebenen Technik der intel-
lektuellen Codierung von Textsegmenten weist die lexikalische Suche eine 
Reihe von Vorzügen, aber auch Nachteile auf. Oft ist es empfehlenswert, 
beide Methoden zu kombinieren und mit einer lexikalischen Suche zu be-
ginnen, um sich zunächst einen Eindruck über die Worte, Redewendungen 
und Metaphern zu verschaffen, die die Befragten selbst verwenden. 

Die  lexikalische  Suche  mit  der  Möglichkeit  der  automatischen  Codie-
rung stellt durchaus eine wertvolle, eigenständige Auswertungstechnik dar, 
sie ist nicht bloße Ergänzung von Code-and-retrieve Techniken. Der größte 
Vorteil dieser Technik ist, dass sie viel einfacher und schneller als das ma-
nuelle Segmentieren und Codieren zu realisieren ist. Nahezu ohne spezielle 
Vorbereitung kann mit der Auswertungsarbeit begonnen werden. Es lassen 
sich nicht nur für den gesamten Textkorpus Informationen zu einem be-
stimmten Wort oder Begriff zusammenstellen, sondern unschwer lässt sich 
auch beantworten, wer bestimmte Begriffe benutzt und in welchem Kon-
text diese benutzt werden. 

Speziell  für  Beobachtungsstudien,  Feldforschungen  und  Dokumenten-
analysen erweist sich die lexikalische Suche als vorteilhaft. Für bestimmte, 
in den Texten vorkommende Personen lässt sich zusammenstellen, wie an-
dere  sie  wahrnehmen  und  wie  sie  sich  über  sie  äußern.  Kernstück  dieser 
Technik ist die Zusammenstellung von Keyword-in-context-Listen. Die le-
xikalische Suche ist allerdings immer eine syntaktische Suche nach dem Vor-

Stärken und Schwächen der lexikalischen Suche 

129 

kommen von Zeichenketten („Strings“) und dies hat eine Reihe von Pro-
blemen zur Folge: Einerseits sollten die analysierten Texte möglichst fehler-
frei  sein,  denn  falsch  geschriebene  Worte  werden  nicht  gefunden.  Auch 
muss  durchgehend  die  gleiche  Schreibweise  für  zusammengesetzte  Worte 
gewählt werden, denn für den Computer ist ein „Internet-User“ etwas an-
deres  als  ein  „Internetuser“.  Diese  Probleme  lassen  sich  ebenso  wie  die 
Probleme  der  Groß-  und  Kleinschreibung  und  der  Silbentrennung  durch 
sorgfältige Datenaufbereitung noch relativ leicht bewältigen. Anders ist es 
hingegen um solche Probleme bestellt, die im Zusammenhang mit der Be-
deutung  von  Worten  stehen.  Sehr  viele  Worte  sind  mehrdeutig,  ihre  Be-
deutung hängt in starkem Maße vom Kontext der anderen Worte ab, für 
die  wiederum  das  gleiche  gilt.  Insofern  ist  es  äußerst  problematisch,  das 
Vorkommen eines Wortes im Text als Indikator für das Vorliegen eines be-
stimmten Phänomens zu werten. Bei der lexikalischen Suche ist es deshalb 
unbedingt erforderlich, dass jederzeit die Möglichkeit besteht, den erweiter-
ten Kontext von Treffern heranzuziehen, um so entscheiden zu können, ob 
es  sich  wirklich  um  einen  für  die  jeweilige  Fragestellung  gültigen  Treffer 
handelt. 

Im Zuge der  Diskussion um die Schwächen der quantitativen Inhalts-
analyse, bei der ja die lexikalische Suche mit automatischer Codierung ver-
knüpft wird, hat man lange Zeit diesen bloß mechanischen Charakter der 
lexikalischen  Suche  kritisiert  und  deren  Leistungsfähigkeit  eher  unter-
schätzt. Die im Kapitel 3 beschriebene intellektuelle Codierung verlangt ei-
nerseits  eine  gründliche  Kenntnis  der  Texte,  andererseits  verschlingt  die 
Codierung  viel  Zeit  und  oktroyiert  mehr  oder  weniger  automatisch  einen 
bestimmten Arbeitsstil, der an der Linearität des Textes orientiert ist. Der 
Zugang  der  lexikalischen  Suche  ist  demgegenüber  ein  völlig  anderer  und 
eher mit der Logik von Hypertext vergleichbar. Der Analyseprozess ist bei 
der lexikalischen Suche weitaus weniger vorgezeichnet und strukturiert. Das 
hat einerseits den Vorteil, dass Exploration und Flexibilität im Vordergrund 
stehen, andererseits aber auch den Nachteil, dass sich der Benutzer in sei-
nen Daten verlieren kann und nicht so recht weiß, wo er beginnen und auf-
hören soll. 

 

130 

Textexploration: Volltext-Recherche 

6.5  Praktische Hinweise für MAXQDA 

Die lexikalische Suche in  MAXQDA erlaubt es, in den Originaltexten, in 
einer Selektion der Texte („aktivierte Texte“), den Memos oder in der Zu-
sammenstellung  der  codierten  Textsegmente,  d.h.  in  den  Resultaten  eines 
Text-Retrievals  zu  suchen.  Dadurch  werden  schrittweise  aufeinander  auf-
bauende  Suchvorgänge  ermöglicht.  Ferner  kann  die  lexikalische  Suche  in 
vielfältiger Weise mit dem Text-Retrieval verknüpft werden. 

Sofern  die  lexikalische  Suche  in  den  Originaltexten  und  nicht  in  den 
Memos  stattfindet,  arbeitet  sie  ähnlich  wie  das  Text-Retrieval:  Will  man 
nicht mit dem gesamten Textkorpus arbeiten, sind zunächst diejenigen Tex-
te  zu  aktivieren,  die  in  den  Suchprozess  einbezogen  werden  sollen.  Das 
können einzelne Texte sein, alle Texte einer Textgruppe oder nur die Texte, 
die bestimmten Selektionskriterien genügen (vgl. Kapitel 8). 

Resultat der lexikalischen Suche ist zunächst eine Liste aller Fundstellen, 
wobei  jede  Zeile  eine  Fundstelle  repräsentiert.  Durch  Anklicken  dieser 
Fundstelle öffnet sich automatisch der Originaltext und wird an die betref-
fende  Stelle  positioniert.  Die  Gesamtheit  aller  Fundstellen  kann  auch  als 
Datei exportiert werden. Dabei wird ein Keyword-in-context erzeugt, wo-
bei der Umfang des Kontextes variabel bestimmt werden kann (durch An-
gabe der gewünschten Anzahl der Absätze vor und nach der Fundstelle). 

Die Ergebnisse können zudem codiert werden, also einer bestehenden 
oder neu definierten Kategorie zugewiesen werden. Die Angabe des Kon-
textumfangs bestimmt auch die Größe der Textsegmente, die durch die au-
tomatische Codierung der Fundstellen erzeugt werden. 

Abb. 35: Anzeige der Suchergebnisse als Tabelle 

 

Praktische Hinweise für MAXQDA 

131 

Text-Retrieval und lexikalische Suche lassen sich auf einfache Art miteinan-
der verbinden, in dem zunächst ein Text-Retrieval durchgeführt wird und 
anschließend nur in den Resultaten, d.h. in der „Liste der Codings“ gesucht 
wird.  In  der  Studie  „Rehabilitation  und  Pädagogik“  ging  es  etwa  um  die 
Frage, welche spezifischen Erwartungen die Patienten an die Ärzte haben. 
Zunächst  wird  ein  Text-Retrieval  für  den  Code  „Erwartungen“  durchge-
führt, dem alle Textpassagen zum Leitfadenpunkt „Erwartungen“ zugeord-
net  sind.  Die  Retrieval-Resultate  werden  im  Fenster  „Liste  der  Codings“ 
zusammengestellt und es lässt sich eine lexikalische Suche nach den Such-
worten „Arzt“ und „Ärztin“ in diesen Segmenten anschließen. 

In  MAXQDA  kann  die  automatische  Codierung  der  Suchfunktionen 
auch  benutzt  werden,  um  Textabschnitte  automatisch  bestimmten  Spre-
chern, z.B. zur Auswertung von Gruppendiskussionen und Fokusgruppen, 
zuzuordnen. Dazu ist es erforderlich, eine bestimmte Syntax bei der Trans-
kription einzuhalten. Jeder Beitrag eines Sprechers muss mit der Sprecher-
bezeichnung  beginnen  und  darf  nur  ein  Absatzzeichen  enthalten.  Die  au-
tomatische  Codierung  macht  es  möglich,  alle  Beiträge  eines  bestimmten 
Sprechers zusammenzustellen und zu kontrastieren. Ohne dass irgendwel-
che weiteren Vorarbeiten zu leisten sind, lässt sich bei einer so automatisch 
codierten  Gruppendiskussion  sofort  auswerten,  wer  wie  häufig  redet  und 
wie  umfangreich  diese  Beiträge  sind.  Exportiert  man  diese  Zusammen-
stellung in Form eines Keyword-in-context erhält man eine übersichtliche 
Darstellung aller Beiträge eines Sprechers in Form einer HTML-Tabelle. 

Wenn in den Memos anstatt in den Texten gesucht wird, enthält die Er-
gebnistabelle eine Liste der Memos, in denen die Suchbegriffe vorkommen. 
Auch hier kann durch Anklicken direkt zum betreffenden Memo gesprun-
gen  werden  oder  ein  entsprechendes  KWIC-Listing  aller  Fundstellen  in 
Form einer Tabelle erzeugt werden. 

Übungen 

1.  Öffnen Sie Ihr Projekt „test1“ oder erzeugen sie ein neues Projekt 
bestehend  aus  einer  Textgruppe  und  den  Beispielinterviews  Inter-
view1 bis 4. 

2.  Gehen Sie in das Suchmenü. Welche Texte würden jetzt durchsucht? 
Wie  könnte  man  es  bewerkstelligen  das  nur  in  bestimmten  Texten 
gesucht wird, aber nicht in allen? 

 

132 

Textexploration: Volltext-Recherche 

3.  Lassen Sie nach dem Wort „Jugend“ suchen, wobei die Groß- und 
Kleinschreibung nicht beachtet und auch Teilwörter gesucht werden 
sollen. Wie viele Fundstellen gibt es? 

4.  Klicken sie auf jede Fundstelle und beobachten Sie was passiert. Be-

wegen sie sich mit den Cursortasten durch die Fundstellen. 

5.  Erstellen Sie einen neuen Code „Jugend“ im Codesystem und codie-
ren  Sie  alle  gefundenen  mit  diesem  Code,  wobei  nur  der  entspre-
chende Absatz, in dem sich das Wort befindet, codiert werden soll. 
Aktivieren  Sie  anschließend  alle  vier  Texte  und  nur  den  Code  „Ju-
gend“. Wie viele codierte Segmente gibt es jetzt? 

6.  Exportieren Sie alle Fundstellen in eine Datei, nennen Sie die Datei 

„fundstellen.rtf“ und öffnen Sie diese mit Microsoft Word. 

7.  Suchen Sie jetzt auch nach dem Wort „Themen“ mittels der „UND“ 
Kombination innerhalb von 2 Absätzen. Wie viele Fundstellen gibt 
es? 

 

7  Die Memos: Eigene Ideen aufzeichnen und 

organisieren 

7.1  Notizen und Aufzeichnungen im Forschungsprozess 

Benutzer von QDA-Software werden in der Programmbeschreibung häufig 
entdecken,  dass  die  Möglichkeit  besteht,  eigene  Aufzeichnungen  („Me-
mos“)  anzufertigen  und  zusammen  mit  den  Texten  zu  verwalten.  Häufig 
wird man sich dann die Frage stellen, ob es sinnvoll ist, bei der Datenanalyse 
diese Möglichkeit des Programms zu nutzen und wie dies am besten zu be-
werkstelligen ist. Dieses Kapitel will einen Eindruck davon vermitteln, wozu 
Memos gut sein können, gibt Beispiele für verschiedene Typen von Memos 
und zeigt, wie die Memo-Funktion in einem QDA-Programm aussieht. 

Im Prozess der sozialwissenschaftlichen Analyse qualitativer Daten ist es 
auch  ohne  Nutzung  von  Computersoftware  eine  gängige  Praxis,  eigene 
Texte  und  Kommentare  über  das  Datenmaterial  zu  erstellen.  Vor  allem 
Strauss, Glaser und Corbin (1991, 1996, 1998, 2008) entwickelten mit der 
Grounded  Theory  einen  Analysestil,  zu  dessen  Charakteristika  es  gehört, 
mit verschiedenen Typen von Aufzeichnungen (Memos) zu arbeiten  

Für solche Aufzeichnungen, Anmerkungen, Kommentare und Notizen 
gilt,  dass  sie  einen  anderen  Status  als  die  Originaltexte  haben:  Sie  sind 
Hilfsmittel des Forschers auf dem Weg zu einem von ihm zu erstellenden 
Text,  beispielsweise  einer  Dissertation  oder  einem  Forschungsbericht  für 
den Auftraggeber. Sie sind keine Dokumente wie die Originaltexte, sondern 
Produkte des Forschers. Das Schreiben von Memos kann zu verschiedenen 
Zeitpunkten im Projektverlauf stattfinden: 
 

1.  zu Beginn des Projektes z.B. als Beschreibung der Interviewsituation, 
der Wohnung des Befragten, des persönlichen Eindrucks und ande-
rer Dinge mehr 

2.  in der ersten Phase der Analyse als erste Zusammenfassung z.B. in 

Form der oben erwähnten Interviewsummaries 

134 

Die Memos: Eigene Ideen aufzeichnen und organisieren 

3.  während des gesamten Analyseprozesses, um die Definition und in-

haltliche Bedeutung von Codes zu dokumentieren 

4.  bei der Interpretation von Texten, um Hypothesen und Vermutun-

gen zu einzelnen Textstellen festzuhalten 

5.  im Verlauf der kontrastierenden Datenauswertung bei der Entwick-

lung von Theorien 

 
Das systematische Anfertigen von Memos im Verlauf des Forschungspro-
zesses  stellt  eine  wertvolle  Hilfe  für  die  Theoriebildung  dar.  Das  Memo-
Schreiben zwingt die Forschenden dazu, die eigenen Ideen, Gedanken und 
Hypothesen festzuhalten und zu ordnen. Die Aufgabe, Zwischenergebnisse 
zu formulieren, verkürzt den Sprung von der Datenbearbeitung zur Erstel-
lung des Forschungsberichtes. Wichtige Teile des Forschungsberichtes ent-
stehen  gewissermaßen  „nebenbei“,  d.h.  während  der  Datenanalyse  und 
Interpretation. Für die Arbeit im Team stellen Memos ein wichtiges Kom-
munikationsmittel  dar:  Sie  geben  allen  Mitarbeitern  die  Chance,  die  aus-
gearbeiteten Ideen der anderen Teammitglieder zu lesen, diese zu kommen-
tieren und weiterzuentwickeln. Memos über die definierten Kategorien, mit 
Anwendungs-  und  Ankerbeispielen,  sind  jederzeit  für  jedes  Mitglied  der 
Forschergruppe verfügbar und können die Vereinheitlichung des Codierens 
innerhalb  der  Arbeitsgruppe  fördern.  Insofern  dienen  Memos  der  Erhö-
hung der internen Validität. 

7.2  Systematisches Arbeiten mit Memos in der Grounded 

Theory 

So sehr es zu den Alltagsgebräuchen von Forschern gehört, Notizen und 
Memos während der Auswertung anzufertigen, so wenig findet man diesen 
Vorgang  in  der  Methodenliteratur  thematisiert.  Eine  systematische  Be-
schreibung des Arbeitens mit dem Hilfsmittel Memo ist dort nur selten zu 
finden. Eine Ausnahme stellt die Grounded Theory dar, die sich seit ihren 
Anfängen  intensiv  mit  dem  Thema  „Memos“  befasst  hat  (Glaser/Strauss 
1998; Hopf/Weingarten 1979; Strauss/Corbin 1996; Corbin/Strauss 2008). 
Strauss und Corbin definieren Memos als schriftliche Analyseprotokolle, die sich 
auf das Ausarbeiten der Theorie beziehen. Aufgrund der unterschiedlichen Funk-
tion  im  Forschungsprozess  differenziert  Strauss  unter  anderem  zwischen 
drei Memo-Typen: 

Systematisches Arbeiten mit Memos in der Grounded Theory 

135 

 

1.  Code-Notizen beziehen sich auf die Ergebnisse des Codierens. 
2.  Theoretische  Memos  oder  Theorie-Memos  sind  explizit  auf  die  Theorie-
entwicklung bezogen und enthalten die Produkte des induktiven und 
deduktiven Denkens. 

3.  Planungs-Memos  enthalten  weitergehende  Anweisungen  für  den  For-
scher  selbst  oder  das  Forscherteam,  z.B.  in  Bezug  auf  die  weitere 
Auswahl von Forschungsfällen. 

Definition 
In ihrem Lehrbuch der Grounded Theory geben Strauss und Corbin (1996: 
169) die im folgenden Kasten wiedergegebenen Definitionen der verschie-
denen Memotypen: 

Art 

Memos: 
 

 

Code-Notizen: 
 

Theoretische Notizen: 
 

Definition 

Schriftliche Analyseprotokolle, die sich auf das Ausarbeiten der Theorie 
beziehen. 

Memos, die Ergebnisse der drei Formen des Codierens beinhalten, wie zum 
Beispiel konzeptuelle Begriffe (Labels), paradigmatische Eigenschaften und 
Indikatoren für den Prozess. 

Theoretisch sensibilisierende und zusammenfassende Memos. Theoretische 
Notizen enthalten die Produkte des induktiven und deduktiven Denkens über 
tatsächlich und möglicherweise relevante Kategorien, ihre Eigenschaften, 
Dimensionen, Beziehungen, Variationen, Prozesse und die 
Bedingungsmatrix. 

Planungs-Notizen: 
 

Memos, die Handlungsanweisungen für die eigene Person und das Forscher-
Team enthalten. Diese beziehen sich z.B. auf die Auswahl von Fällen, auf 
Interview-Fragen, mögliche Vergleiche, weiterzuverfolgende Ideen etc. 

Abb. 36: Definitionen verschiedener Memotypen nach Strauss/Corbin (1996: 169) 

Analysiert man seine Daten orientiert am Analysestil der Grounded Theory, 
so beginnt das Schreiben von Memos gleich zu Anfang des Projektes und 
wird durch das gesamte Projekt hindurch beibehalten. Anfangs werden mit 
diesem Hilfsmittel mögliche Hypothesen festgehalten und generative Fra-
gen  gestellt.  Die  ersten  Memos  sind  vielleicht  noch  ziemlich  einfach  und 
unklar.  In  den  weiteren  Phasen  dienen  sie  dazu,  die  konzeptuell  dichter 
werdende  Theorie  festzuhalten.  Theoretische  Gedanken  werden  in  Form 
von  Theorie-Memos  kontinuierlich  festgehalten.  In  der  Phase  des  Schrei-
bens des Forschungsberichtes werden sie sortiert und integriert. Durch alle 
Projektphasen  hindurch  dienen  sie  dazu,  weitergehende  Fragen  zu  stellen 

 

136 

Die Memos: Eigene Ideen aufzeichnen und organisieren 

und  neue  Datenerhebungen  zu  initiieren  und  ihre  Zielsetzung  zu  bestim-
men. 

Im Ablauf der Forschungsarbeit der Grounded Theory spielt das Schrei-
ben von Memos also eine tragende Rolle. Strauss stellt den Ablauf des For-
schungsprozesses  als  einen  ständig  zwischen  Codieren,  Memo  schreiben 
und der Erhebung neuer Daten zirkulierenden Prozess dar (Abb. 37). 

Datenerhebung 

Codieren 

Memo  
schreiben 

Abb. 37: Codierparadigma nach Strauss (1998: 46) 

 

Memos sind eine Form der Fixierung der eigenen Ideen und theoretischen 
Gedanken. Jeder muss seinen eigenen Stil zum Erstellen von Memos finden 
und sich darin üben, diese kontinuierlich anzufertigen. Die Kreativität wird 
hierdurch  angeregt  und  das  Theoretisieren  wird  nicht  auf  das  Ende  des 
Projektes  verschoben,  sondern  zu  einem  ständigen  Begleiter  des  For-
schungsprozesses. 

Nach dem in Abb. 37 dargestellten Schema ist das Memoschreiben eine 
prinzipiell nie völlig abgeschlossene Angelegenheit, stets kann man bereits 
vorhandene Memos „verdichten“: Man schreibt Memos über Memos, d.h. 
zusammenfassende Memos, die mehrere Memos integrieren und auf einer 
neuen Ebene konzeptualisieren. Das Arbeiten mit Memos ist zwar im Prin-

Systematisches Arbeiten mit Memos in der Grounded Theory 

137 

zip eine relativ freie Tätigkeit, Strauss gibt aber ein Set von Regeln für das 
Arbeiten an (Strauss/Corbin 1996: 173): 
 

1.  Memos sollen datiert sein und es sollte nachvollziehbar sein, wer der 

Autor des Memos ist. 

2.  Das  Memo  sollte  einen  Verweis  auf  das  Dokument  enthalten,  auf 
das es sich bezieht (Interview, Beobachtungsprotokoll, Seite, Zeilen-
nummer etc.). 

3.  Jedes Memos sollte eine Überschrift haben, in der das Konzept (die 
Konzepte) oder die Kategorie (die Kategorien) genannt werden, um 
die es sich dreht. 

4.  Memos,  die  zwei  oder  mehr  Kategorien  zueinander  in  Beziehung 

setzen, sollten alle diese Kategorien enthalten. 

5.  Memos  sollten  nach  ihren  verschiedenen  Formen  gekennzeichnet 

werden. 

 
Während in den Anfängen der Grounded Theory die Art und Weise, wie 
mit  Memos  zu  arbeiten  ist,  noch  relativ  vage  blieb,  hat  Strauss  in  seinen 
späteren Arbeiten zahlreiche konkrete Beispiele gegeben, wie er selbst mit 
dem Mittel der Memos arbeitet. Memos enthalten die Ergebnisse der Da-
tenanalyse,  sie  stellen  „die  schriftlichen  Formen  unseres  abstrakten  Den-
kens  über  die  Daten  dar“  (Strauss/Corbin  1996:  170).  Memos  verändern 
sich im Laufe des Forschungsprozesses: Sie nehmen  an  Komplexität und 
Abstraktheit zu. Im Folgenden werden für drei Arten von Memos – Code-
Memos, Planungs-Memos und Theorie-Memos – Beispiele gegeben23. Code-
Memos befassen sich mit den Eigenschaften und Dimensionen einer Kate-
gorie.  Abb.  38  zeigt  ein  typisches  Beispiel  zum  Thema  „Schmerz“ 
(Strauss/Corbin 1996: 177). 

                                                           
 
23 Strauss (1991: 151 ff.) widmet dem Thema „Memos und Memo schreiben“ mehrere Ka-
pitel  und  präsentiert  eine  Vielzahl  von  Beispielen  aus  der  eigenen  Forschungspraxis. 
Strauss/Corbin 1996 gehen in Kapitel 12 dieses einführenden Textes auf die verschiede-
nen Formen von Memos in der Grounded Theory ein und stellen ebenfalls eine Reihe 
von Beispielen aus ihrer Forschung dar. 

 

138 

Die Memos: Eigene Ideen aufzeichnen und organisieren 

 
 
 

Code-Notiz: SCHMERZ UND SEINE EIGENSCHAFTEN UND DIMENSIONEN 
Schmerz hat bestimmte Eigenschaften, die entlang dimensionaler Kontinua variieren können. Darun-
ter befinden sich folgende: 
Allgemeine Eigenschaften  
Dauer 
 
Intensität   
Variation 
 
Lokalisierung im Körper 
Kontinuitätsgrad 
      
Zum Beispiel: Arthritis war die Ursache dieses Schmerzereignisses. 
Unter der Bedingung von „kalt-feuchtem Wetter“ nimmt der Schmerz in seiner Intensität zu. 
Unter der Bedingung von „Wärme“ nimmt der Schmerz in seiner Intensität ab. 
Unter der Bedingung von „morgens“ beginnt der Schmerz. 
Unter der Bedingung von „nachts“ ist der Schmerz ein wenig gelindert. Potenzielle andere Kategorie: 
Schmerzlinderung. 

kurz 
leicht 
abnehmend 
zum Fuß 
intermittierend   vorübergehend 

 
 
 
 
 
 

Mögliche Dimensionen 
 
lang 
stark 
 
zunehmend 
vom Kopf   
kontinuierlich 

Abb. 38: Beispiel für ein Code-Memo 

Auf dieser Basis konzipiert Strauss weitere Datenerhebungen und verfasst 
eine Planungsnotiz: 

PLANUNGS-NOTIZ: DATENAUSWAHL FÜR SCHMERZ 

Ausgehend von meinem theoretischen Memo des heutigen Tages scheine ich jetzt 
mehrere verschiedene Bereiche zu haben, aus denen ich Daten über Schmerz be-
kommen  kann.  Das  wird  weitere  Eigenschaften  von  Schmerz  erkennbar  machen 
und Informationen über die verschiedenen Dimensionen dieser Eigenschaften und 
die Bedingungen liefern, die diese Eigenschaften zur Variation auf den Dimensio-
nen bringen. Ein guter Startpunkt ist die Entbindung. Ein anderer ist es, mit Krebs-
kranken zu sprechen. Wenn ich mit diesen Gruppen spreche und sie beobachte, 
sollte ich mich an den bereits identifizierten Eigenschaften und Dimensionen orien-
tieren und nach anderen suchen, die ich vielleicht noch nicht entdeckt habe. Bei-
spielsweise möchte ich Schmerz bezüglich Typ, Qualität, Intensität, Verlauf, Dauer, 
Ausprägung  etc.  untersuchen.  Ich  möchte  darüber  hinaus  die  Bedingungen  ver-
merken, unter denen die Eigenschaften verschiedene dimensionale Ausprägungen 
annehmen. Mit anderen Worten: welche Bedingungen führen dazu, dass Schmerz 
von einer bestimmten Person zu einem bestimmten Zeitpunkt als intensiv beschrie-
ben wird, von einer anderen Person oder zu einem anderen Zeitpunkt aber nicht? 
Oder  was  veranlasst  die  Schmerzqualität  zu  variieren,  ist  es  die  Quelle  des 
Schmerzes oder erleben verschiedene Personen Schmerz unterschiedlich? Warum 
ist Schmerz manchmal kontinuierlich, manchmal intermittierend? 

Abb. 39: Beispiel für ein Planungs-Memo (Strauss/Corbin, 1996: 179 f.) 

Abb.  40  gibt  einen  Ausschnitt  des  Theorie-Memos  „Gefahr“  wieder.  Im 
Weiteren  befasst  sich  dieses  mit  den  unterschiedlichen  Definitionen  von 
Gefahr durch Personal, Patienten und Familie, mit den Problemen der Ge-

Systematisches Arbeiten mit Memos in der Grounded Theory 

139 

fahrenvorbeugung  und  dem  Patienten  als  Gefahrenquelle.  Im  Projektver-
lauf nehmen  die Theorie-Memos  naturgemäß  an Umfang zu und können 
als integrative Memos eine beachtliche Länge erreichen – durchaus bis zu 10 
Seiten und mehr. An dieser Stelle ist es deshalb nicht möglich, ein Beispiel 
für solche hoch aggregierten Memos abzudrucken. Man findet ein solches 
zum Thema „Sicherheit, Gefahr und Risiko auf der Intensivstation in Kin-
derkliniken“ bei Strauss (1998: 176). 

GEFAHR: Die Gefahr, wie man sie gewöhnlich im Hinblick auf den Patienten wahrnimmt, kann fünf 
Ursachen haben: 

1.  die Apparatur selbst einschließlich ihrer einzelnen Teile wie etwa Medikamente, die über die 

Apparatur angewandt werden; 

2.  die Verbindung (Anschluss) zwischen Apparatur und Körper; 
3.  der „Patient“ als Ensemble von Körpersystemen; 
4.  der Patient als Person (die sich bewegt, einen Willen hat, sich widersetzt usw.); 
5.  andere Therapien, die mit der Apparatur kombiniert sind oder diese ergänzen. 

Anzeichen von drohender oder unmittelbarer Gefahr 

1.  Anzeichen haben verschiedene Eigenschaften: 

2.  wahrnehmbar – nicht wahrnehmbar 
3.  erwartbar – nicht erwartbar 
4.  usw.? 

Anzeichen stehen in Zusammenhang mit „Zustand“ oder Bedingung des Apparate-Anschlusses, des 
Patienten, der Person. 
Das bedeutet, dass der Interpretierende Anzeichen auch über den Zustand deutet; auch über die Stu-
fe der Behandlung insgesamt und der momentanen Behandlung (erste Stunde, zweite Stunde usw.). 
(...) 

Abb. 40: Beispiel für ein Theorie-Memo (Strauss 1991: 156) 

Strauss vergleicht Memos mit farbig codierten Karteikarten, die man fort-
laufend anordnen und für immer wieder neue Aufgaben sortieren kann. Sie 
sollten für das Herstellen von Querbezügen leicht zugänglich sein und als 
ein  „Lagerhaus  für  analytische  Ideen“  (1996:  172)  fungieren,  dem  man  je 
nach Erfordernissen immer wieder Einzelteile entnehmen und neu anord-
nen kann. 

Beim Schreiben von Memos ist es wichtig, sich von den Texten zu lösen 
und nicht die Texte lediglich deskriptiv zu wiederholen bzw. zu paraphra-
sieren. Es gilt, eigene Ideen zu entfalten und Theorien zu entwickeln. Eine 
analytische Distanz ist hierzu notwendig und das Schreiben von Memos ist 
ein  wichtiges  Hilfsmittel,  um  diese  Distanz  zu  gewinnen.  Memos, zumin-
dest die aus den Anfängen eines Projektes, sind nicht primär für die Veröf-

 

140 

Die Memos: Eigene Ideen aufzeichnen und organisieren 

fentlichung gedacht, sondern dienen dem Forscher. Mit Fortschreiten des 
Projektes nehmen sie an theoretischer Qualität zu und können in Teilen in 
den  Forschungsbericht  eingearbeitet  werden.  Strauss  gibt  die  dringende 
Empfehlung:  „Memos  handeln  nicht  von  Personen  oder  von  Handlungen, 
Vorfällen oder Ereignissen an sich, sondern sie beziehen sich auf Konzepte, 
die Abstraktionen dieser Handlungen, Vorfälle, Ereignisse und Geschehnis-
se  darstellen.“  Resümierend  könnte  man  raten:  Verwenden  Sie  Memos 
konzeptionell! 

7.3  Memos im QDA-Programm 

Bei der Arbeit mit QDA-Software können sich die beschriebenen Memo-
Typen also auf folgende Bestandteile eines Projektes beziehen: 
 

1.  auf  Textpassagen  –  solche  Memos  entstehen  bei  Anwendung  der 

Grounded Theory vor allem in der Phase des offenen Codierens 

2.  auf einen Text in seiner Gesamtheit – so etwa bei einem Dokument-
Summary  im  Falle  eines  narrativen  Interviews,  oder  bei  einer  Zu-
sammenfassung  einer  Argumentationslinie  in  der  Argumentations-
analyse 

3.  auf Gruppen von Texten – beispielsweise alle Feldnotizen, die von be-

stimmten Situationen im Feld angefertigt werden 

4.  auf das gesamte Projekt – das ist prototypisch bei theoretischen Memos 

in einer fortgeschrittenen Phase des Projektverlaufs der Fall 

5.  auf  Codes  –  hierzu  zählen  z.B.  Code-Memos  im  Sinne  von  Strauss 
oder  auch  Kategoriendefinitionen  mit  Ankerbeispielen  bei  inhalts-
analytischen Verfahren 

 
Außerdem können sich Memos auf Memos beziehen. Solche, in der Termi-
nologie von Strauss „integrative Memos“ genannt, beziehen sich aber ent-
weder auf integrative Konzepte, d.h. wiederum auf Codes, oder ihr Bezug ist 
auch wieder das gesamte Projekt, so dass sie nicht unbedingt vom vierten 
Typ unterschieden werden müssen. 

Memos lassen sich einerseits mit Post-it-Zetteln vergleichen, die man an 
die  Bezugsstelle  anheftet,  andererseits  ähneln  sie  Karteikarten,  die  man 
nach beliebigen Kriterien sortieren kann und die man nach dem Vorkom-
men bestimmter Worte durchsuchen kann. 

Memos im QDA-Programm 

141 

Die meisten QDA-Programme sind in der Lage, Memos zu verwalten. 
Allerdings variieren die Fähigkeiten dabei relativ stark: Sie reichen von eher 
simplen Möglichkeiten, die lediglich vorsehen, dass für jeden Text ein „Do-
cument memo“ eingegeben werden kann, bis hin zu relativ komplexen Op-
tionen: Dem Memo kann ein Titel und eine Farbe zugeordnet werden, Au-
tor und Erstellungsdatum werden festgehalten, den Memos können Codes 
zugeordnet werden, Memos können untereinander verknüpft werden, Me-
mos können nach verschiedenen Kriterien sortiert bzw. ausgewählt werden 
und anderes mehr. 

Regeln für den Umgang mit Memos im Rahmen der computergestützten Auswertung 

Regel 1: Verwenden Sie Memos!  
Wann immer Ihnen Ideen kommen, die für die Hypothesenbildung und 
den weiteren Gang der Auswertung wichtig sind, sollten Sie diese festhal-
ten. 

Regel 2: Kommen Sie zur Sache, fassen Sie sich möglichst kurz und seien Sie prä-

zise!  

Memos sollten in der Regel überschaubar bleiben und nicht zu kleinen 
Forschungsberichten anwachsen. Eine Ausnahme stellen hier die integrati-
ven Theorie-Memos der Grounded Theory dar, die durchaus umfangreich 
sein können. 

Regel 3: Vermeiden Sie einen inflationären Gebrauch von Memos!  
Man muss Memos leicht wiederfinden und für die weitere Arbeit benut-
zen können. Auch beim Durcharbeiten eines Buches würde es wenig Sinn 
machen,  hunderte  von  Post-it-Zetteln  an  Seiten  anzuheften.  Verfügt  man 
nicht über ein Wundergedächtnis, so würde man seine Zeit hauptsächlich 
mit dem Suchen und Lesen von Memos verbringen, die man da oder dort 
vermutet. Gerade in größeren Projekten verliert man leicht den Überblick. 
Memos  müssen  zahlenmäßig  noch  handhabbar  sein!  Also  nicht  etwa  100 
Memos pro Text. 

Memos können eine Art Modul für zukünftige Forschungsberichte und 
eigene Texte sein. Man sollte sich vergegenwärtigen, dass das Hauptprob-
lem der Datenauswertung in der qualitativen Forschung das der systemati-
schen Zusammenfassung und der Zuspitzung auf den Punkt ist. Auch Me-
mos erzeugen zunächst einmal noch mehr Material, noch mehr Daten. Den 
von  Huberman/Miles  (1983)  beschriebenen  „data  overload“,  die  Gefahr, 
von  den  eigenen  Datenmassen  zugeschüttet  zu  werden,  sollte  man  nicht 

 

142 

Die Memos: Eigene Ideen aufzeichnen und organisieren 

noch dadurch vergrößern, dass man zusätzlich Massen von Memos produ-
ziert. 

Regel 4: Benutzen Sie Codes anstelle von kurzen Memos!  
Auch zu kurze Memos sind wenig nützlich, d.h. solche Memos, die viel-
leicht  nur  aus  einer  Zeile  bestehen.  Will  man  unbedingt  eine  bestimmte 
Stelle markieren und mit einem kurzen Stichwort versehen, ist die Zuord-
nung  eines  Codes  oder  u.U.  die  bloße  farbige  Markierung  der  Textstelle 
vorzuziehen. 

Regel 5: Halten Sie die Memos zugänglich!  
QDA-Programme  schaffen  weitaus  bessere  Möglichkeiten  zum  Arbei-
ten mit Memos als der traditionelle Karteikasten. Vor allem die Zugänglich-
keit der Memos ist unvergleichlich besser und die Möglichkeiten zum Ord-
nen und Auswählen erreichen eine qualitativ völlig andere Dimension. Aus 
Hunderten von Memos lässt sich in Sekundenschnelle dasjenige ermitteln, 
in dem ein bestimmtes Thema angesprochen wird oder nur ein bestimmtes 
Wort  vorkommt.  Auch  der  Computer  enthebt  einen  nicht  des  Problems, 
seine Memos so zu organisieren, dass man sie auch wiederfindet. So sollten 
Planungsmemos sich nicht an irgendeiner Stelle des Textes verstecken, wo 
man sie nicht ohne weiteres wiederfinden würde. Man kann beispielsweise 
eine  Textgruppe  für  Planungsmemos  anlegen  und  das  Memo  (auch)  hier 
zuordnen.  Eine  andere  Variante  besteht  darin,  einen  Code  „Planungsme-
mos“ zu definieren und diesen Code allen Planungsmemos zuzuordnen. So 
ist jedes Planungsmemo im Weiteren leicht zu finden, selbst dann, wenn es 
eigentlich an irgendeiner Textstelle verborgen ist. 

Für das Arbeiten mit Memos ist es von existenzieller Bedeutung, in wel-
cher  Weise  die  einmal  geschriebenen  Memos  im  Auswertungsprozess  zu-
gänglich sind und wie man die in den Memos enthaltenen Informationen in 
einen Forschungsbericht transferieren kann. 

7.4  Praktische Hinweise für MAXQDA 

In MAXQDA können an folgenden Stellen Memos erzeugt werden: 
 

(cid:120)  Projekt-Memos beziehen sich auf das gesamte Projekt und enthalten 

Informationen über Projektverlauf, Design und Sampling. 

(cid:120)  Textgruppen-Memos beziehen sich auf die jeweilige Textgruppe. 

Praktische Hinweise für MAXQDA 

143 

(cid:120)  Dokument-Memos  beziehen  sich  auf  ein  Textdokument  als  ganzes 
und  enthalten  beispielsweise  Anmerkungen  zum  Interviewverlauf 
und zur Interviewsituation. 

(cid:120)  Text-Memos sind einzelnen Textstellen zugeordnet. 
(cid:120)  Code-Memos sind Codes zugeordnet. 

 
Im Analyseprozess werden insbesondere Text-Memos, Dokument-Memos 
und Code-Memos benutzt. Text-Memos können an jede beliebige Textzeile 
geheftet werden, indem einfach in den Memosektor vor der entsprechen-
den Textzeile hinein geklickt wird und das Memo in die Dialog-Box einge-
geben wird. Das Vorhandensein von Text-Memos wird durch gelbe Sym-
bole – ähnlich Post-it-Zetteln – visualisiert. 

Abb. 41: Ein Memo in MAXQDA – hier ein Code-Memo 

 

Memos sind jederzeit zugänglich, sie können gelesen und verändert werden, 
Teile von ihnen können für die Anfertigung eigener Texte kopiert werden. 
Zu einem Memo (vgl. Abb. 41) gehören ein Memo-Titel, die Angabe des 
Autors  des  Memos,  das  Erstellungsdatum,  sowie  zugeordnete  Codes  und 

 

144 

D
Die Memos: Eige

ene Ideen aufzei

ichnen und orga

anisieren 

Memo ein Me
ole  visualisier
Methoden-M
Datenerheb

emotyp 
t  wird. 
Memos, 
bungen 

gentliche Tex
der eig
rdnet  werden
zugeo
schieden  wer
Unter
e  Memos  s
farbige
oretical Samp
(„The
Zu
u  jeder  Kateg
-Memos eing
Code-
ie  Definition
um  di
uhalten. Abb. 
festzu
n und Lokale 
kation
Sozietätsstifte
rie  „S
igen  Code  e
jeweili
Memos, d.h. 
Text-M
und Codes z
merkt 
nkerbeispiele 
als An
Me
emos, die sic
mten  Text bez
gesam
Textn
amen  des  be
Memos eines P
Alle M
tabellarische
einer 
die Memos z
durch 
le zu s
springen. Die
n Spalten sort
denen
n,  zugeordne
Texten
Suchbegriffs 
eines S
gestell
lungen lassen

xt des Memo
n,  der  durch
rden  beispiel
owie  Memo
pling“) und N
gorie  und  Su
egeben werd
nen  von  Kat
41 gibt ein B
Agenda 21“
nde  Imagina
ingegeben.  S
auch hier kö
zugeordnet w
in solche Co
ch nicht auf 
ziehen, werd
etreffenden  T
Projektes sin
n  Darstellun
zu blättern un
e Tabelle der
tiert werden. 
eten  Codes  e
im Memotex
n sich so die r

os. Ferner ka
h  unterschied
lsweise  Theo
os,  die  sich 
Nachfragen b
ubkategorie 
den. Die Code
tegorien  und
Beispiel aus d
“ wieder, näm
ationen“.  Cod
Sie  haben  fo
önnen Autor 
werden. Emp
de-Memos ei
eine  bestimm
den am beste
Textes  in  der
nd in MAXQD
ng  (Abb.  42)
nd vom Mem
r Memos kan
So ist man in
etc.  sortieren
xt kann gesuc
relevanten M

ann jedem M
dliche  Symbo
orie-Memos, 
auf  weitere 
eziehen. 
des  Kategor
e-Memos we
d  entsprechen
dem Projekt „
mlich die Def
de-Memos  w
ormal  den  gle
und das Ers
fehlenswert i
inzufügen. 
mte Textstell
n als Dokum
r  „Liste  der 
DA über den
)  verfügbar. 
mo zur entspr
nn in Abhäng
n der Lage, n
.  Auch  nach
cht werden. F
emos zusamm

iensystems  k
rden meist g
nde  Ankerbe
„Umweltkom
finition der K
werden  direk
eichen  Aufb
stellungsdatu
ist es, Textpa

können 
genutzt, 
eispiele 
mmuni-
Katego-
kt  beim 
au  wie 
m ver-
assagen 

e,  sondern a
ment-Memo  a
Texte“  ange
n Memo-Man
Dieser  erlau
rechenden Te
gigkeit der ve
nach Datum, 
h  dem  Vorko
Für bestimm
menstellen. 

auf  den 
an den 
eheftet. 
nager in 
ubt  es, 
extstel-
erschie-
Autor, 
ommen 
mte Fra-

Abb. 42

2: Memo-Man

ager in MAXQ

QDA 

 

Praktische Hinweise für MAXQDA 

145 

Übungen 

1.  Sie  möchten  bei  einem  Text  einen  Hinweis  anbringen,  der  besagt, 
dass  der  Interviewer  nach  einer  bestimmten  Methode  vorgegangen 
ist. Öffnen Sie dazu Text „interview2“ in der Textgruppe „Bürger“ 
und erstellen Sie ein Memo direkt am Text neben dem ersten Absatz. 
Das Memo soll Ihren Namen, das aktuelle Datum, den Titel „Inter-
viewmethode“ und einen entsprechenden Inhalt enthalten. Schließen 
Sie das Memo. 

2.  Öffnen Sie das Memo erneut und versehen Sie es mit einem anderen 

Symbol. Wählen Sie das „M“ als Symbol für „Methoden-Memo“. 

3.  Fügen Sie ein weiteres Memo an eine beliebige Textstelle dieses Tex-
tes  ein,  um  Ihre  Ideen  bzw.  theoretische  Anmerkungen  zu  diesem 
bestimmten  Abschnitt  festzuhalten.  Wählen  Sie  ein  geeignetes  Me-
mo-Symbol aus. Begründen Sie die Auswahl! 

4.  Lassen Sie sich jetzt die Übersicht aller Memos anzeigen und sortie-
ren  Sie  diese  zunächst  nach  dem  Autor.  Danach  sortieren  Sie  die 
Memos nach den Memo-Symbolen und exportieren das Ergebnis in 
eine Datei namens „memos.rtf“ in einen Ordner Ihrer Wahl. 

5.  Lassen Sie sich jetzt alle Memos auflisten, die zur Textgruppe „Bür-
ger“ gehören. Verändern Sie die Spaltenanordnung und vergrößern 
Sie die Spalte der Textvorschau. 

6.  Öffnen Sie eines der Memos durch Doppelklick und verändern bzw. 

ergänzen den Text und ändern den Autor. 

7.  Markieren  Sie  alle  Memos  in  der  Übersicht  und  kopieren  Sie  diese 
mit der Tastenkombination Strg+c in die Zwischenablage. Fügen Sie 
diese  dann  mit  Strg+v  in  Microsoft  Excel  und  in  Microsoft  Word 
ein. Wo liegt der Unterschied? 

8.  Aufgrund der Schwierigkeiten der Zuordnung möchten Sie für eine 
Subkategorie,  z.B.  „Einstellungen/politisch“,  ein  Ankerbeispiel  an-
geben und dies in einem Code-Memo festhalten. Markieren Sie einen 
Satz, der Ihnen als Beispiel für die Zuordnung dieser Kategorie sinn-
voll  erscheint  und  kopieren  ihn  mit  Strg+c  in  die  Zwischenablage. 
Danach erstellen Sie ein Code-Memo mit dem Symbol Ausrufezei-
chen und fügen auch Ihr Ankerbeispiel ein. 

 

8  Die Fallvariablen: Strukturierte Übersicht 

 

8.1  Sinn und Zweck von Fallvariablen 

Zu  den  fortgeschrittenen  Techniken  der  computergestützten  Textanalyse 
gehört es, parallel zu jedem Text einen Datensatz mit Variablen (Attributen, 
Einschätzungsdimensionen) zu verwalten. Diese Variablen haben den Cha-
rakter von globalen Merkmalen oder Fallvariablen, d.h. die Variablen bezie-
hen  sich  auf  Merkmale  des  gesamten  Texts  und  nicht  nur  auf  einzelne 
Textpassagen  bzw.  codierte  Segmente.  Diese  Fallbezogenheit  ist  proto-
typisch  bei  sozio-demographischen  Merkmalen  gegeben:  Eine  interviewte 
Person ist weiblich, besitzt einen Hochschulabschluss und hat zwei Kinder. 
Diese Merkmale treffen nicht nur für ein bestimmtes Segment des Textes 
zu, sondern für den gesamten Text. Es handelt sich um Informationen, die 
bei der Interpretation von Textabschnitten hilfreich sein können und die als 
Selektionskriterien  bei  der  Kontrastierung  von  Fällen  dienen  können.  Zu 
jedem Text gehört also genau ein Datensatz mit Fallvariablen.  

TEXT 1 

 

 

 

 

 

 

 

 

 

 

 

 

VARIABLEN 
 
Karl Moll 
Befragter: 
25 
Alter: 
Geschlecht:  m 
1 
Kinder: 
Beruf:
Bäcker

 

Abb. 43: Fallvariablen parallel zum Text 

Auch  bei  den  Klassikern  der  Feldforschung,  wie  bei  Lofland/Lofland 
(1984), dienen solche Variablen dazu, die Charakteristika jedes Originaltex-
tes zu definieren und ständig für die Analyse verfügbar zu halten. 

Sinn und Zweck von Fallvariablen 

147 

Der erste Verwendungszweck von Fallvariablen ist es also, Rahmendaten 
(Profildaten)  zu  den  Originaltexten  zu  speichern:  In  Interviewstudien  er-
hebt man meist zu jedem Befragten eine Reihe von persönlichen Daten und 
Fakten, die sich am besten in standardisierter Form als Variablen festhalten 
lassen. Witzel (1982) empfiehlt in diesem Zusammenhang, parallel zu einem 
problemzentrierten Interview einen Kurzfragebogen zur Ermittlung solcher 
Daten einzusetzen, ein Verfahren, das im Forschungsalltag auch recht häu-
fig praktiziert wird: 

„Der Kurzfragebogen dient zum einen der Ermittlung von Sozialdaten 
(Alter, Beruf der Eltern usw.). Das nachfolgende Interview, das eine Aus-
handlung  der  subjektiven  Sichtweise  der  Interviewten  zum  Ziel  hat,  wird 
von denjenigen Fragen entlastet, die als Frage-Antwort-Schema aufgebaut 
sind.  Zum  anderen  können  die  in  ihm  enthaltenen  Informationen  –  und 
insbesondere in Kombination mit einer offenen Frage – einen Gesprächs-
einstieg  ermöglichen.  So  lassen  sich  etwa  Berufswunschangaben  für  eine 
Einleitungsfrage  zum  untersuchten  Problemfeld  des  Übergangs  Jugendli-
cher von der Schule in die Ausbildung nutzen (zu beiden Aspekten siehe 
die folgenden Ausführungen in Abschnitt 4).“ (Witzel 2000: 7) 

Die Möglichkeit, Fallvariablen zu definieren ist nicht in allen QDA-Pro-
grammen  vorhanden.  THE  ETHNOGRAPH,  MAXQDA  und  NVivo  sehen 
einen expliziten Datentyp hierfür vor, MAXQDA und NVivo erlauben es, 
die entsprechende Werte in übersichtliche Tabellen einzugeben, die ähnlich 
wie  Excel-Arbeitsblätter  oder  der  SPSS-Daten-Editor  zu  handhaben  sind. 
Andere Programme, die entsprechende Features nicht beinhalten, empfeh-
len, solche Merkmale als Codes zu definieren und dann diese Codes dem 
gesamten  Text  zuzuweisen.  Dies  ähnelt  der  Verschlagwortung  im  Biblio-
thekswesen, bei der Deskriptoren einer Dokumentationseinheit zugewiesen 
werden.  Man  definiert  beispielsweise  einen  Code  „Geschlecht“  mit  den 
Subcodes „männlich“ und „weiblich“, markiert das gesamte Interview eines 
Befragten und weist diesem den Code „männlich“ zu. Dieses Verfahren ist 
allerdings  recht  umständlich  und  hat  entscheidende  Nachteile  gegenüber 
der Möglichkeit zur expliziten Definition von Fallvariablen. Faktisch kön-
nen auf diese Weise nur Variablen mit Nominal- oder Ordinalskalenniveau 
gebildet  werden,  denn  für  jede  denkbare  Ausprägung  der  Variablen  muss 
ein Code im Kategoriensystem gebildet werden. Soll etwa das Einkommen 
der  Befragten  in  Form  eines  Codes  festgehalten  werden,  sind  vorab  Ein-
kommensklassen  zu  bilden,  und  zwar  möglichst  nicht  zu  viele,  denn  an-

 

148 

Die Fallvariablen: Strukturierte Übersicht 

sonsten entsteht ein kaum mehr überschaubares Codesystem mit hunderten 
von Codes. 

Wenn  mit  Fallvariablen  gearbeitet  wird,  entsteht  eine  rechteckige  Da-
tenmatrix, die so viele Zeilen aufweist, wie Texte vorhanden sind, und so 
viele Spalten, wie Variablen definiert sind (Abb. 44). Die Matrix lässt sich 
dann im zweiten Schritt, ohne dass Konvertierungen notwendig wären, sta-
tistisch auswerten. 

 

Befragter 

Alter 

Geschlecht 

Familienstand 

Kinder 

Beruf 

Interview 1 

Karl M. 

25 

Interview 2 

Susanne B.  31 

Interview 3 

Monika H. 

Interview n 

.. 

43 

.. 

m 

w 

w 

.. 

Abb. 44: Datenmatrix der Fallvariablen 

ledig 

verh. 

verh. 

.. 

1 

2 

1 

.. 

Bäcker 

Sekretärin 

Ingenieurin 

.. 

Das Instrument Fallvariablen spielt in der computergestützten qualitativen 
Datenanalyse nicht nur eine Rolle, um a priori vorliegende Fakten oder so-
zio-demographische Daten zu speichern, das Instrument „Variablen“ kann 
auch  sinnvoll  eingesetzt  werden,  um  Resultate  von  Textinterpretationen 
und Textanalysen in Form von Variablenwerten zu speichern. 

8.2  Forschungsbeispiel: Adult Attachement Interviews 

Hopf und Schmidt codieren die von ihnen geführten Interviews (vgl. oben 
Kap.  4.2)  mit  einem  detaillierten,  aus  der  Attachement-Forschung  stam-
menden  Kategoriensystem.  Auf  der  Grundlage  des  „Adult  Attachement 
Interview“ werden in den offenen Interviews Fragen zur emotionalen Qua-
lität der Beziehung zu den Eltern gestellt, etwa zu den Erfahrungen mit el-
terlicher Zuwendung und Zurückweisung (Hopf u.a. 1995: 84 ff.). Zur Er-
fassung dieser fallbezogenen Informationen wurden u.a. folgende Variablen 
gebildet: 

Forschungsbeispiel: Adult Attachement Interviews 

149 

2 viel 

Zuwendungserfahrungen (liebevolle, persönliche Zuwendung von Seiten der Mutter) 
1 wenig und mittel 
Erfahrungen mit elterlichen Versuchen der Begründung von Geboten und Verboten 
1 keine oder kaum 
Erfahrungen mit körperlichen Strafen 
1 ja (mittel bis stark)   

2 eher ja (meist nur in einem mittleren Umfang) 

2 nicht oder selten 

 

 

 

 

 

 

 

 

 

3 unklar 

3 unklar 

3 unklar 

Abb. 45: Beispiel für Variablen 

Je zwei Mitarbeiter codierten diese Einschätzungsdimensionen zunächst un-
abhängig voneinander. Die Zahl der Übereinstimmungen und Unterschiede 
wurde festgehalten, eine Inter-Coder-Reliabilität berechnet. Bei differenten 
Codierungen wurde argumentativ eine Einigung erzielt, wobei die Katego-
rienbeschreibungen eventuell präzisiert und ausdifferenziert wurden. Diese 
von Hopf als „kooperatives Codieren“ bezeichnete Vorgehensweise ist in-
sofern von großem Interesse, weil hier der bei der qualitativen Datenana-
lyse  häufig  naiv  praktizierte  und  nicht  weiter  thematisierte  Codiervorgang 
Gegenstand ausführlicher Überlegungen und forschungstechnischer Rege-
lungen ist: 

„Um ein möglichst gleiches Vorwissen in Bezug auf den Befragten zu garan-
tieren  und  damit  „Chancengleichheit“  der  an  der  Vercodung  Beteiligten 
herzustellen, hatten wir die Regel aufgestellt, daß die Person, die das Inter-
view geführt hatte, nicht an der Vercodung beteiligt sein sollte. Wie sinnvoll 
diese  Regel  war,  erwies  sich  auch  bei  der  abschließenden  Diskussion  zur 
Vercodung, bei der wir zu bestimmten zentralen Kategorien die Codierun-
gen anhand einzelner Fälle noch einmal in der gesamten Gruppe diskutiert 
haben. Hier zeigte sich, in welchem Ausmaß Einzelne die von ihnen geführ-
ten  Interviews  unter  bestimmten  Aspekten  in  Erinnerung  behalten  und 
schon während der Erhebung für sich „vercodet“ hatten.“ (Hopf/Schmidt 
1995: 63) 

Fallvariablen, so kann man resümieren, sind Instrumente expliziter Codie-
rung, die insbesondere im fortgeschrittenen Stadium des Analyseprozesses 
sinnvoll  zum  Einsatz  kommen,  wenn  es  nicht  mehr  um  die  Entwicklung 
von Kategorien geht, sondern um die zuverlässige Codierung des Materials 
mit anschließender statistischer Auswertung. 

 

150 

Die Fallvariablen: Strukturierte Übersicht 

8.3  Forschungsbeispiel: Strukturierende Inhaltsanalyse 

Ein ausführlicher methodischer Vorschlag, wie das Hilfsmittel Fallvariablen 
sinnvoll eingesetzt werden  kann, findet sich bei Mayring mit dem Modell 
der strukturierenden Inhaltsanalyse (Mayring 2003: 84). 

1. Schritt: 

Bestimmung der Analyseeinheiten 

2. Schritt: 

Festlegung der Strukturierungsdi-

mensionen (theoriegeleitet) 

3. Schritt: 

Bestimmung der Ausprägungen 
(theoriegeleitet); Zusammen-
stellung des Kategoriensystems 

Materialdurchlauf: Fundstellenbe-

5. Schritt: 

zeichnung 

 
  Materialdurchlauf, Bearbeitung und 

6. Schritt: 

Extraktion der Fundstellen 

7. Schritt 

4. Schritt: 

 Überarbeitung, gegebenenfalls 

Revision von Kategoriensystem und 

Kategoriendefinition 

Formulierung von Definitionen, An-
kerbeispielen und Codierregeln zu 

den einzelnen Kategorien 

 
 
 

 
 

 

 
 

 

 

 
 

 

 
 

 

 
 

 

 
 
 

 
 

 

 
 

 

 
 

 

 
 

 

 

 
 

 
 

 

 
 

 
 

 
 

 
 

8. Schritt: 

Ergebnisaufbereitung 

Abb. 46: Ablaufmodell strukturiender Inhaltsanalyse nach Mayring 

Mayring unterscheidet vier Formen strukturierender Inhaltsanalyse: forma-
le,  inhaltliche,  typisierende  und  skalierende  Strukturierung.  Die  formale 
Strukturierung zielt auf formale Textmerkmale wie Satzbau, Sprecherwech-
sel,  thematische  Abläufe  u.  Ä.  Die  inhaltliche  Strukturierung  zielt  auf  die 
Zusammenfassung der Themen oder inhaltlicher Aspekte, ganz ähnlich wie 
die typisierende Strukturierung, die das Material im Hinblick auf eine Typi-

Weiterarbeit mit Fallvariablen in SPSS 

151 

sierungsdimension  durcharbeitet.  Die  skalierende  strukturierende  Inhalts-
analyse arbeitet mit der Definition von Fallvariablen und soll deshalb hier 
näher betrachtet werden. 

Ziel der skalierenden Strukturierung ist es, eine bestimmte Struktur aus 
dem Material herauszufiltern. Sie will einen Querschnitt durch das Material 
legen  und  dieses  auf  Skalen  (in  der  Regel  Ordinalskalen)  einschätzen.  Sie 
geht in folgenden prinzipiellen Schritten vor (Mayring 2003: 92 ff.): 
 

1.  Definition  von  Einschätzungsdimensionen.  Diese  werden  aus  der 
Forschungsfrage abgeleitet und stellen im Grunde Variablen mit ver-
schiedenen Ausprägungen dar.  

2.  Bestimmung der Ausprägungen der Einschätzungsdimensionen. 
3.  Formulierung  von  Definitionen  und  Ankerbeispielen  –  Es  werden 
konkrete Textstellen angeführt, die unter eine Einschätzungsdimen-
sion fallen und als Beispiele für diese Einschätzungsdimension gelten 
sollen. 

4.  Fundstellenzeichnung – überall, wo die Einschätzungsdimension an-

gesprochen ist, wird diese Stelle markiert. 

5.  Codierung  –  d.h.  die  Einschätzung  wird  vorgenommen  und  ent-

schieden, welche Ausprägung angemessen ist.. 

 
Mindestens zwei Materialdurchläufe sind notwendig. Im ersten Durchlauf 
wird das Material daraufhin durchgesehen, welche Einschätzungsdimensio-
nen im Text angesprochen werden. Diese Fundstellen werden zunächst nur 
markiert. Beim zweiten Materialdurchlauf wird das so kenntlich gemachte 
Material  auf  den  Einschätzungsdimensionen  bewertet.  Bei  den  Einschät-
zungsdimensionen  handelt  es  sich  um  Fallvariablen  mit  einer  bestimmten 
Skalierung, z.B. mit der ordinalen Skala „viel“, „mittel“, „wenig“. Resultat 
dieser aufwändigen Form von Inhaltsanalyse ist die Charakterisierung der 
Einzelfälle durch Kategorienkombination und die Möglichkeit zu fallüber-
greifenden Generalisierungen. 

8.4  Weiterarbeit mit Fallvariablen in SPSS 

Wenn die Fallvariablen auch statistisch analysiert werden sollen, so sind die 
vom jeweiligen Statistikprogramm auferlegten Regeln zu beachten. Das gilt 
vor allem für die Variablennamen und die Variablenwerte. Häufig sind Sta-

 

152 

Die Fallvariablen: Strukturierte Übersicht 

tistikanalyseprogramme nicht in der Lage, lange Stringvariablen zu analysie-
ren oder sie vermögen dies nur mit Einschränkungen. Die Variablenwerte 
sollten deshalb so bestimmt werden, dass sie vom jeweiligen Statistikanaly-
seprogramm auch bearbeitet werden können. Dazu ist meistens ein Blick in 
das Programmhandbuch oder die Online-Hilfe notwendig. 

SPSS erlaubt zwar nur das Rechnen mit numerischen Variablen, doch ist 
in neueren Versionen eine automatische Umcodierung von Strings in nu-
merische  Werte  (SPSS:  Transformieren>Automatisch  umcodieren)  mög-
lich, so dass in dieser Hinsicht keine Beschränkung mehr besteht. Oft wird 
man  deshalb  Fallvariablen  eher  als  Stringvariable  definieren,  weil  die  Va-
riablenwerte  selbsterklärend  sind  –  etwa  „m“  für  „Geschlecht  männlich“. 
Wählt  man  die  String-Variante,  erstellt  SPSS  bei  der  automatischen  Um-
wandlung  in  eine  Variable  numerischen  Typs  eine  Korrespondenztabelle, 
die für jeden String den zugeordneten numerischen Wert enthält. 

Die  Regeln  für  die  Bildung  von  Variablennamen  haben  sich  seit  der 
Version SPSS 12 gelockert. Seither sind auch Variablennamen mit mehr als 
acht Zeichen erlaubt. Allerdings darf jeder Variablenname nur genau einmal 
vorkommen. Bei älteren SPSS-Versionen sind die Beschränkungen zu be-
achten, nämlich maximal 8 alphanumerische Zeichen, d.h. nur Buchstaben 
und Zahlen. Diese Beschränkung gilt noch für SYSTAT/MYSTAT24. Wer-
den beim Import nicht legale Variablennamen entdeckt, schneidet SPSS die 
überzähligen  Zeichen  des  Variablennamens  einfach  ab  oder  ersetzt  bei 
Namen mit nicht legalen Zeichen den bisherigen durch einen neu gebilde-
ten Namen, der mit dem Buchstaben V beginnt und von der sequentiellen 
Nummer in der Variablenliste gefolgt wird, also beispielsweise „V7“.  

SPSS ist in der Lage, eine Variablenmatrix im Text-Format (tab-delimi-
ted) oder Excel-Format zu importieren. In diesem Format sind die einzel-
nen Variablenwerte durch ein Tabulatorzeichen voneinander getrennt und 
am Ende jedes Falles befindet sich ein Absatzzeichen. Zum Import einer so 
aufgebauten Datei offeriert SPSS einen Eingabeassistenten, der den Benut-
zer in sechs Schritten durch den Importprozess führt. Zunächst muss die 
Menüoption „Datei>Textdaten“ einlesen und der Dateityp „Text“ gewählt 
werden. Ein SPSS-Assistent führt durch die Importfunktion, wobei die im 
Folgenden angegebenen Optionen zu wählen sind: 
                                                           
 
24  MYSTAT  ist  eine  kostenfreie  Ausbildungsversion  des  sehr  umfangreichen  SYSTAT-

Pakets (www.systat.com). 

Weiterarbeit mit Fallvariablen in SPSS 

153 

Schritt 1: Wählen Sie die Option „Die Daten weisen kein vordefiniertes 
Format auf.“ 
Schritt 2: Die Variablen sind mit Trennzeichen angeordnet und die erste 
Zeile enthält die Variablennamen. 

 

Abb. 47: SPSS-Eingabeassistent bei Schritt 2 

Schritt 3: Jede Zeile stellt einen Fall dar, es sollen alle Fälle importiert 
werden. 
Schritt  4:  Trennzeichen  ist  der  Tabulator.  Entfernen  Sie  alle  weiteren 
Haken in den Checkboxen. Eventuell teilt SPSS nun mit, dass Variab-
lennamen, die nicht der SPSS-Konvention entsprechen geändert werden 
müssen. Dies muss mit OK bestätigt werden. 
Schritt 5: SPSS präsentiert die Datenvorschau, so dass eventuell Korrek-
turen möglich sind, indem Sie noch einmal zurückgehen. 
Schritt 6: Das Dateiformat muss nicht gespeichert werden, klicken Sie 
einfach „Fertigstellen“. 

Jetzt erscheint die importierte Variablenmatrix im SPSS Daten-Editor und 
es kann mit der statistischen Analyse begonnen werden. Die Datenmatrix 
hat  so  viele  Zeilen,  wie  Texte  im  Projekt  vorhanden  sind,  d.h.  jede  Zeile 
entspricht einem Interview. Nach dem Datenimport protokolliert SPSS die 
Liste der Variablen.  

 

154 

D

ie Fallvariablen:

: Strukturierte Ü

Übersicht 

8.5  P

Praktische 

Hinweise f

für MAXQD

DA 

In MA
jekt de
riablen
fernt o
denen
oder F
logisch
Bei  d
TAT/
schaue
Regeln
beim 
Doubl

AXQDA wird
efiniert, d.h. 
n ist nicht be
oder an die L
n  Variablenty
Fließkomma)
hen  Variable
der  Definitio
/MYSTAT  o
end handeln 
n der Statisti
späteren eve
letten erzeug

d eine Liste v
diese Variabl
schränkt, es k
Liste angefüg
ypen  gewählt
, String-Varia
en  mit  den  A
n  der  Varia
oder  ältere 
und diese so
ik-Software e
entuellen Ver
gt werden. 

von Fallvariab
len gelten für
können jeder
gt werden. E
t  werden:  nu
ablen (Zeiche
Alternativen  w
ablennamen 
Versionen  a
o wählen, da
entsprechen u
rkürzen von 

blen global fü
r alle Texte. D
rzeit Variable
Es kann zwisc
umerische  V
enketten), Da
wahr  und  fal
sollte  man, 
als  SPSS  12
ass die ersten
und  zudem d
längeren Var

ür das gesamt
Die Anzahl d
en aus der Lis
chen fünf ve
Variablen  (Ga
atumsvariable
lsch  (Typ  bo
sofern  man
2  benutzt,  v
n acht Zeiche
darauf  achten
riablennamen

te Pro-
der Va-
ste ent-
erschie-
anzzahl 
en und 
oolean). 
n  SYS-
voraus-
en den 
n, dass 
n keine 

 

Abb. 48

8: Liste der Va

ariablen im MA

AXQDA Variab

blenfenster 

Abb. 4
tion“, 
Onlin
QDA 
men  i
wie ob

48 zeigt die V
sie  enthält 
e-Fragebogen
kann die ko
in  Form  eine
ben beschrieb

Variablenliste
alle  standard
ns  erhoben  w
omplette Var
er  Datei  im  T
ben in SPSS i

e aus dem Pro
disierten  Info
wurden  (vgl.
iablenmatrix
TXT-  oder  H
importiert we

ojekt „Intern
ormationen,  d
.  Kuckartz  e
einschließlic
HTML-Form
erden können

netgestützte E
die  mit  Hilfe
et  al.  2009). 
ch der Variab
mat  exportiere
n, so dass die

Evalua-
e  eines 
MAX-
blenna-
en,  die 
e statis-

Praktische Hinweise für MAXQDA 

155 

tische Analyse sofort beginnen kann, ohne dass irgendwelche Variablenbe-
schreibungen  oder  Definitionen  der  Variablenmatrix  eingegeben  werden 
müssen. 

Die Eingabe von Variablenwerten kann in MAXQDA auf zweierlei Art 
erfolgen, entweder direkt beim Text (dann sind nur die Variablenwerte die-
ses Textes sichtbar) oder über das Menü „Variablen“ und die Variablenta-
belle,  bei  dem  die  komplette  Variablenmatrix  mit  den  Werten  aller  Texte 
verfügbar ist. Der Aufbau der Variablenmatrix ist ähnlich wie im SPSS oder 
SYSTAT-Daten-Editor,  d.h.  jede  Zeile  entspricht  einem  Fall  (Text).  Ein 
Doppelklick auf eine Zeile öffnet den zugehörigen Text zur Bearbeitung im 
Text Browser 

Informationen über die Zuordnungen von Codes zu Texten können in 
MAXQDA automatisch in Variablenwerte umgeformt werden (mittels der 
Funktion „In Variable transformieren“). In diesem Fall wird der Codename 
zum  neuen  Variablennamen  und  die  Anzahl  der  pro  Text  vorhandenen 
Codierungen  wird  jeweils  als  Variablenwert  in  die  Datenmatrix  übernom-
men.  Hierzu  ein  Beispiel:  Verwandelt  man  den  Code  „Einsamkeit  in  der 
Kur“ auf diese Weise in eine Variable, dann erhält jede Person die Anzahl 
der bei ihr zu diesem Thema codierten Segmente als Variablenwert zuge-
wiesen und die neu gebildete Variable erhält den Namen „Einsamkeit in der 
Kur“. Je größer der Zahlenwert dieser Variablen ist, desto häufiger hat die 
interviewte  Person  im  Verlauf  des  Interviews  über  das  Problem  der  Ein-
samkeit in der Kur gesprochen. 

Die aus einem Code durch Transformation entstandenen Variablen sind 
dynamisch,  d.h.  wenn  ein  neuer  Text  eingelesen  wird,  erhalten  die  dyna-
misch erzeugten Variablen dieses Textes zunächst den Default-Wert 0 zu-
gewiesen. Wenn der Text bearbeitet wird und dabei Codierungen von Text-
segmenten  zum  Thema  „Einsamkeit  in  der  Kur“  vorgenommen  werden, 
erfolgt eine automatische Anpassung des Variablenwertes.  

Eine Datenmatrix im TXT-Format („tab-delimited“) lässt sich auch in 
MAXQDA importieren. Dies ist insbesondere nützlich, um Studien auszu-
werten, die sowohl einen qualitativen als auch einen quantitativen Teil be-
sitzen. Beispielhaft zu nennen sind hier Fragebogenerhebungen, deren Fra-
gebögen sowohl standardisierte Fragen mit Antwortvorgaben als auch of-
fene  Fragen  enthalten.  Hier  wird  der  standardisierte  Teil  in  Form  einer 
SPSS-Datei eingegeben und die offenen Fragen werden in der von MAX-
QDA verlangten Form für den Text-Preprozessor aufbereitet und impor-

 

156 

Die Fallvariablen: Strukturierte Übersicht 

tiert (vgl. oben Kap. 2). Über den Import der SPSS-Matrix können die ver-
schiedenen  Teile  der  Studie  zusammengefügt  und  aufeinander  bezogen 
werden. Nützlich ist der Import einer Datenmatrix auch, wenn in SPSS eine 
Clusterung der Fälle vorgenommen wird und auf diese Weise die Informa-
tion über die Zugehörigkeit zu einem Cluster zu MAXQDA zurück transfe-
riert werden kann. 

Übungen 

1.  Öffnen Sie die Variablenliste. Erstellen Sie drei neue Variablen: „Al-
ter“ (Typ: Ganzzahl), „Abiturnote“ (Typ: Ganzzahl) und „Familien-
stand“ (Typ: String). 

2.  Geben Sie für alle Texte Ihres Projektes fiktive Werte für diese drei 

neuen Variablen ein. 

3.  Sortieren Sie die Variablenmatrix nach der Variable „Alter“. 
4.  Lassen Sie sich nur die Variablen der Textgruppe „Bürger“ anzeigen 

5.  Blenden Sie die Spalte für die Abiturnote aus und blenden Sie diese 

und ändern Sie einige Werte. 

anschließend wieder ein. 

6.  Exportieren Sie alle Variablen über die Windows-Zwischenablage zu 

Excel und einmal via Exportfunktion in eine Datei „variablen.txt“. 

7.  Öffnen Sie die Exportdatei per Doppelklick. Danach öffnen Sie die 
Datei mit SPSS (Menü Datei> Textdaten einlesen). Folgen Sie dem 
SPSS-Assistenten. 

8.  Berechnen Sie in SPSS eine neue Variablen, indem Sie die Altersva-
riable in Altersgruppen umwandeln (0-20 Jahre = 1; 21-30 Jahre = 2 
usw.). 

9.  Speichern Sie diese Datei als Excel- oder Textdatei. 
10. Importieren  Sie  in  MAXQDA  die  neu  erstellte  Variablendatei  und 
überprüfen  Sie  das  Ergebnis.  Löschen  Sie  ungewünschte  Variablen 
in MAXQDA. 

9  Komplexe Formen des Text-Retrievals  

 

9.1  Subgruppen von Daten vergleichen 

Moderne  QDA-Software  offeriert  eine  Reihe  von  Verfahren,  die  weitaus 
komplexer sind als die einfachen Techniken des Wiederfindens, die in Ka-
pitel 5 dargestellt sind. Dazu gehören beispielsweise: 
 

1.  das  selektive  Text-Retrieval,  bei  dem  die  Fallvariablen  und  ihre 
Merkmalsausprägungen  als  Kriterium  zur  Auswahl  von  codierten 
Textsegmenten dienen 

2.  die Visualisierung von Beziehungen und Zusammenhängen im Text-

korpus 

3.  die  Möglichkeiten  zur  komplexen  Kombination  von  Codes,  z.B.  in 

Form von Codesequenzen und Überlappungen 

4.  die  Option  zur  Benutzung  von  Segmentgewichtungen  („Relevanz-
Scores“)  als  zusätzliches  Kriterium  zum  Wiederfinden  codierter 
Segmente 

 
In diesem Kapitel werden das selektive Text-Retrieval, die darauf aufbauende 
Themenmatrix und die Suche nach Code-Kombinationen behandelt. 

Beispiel aus der Forschungspraxis 
In Projekten der qualitativen Sozialforschung geht man bei der Bildung der 
Untersuchungsgruppe häufig so vor, dass möglichst kontrastierende Fälle, 
Gruppe oder  Situationen ausgewählt werden. Dies ist prototypisch in der 
Grounded Theory der Fall, wo die Fallkontrastierung ein wichtiges Krite-
rium beim Theoretical Sampling darstellt (Strauss/Corbin 1999: 150). Man 
stellt  etwa  eine  Person,  die  sich  vornehmlich  aus  politischen  Gründen  in 
einer  Lokalen  Agenda  21-Initiative  engagiert,  einer  Person  gegenüber,  die 
primär die Zusammenarbeit in der Gruppe und das Wir-Gefühl schätzt. 

Kluge  (1995)  berichtet  von  einem  Projekt  am  Bremer  Sonderfor-
schungsbereich „Statuspassagen und Risikolagen im Lebensverlauf“, in dem 

158 

Komplexe Formen des Text-Retrievals 

Untersuchungsgruppen von Haupt- und Sonderschülern nach diesem Kon-
zept  der  Fallkontrastierung  möglichst  heterogen  gebildet  wurden.  Die 
Stichprobenauswahl erfolgte hier anhand von drei Merkmalen: Geschlecht, 
Einstieg in das Berufsbildungssystem (berufsqualifizierend versus nichtbe-
rufsqualifizierend)  und  schulischer  Abgangsstatus  (mit  bzw.  ohne  Haupt-
schulabschluss oder Abgang von der Sonderschule). Abb. 49 zeigt den rea-
lisierten Stichprobenplan. 

 

 

Geschlecht 

Schulabgang 

30 Jungen 

HS mit Abschluss 

 

 

HS ohne Abschluss 

Sonderschule 

30 Mädchen 

HS mit Abschluss 

 

 

HS ohne Abschluss 

Sonderschule 

Total 

 

Ausbildung mit berufsqualifizieren-
dem Abschluss 
ja 

nein 

 

Total 

13 

- 

1 

14 

- 

- 

28 

4 

4 

8 

9 

4 

3 

32 

17 

4 

9 

23 

4 

3 

60 

Abb. 49: Interviewplan nach dem Konzept der maximalen Variation (Kluge 1995: 5) 

Bei der Analyse der Interviews erweisen sich nun selektive Zugriffe auf ein-
zelne Subgruppen als besonders nützlich. Man will sich beispielsweise näher 
anzuschauen, was die 9 Mädchen mit Hauptschulabschluss, die nicht über 
einen  berufsqualifizierenden  Abschluss  verfügen,  in  den  Interviews  geäu-
ßert haben. Jede Zelle der obigen Tabelle enthält die Information, wie viele 
Personen die jeweilige Merkmalskombination aufweisen. Ziel dieser speziel-
len Form von Text-Retrieval ist es, die zu einem bestimmten Code vorhan-
denen Textsegmente selektiv für bestimmte Zellen des Designs zusammen-
zustellen. Diese Form der Analyse ist folgendermaßen zu realisieren: 

Die  drei  Kriteriumsvariablen  der  Stichprobenauswahl  müssen  als  Fall-
variablen  definiert  werden,  beispielsweise  mit  den  Variablennamen  „Ge-
schlecht“, „Schulabgang“ und „Abschluss“. Die Variablenwerte können so-
wohl als Strings wie als numerische Werte definiert werden. Die Definition 
als Strings hat den Vorteil, dass sich immer sofort die Bedeutung des Variab-
lenwerts erkennen lässt. Wählt man für die beiden Geschlechter die Abkür-
zung „w“ bzw. „m“, so ist das selbst erklärend, während die Werte „1“ und 

Themenmatrix 

159 

„2“  entweder  Gedächtnisleistung  oder  einen  stets  griffbereiten  Codeplan 
verlangen. 

Bevor man das angestrebte selektive Retrieval durchführen kann, müs-
sen für alle Befragten die Werte dieser drei Variablen eingegeben werden. 
Das selektive Retrieval arbeitet per definitionem immer mit einer Teilmenge 
der Texte: Mit Hilfe der Fallvariablen wird eine Bedingung so formuliert, 
dass nur die Texte für das Retrieval herangezogen werden, die diese Bedin-
gung erfüllen (Abb. 50). Will man die Gruppe der 9 Mädchen mit Haupt-
schulabschluss  und  nicht  berufsqualifizierendem  Berufseinstieg  näher  un-
tersuchen, so lauten die formalisierten Kriterien: 

(Schulabgang=HSmit) UND (Geschlecht=w) UND (Abschluss=nein) 

 
 
 
 

Alle Texte 
des Projekts 

 

I

G
N
U
G
N
D
E
B
R
E
T
L
F

I

 

Teilmenge von 
Texten, die die 
Kriterien erfüllen 

 

Abb. 50: Variablenwerte als Filter für das Retrieval 

9.2  Themenmatrix 
Das übersichtliche Arrangement von qualitativen Daten in Tabellen ist ein 
Verfahren, das vor  allem von Miles und Huberman  (1994) vorgeschlagen 
wurde. Damit eine solche Darstellung nicht zu umfangreich wird, kann man 
normalerweise  nur  mit  zweidimensionalen  Matrizen  arbeiten.  Dreidimen-
sionale Tabellen wie im obigen Beispiel werden auch dann, wenn man es 
mit dichotomen Dimensionen zu tun hat, leicht unübersichtlich, denn man 
hat  es  minimal  mit  2  mal  2  mal  2,  d.h.  mit  8  Zellen  zu  tun.  Besitzt  ein 
Merkmal  drei  Ausprägungen,  wie  die  Variable  „Schulabgang“  in  diesem 
Beispiel, hat die Tabelle bereits 12 Zellen. 

 

160 

Komplexe Formen des Text-Retrievals 

Das  gesamte  Verfahren  der  Themenmatrix  hat  eine  unverkennbare 
Ähnlichkeit  mit  der  Kreuztabellenanalyse  bei  statistischen  Auswertungen. 
Die Grundform einer Vierfeldertafel sieht folgendermaßen aus: 

 

Merkmal Y ja 

Merkmal Y nein 

Merkmal X ja 

Merkmal X nein 

A 

C 

B 

D 

Abb. 51: Grundprinzip der Matrixanalyse 

Die Inhalte der Matrixzellen A bis D erhält man durch selektive Retrievals, 
d.h. durch Formulierung der entsprechenden logischen Bedingungen. Das 
Feld A also über die Anweisung „Merkmal X=ja UND Merkmal Y=ja“. 

Welchen  Gewinn  hat  man  nun  von  einer  solchen  Matrix-Darstellung? 
Erstens  erhält  man,  so  Miles  und  Huberman,  einen  sehr  guten  Überblick 
über die Daten, zweitens kann man unmittelbar Vergleiche durch Gegenü-
berstellung von Matrixfeldern anstellen und drittens lassen sich derart über-
sichtlich  aufbereitete  Resultate  auch  der  Scientific  Community  wesentlich 
besser und plausibler nahe bringen. 

Um die zwölf Zellen des obigen Beispiels von Kluge zu bearbeiten, sind 
insgesamt zwölf selektive Text-Retrievals durchzuführen, jeweils mit einer 
anderen logischen Bedingung zur Auswahl der entsprechenden Befragten. 
In diesem Beispiel sind es allerdings faktisch nur neun Durchläufe, weil drei 
Zellen des Designs leer sind. Man kann die für jede Zelle der Matrix zu-
sammengestellten  Textsegmente  am  Bildschirm  lesen  oder  für  intensivere 
Vergleiche ausdrucken. Eine gute Idee ist es auch, die Segmentzusammen-
stellungen  zu  speichern  und  zunächst  im  Textverarbeitungsprogramm  zu 
editieren. Dort kann man die eventuell vorhandene Redundanz vermindern, 
Textstellen löschen oder zusammenstreichen. Am einfachsten lässt sich ei-
ne  Matrix  mittels  der  komfortablen  Tabellenfunktion  von  Textverarbei-
tungsprogrammen erstellen. Man definiert eine Tabelle mit entsprechender 
Spalten- und Zeilenanzahl und platziert dann die mit einem selektiven Ret-
rieval gefundenen Segmente in die entsprechende Matrixzelle. Werden für 
eine Zelle eine erhebliche Anzahl von Segmenten gefunden, so sollte man 
sich bemühen, diese zusammenzufassen bzw. ein möglichst repräsentatives 
Beispiel  auszuwählen.  Ebenfalls  möglich  ist  die  Synthetisierung  bzw.  pa-
raphrasierende  Zusammenfassung  des  gefundenen  Sets  von  Segmenten. 
Für  die  Zusammenarbeit  in  einer  Forschergruppe  oder  für  Präsentations-

Die Suche nach Mustern von Codierungen 

161 

zwecke kann es auch nützlich sein, die Ergebnisse in Form einer Wandzei-
tung als übersichtliche Matrix zu montieren. Generell ist die Methode des 
selektiven Retrievals hervorragend geeignet, um Kontraste darzustellen. 

9.3  Die Suche nach Mustern von Codierungen 

Während die einfachen Techniken des Text-Retrievals noch weitgehend der 
Logik des Arbeitens mit den guten alten Karteikarten folgen, sind die komp-
lexeren Techniken ohne Computersoftware gar nicht realisierbar. Diese Ver-
fahren  unterstützen  wirkungsvoll  die  Theoriebildung  und  ermöglichen  es, 
komplizierte Fragen an das Datenmaterial zu stellen. Im Kern geht es dar-
um, Muster von Codierungen zu entdecken bzw. in den Codierungen nach 
empirischen  Bestätigungen  für  vermutete  Zusammenhänge  zu  suchen. 
Manche Autoren (Huber 1996; Hesse-Biber/Dupuis 1996) sprechen in die-
sem Kontext von „Hypothesen testen“, einer Bezeichnung, die für jeman-
den mit einem traditionellen Hypothesenbegriff (vgl. etwa Schnell/Hill/Es-
ser 2004: 53 f.) aber eher irritierend sein dürfte. 

Bei den komplexen Formen des Text-Retrievals geht es um die Bezie-
hungen der Codes bzw. Codierungen untereinander und um die Formulie-
rung  von  Suchabfragen  zum  Zwecke  des  Wiederfindens  codierter  Text-
segmente. Anders als beim einfachen Text-Retrieval werden Suchabfragen 
nicht nur mit einfachem ODER und einfachem UND formuliert, sondern 
es werden komplexere Operationen möglich: In natürlicher Sprache formu-
liert beispielsweise Fragestellungen wie: Suche nach Textpassagen, die ent-
weder mit „Unterricht“ (Code A) oder mit „Seminarlehrer“ (Code B) co-
diert  wurden  und  gleichzeitig  mit  „Befindlichkeit“  (Code  C).  Formalisiert 
heißt es dann: „(A ODER B) UND C“. 

Mittels  logischer  Operatoren  lassen  sich  Suchabfragen  formulieren,  in 
denen  die  Operatoren  ODER  und  UND  vielfältig  kombiniert  werden. 
Auch können hierarchische Beziehungen von Kategorien zu Subkategorien 
Berücksichtigung finden. Suchabfragen dieses Grundmusters lassen sich zu 
sehr komplexen Gebilden erweitern, z.B.: 

(A ODER B ODER D ODER F) UND (C ODER K) UND (L ODER M ODER N) 

Nun  sind  nicht  nur  Zusammenhänge  des  Typs  „gleichzeitiges  Vorkom-
men“  bzw.  „Überschneidung“  denkbar,  sondern  es  existieren  weitere 
Grundformen der Relation von Codes.  Die entsprechenden Algorithmen, 

 

162 

Komplexe Formen des Text-Retrievals 

die  in  fortgeschrittener  QDA-Software  implementiert  sind,  arbeiten  mit 
drei Varianten von Operatoren: 
 

1.  Sequenz-  und  Entfernungsoperatoren  (Nähe,  Distanz,  Eingebette-

theit), 

2.  Überschneidungsoperatoren und 
3.  Mengenoperatoren. 

9.4  Sequenz- und Entfernungsoperatoren 

Sequenzoperatoren dienen dazu, nach Mustern im Hinblick auf die Abfolge von 
Codes in einem Text zu suchen. Es lässt sich etwa danach suchen, ob ein 
Textsegment, das mit Code B oder mit Subcodes von B codiert wurde, auf 
ein mit A codiertes Segment folgt. 

A [ 

B [ 

 
 
 
 
 
 
 
 
 

 

Abb. 52: Segment mit Code B folgt auf ein mit Code A codiertes Segment 

Man kann so z.B. erkunden, ob und wie häufig es vorkommt, dass der Code 
„Einsam in der Kur“ innerhalb einer Distanz von maximal 2 Textabsätzen 
auf den Code „Mitpatienten“ folgen. Alle Texte des Projektes werden dar-
aufhin durchsucht, ob diese Konstellation von Codierungen vorhanden ist. 
Man erfährt, wie oft solche Abfolgen gefunden werden und erhält eine Zu-
sammenstellung  der  entsprechenden  Textstellen.  QDA-Programme,  die 
diesen Typ von Operatoren anbieten, lassen die Wahl, ob bei der Zusam-
menstellung  der  Textstellen  nur  die  Segmente  des  vorangehenden  Codes 
(hier „Mitpatienten), des nachfolgenden Codes (hier „Einsam in der Kur“) 
oder beide in einer Liste ausgegeben werden. 

Überschneidungs- und Einbettungsoperatoren 

163 

Eine vergleichbare Aufgabe wie Sequenzoperatoren haben Entfernungsopera-
toren. Mit ihrer Hilfe wird nach Mustern im Hinblick auf die Nähe von Codes 
im Text gesucht. Taucht im Umkreis von Thema A immer Thema B auf? 

A (cid:62) 

Abstand:  
3 Absätze 

B (cid:62) 

 
 
 
 
 
 
 
 
 

Abb. 53: Code B in der Nähe von Code A 

 

Angenommen, das mit B codierte Segment folge bei einer Anordnung wie 
in der Abbildung im Abstand von 3 Absätzen auf Segment A. Würde man 
für  den  Entfernungsparameter  einen  Wert  von  2  Absätzen  oder  kleiner 
wählen, dann würde diese Textstelle nicht mehr gefunden: das mit Code B 
codierte Segment wäre zu weit von dem mit A codierten Segment entfernt. 
Neben der bloßen Angabe, ob solche Codeabfolgen vorkommen, offeriert 
QDA-Software  verschiedene  Arten  der  Resultatausgabe:  In  den  Pro-
grammen NVivo und MAXQDA lässt sich auswählen, welche Segmente im 
Falle eines Treffers gelistet werden, nur die mit A codierten, nur die mit B 
codierten oder beide. 

9.5  Überschneidungs- und Einbettungsoperatoren 

Mit  Überschneidungsoperatoren  lässt  sich  ermitteln,  ob  sich  in  den  Texten  der 
Studie codierte Segmente befinden, bei denen sich zwei oder mehrere Codes 
direkt überschneiden. In QDA-Programmen findet man hierzu die Opera-
toren Überschneidung und Überlappung, die sich lediglich hinsichtlich des aus-
gegebenen Resultats des Text-Retrievals unterscheiden. Im ersten Fall sind 
es  nur  die  sich  direkt  überschneidenden  Textzeilen,  im  zweiten  Fall  wird 

 

164 

Komplexe Formen des Text-Retrievals 

der gesamte Bereich vom Beginn des ersten Segments bis zur letzten Zeile 
des letzten Segments ausgegeben. 

A (cid:62) 
B (cid:62) 

 
 
 
 
 
 
 
 
 
 
 
 

}

Textausgabe: 
nur direkter Über-
schneidungsbereich 

 

Abb. 54: Überschneidung von Code A und Code B 

Einbettungsoperatoren untersuchen die Frage, ob bestimmte Codes immer im 
Rahmen  größerer,  mit  einem  bestimmten  anderen  Code  codierter  Ab-
schnitte auftreten. Oder, gewissermaßen das Gegenteil zu dieser Konstella-
tion, man sucht nach codierten Segmenten außerhalb des Bereichs eines be-
stimmten Codes. 

Man  kann  sich  etwa  das  Beispiel  von  Gruppendiskussionen  vergegen-
wärtigen: Man sucht Textstellen eines bestimmten Sprechers zu einem be-
stimmten Thema (=Einbettung). Man sucht Textstellen zu einem bestimm-
ten Thema, die nicht von einem bestimmten Sprecher stammen (=außer-
halb des Bereiches dieses Sprechers). 

Überschneidungs- und Einbettungsoperatoren 

165 

A [ 

B [ 

 
 
 
 
 
 
 
 
 
 
 

In diesem Beispiel 
wird Code A 
gefunden, weil es 
außerhalb von 
Code B liegt. 

 

Abb. 55: Code A ist außerhalb von Code B 

Genau umgekehrt hierzu lässt sich nach solchen Stellen im Text suchen, wo 
eine  mit  Code  A  codierte  Textstelle  sich  innerhalb  eines  mit  B  codierten 
Segmentes befindet. Dies ist im folgenden Beispiel der Fall, wo sich A tat-
sächlich innerhalb von dem mit B codierten Segment befindet. 

A [ 

B [ 

 
 
 
 
 
 
 
 
 
 
 
 

Das mit Code A 
codierte Segment liegt 
innerhalb von Code B.

 

Abb. 56: Code A ist innerhalb von Code B 

Die Möglichkeit nach eingebetteten Segmenten zu suchen ist bei der Analy-
se  von  Gruppendiskussionen  und  Fokusgruppen  sehr  praktisch,  denn  so 
lässt sich die Suche nach Textstellen einer bestimmten Kategorie auf aus-
gewählte Sprecher beschränken, d.h. man sucht nur nach solchen Stellen, in 
denen  Person  X  sich  über  ein  bestimmtes  Thema  äußert.  Auch  bei  der 

 

166 

Komplexe Formen des Text-Retrievals 

Interviewauswertung  können  sich  komplexe  Formen  des  Retrievals  als 
sinnvoll  erweisen:  Man  sucht  beispielsweise  nach  „negativen  Emotionen“ 
innerhalb  von  Textpassagen,  in  denen  es  um  das  Thema  „Familie“  geht. 
Voraussetzung ist natürlich immer, dass die Texte zuvor entsprechend sys-
tematisch codiert wurden. 

9.6  Mengenoperatoren 

Mengenoperatoren  machen  es  möglich,  eine  Auswahlliste  von  Codes  zu 
erstellen und das Auffinden von Textsegmenten an das Vorliegen bestimm-
ter Mengenbedingungen zu knüpfen. Es kann beispielsweise verlangt wer-
den,  dass  eine  bestimmte  Anzahl  von  Codes  der  Auswahlliste  vorhanden 
sein müssen. Nur in diesem Fall wird das Segment gelistet. 

Weiterhin  kann  nach  solchen  Textstellen  gesucht  werden,  wo  ein  be-
stimmter  Code  einer  Auswahlliste  vorhanden  ist,  die  anderen  Codes  der 
Auswahlliste  aber  nicht.  Hierzu  ein  inhaltliches  Beispiel:  Jemand  spricht 
über  die  Motive  seines  Engagements,  aber  nicht  gleichzeitig  über  seine 
Wünsche, seine Einschätzung des Machbaren und Erfolgskriterien. 

9.7  Hypothesenprüfung 

Verschiedene Autoren betrachten die Suche nach dem gemeinsamen Auf-
treten von Codes nicht nur als ein heuristisches Hilfsmittel zur Datenexplo-
ration  und  Hypothesengenerierung,  sondern  begreifen  dies  als  „Hypothe-
sen testen“ (vgl. Huber 1996; Hesse-Biber/Dupuis 1996). Eine inhaltliche 
Hypothese wird so formuliert bzw. operationalisiert, dass sie mit dem ge-
meinsamen Vorkommen von Kategorien überprüfbar ist. Hesse-Biber und 
Dupuis  unterscheiden  dabei  zwischen  zwei  Situationen  von  Hypothesen-
prüfung.  Zum  einen  kann  es  darum  gehen,  aus  dem  Datenmaterial  einen 
theoretischen Rahmen zu entwickeln, induktive Theorieentwicklung zu be-
treiben und diese generierten Hypothesen dann auch zu testen. Zum ande-
ren können bereits zu Beginn des Forschungsprojektes vorhandene Hypo-
thesen geprüft werden. Ausgangspunkt des Verfahrens ist eine Tabelle, die 
Informationen  über  die  bei  jedem  Text  vorgenommenen  Codierungen 
enthält. Das Prinzip besteht nun darin, auf die Kategorien bezogene Wenn-

Hypothesenprüfung 

167 

dann-Statements zu formulieren und diese Statements im Datenmaterial zu 
überprüfen, etwa nach folgendem Muster: 
 

1.  Wenn jemand CDU wählt (Code „CDU-Wähler“) und sonntags zur 

Kirche (Code „Kirchgänger“) geht, nenne ich ihn konservativ. 

2.  Wenn jemand in seiner Familie Diskussionen mit den Kindern ab-
lehnt  (Code  „Keine  Diskussionen“)  und  Gehorsam  für  ein  Erzie-
hungsziel (Code: „Gehorsamkeit“) hält, nenne ich ihn autoritär. 

3.  Hypothese: Wenn jemand konservativ und autoritär ist, hat er wahr-
scheinlich Konflikte mit seinen Kindern (Code: „Konflikt mit Kin-
dern“). 

 
Ziel des Verfahrens ist es hier, eine Hypothese über die Ursache von Kon-
flikten zwischen Eltern und Kindern zu testen. Das Datenmaterial muss es 
erlauben, in dieser Hinsicht zwischen zwei Gruppen von Befragten zu dif-
ferenzieren, nämlich solchen, die Konflikte mit ihren Kindern haben, und 
solchen, die keine Konflikte haben. Die Codes „CDU-Wähler“, „Kirchgän-
ger“, „Keine Diskussionen“, „Gehorsam“ und „Konflikt mit Kindern“ sind 
manifeste Codes, d.h. sie sind im Textmaterial codiert bzw. nicht codiert. 
Hingegen sind die Kategorien konservativ und autoritär Konstrukte des For-
schers, die als logische Kombination von Codes gebildet werden. 

Zur  Vorgehensweise  bei  der  Prüfung  solcher  Hypothesen  gibt  Hesse-
Biber das in Abb. 57 abgebildete Beispiel aus ihrer Forschungspraxis. Das 
Beispiel besteht aus vier Wenn-dann-Statements, die von oben nach unten 
abgearbeitet werden. 

Regel 1 

Regel 2 

Regel 3 

Regel 4 

IF 
THEN 

IF 
THEN 

IF 
THEN 

IF 
THEN 

I am makg high salary AND fabulous non trad job 
ADD HIGH WORK COMMITMENT 

gets married and stays married AND wants kids 
ADD HIGH FAMILY COMMITMENT 

HIGH WORK COMMITMENT AND HIGH FAMILY COMMITMENT 
ADD HI POTEN FOR WORK FAM CONF  

HI POTEN FOR WORK FAM CONF AND (cmb wrk fam no problems OR 
successful) 
ADD CINDERELLA COMPLEX 
GOAL REACHED 

Abb. 57: Liste einer Abfolge von Wenn-dann-Statements beim Hypothesentest 

(Weitzman/Miles 1995: 235) 

 

168 

Komplexe Formen des Text-Retrievals 

Das  erste  Statement  (Regel  1)  bedeutet:  Wenn  ein  Text  die  Codes  „be-
komme  hohes  Gehalt“  (I  am  making  high  salary)  und  „habe  tollen  Job“ 
(fabulous non trad job) enthält, lässt sich daraus schließen, dass der Befrag-
te einen hohen Grad an Engagement und Bindung an seine Arbeit besitzt, 
und man kann diesem Text einen entsprechenden neuen Code „High Work 
Commitment“ zuordnen. 

Die zweite Regel besagt: Wenn ein Text die Codes „ist verheiratet und 
will es bleiben“ und „will Kinder“ besitzt, dann kann man als Konsequenz 
den Code „high hamily commitment“ zuordnen. Nun könnte man für den 
Fall, dass eine Person sowohl eine hohes Engagement in Bezug auf die Fa-
milie wie die Arbeit aufweist (d.h. beide Codes sind zugeordnet), vermuten, 
dass es hier ein hohes Konfliktpotential gibt. Regel 3 ordnet diesen Perso-
nen eine entsprechende Kategorie zu („hi poten for wrk fam conf“). 

Der entscheidende Schritt wird in der abschließenden Regel 4 getan, die 
auf die vorangehenden Statements 1 bis 3 aufbaut. Wenn ein hohes Poten-
zial für Konflikte zwischen Arbeit und Familie vorhanden ist („hi poten for 
wrk  fam  conf“)  und  der  Befragte  dies  aber  nicht  wahrnimmt,  dann  spre-
chen die Forscher vom „Cinderella Komplex“ und sehen ihre Hypothese 
bestätigt.  Die  beiden  in  Klammern  stehenden  Codes  (cmb  wrk  fam  no 
problems  OR  successful)  gelten  hier  als  Indikatoren  dafür,  dass  jemand 
selbst  keine  Probleme  darin  sieht,  die  beruflichen  und  privaten  Ziele  zu 
vereinbaren.  Ist  dies  bei  einer  Person  der  Fall,  d.h.  sind  beide  Codes  zu-
geordnet, dann spricht Hesse-Biber davon, dass die Person das Ziel der Hy-
pothese erreicht habe. 

Das Hypothesentesten nach diesem Grundmuster besteht also aus einer 
Abfolge von Wenn-dann-Statements, die von den Basisannahmen („toller 
Job“ + „hohes Gehalt“ = „Engagement/Bindung bzgl. Beruf“) über ver-
schiedene Zwischenglieder bis zur eigentlichen Zielhypothese führen. Eine 
Art  Inferenzpfad  wird  durchschritten:  Für  den  Fall,  dass  bestimmte  Codes 
oder  Codekombinationen  vorhanden  sind,  erfolgt  die  Zuweisung  eines 
neuen Codes. Mehrere Wenn-dann-Zuordnungsregeln können hintereinan-
der  gestaffelt  sein  und  aufeinander  aufbauen.  Sie  führen  zu  einer  finalen 
Entscheidung,  ob  die  betrachtete  Person  (=der  Fall)  als  Bestätigung  der 
Hypothese  zu  werten  ist.  Die  Evaluation  der  Wenn-dann-Kette  wird  für 
jede  Person  durchgeführt,  so  dass  sich  die  Probanden  auf  drei  Segmente 
verteilen: 

Hypothesenprüfung 

169 

Ziel erreicht:  
Cinderella Komplex 

Ziel nicht erreicht:  
hohes Konfliktpotential, 
aber keine Verdrängung 

Alle anderen Fälle, 
die bereits vorher 
den Inferenzpfad 
verlassen haben 

Abb. 58: Modell des Hypothesentestens bei Hesse-Biber 

 

Das erste Feld (Hypothesen-Ziel erreicht) enthält die Anzahl der Personen, 
für  die  die  Hypothese  zutrifft,  das  zweite  Feld  beinhaltet  die  Anzahl  der 
Personen, die das Hypothesen-Ziel nicht erreichen, obwohl alle Bedingun-
gen hierzu vorhanden sind, und das dritte Feld der Tabelle enthält die An-
zahl  der  Personen,  die  bereits  zuvor  eine  Wenn-dann-Hürde  nicht  über-
sprungen  haben.  In  diesem  Beispiel  etwa  Personen,  bei  denen  der  Code 
„habe tollen Job“ gar nicht zugeordnet ist. 

Das von Hesse-Biber u.a. entwickelte Programm HyperResearch verfügt 
über eine „hypothesis tester“ genannte Funktion, mit deren Hilfe sich sol-
che  Wenn-dann-Statements  formulieren  lassen.  Die  Logik  dieses  Verfah-
rens lässt sich aber auch ohne weiteres mit anderen QDA-Programmen rea-
lisieren, die es erlauben, die Resultate von Retrieval-Prozeduren mit neuen 
Codes zu versehen. Die Bildung neuer Codes, wie sie hier praktiziert wird, 
geschieht  ausschließlich  auf  der  Basis  der  vorhandenen  Codierungen  und 
ihrer logischen Kombination. Das Verfahren ist äquivalent zur Berechnung 
neuer  Variablen  in  SPSS  mittels  der  dort  implementierten  If-Statements. 
Dort  wäre  etwa  sinngemäß  zu  formulieren:  If  (CDU-Wähler  eq  1  and 
Kirchgänger eq 1) Konservativ=1. 

Der Ansatz der Hypothesenprüfung setzt voraus, dass nicht mit themati-
schen Codes, sondern mit bewertenden Codes oder mit Aussagesätzen als Codes 
gearbeitet wird. Betrachtet werden beim Hypothesentest immer die Codie-
rungen  auf  Fallebene,  nicht  die  codierten  Segmente.  Insofern  eignet  sich 
das Verfahren weniger zur „Feinanalyse“ von Segmenten und ihren Codie-
rungen als vielmehr zur Analyse von relativ hoch aggregierten Konzepten 
wie „hohes Konfliktpotential zwischen Berufs- und Familienengagement“. 

 

170 

Komplexe Formen des Text-Retrievals 

Bewertende Codes – in der Terminologie von Hesse-Biber/Dupuis (1996) 
„directional  codes“  –  codieren  nicht  nur  das  bloße  Vorhandensein  oder 
Nicht-Vorhandensein  eines  Themas  oder  Phänomens  im  Text,  sondern 
stellen eine Bewertung dar. Es wird dann beispielsweise nicht mit den the-
matischen Kategorien „Selbstbild“ und „Fremdbild“ gearbeitet, sondern es 
werden bewertende Codes wie „positives Selbstbild“, „negatives Selbstbild“ 
und „positives Fremdbild“, „negatives Fremdbild“ gebildet. Für diese vier 
Codes lässt sich auf Fallebene eine Vierfeldertafel erstellen: 

 
Selbstbild positiv 
Selbstbild negativ 

Fremdbild positiv 

Fremdbild negativ 

A 

C 

B 

D 

Abb. 59: Vierfeldertafel beim Hypothesentesten 

Die Hypothese, ein positives Selbstbild gehe  mit  einem positiven  Fremd-
bild einher, würde sich so auswirken, dass sich alle – oder doch zumindest 
die Überzahl – der Probanden mit positivem Selbstbild in der Tabellenzelle 
A befinden und diejenigen mit negativem Selbstbild in der Zelle D. Wenn 
dies der Fall ist, sprechen  die Protagonisten der Hypothesentester  davon, 
dass die Hypothese bestätigt bzw. „wahr“ ist (Huber 1996: 200 ff.). 

Nimmt  man  solche  Codierungen  wie  „positives  Selbstbild“  nun  auf 
Fallebene vor, d.h. werden nicht nur die betreffenden Segmente mit „posi-
tives Selbstbild“ bzw. „negatives Selbstbild“ codiert, sondern das gesamte 
Interview bewertet, so entsteht eine Tabelle folgender Art. 

 
 
Person 1 
Person 2 
Person 3 
Person n 

Selbstbild positiv 

Selbstbild negativ 

Fremdbild positiv 

Fremdbild negativ 

0 

1 

1 

0 

1 

0 

0 

1 

1 

0 

0 

0 

0 

1 

1 

1 

Abb. 60: Tabelle von „Wahrheitswerten“ 

In den Zellen der Tabelle befinden sich die Werte 0 oder 1, je nachdem ob 
das jeweilige Merkmal vorhanden ist (1) oder nicht (0). Aus den Daten der 
Matrix lassen sich einfache und komplexe Wenn-dann-Fragen problemlos 

Hypothesenprüfung 

171 

tabellieren.  Ferner  lassen  sich  auf  dieser  Basis  neue  Ergebnisvariablen  er-
zeugen. In der obigen Vierfeldertafel könnte man den Personen mit positi-
vem Selbstbild und positivem Fremdbild (Zelle A der Tabelle) einen ent-
sprechenden  Code  „positives  Selbst-  und  Fremdbild“  zuordnen,  desglei-
chen den Personen in den übrigen Zellen Codes, die ihre Merkmalskombi-
nationen benennen.25 

Die neu gebildeten Codes beziehen sich bei diesen Prozeduren immer 
auf den einzelnen Fall wie sich in der Terminologie von Hesse-Biber auch 
der Begriff „Hypothese“ auf den einzelnen Fall und nicht auf die gesamte 
Studie bezieht. Sie spricht vom „success or failure of a given hypothesis on 
each case of a study“ (Hesse-Biber/Dupuis 1996: 355). Die Kriterien der 
Over-all-Hypothesenprüfung  sind  dabei  nicht  statistisch  streng,  sondern 
eher weich. So wird davon ausgegangen, dass eine Hypothese dann, wenn 
eine Mehrheit der Fälle dieser Regel folgt, „some degree of validity“ besitzt. 
Der gesamte Prozess des Testens der Hypothese beinhaltet keinen interpre-
tativen, qualitativen Schritt mehr, sondern alle Codezuweisungen geschehen 
mechanisch  aufgrund  des  Vorliegens  von  logischen  Kombinationen.  Die 
Codes höherer Ordnung sind reine Derivate und nicht wie in der Groun-
ded  Theory  Resultat  interpretativer  und  konzeptueller  Arbeit.  Wenn  dies 
schon so ist, fragt sich allerdings, warum auf alle Abwägungen hinsichtlich 
der Zufälligkeit der Ergebnisse verzichtet werden soll. Exportiert man die 
komplette  Tabelle  (Fälle  mal  Codierungen)  zu  einem  Statistikprogramm, 
dann lassen sich ohne Probleme alle Wenn-dann-Formulierungen und re-
sultierende  Variablenzuweisungen  auch  dort  vornehmen.  Gleichzeitig  er-
zielt  man  aber  Gewinne,  weil  nun  Tabellenanalysen  mit  Signifikanztests 
durchgeführt werden können. 

Der  Weg  über  ein  Statistikprogramm  vermeidet  es  auch,  dem  Fehl-
schluss  zu  erliegen,  eine  Hypothese  habe  sich  dann  als  „wahr“  erwiesen, 
wenn in der obigen Tabelle mehr Personen in Zelle A zu finden sind als in 
Zelle B. Nicht unproblematisch erscheint der von Hesse-Biber propagierte, 
recht ungezwungene Umgang mit dem gesamten Vorgang des Hypothesen-
testens: Der Ratschlag, man möge, sofern sich Hypothesen als falsch erwei-
sen, doch einfach die Operationalisierungen so lange verändern, bis sich das 
                                                           
 
25 Ein  systematisches  Verfahren  zur  Auswertung  solcher  0/1-Matrizen  hat  Ragin  (1987, 
1994) mit der Methode der logischen Minimierung entwickelt. Computerimplementatio-
nen hiervon finden sich in den Programmen QCA und Aquad. 

 

172 

Komplexe Formen des Text-Retrievals 

Ergebnis ändere, mag unter der Überschrift „Exploration von Beziehungen 
im  Datenmaterial“  noch  gerade  durchgehen,  aber  von  Hypothesen  testen 
kann dann sicherlich nicht mehr die Rede sein. 

Ein problematischer Punkt des vorgenannten Ansatzes ist, dass eine in-
duktiv an Daten gewonnene Hypothese schwerlich an den gleichen Daten 
bestätigt werden kann. Hierzu sei an dieser Stelle lediglich auf Max Webers 
Dictum hingewiesen, dass eine noch so plausible Deutung zunächst immer 
nur  Hypothese  ist  und  nicht  mit  einer  kausalen  Erklärung  gleichgesetzt 
werden dürfe. Hierzu bedarf es, so Weber, einer neuen Stichprobe und ei-
ner entsprechenden statistischen Hypothesenprüfung26 (vgl. Weber 1964: 7; 
Kelle 1996: 46 ff.; Kuckartz 1988: 57 ff.). 

Die Konstruktion einer Tabelle von „Wahrheitswerten“ macht im Ana-
lyseprozess die Texte selbst überflüssig. Ist die Tabelle einmal konstruiert, 
so spielen für den Akt der Hypothesenprüfung die Texte keine Rolle mehr. 
Man sollte sich darüber im Klaren sein, dass man mit dieser Vorgehenswei-
se das Feld der qualitativen Analyse verlässt und sich in den Bereich der sta-
tistischen  Analyse  begibt.  Dies  hat  Konsequenzen  auf  mehreren  Ebenen. 
Erstens stellt sich bei den Codierungen natürlich die Frage nach der Zuver-
lässigkeit,  denn  die  Analyse  steht  und  fällt  mit  der  Reliabilität  der  vorge-
nommenen Codierungen. Will man sich nicht dem Vorwurf aussetzen, die 
Resultate der Analyse seien durch die Methode produzierte Artefakte, so ist 
durch  ein  geeignetes  Verfahren  die  Inter-  und  Intra-Coder-Reliabilität  si-
cherzustellen.  Aus  dem  Bereich  der  quantitativen  Inhaltsanalyse  sind  hier 
Verfahren  (etwa  Cohens  Kappa)  vorhanden  und  hinreichend  erprobt  (vgl. 
Merten 1995: 302 ff.). 

Zweitens sollte man natürlich zur Kenntnis nehmen, dass man sich nun 
in einem Feld bewegt, in dem bereits hinreichend erprobte probabilistische 
Methoden existieren. Die Hoffnung, bei sozialwissenschaftlichen Fragestel-
lungen  mit  deterministischen  Zusammenhängen  des  Typs  „wenn  a,  dann 
b“ operieren zu können, dürfte sich wohl als allzu naiv erweisen. Man be-
kommt es unweigerlich mit Varianz zu tun, d.h. man muss mit Wahrschein-

                                                           
 
26 Verschiedene Wege der qualitativen Hypothesenprüfung diskutiert Kelle (1994: 364 ff.). 
Hierzu  gehören  beispielsweise  die  gezielte  Erhebung  neuer  Daten  (von  Glaser/Strauss 
als  „theoretical  sampling“  bezeichnet),  wiederholte  Befragungen  („qualitative  Panels“), 
kommunikative  Validierung  und  die  Überprüfung  mit  quantitativen  Verfahren  auf  der 
Basis einer größeren Stichprobe. 

Praktische Hinweise für MAXQDA 

173 

lichkeiten operieren und abschätzen, wann man einen Zusammenhang in ei-
ner solchen Vierfeldertafel als signifikant bewerten will und wann als zufällig. 
Damit ist man bei der Diskussion von Verteilungsmodellen und bei der Be-
rechnung  von  Irrtumswahrscheinlichkeiten  angelangt.  In  diese  Richtung 
werden  diese  Verfahren  unweigerlich  getrieben:  So  wünscht  sich  Hesse-
Biber  für  die  Zukunft  „certainty  factors“  für  beides,  für  die  Codierungen 
und  für  die  untersuchten  Zusammenhänge.  Im  Grunde  existiert  beides 
schon, für die Kreuztabellenanalyse in Form der Irrtumswahrscheinlichkeit 
und für die Codierungen in Form von Skalen höherer Qualität. Zum einen 
ist  es  denkbar,  im  obigen  Beispiel  die  dichotome  Skala  der  Selbstbild-
/Fremdbildkategorien durch Ratingskalen zu ersetzen – so lässt sich dann 
erfassen, welches Ausmaß das positive Selbstbild aufweist (Einschätzungs-
skala) – zum anderen kann mittels einer Gewichtungsvariable festgehalten 
werden, wie sicher die Zuordnung aufgrund des Datenmaterials für die je-
weilige Person ist. 

9.8  Praktische Hinweise für MAXQDA 

Die Aktivierung von Texten für das Retrieval kann in MAXQDA nicht nur 
manuell, sondern auch automatisch durchgeführt werden. Bei der Funktion 
„Logische Aktivierung“ übernehmen die Werte der Fallvariablen die Steue-
rungsfunktion für die Textaktivierung. Hat man wie im obigen Beispiel die 
Variablen „Geschlecht“, „Schulabgang“ und „Abschluss“ definiert, so kann 
man  Textauswertungen  nur  für  bestimmte  Zellen  der  Kreuztabelle  vor-
nehmen,  etwa  nur  für  die  Mädchen,  die  über  einen  Hauptschulabschluss, 
aber keinen berufsqualifizierenden Abschluss verfügen. Dieses Auswahlkri-
terium für die Textanalyse muss in formalisierter Weise angegeben werden. 
Die Syntax für die Eingabe solcher logischen Bedingungen entspricht der 
von  Statistikprogrammen.  Alle  logischen  Bedingungen  werden  nach  dem 
Schema  Variablenname-Operator-Wert  formuliert.  Wenn  das  Geschlecht 
mittels der Variablenwerte „m“ (=männlich) und „w“ (=weiblich) codiert 
und  die  entsprechende  Variable  „Geschlecht“  genannt  wird,  dann  ist  zur 
Auswahl von Frauen die logische Bedingung „Geschlecht = w“ zu formu-
lieren. 

Selektionsbedingungen  können  beliebig  komplex  gestaltet  werden,  in 
dem  einzelne  Bedingungen  durch  „und“  bzw.  „oder“  miteinander  ver-

 

174 

Komplexe Formen des Text-Retrievals 

knüpft werden. Selektive Retrievals von Textsegmenten für eine bestimmte 
Zelle des obigen Designs werden vorgenommen, indem eine logische Be-
dingung für die Auswahl der Texte formuliert wird, die alle drei Variablen 
miteinander verknüpft. Um die oben erwähnte Auswahl der neun Mädchen 
mit  Hauptschulabschluss,  die  nicht  über  einen  berufsqualifizierenden  Ab-
schluss  verfügen,  zu  realisieren,  muss  also  folgende  komplexe  Bedingung 
formuliert werden: 

(Geschlecht=Mädchen) UND (Schulabgang=HSmit) UND (Abschluss=nein) 

In MAXQDA werden solche Bedingungen im Dialogfenster „Logische Ak-
tivierung“  eingegeben.  Wenn  nach  der  Definition  der  logischen  Bedin-
gung(en) die Funktion gestartet wird, erfolgt ein Durchlauf durch alle Tex-
te, die daraufhin überprüft werden, ob die logische Bedingung zutrifft. Falls 
ja, wird der entsprechende Text aktiviert und seine codierten Textsegmente 
für  die  aktivierten  Codes  werden  im  Fenster  „Liste  der  Codings“  zusam-
mengestellt. 

Um andere Gruppen des Designs auszuwählen, muss die logische Be-
dingung  entsprechend  umformuliert  werden.  Die  korrespondierenden 
männlichen Probanden mit Hauptschulabschluss ohne berufsqualifizieren-
den Abschluss erhält man, wenn die erste Bedingung in „Geschlecht=m“ 
geändert  wird  und  die  beiden  anderen  Bedingungen  beibehalten  werden. 
Resultat des selektiven Retrievals ist wie beim einfachen Retrieval eine Zu-
sammenstellung  der  codierten  Segmente,  die  man  ggf.  ausdrucken  oder 
speichern kann. 

Die verschiedenen Möglichkeiten zur komplexen Kombination von Codes 
werden in MAXQDA über die Menüoption „Analyse“ gesteuert. Das Dialog-
feld  „Text  Retrieval“  ermöglicht  die  Auswahl  der  oben  beschriebenen 
komplexen Operatoren und die Angabe, welche Codes in die Analyse ein-
zubeziehen  sind.  Insgesamt  stehen  neun  Varianten  zur  komplexen  Suche 
nach  Codemustern  in  einer  Auswahlliste  „Funktion“  zur  Verfügung,  und 
zwar die Funktionen: Überschneidung, Überlappung, Überschneidung (Set), Nur ein 
Code allein, Nur dieser Code allein, Wenn innerhalb, Wenn außerhalb, Gefolgt von und 
Nähe. 

Im oberen Fensterbereich kann aus einer Auswahlliste die gewünschte 
Funktion ausgewählt werden. Die Auswahlfenster A, B und C dienen der 
für die jeweilige Funktion notwendigen Auswahl von Codes und Festlegung 
von Parametern. Auf der rechten Seite wird die Funktion visualisiert. 

Praktische Hinweise für MAXQDA 

175 

Fenster A bezieht sich auf die aktivierten Codes. Wenn man die Über-
schneidungen eines Codes mit einem anderen Code ermitteln will, müssen 
beide  Codes  zunächst  aktiviert  und  anschließend  durch  Klicken  auf  den 
Button „Alle aktivierten“ in das Fenster A (siehe Abb. 61) transferiert wer-
den. 

Die Funktionen „Überschneidung“ und „Überlappung“ erfordern keine 
zusätzliche Parametereingabe – hier kann das Text-Retrieval sofort gestartet 
werden. Bei den komplexeren Funktionen sind auch die Auswahlfenster B 
und C aktiv, in denen spezielle Selektionen vorgenommen werden können. 
Sobald die notwendige Auswahl getroffen ist, wird der Retrievalvorgang ge-
startet. Nach der Evaluation aller (aktivierten) Texte werden als Resultat die 
entsprechenden Segmente, die die komplexen Kriterien erfüllen, im Fenster 
„Liste der Codings“ gelistet. Es besteht dann die Möglichkeit, diese auszu-
drucken, zu speichern, in Form einer übersichtlichen HTML-Tabelle zu lis-
ten  oder  auch  die  gefundenen  Segmente  mit  einem  neuen  Code  automa-
tisch zu codieren. 

Hat man das Werkzeug der Gewichtungsvariablen benutzt, um die Be-
deutsamkeit von Textsegmenten für die Kategorie zu markieren, dann las-
sen sich die Werte der Gewichtungsvariable auch für den Retrieval-Vorgang 
benutzen: Es kann ein Wertebereich definiert werden, der für das Auffin-
den von Segmenten maßgeblich sein soll. In einer Dialogbox „Gewichtsfil-
ter“ lassen sich ein minimaler und ein maximaler Wert einstellen. Sind dort 
z.B. die Werte 50 und 80 eingestellt, dann werden nur solche Textsegmente 
in das Retrieval einbezogen, deren Relevanz-Scores sich innerhalb des Wer-
tebereichs von 50 bis 80 befinden. Diese Selektion wirkt sich auch auf alle 
in diesem Kapitel beschriebenen komplexen Retrieval-Techniken aus. 

Ähnlich wie beim einfachen Retrieval lassen sich auch beim komplexen 
Retrieval automatisch die Subkategorien berücksichtigen. Voraussetzung ist, 
dass  die  Hierarchie-Option  eingeschaltet  ist.  Ist  dies  der  Fall,  wird  die 
Baumstruktur  des  Kategoriensystems  beachtet,  und  es  werden  alle  Ver-
zweigungen  eines  Astes  berücksichtigt.  Führt  man  beispielsweise  ein  Re-
trieval mit Mengenoperatoren durch, werden alle Subkategorien der ausge-
wählten Codes bei der Evaluierung der Kombinationsbedingung einbezo-
gen. Wird das Blattsymbol gewählt, werden die Suchprozeduren nur für die 
jeweilige Hierarchieebene durchgeführt. 

 

 

176 

Komplexe Formen des Text-Retrievals 

Funktionsauswahl

Visualisierung 
der Funktion 

Fenster A 

Code 

Fenster B 

Code 

Fenster C 
Optionen 

 

Abb. 61: Auswahl der Funktion für das komplexe Text Retrieval 

Der große Vorteil des Arbeitens mit QDA-Software ist, dass auch bei der 
Anwendung  komplexer  Algorithmen  zur  Überprüfung  der  Relation  von 
Codierungen  immer  auf  das  analysierte  Originalmaterial  zurückgegriffen 
werden  kann.  Der  Kontext,  in  dem  ein  bestimmtes  Textsegment  steht, 
bleibt verfügbar, denn der das Segment umgebende Originaltext ist sofort 
wieder einsehbar. Eine erneute Analyse und Re-Interpretation von bereits 
interpretierten Daten sind so zu jedem Zeitpunkt des Analyseprozesses oh-
ne größeren Aufwand realisierbar. 

Praktische Hinweise für MAXQDA 

177 

Übungen 
Arbeiten  Sie  weiterhin  mit  dem  Übungsprojekt.  Stellen  Sie  sich  vor,  Sie 
wollen  nun  nur  die  Aussagen  herausfinden,  die  von  ledigen  Interviewten 
über 30 Jahre gemacht wurden. 
 

1.  Öffnen Sie dazu das Fenster der „Logischen Aktivierung“ und wählen 
Sie „Neu“. Wählen Sie die Variablen „Alter“ und „Familienstand“ aus. 
2.  Der Wert für das Alter soll größer als „30“ und der Familienstand 
soll „ledig“ sein. Achten Sie darauf, dass beide Bedingungen richtig 
mit UND verknüpft sind. 

3.  Aktivieren  Sie  Ihre  Auswahl.  Was  ist  passiert?  Aktivieren  Sie  jetzt 

auch den Code „Einstellungen“ mit den entsprechenden Subcodes. 

4.  Speichern Sie die Aktivierung unter dem Namen „Aktivierung 1“ an 

einem beliebigen Ort ab. 

5.  Erzeugen Sie aus den aktivierten Texten ein Text-Set mit dem Na-
men  „ledig_über_30“.  Deaktivieren  sie  das  Text-Set  und  aktivieren 
Sie es später wieder. 

6.  Erzeugen sie vier neue Codes „Agenda“, „Wirtschaft“, „Menschen“ 

und „I:“. 

7.  Suchen Sie nacheinander mit der Suchfunktion nach diesen Begriffen 
und codieren sie jeden Absatz automatisch zum entsprechenden Code. 
8.  Rufen Sie die Text-Retrieval-Funktion von MAXQDA auf (entweder 
über  das  Menü  Analyse  oder  den  Button  Fx)  und  wählen  Sie  dort 
„Gefolgt  von“.  Aktivieren  Sie  alle  Texte  und  den  Code  „Agenda“, 
übernehmen  Sie  „Agenda“  ist  den  „Fenster  A  Code“  durch  An-
klicken von „Alle Aktivierten“. Geben Sie als „Fenster B Code“ die 
Kategorie  „Wirtschaft“  ein  und  stellen  Sie  den  Abstandszähler  auf 
maximal  einen  Absatz.  Als  Ausgabe  wählen  Sie  „Fenster  B  Code“. 
Was würde jetzt gesucht werden? 

9.  Wir möchten jetzt alle Textstellen zum Code „Agenda“ wieder finden, 
bei  denen  nicht  zusätzlich  noch  ein  anderer  Code  vergeben  wurde. 
Wählen Sie dazu im Text Retrieval die Funktion: „Dieser Code allein“ 
und setzen sie den Code „Agenda“ in „Fenster B“ und alle anderen 
Codes in „Fenster A“. Wie viele Fundstellen werden angezeigt? 

10. Wir möchten jetzt alle Aussagen zu „Agenda“, die nicht vom Inter-
viewer  stammen  und  bei  denen  auch  kein  anderer  Code  vergeben 
wurde. Welche Einstellung ist hier vorzunehmen? 

 

10  Daten-Display und Visualisierung  

 

10.1 Sinn und Zweck von Visualisierungen  

Visualisierung als Hilfsmittel der Auswertung, aber auch als Modus der Prä-
sentation von Analyseergebnissen, gewinnt in vielen Wissenschaftsdiszipli-
nen zunehmend an Bedeutung. Die Sozialwissenschaften sind allerdings ein 
Wissenschaftszweig,  in  dem  vornehmlich  textbasiert  gearbeitet  und  argu-
mentiert wird. Anders als in den Naturwissenschaften oder in der Medizin, 
wo  es  heute  gang  und  gäbe  ist,  Zusammenhänge  visuell  darzustellen  und 
zunehmend auch in der medizinischen  Diagnostik  bildgebende Verfahren 
einzusetzen,  hat  die  sozialwissenschaftliche  Methodik  diese  Möglichkeiten 
bislang nur spärlich genutzt: Sozialwissenschaftliche Methodenliteratur, die 
sich  explizit  mit  Visualisierungsmöglichkeiten  von  Analyseergebnissen  be-
fasst, ist sehr dünn gesät (Banks 2001; Blasius/Greenacre 1998; Miles/Hu-
berman 1984; Strauss/Corbin 1996) und allenfalls in der Netzwerkanalyse 
häufiger anzutreffen (z.B. Krempel 2005). Feldmann vermutet eine generel-
le Bilderfeindlichkeit der Sozialwissenschaften als Ursache:  

„Die  heiligen  Schriften  der  Soziologie  von  Marx,  Durkheim,  Weber,  Par-
sons, Luhmann, Habermas, Giddens etc. sind meist bilderlos, selten mit Sta-
tistiken besudelt. Du sollst Dir kein Bild machen! Doch nicht nur die Klas-
siker, sondern auch die neuen soziologischen Schriften über die alten und 
neuen Medien und das Internet sind großteils bildfrei.“ (Feldmann 2003) 

Allerdings ist es allgemein üblich, Resultate einfacher statistischer Verfah-
ren  als  Grafiken  zu  präsentieren,  etwa  in  Form  von  Kreis-,  Balken-  oder 
Liniendiagrammen.  Weitaus seltener sind hingegen  Visualisierungsformen, 
die  komplexe  Zusammenhänge  darstellen.  Beispiele  hierfür  sind  Pfad-
diagramme oder lineare Kausalmodelle, in denen die Zusammenhänge zwi-
schen einer Vielzahl von Variablen – sowohl latenten wie manifesten – rep-
räsentiert werden können.  

Im  Rahmen  der  computergestützten  qualitativen  Datenanalyse  lassen 

sich vier Arten von Visualisierung unterscheiden: 
 

Visualisierung bei der Arbeit mit der QDA-Software 

179 

1.  Visualisierungen  innerhalb  der  QDA-Software  selbst.  Diese  haben 
die Funktion, die Handhabung der Daten bei der Auswertungsarbeit 
zu verbessern und den Zugriff auf Daten und Analyseergebnisse ef-
fizienter zu gestalten. 

2.  Fallbezogene  Visualisierungen  (Within-Case-Displays).  Solche  Dar-
stellungen bilden bspw. zeitliche Verläufe ab (z.B. in der Biografie-
forschung)  oder  stellen  die  Sequenz  und  Verknüpfung  von  Codes 
und  Konzepten  dar.  Der  Begriff  „Fall“  („Case“)  kann  sich  in  Ab-
hängigkeit vom Typ der empirischen Studie auf sehr Verschiedenes 
beziehen, z.B. eine Person, eine Institution oder eine Organisation. 

3.  Fallübergreifende  Visualisierungen  (Cross-Case-Displays),  in  denen 
die Sequenzen von Codes, Codeüberschneidungen sowie die Häufig-
keiten von Codes als Vergleich verschiedener Fälle  abgebildet wer-
den. 

4.  Konzept Maps, die es – ähnlich wie lineare Strukturdiagramme in der 
quantitativen  Datenanalyse  –  erlauben,  Zusammenhänge  zwischen 
Konzepten,  Kategorien,  Memos  sowie  deren  Verknüpfungen  und 
Wirkungszusammenhänge als bildliche Darstellung wiederzugeben. 

10.2 Visualisierung bei der Arbeit mit der QDA-Software 

Wozu können Visualisierungen bei der Arbeit mit einem QDA-Programm 
nützlich  sein?  Als  erstes  wäre  zu  nennen,  dass  Visualisierungen  sichtbar 
machen können, ob und in welcher Weise ein Text bei der Auswertung be-
reits bearbeitet wurde. Man kann etwa sehen, dass eine bestimmte Textstel-
le codiert wurde, wo eine solche codierte Textpassage beginnt, wo sie endet 
und welchen Code bzw. welche Codes ihr zugeordnet wurden. Möglicher-
weise ist es – jedenfalls dann, wenn mehrere KollegInnen in einer Arbeits-
gruppe zusammenarbeiten – auch von Interesse, zu erfahren, wer eine be-
stimmte Codierung vorgenommen hat und wann genau dies geschehen ist. 
Auch anderes soll sichtbar sein, z.B. Textstellen, die als besonders wichtig 
oder aufschlussreich eingeschätzt werden, ganz ähnlich wie beim Lesen ei-
nes Buches besonders Interessantes mittels eines Markierstifts hervorgeho-
ben wird und dadurch später auch leichter wiederzufinden ist. Schließlich 
hat  man  vielleicht  Anmerkungen  zu  einer  bestimmten  Textpassage  ge-
schrieben – auch diese sollen beim Durchblättern des Textes gut erkennbar 

 

180 

Daten-Display und Visualisierung 

sein, am besten so, dass ein Symbol, ähnlich wie ein Post-it-Zettel, deutlich 
macht, dass an einer bestimmten Textstelle Anmerkungen angeheftet sind. 
Die  von  der  QDA-Software  unterstützten  Visualisierungsformen  kön-
nen also ein wichtiges Hilfsmittel bei der Auswertungsarbeit darstellen. Zu 
solchen Visualisierungen, welche die effektive Arbeit mit der Software er-
leichtern, ist eine Reihe von Möglichkeiten zu zählen, die allerdings nicht in 
allen QDA-Programmen angeboten werden: 
 

(cid:120)  An  erster  Stelle  zu  nennen  sind  die  Codiersymbole  („Coding  Stri-
pes“), die neben dem Text verdeutlichen, wo etwas codiert worden 
ist und um welchen Code es sich dabei handelt.  

(cid:120)  Zweitens erleichtert die Farbigkeit der Codiersymbole die Lesbarkeit 
der  Bildschirmdarstellung,  wobei  allerdings  nur  in  MAXQDA  die 
Zuordnung von Farben zu Codes kontrolliert werden kann, während 
andere QDA-Programme die Farben rein zufällig zuordnen. Durch 
adäquate Farbwahl lassen sich Kategorien gezielt kenntlich machen, 
bspw. die geäußerten Emotionen von Befragten, bestimmte Themen, 
interessierende kritische Lebensereignisse und dergleichen mehr, so 
dass solche Textstellen beim Blättern durch den Text sofort erkenn-
bar sind. 

(cid:120)  Ferner  sind  Anmerkungen  und  Memos  zu  nennen,  die  erst  dann 
wirksam  genutzt  werden  können,  wenn  sie  auch  leicht  zugänglich 
sind. Besonders vorteilhaft ist es, wenn eine Anzeige im oder neben 
dem Text erkennen lässt, wo Anmerkungen und Memos zugeordnet 
sind.  Weiterhin  erweist  es  sich  als  hilfreich,  wenn  unterschiedliche 
Memosymbole deutlich machen, welchen Typs ein Memo ist, also ob 
es  sich  beispielsweise  um  ein  Theorie-Memo  oder  ein  Methoden-
Memo handelt. 

 
In den Anfängen kamen QDA-Programme nahezu ohne jegliche Visualisie-
rung  aus.  Doch  entstand  bei  den  Benutzern  schnell  das  Bedürfnis,  nach-
vollziehen zu können, was während der Auswertungsarbeit gemacht wurde. 
Besonders hilfreich ist die Möglichkeit, den Kategorien und Subkategorien 
Farben zuzuordnen. Dies haben wir beispielsweise im Projekt „Qualitative 
Lehrevaluation“ dazu genutzt, dem Code „Kritik an der Lehrveranstaltung“ 
und den zugehörigen Subcodes die Farbe Rot und dem Code „Verbesse-
rungsvorschlägen“  die  Farbe  Grün  zuzuordnen,  während  Codes,  die  sich 
auf  den  „Lernverlauf“  beziehen,  mit  unterschiedlichen  Blautönen  codiert 

Visualisierung von Analyseergebnissen 

181 

wurden.  Beim  Durchblättern  der  Interviews  lassen  sich  entsprechende 
Textstellen  und  auch  entsprechende  Code-Überschneidungen,  etwa  zwi-
schen  „Lernverlauf“  und  „Verbesserungsvorschlägen“,  weitaus  schneller 
identifizieren, als es durch Lesen der Codenamen möglich wäre. 

Bei  psychologisch  orientierten  Studien  ist  es  denkbar,  verschiedenen 
Formen  von  Emotionen  oder  Motivationen  korrespondierende  Farbtöne 
zuzuordnen. Es lassen sich dann nicht nur, wie oben beschrieben, einschlä-
gige Textstellen beim Lesen eines Textes wiederfinden, sondern es besteht 
auch die Möglichkeit, fallorientierte Displays (vgl. Kapitel 10.5)  anzuferti-
gen,  aus  denen  hervorgeht,  an  welchen  Stellen  eines  Interviews  der  Pro-
band aggressive Äußerungen macht und in welchem thematischen Kontext 
diese stehen. 

Die Farbzuordnungen sollte man von vornherein in Relation zu den ge-
planten Datenanalysen vornehmen, d.h. genau solche Differenzierungen in 
den Farben abbilden, die auch analytisch untersucht werden sollen. Wenn 
man  die  Farbzuordnungen  sorgfältig  vornimmt,  wird  die  Arbeit  mit  der 
QDA-Software  effektiver  und  die  Zugänglichkeit  zu  den  Daten  entschei-
dend verbessert. 

10.3 Visualisierung von Analyseergebnissen  

Generell werden in Visualisierungen von Analyseergebnissen Daten, The-
men,  Kategorien  oder  Konzepte  in  Grafiken  und  Diagramme  übersetzt. 
Meist sind es in der Sozialforschung Ergebnisse von statistischen Analysen, 
die visualisiert werden. Es ist gängige Praxis, bei der Ergebnispräsentation 
quantitativer  Studien  Balken-  und  Kreisdiagramme  zur  Darstellung  von 
univariaten  Verteilungen  zu  benutzen.  So  werden  beispielsweise  bei  einer 
Wahlanalyse die relativen Häufigkeiten der Stimmen der einzelnen Parteien 
in Kreisdiagrammen präsentiert: Werden die Parteien zudem noch nach ih-
rer wechselseitigen Affinität bzw. nach Koalitionsabsichten gruppiert, kann 
man  der  Grafik  –  anders  als  einer  Tabelle  –  sofort  Koalitionsmehrheiten 
entnehmen. Man muss nicht mehr rechnen und Zahlen vergleichen (Pro-
zentsatz von Partei A + Prozentsatz von Partei B > 50%), sondern kann 
mittels der Kreisdarstellung sofort erfassen, ob auf eine bestimmte Konstel-
lation mehr als die Hälfte des Kuchens entfällt.  

 

182 

Daten-Display und Visualisierung 

In der qualitativen Methodik wird dem Thema Visualisierung bisher so-
gar  noch  weniger  Aufmerksamkeit  als  in  der  quantitativen  Methodik  ge-
widmet.  Im  weit  verbreiteten  „Handbook  of  Qualitative  Research“  von 
Denzin  und  Lincoln  (2000)  finden  sich  auf  fast  1.100  Seiten  nur  äußerst 
wenige  graphische  Darstellungen  und  man  sucht  vergeblich  nach  einem 
Aufsatz, der sich systematisch mit dem Thema „Daten-Display und Visuali-
sierung“  auseinandersetzen  würde. Nur in zwei Artikeln lassen sich über-
haupt Grafiken entdecken:  

Im  Beitrag  „Clinical  Research“  von  Miller  und  Crabtree  wird  ein  Ab-
laufdiagramm des Forschungsprozesses, genauer gesagt der klinischen For-
schung, präsentiert (ebd.: 618 f.). Solche, für die Darstellung der Forschung 
äußerst  hilfreichen,  Diagramme  folgen  einer  Logik  wie  in  der  folgenden 
Abb. 62: Abläufe werden durch Verbindungslinien in eine Reihenfolge ge-
bracht  und  Rückbezüge  einzelner  Forschungsschritte  werden  vermerkt. 
Dies  erlaubt  Leserinnen  und  Lesern  ein  wesentlich  schnelleres  Begreifen 
der Abläufe als bei einer verbalen Beschreibung des gleichen Sachverhalts. 

Dokumentation 

Datensammlung 

Datenbeschreibung 

Datenorganisation 

Abb. 62: Typisches Diagramm zur Darstellung eines Prozessverlaufs 

 

Der zweite Beitrag im Denzin/Lincoln Handbuch, der nicht nur Text, son-
dern auch Grafiken enthält, stammt von Ryan und Bernard. In ihrem Auf-
satz  „Data  Management  and  Analysis  Methods“  (ebd.:  769 ff.)  stellen  sie 
Visualisierungen für vier verschiedene Aufgaben vor: 
 

1.  um  Taxonomien  darzustellen,  z.B.  eine  Taxonomie  der  Techniken 
qualitativer Datenanalyse, die in etwas veränderter Form die Diffe-
renzierungen von Tesch (s.o. S. 18) aufgreift (ebd.: 771), 

2.  um  ein  ethnographisches  Entscheidungsmodell  (aus  dem  medizini-

schen Anwendungsfeld) zu schematisieren, 

3.  zur Erstellung sogenannter „Mental Maps“, einer Art Clusterbildung 
von ähnlichen Objekten (meist Wörtern), welche die Autoren folgen-

Visualisierung von Analyseergebnissen 

183 

dermaßen definieren: „Mental maps are visual displays of the simila-
rities among items, whether or not those items are organized hierar-
chically.“ (ebd.: 773), 

4.  zur Erstellung von „Coded Maps“, in denen kognitive Modelle, die 
mittels einer sorgfältigen Textanalyse herausgearbeitet werden, in ih-
rem logischen Bezug abgebildet werden (ebd.: 777). 

 
Deutschsprachige Handbücher der qualitativen Methoden erweisen sich im 
Umgang mit Visualisierungen als ähnlich zurückhaltend. Im fast 1.000 Sei-
ten umfassenden Handbuch „Qualitative Forschungsmethoden in der Er-
ziehungswissenschaft“ von Friebertshäuser und Prengel (1997) finden sich 
immerhin zwei einschlägige Beiträge: Lutz u.a. stellen ein Verfahren zur Er-
stellung „narrativer Landkarten“ vor (ebd.: 414 ff.) und Carle nutzt in ihrem 
an  der  naturalistischen  Forschungsstrategie  orientierten  Beitrag  zur  Kind-
Umfeld-Analyse eine Reihe von graphischen Darstellungen, die den Mental 
Maps und Coded Maps von Ryan/Bernard ähneln (ebd.: 711 ff.). Im Hand-
buch „Qualitative Forschung“ von Flick u.a. findet sich im Grunde nur ein 
Beitrag,  der  Visualisierungen  enthält,  nämlich  der  Artikel  von  Udo  Kelle 
„Computergestützte Analyse qualitativer Daten“ (in Flick u.a. 2005: 485 ff.) 
Nur selten haben sich qualitative Methodiker so intensiv mit dem The-
ma „Daten-Display und Visualisierung“  auseinandergesetzt wie Miles und 
Huberman in ihrem Buch „Qualitative data analysis“ (1994), das eine wahre 
Fundgrube für Visualisierungen der unterschiedlichsten Art ist. Man findet 
dort bspw. folgende Formen der Darstellung: 
 
(cid:120)  Flussdiagramme von Projektabläufen, 
(cid:120)  Modelle  der  Interaktion  von  Datenerhebungen  und  –analysen  im 

Forschungsprozess, 

(cid:120) 

(cid:120) 

(cid:120)  schematische  Darstellungen  des  konzeptuellen  Rahmens  von  For-

schungsprojekten („Conceptual Frameworks“), 
taxonomische Darstellungen von Begriffen und Abläufen (meist hie-
rarchischer Art), 
tabellarische  Fallübersichten  hinsichtlich  von  ausgewählten  Charak-
teristika, 

(cid:120)  verschiedene Typen von Maps – sowohl mehr in Richtung „Mental 
Map“  orientierte  Darstellungen  von  Ähnlichkeiten  als  auch  „Con-
cept  Maps“  mit  Beziehungsgeflechten  zwischen  Kategorien  und 
Konzepten.  

 

 

184 

Daten-Display und Visualisierung 

Für Miles und Huberman (1994) stellen Visualisierungen äußerst wirksame 
Formen von Datenkondensierung dar, d.h. hierdurch wird Information re-
duziert und komprimiert, so dass leichter Schlussfolgerungen gezogen wer-
den  können.  Visualisierungen  sind  nach  dem  Verständnis  von  Miles  und 
Huberman nicht nur ein Hilfsmittel der Analyse, sondern sie stellen im ori-
ginären Sinne analytische Arbeit dar: „Data reduction is not something se-
parate from analysis, it is part of the analysis. (...) The dictum ‚You are what 
you eat’ might be transposed to ‚You know what you display’“ (ebd.: 11). 
Nur folgerichtig ist es deshalb, wenn sie die Weiterentwicklung von Daten-
Display  und  Visualisierung  für  vordringlich  halten:  „Better  displays  are  a 
major avenue to valid qualitative analysis“ (ebd.: 11).  

10.4 Konzept Maps und Mapping Tools 

Bei wissenschaftlichen Vorträgen mit Präsentationssoftware wie Microsoft 
Powerpoint  oder  Apple  Keynote  zu  arbeiten,  ist  heute  eine  Selbstver-
ständlichkeit. Daten-Display und Visualisierungen haben deshalb nicht nur 
eine  Funktion  im  Prozess  der  Datenanalyse  selbst,  sondern  auch  bei  der 
Präsentation der Ergebnisse. Bei qualitativer Forschung füllt klassischerwei-
se Text – häufig in Form von Zitaten – die Präsentationsfolien, zunehmend 
kommen aber auch graphische Darstellungen zum Einsatz. 

Miles/Huberman stellen eine kaum überschaubare Vielzahl von Grafi-
ken  vor:  Ablaufdiagramme,  Organigramme,  Flow  Charts,  Planungsdia-
gramme,  Netzwerkdiagramme,  Konzept  Maps,  Mental  Maps,  Mind  Maps 
und andere. Je nachdem, auf welche Ebene der Daten sich die Grafiken be-
ziehen,  sprechen  sie  von  Within-Case  Displays  (fallorientierte  Darstellun-
gen) und Cross-Case  Displays (fallvergleichende Darstellungen).  Viele der 
von Miles und Huberman vorgestellten Grafiken lassen sich bereits mit ein-
facher Standardsoftware wie Word oder Powerpoint erstellen. Bessere Re-
sultate  erreicht  man  mit  spezieller  Grafiksoftware  (z.B.  ConceptDraw, 
MindManager  etc.27)  und  schließlich  bieten  die  von  einigen  QDA-Pro-
grammen offerierten Mapping Tools die Möglichkeit, Grafiken mit direk-
tem Link zu den analysierten Daten zu erstellen.  

                                                           
 
27 Siehe www.conceptdraw.com und www.mindjet.com/de.  

Konzept Maps und Mapping Tools 

185 

Eine  weithin  bekannte  Form  von  konzeptuellen  Maps  stellen  Mind 
Maps dar, die von ihren Erfindern als eine nahezu unbegrenzt einsetzbare 
Form von Visualisierung begriffen werden (vgl. Buzan 2004). Ursprünglich 
von Buzan als Hilfsmittel zum Festhalten von Ideen und Assoziationen er-
funden, lassen sich Mind Maps auch sehr gut in der qualitativen Forschung 
einsetzen. „Ein Bild sagt mehr als 1.000 Worte“ heißt es bei Buzan, der die 
Mind  Map-Technik  als  ein  universell  einsetzbares  Denkwerkzeug  zur  all-
gemeinen  Steigerung  des  geistigen  Potenzials  begreift  (vgl.  Buzan  2004: 
113). 

Klassische Mind Maps sind weniger netzwerkorientiert, als vielmehr auf 
einen  zentralen  Punkt  hin  ausgerichtet,  von  dem  aus  mehr  oder  weniger 
verzweigte  Äste  abgehen,  an  denen  möglicherweise  wiederum  kleinere 
Zweige und Blätter angeordnet sind. Auf diese Weise lassen sich verschie-
dene Dimensionen eines Begriffs ebenso gut darstellen wie Organigramme. 
Beispielsweise könnte man eine Mind Map „Bundesregierung“ erstellen, in 
der das Kanzleramt die Mitte darstellt und die einzelnen Ministerien die Äs-
te. Als Zweige der Ministerien wären dann deren Abteilungen, untergeord-
neten  Bundesämter  und  Institutionen  denkbar.  Charakteristisch  für  Mind 
Maps sind Darstellungen wie in Abb. 63, in der die verschiedenen Dimen-
sionen des Begriffs „Typ“ dargestellt sind: 

Individuen
Elemente

Form/Modell
Cast
Gießform

Taxonomie, 
Typologie, 
System, 
Hierarchien

Klassifikation

Konstruktion

Typ

Etymologie

Deskription

Theorie,
Heuristik

Empirie-
bezug

Begriffs-
geschichte

natürlich
real, Realtypen
ideal, Idealtypen

Morphologie
Dilthey
Weber
Parsons
Biologie

Merkmale

Hierarchie von Merkmalen
Schlüsselmerkmale
Variablen

 

Abb. 63: Mind Map zum Begriff „Typ“ (de Haan/Kuckartz/Rheingans 2000, S. 20) 

Wer Mind Maps erstellen will, sollte am besten auf entsprechende Spezial-
software wie MindManager oder Concept Draw zurückgreifen. Diese Tools 
bieten ein vielfältiges Funktionsspektrum und erstellen hochwertige präsen-

 

186 

Daten-Dis

splay und Visua

lisierung 

tation
dings 
Hier  s
MAXM
lich im
sonde
Wenn
lyse d
den,  s
Memo
auch m

sfähige  Grafi
der  Nachtei
sind  die  in  d
Maps von MA
m Vorteil. Sie
rn  auch  die 
, wie in Abb.
des  Diskurses
so  sind  diese
os, denen ma
mit den Texts

fiken.  Dem  V
il  der  fehlen
die  QDA-Sof
AXQDA un
e sind nicht n
im  Projekt 
 64, die Kate
s über Eliteu
e  direkt  mit 
an die Defini
stellen, denen

Vorteil  der  h
den  Verbind
ftware  integr
d der Netwo
nur in der La
bestehenden
egorien einer D
universitäten –
der  Datenba
ition der Ka
n die Kategor

hohen  Grafik
dung  zu  den
rierten  Mapp
rk Editor von
age, Konzept
n  Beziehunge
Diskursanaly
– in einer  M
asis  verbunde
ategorien entn
rien zugeordn

kqualität  steh
  Daten  gege
ping  Tools  – 
n ATLAS.ti –
t Maps zu er
en  zu  visuali
se – hier eine
Map dargestel
en,  z.B.  mit 
nehmen kann
net wurden. 

ht  aller-
enüber. 
bspw. 
– deut-
stellen, 
isieren. 
er Ana-
llt wer-
Code-
n, aber 

Förderung einz

zelner Fachbereiche

Auswahlverfahren 

für die Unis

Auswahl

 der Studenten 

Zeitpla
an

Finan

nzierung

Elite – das ist falsc

ch 

Wettbewerb 

Alternativkonzepte
e

Was ist ein

ne Eliteuniversität? 

Tabuwort Elite 

Konzepte für

r Eliteuniversitäten? Ide

een? 

Konz

zept der SPD 

private A

Alternativkonzepte 

Deutsche T

Tradition

Begabung

gsförderung 

 

Abb. 64

4: Visuelle Dar

rstellung der K

Kategorien eine

er Diskursanaly

yse 

Konze
Kante
matisc
befass
eines P
 

ept Maps sin
en (Linien) b
chen  Graphe
st.  Im  Rahm
Projektes als 

nd Netzwerkd
estehen. Die
entheorie,  die
en  der  qualit
Knoten auftr

darstellungen
ese Bezeichnu
e  sich  mit  de
tativen  Date
reten, also 

, die aus Kno
ungen stamm
en  Eigenscha
nanalyse  kön

oten (Punkte
men aus der m
aften  von  Gr
nnen  alle  Ele

en) und 
mathe-
raphen 
emente 

Konzept Maps und Mapping Tools 

187 

(cid:120)  Codes und Subcodes, 
(cid:120)  Texte und Textgruppen, 
(cid:120)  Memos und  
(cid:120)  codierte Textstellen. 

 
Ferner können auch freie Elemente in Konzept-Maps integriert werden, die 
keine Entsprechung in den Daten des Projektes haben.  

Die  Knoten  werden  durch  Kanten  miteinander  verbunden,  wobei  die 
Verbindungen gerichtet oder ungerichtet sein können. Gerichtete Verbin-
dungen werden durch einen Pfeil kenntlich gemacht. Sie können etwa dazu 
dienen die Wirkungsrichtung kenntlich zu machen. 

Knoten

Kante 

Abb. 65: Knoten und Kanten eines Netzwerkes 

 

Wie die Beispiele von Miles/Huberman deutlich machen, lassen sich Kon-
zept Maps sehr vielfältig anwenden. Besonders interessant ist es, sie als ana-
lytisches Tool zu nutzen, d.h. mit ihrer Hilfe Beziehungen, die in den Daten 
bestehen, sichtbar zu machen. So lassen sich Elemente der Datenbasis auf 
einen Klick hin automatisch in die grafische Arbeitsfläche importieren, z.B. 
 

(cid:120)  alle bei einem Text vorkommenden Codes  
(cid:120)  alle Memos eines ausgewählten Textes  
(cid:120)  alle Subkategorien eines Codes  
(cid:120)  alle Memos, die mit einem bestimmten Code verknüpft sind 
(cid:120)  Codes, die sich mit einem ausgewählten Code überschneiden 
(cid:120)  codierte Segmente eines bestimmten Codes 
(cid:120)  codierte Segmente eines bestimmten Textes 

 
Maps, die auf diese Weise erstellt werden, erlauben einen anderen Blick auf 
das  Datenmaterial  und  produzieren  automatisch  Netzwerkdarstellungen, 

 

188 

Daten-Dis

splay und Visua

lisierung 

die  ne
Codes
mehr. 
De
volle I
fach n
ware  a
Klick 
sem T
MAXM
Grafik
tures i
sehen 
Ebene
der ein
gestalt
gestell
fiken z

eue  Erkenntn
s,  die  Verknü
 
er Vorteil der
Integration d
nur um eine b
anfertigt,  son
auf ein Text
Text, der sofo
Maps offerier
ksoftware, do
integriert, die
MAXQDA 
en (Layer) zu
ngeblendet w
tung möglich
lten Objekte 
zu importiere

nisse  beförde
üpfungen  vo

ern:  Man  erk
on  Texten  m

kennt  etwa  d
mit  Kategorie

die  Zentralit
en  und  dergl

tät  von 
leichen 

r Mapping T
der qualitative
bildliche Dar
ndern  man  is
tsymbol oder
ort zur Einsic
ren zwar nich
och werden a
e eine effektv
und NVivo
uzuweisen, di
werden könne
h wird. MAX
und Texte fr
en. 

Tools im Rahm
en Datenbasi
rstellung, die 
st  interaktiv 
r Codesymbo
cht bereit steh
ht derart viele
auch in die Q
volle Präsenta
vor, die Elem
e bei einer sp
en, so dass e
QDA bietet 
frei zu gestalt

men von QD
is, d.h. es han
man mit Hil
mit  den  Dat
ol der Map b
ht. Konzept M
e Layout-Op
QDA-Softwar
ation ermögli
mente einer M
päteren Präse
eine recht au
zudem die M
ten oder auch

DA Software 
ndelt sich nic
fe einer Graf
ten  verbunde
bringt einen z
Mapping Too
tionen wie sp
re zunehmen
chen. Zum B
Map verschie
entation nach
ufwändige Vo
Möglichkeit, d
h Photos ode

ist die 
cht ein-
fiksoft-
en:  Ein 
zu die-
ols wie 
pezielle 
nd Fea-
Beispiel 
edenen 
heinan-
ortrags-
die dar-
er Gra-

Abb. 66

6: Visualisierun

ng von Zuordn

nungen zu Kat

egorien und U

Unterkategorien
n 

 

Visuelle Repräsentation von Zusammenhängen 

189 

Die vorstehende, mit MAXMaps erstellte Grafik aus dem Projekt „Qualita-
tive Lehrevaluation“ (vgl. Kuckartz u.a. 2008) zeigt, bezogen auf die befrag-
te  Person  „B3“  die  Hauptkategorien  „Kritik“,  „Verbesserungswünsche“ 
und „Grundhaltung“ sowie die bei dieser Befragten  codierten Subkatego-
rien.  Bei  der  Erstellung  dieser  Map  könnte  man  die  Subkategorien  einer 
oder mehreren verschiedenen Ebenen zuweisen, so dass man sie später in 
der Präsentation nacheinander einblenden kann. Ferner erscheinen die Ka-
tegoriendefinitionen  auf  dem  Bildschirm  als  Quickinfo,  sobald  man  die 
Maus über die Kategoriensymbole bewegt. Schließlich ließe sich der Infor-
mationswert  der  Map  noch  erhöhen,  indem  man  für  die  Subkategorien 
noch charakteristische Textsegmente in die Map einfügt. 

10.5 Visuelle Repräsentation von Zusammenhängen 

Neben den Konzept Maps bieten QDA-Programme noch weitere Formen 
von Visualisierung an. Dabei ist es sinnvoll, in Anlehnung an Miles/Huber-
man  zwischen  fallorientierter  und  fallübergreifender  Repräsentation  von 
Zusammenhängen zu unterscheiden. 

Fallorientierte Visualisierungen stellen Elemente eines interessierenden Falls 
in tabellarischer Form oder als Grafik bzw. Diagramm dar. Bei einem Fall 
kann es sich sowohl um ein Individuum als auch um eine Organisation, In-
stitution oder ein Setting handeln. Für die Arbeit mit einer QDA-Software 
bedeutet dies, dass es sich meistens um einen einzelnen Text handelt, wel-
cher  Objekt  der  Darstellung  ist.  Elemente  der  Darstellung  können  z.B.  
Codes, Subcodes, Memos oder codierte Textpassagen sein. Es ist sinnvoll, 
zwischen beschreibenden und erklärenden Displays zu unterscheiden. Be-
schreibende Displays geben bspw. einen Überblick über zeitliche Abläufe, 
in  dem  sie  kritische  Lebensereignisse  in  einer  sequenziellen  Anordnung 
oder  die  Rahmenbedingungen  eines  Phänomens  in  räumlicher  Nähe  und 
Ferne  in  einer  konzentrischen  Anordnung  präsentieren.  Zwei  neuartige 
fallorientierte beschreibende Visualisierungen sind in MAXQDA integriert: 
 
1.  TextPortrait erzeugt ein Bild, das technisch ähnlich wie ein Fernseh-
bild  aufgebaut  wird,  und  die  Codierungen  eines  Textes  zeilenweise 
darstellt, 

2.  Codeliner generiert eine Art Partitur des ausgewählten Textes, in der 
die Codes als Notenlinien erscheinen und in der Sequenz des Inter-
views Codierungen ähnlich wie Noten abgebildet werden. 

 

190 

Daten-Display und Visualisierung 

TextPortrait 
Dies ist ein neues Verfahren zur Visualisierung des Inhalts von Texten, das 
darauf aufbaut, dass inhaltliche Abschnitte eines Textes zuvor Kategorien 
zugewiesen wurden. Jede Kategorie ist mit einer Farbe assoziiert, wobei die 
Kategorienfarbe aus einer Auswahl von nahezu unbegrenzt vielen Farben 
gewählt werden kann. Der Inhalt des Dokuments wird so visualisiert, dass 
in der sequenziellen Reihenfolge der Absätze des Dokuments die Farbattri-
bute in einer rechteckigen Grafik dargestellt werden. Diese besteht aus ei-
ner bestimmten Anzahl von farbigen Kacheln, die fortlaufend zeilenweise 
dargestellt werden. 

Abb. 67: TextPortrait in MAXQDA 

 

Beginnend mit der ersten Zeile und der Kachel links oben werden die Ka-
cheln von links nach rechts mit einer Farbe „beschrieben“. Ist das Ende der 
ersten Zeile erreicht, wird – wie beim Zeilenrücklauf einer Schreibmaschine 
– in der folgenden zweiten Zeile vorne in der ersten Spalte fortgesetzt. Die 
normale Darstellungsweise sieht so aus, dass die Gesamtzahl der Kacheln 
auf die codierten Textabschnitte aufgeteilt wird, und zwar so, dass die Zahl 
der Kacheln, die ein Segment bzw. seine Farbe symbolisieren gemäß dem 

Visuelle Repräsentation von Zusammenhängen 

191 

prozentualen  Anteil  der  Größe  des  Segmentes  an  der  Gesamtgröße  aller 
codierten Segmentes bestimmt wird. Gibt es bspw. nur ein codiertes Seg-
ment, dem zwei Codes, nämlich rot und grün, zugewiesen wurden, so be-
steht, bei 30 mal 40 gleich 1.200 Kacheln, die Grafik aus 600 roten und 600 
grünen Kacheln. Sind dem gleichen Segment drei Codes (rot, grün, magen-
ta)  zugewiesen,  besteht  die  Grafik  aus  je  1200:3=  400  roten,  grünen  und 
magenta-farbigen Kacheln. 

TextPortrait  kann  die  thematische  Gestalt  eines  Textes  in  bildlicher 
Form zugänglich machen. Sind etwa in einem tiefenpsychologischen Inter-
view  bestimmten  Emotionen  korrespondierende  Farbwerte  zugewiesen, 
lassen sich die emotionale Grundstimmung ebenso wie besonders auffällige 
Textstellen auf einen Blick erfassen. 

Codeliner 
Codeliner ist eine Visualisierungsfunktion, die den Text Partitur ähnlich als 
sequenzielles Bild seiner Codierungen darstellt. Die X-Achse wird durch die 
Paragraphen (Absätze) des Textes gebildet. Ihre Beschriftung beginnt links 
immer mit der Zahl 1 (= 1. Absatz) und endet mit dem letzten Absatz des 
Textes. Die Y-Achse wird durch die Codes gebildet. In den Zellen der Gra-
fik  wird  durch  ein  quadratisches  Symbol  angezeigt,  ob  der  betreffende   
Code oder Subcode in einem Absatz vorkommt. Die Anzeige erfolgt in der 
Farbe, die dem Code zugeordnet wurde. 

Der Schwarz-Weiß-Druck dieses Buches kann diese Visualisierungsform 
nur unzureichend wiedergeben, so dass hier nur eine schematische Darstel-
lung  des  Prinzips  von  Codeliner-Diagrammen  abgebildet  ist,  bei  der  drei 
Codes und 13 Textabsätze dargestellt werden. Man erkennt, dass „Code 2“ 
den Textabschnitten 5 bis 8 und 11 zugewiesen ist und das sich dieser Code 
in Absatz 5 und 6 mit „Code 3“ überschneidet. Ein Klicken auf ein Symbol 
in  den  Zellen  der  Matrix  bewirkt,  dass  genau  diese  Textstelle  im  Text 
Browser gelistet wird. 

 
Code1 
Code2 
Code3 

1 

 

 

 

2 

(cid:132) 

 

 

3 

 

 

 

4 

 

 

(cid:132) 

5 

 

(cid:132) 

(cid:132) 

6 

 

(cid:132) 

(cid:132) 

7 

 

(cid:132) 

 

8 

 

(cid:132) 

 

9 

10 

11 

 

 

 

 

 

(cid:132) 

(cid:132) 

(cid:132) 

 

12 

(cid:132) 

 

(cid:132) 

13 

(cid:132) 

 

 

Abb. 68: Fallorientierte Visualisierung des Codeliners  

 

192 

Daten-Display und Visualisierung 

Der Codeliner kann verwendet werden, um einen schnellen Überblick über 
die Themen eines Textes zu erhalten. Durch den interaktiven Charakter der 
Grafik kann jede interessante Textstelle mit einem Klick sofort angesprun-
gen werden. Vor allem für explorative Analysen ist eine solche Darstellung 
hilfreich, denn Themenüberschneidungen wie auch die Nachbarschaft von 
Themen lassen sich so entdecken und dann näher inspizieren. 

Sehr nützlich ist der Codeliner bei der Auswertung von Fokusgruppen. In 
diesem Fall sollte man die verschiedenen Sprecher als Codes definieren und 
diese Codes den jeweiligen Abschnitten der Sprecher zuordnen. In der Grafik 
wird so die Sprecherabfolge sofort erkennbar. Ferner kann explorativ erfasst 
werden, welcher Sprecher bei welchem Thema eingreift (oder schweigt). Es 
lässt  sich  zudem  unmittelbar  erkennen,  welche  Effekte  das  Eingreifen  der 
Moderation hat, ob sich nach dem Eingreifen die Themen und Sprecher än-
dern.  

QDA-Software  bietet  ebenfalls  neuartige  Möglichkeiten  zur  fallübergrei-
fenden Visualisierung. Dies bedeutet, dass die in den Texten enthaltenen Mus-
ter  und  Strukturen  in  einer  fallübergreifenden  und  fallvergleichenden  Art 
und  Weise  repräsentiert  werden.  Für  die  Visualisierung  von  Codierungen 
stellen  der  Code-Matrix-Browser  und  der  Code-Relation-Browser  von 
MAXQDA solch neuartige Instrumente dar. Beide Tools stellen die in den 
Texten vorgenommenen Codierungen in einer grafischen Form dar. Dieser 
Matrix lässt sich mit einen Blick entnehmen, bei welchem Text zu welcher 
Kategorie viele bzw. wenige codierte Segmente zu finden sind. Die Visuali-
sierung ist wesentlich leichter erfassbar und besser interpretierbar als dies 
bei einer Zahlenmatrix der Fall ist. 

Der  Weg  von  den  Daten  zum  Erkennen  von  Regelmäßigkeiten  und 
Strukturen  ist  in  Abb.  69  dargestellt.  Ein  fallübergreifendes  Display  von 
Codierungen  beginnt  zunächst  mit  einer  Selektion,  nämlich  der  Auswahl 
der Texte und der zu visualisierenden Codes und Subcodes. Der entschei-
dende Schritt ist die Umwandlung einer Tabelle in eine Grafik, aus der sich 
Regelmäßigkeiten besser als aus der in der Tabelle enthaltenen Informati-
onsmenge erkennen lassen. Um die größte Zahl einer Tabelle zu identifizie-
ren,  müssen  alle  Zahlen  der  Tabelle  gelesen  und  miteinander  verglichen 
werden, während eine Visualisierung in der Form, dass die größte Zahl als 
größte Form und/oder in einer bestimmten Farbe dargestellt wird, das so-
fortige Erkennen ermöglicht. 

Visuelle

e Repräsentation

n von Zusamm

menhängen

193 

Erkenntnis 

R
Regelmäßigkeiten 

Interpretatio
on 

Visualisierung 

Data Mining
g 

Tabelle 

Transform

mation 

Daten-Subs

set 

Vor-Ve

erarbeitung 

Date
en 

Se
elektion 

 

Abb. 69

9: Ablaufschem

ma – von den D

Daten über die 

Visualisierung

g zur Erkenntn

nis 

Für ei
für  ei
einand
zug  a
Matrix

inen Vergleic
in  Cross-Cas
der platziert w
auf  Kategorie
x-Browser vo

h der Texte h
se  Display  a
werden, so d
en  und  Kate
on MAXQDA

hinsichtlich ih
ausgewählt  u
dass der direk
egorienmuste
A erzeugt folg

hrer Codieru
und  in  der  D
kte Vergleich 
er  erleichtert
gendes Diagr

ngen können
Darstellung  n
von Texten 
t  wird.  Der 
ramm: 

n Texte 
neben-
in Be-
Code-

 

Abb. 70

0: Visualisierun

ng der Codieru

ungen pro Tex

xt im Code-Mat

trix-Browser 

 

194 

Daten-Display und Visualisierung 

Die  einzelnen  Knoten  der  Matrix  symbolisieren  durch  ihre  Größe  und 
durch ihre Farbe, wie viele Codierungen die Texte bei den entsprechenden 
Codes und Subcodes aufweisen. Die Spalten der Matrix werden durch die 
Texte gebildet: Je größer der Knoten in der entsprechenden Spalte ist, desto 
mehr codierte Segmente sind bei dem betreffenden Text zu dieser Katego-
rie bzw. Subkategorie vorhanden. In der obigen Abbildung weist beispiels-
weise der Text „Film1“ sehr viele Codierungen zum „Themenfeld Energie“ 
und in den Texten „UBild1“ und „UKomm1“ findet man zahlreiche „Ver-
weise auf Forschungsarbeiten“. Wird die Maus über einen Knoten hinweg-
bewegt, erscheint die Information wie viele codierte Textstellen zu diesem 
Knoten vorhanden sind. Ein Doppelklick auf den Knoten bewirkt, dass alle 
zugehörigen Textsegmente in einer Zusammenstellung gelistet werden, d.h. 
die  Matrix  stellt  nicht  nur  eine  Übersicht  über  die  Zahl  der  Codierungen 
pro Text dar, sondern sie enthält – zunächst nicht sichtbar – auch die Text-
stellen selbst, die sich quasi hinter den Knoten befinden. 

Eine  andere  Form  der  visuellen  Repräsentation  stellt  die  Zusammen-
hänge zwischen Codes dar, d.h. wie häufig sich Codes überschneiden, also 
gleichzeitig derselben Textstelle zugeordnet sind. Das Auffinden von Kate-
gorienüberschneidungen  würde  mit  handwerklichen  Mitteln  zu  einer  Zeit 
verschlingenden Angelegenheit. Mit Computerunterstützung lässt sich dies 
schnell und zuverlässig durchführen. 

Abb. 71 zeigt eine Darstellung des Code-Relations-Browsers von MAX-
QDA. In dieser Code-mal-Code Matrix, die symmetrisch ist wie eine Ent-
fernungstabelle  in  einem  Autoatlas,  werden  die  wechselseitigen  Über-
schneidungen  ausgewählter  Codes  analysiert.  In  den  einzelnen  Zellen  der 
Matrix stehen nicht die Zahlen der hierfür gefundenen Überschneidungen, 
sondern es werden Knoten unterschiedlicher Größe und Farbe dargestellt: 
Je größer der Knoten, desto häufiger finden sich Überschneidungen im Da-
tenmaterial. Die Abbildung zeigt die Überschneidungen des Codes „intern 
fördernde  Faktoren“  mit  anderen  Codes  aus  dem  Projekt  „Umweltkom-
munikation und lokale Agenda“, und zwar mit Textstellen, die Informatio-
nen  für  bestimmte  im  Projekt  entwickelte  Thesen  beinhalten.  Sobald  die 
Maus  über  einen  Knoten  bewegt  wird,  erscheinen  die  zahlenmäßigen  In-
formationen, so in der Abb. 71, dass 22 Überschneidungen zwischen dem 
Code „interne fördernde Faktoren“ und Textstellen zur These 7 „Vertreter 
Theorie“ existieren. Mit einem Doppelklick wird ein Text-Retrieval initiiert 
und die betreffenden 22 Textstellen werden zusammengestellt.  

Praktisc

che Hinweise fü

ür MAXQDA

195 

 

Abb. 71

1: Visualisierun

ng des gleichz

eitigen Vorkom

mmens von Co

odes 

10.6 P

Praktische 

Hinweise f

für MAXQD

DA 

Konze
tellen.
Maps 
point 
Eleme
bei ge
Verbin
gerich
einer M
verkle
Map  i
oder  B
im Fo
spruch
B“ au
„Code

ept Maps lass
  Es  können
können als G
Präsentation
ent von MAX
drückter Alt-
ndungslinien 
htete – lassen 
Map frei pos
einert oder ve
importiert  w
Beschriftunge
ortgang der A
hsfrei sein, d
ftreten und i
e B“ verbund

sen sich mit d
n  beliebig  vie
Grafikdatei exp
nen  eingefügt
XQDA (Text
-Taste in die 
zwischen de
sich im Link
sitioniert wer
ergrößert wer
werden,  zusät
en eingefügt 
Auswertung e
.h. „Code A“
in einer ande
den sein. 

dem dafür en
ele  Maps  ang
portiert und d
t  werden.  Im
t, Code, Mem
Zeichenfläch
en Knoten –
k-Modus zeic
rden und die 
rden. Jedes E
tzlich  können
werden.  Die
erzeugt, müss
“ kann in ein
eren Map nur

ntwickelten T
gelegt,  und  g
dann in Textd
m  Selektions
mo etc.) mit 
he als Knoten
sowohl geri
chnen. Alle E
Symbole kön
Element kann
n  beliebig  vi
e verschieden
sen nicht kon
ner Map als U
r ungerichtet

Tool MAXMa
gespeichert  w
dateien oder P
modus  kann
einem Dopp
n eingefügt w
ichtete als au
Elemente kön
nnen nach W
n nur einmal 
iele  freie  Ele
nen Maps, di
nsistent und 
Ursache von 
t oder gar nic

aps ers-
werden. 
Power-
n  jedes 
pelklick 
werden. 
uch un-
nnen in 
Wunsch 
in eine 
emente 
ie man 
wider-
„Code 
cht mit 

 

196 

Daten-Display und Visualisierung 

Jedes Objekt, das in die Zeichenfläche eingefügt wird, besteht aus einem 
Bild  und  einem  Label  (Namen).  Zunächst  wird  beim  Import  von  MAX-
QDA  Objekten  das  MAXQDA  Standardsymbol  als  Bild  und  die  MAX-
QDA Benennung als Label übernommen, also bei einem Code das farbige 
Codesymbol aus der Liste der Codes und der Codename als Label. Sowohl 
das Label als auch das Bild können verändert werden. Als Bild kann eine 
Grafik, ein Photo o.ä. importiert werden. Das Label lässt sich ebenfalls ver-
ändern, Schriftfarbe, Schriftgröße u.a. können frei gewählt werden.  

Der  Synchro-Modus  synchronisiert  die  Symbole  der  Map  mit  dem 
MAXQDA Projekt. Im Falle eines Textsymbols heißt dies, dass beim Be-
wegen  der  Maus  über  das  Symbol  in  der  Map  das  zum  Text  gehörende 
Textmemo im Tooltipp erscheint und dass ein Doppelklick auf das Symbol 
den  betreffenden  Text  im  Text  Browser  von  MAXQDA  öffnet.  Im  Syn-
chro-Modus  bestehen  zudem  weitere  funktionale  Verbindungen  zwischen 
der Map und der MAXQDA Datenbasis. So können etwa alle Memos eines 
Textes und alle oder ausgewählte Codes importiert werden. Für Codes be-
steht  die  Möglichkeit,  überschneidende  Codes  oder  mit  diesen  verlinkte 
Memos  automatisch  einzufügen.  In  allen  Fällen  werden  automatisch  Ver-
bindungslinien  zwischen  dem  Ausgangsobjekt  und  den  importierten  Ele-
menten gezeichnet. 

Die in diesem Kapitel beschriebenen anderen fallübergreifenden Visua-
lisisierungsformen sind ebenfalls im Menü „Visual Tools“ und als Symbole 
in  der  entsprechenden  Toolbar  verfügbar.  Fallorientierte  Visualisierungen 
können direkt beim betreffenden Text als Option gewählt werden. Bei den 
meisten der genannten Funktionen ist es sinnvoll, die Darstellung auf be-
stimmte Fälle und Codes einzugrenzen. Dies geschieht wie in MAXQDA 
üblich mittels Aktivierung. 

Übungen 

1.  Arbeiten Sie weiterhin mit Ihrem Übungsprojekt und ordnen Sie den 

tel“. 

bisher definierten Codes unterschiedliche Farben zu. 

2.  Erstellen Sie eine neue Map und nennen Sie diese „Interview Har-

3.  Fügen Sie mittels Alt und Doppelklick den Text „interview2“ in die 
Arbeitsfläche der Map ein. Klicken Sie das Textsymbol in der Map 
mit der rechten Maustaste an und importieren Sie alle zugeordneten 

Praktische Hinweise für MAXQDA 

197 

Codes dieses Textes. Ordnen Sie das Symbol für „interview2“ in der 
Mitte der Map an und arrangieren Sie die Codes sternförmig um das 
Textsymbol herum. 

4.  Vergrößern Sie das Textsymbol und importieren Sie die Memos die-
ses  Textes.  Schalten  Sie  nun  in  den  Synchronmodus  und  bewegen 
Sie die Maus über das Textsymbol und das Memosymbol. Was pas-
siert?  Doppelklicken  Sie  anschließend  auf  das  Text-  bzw.  Memo-
symbol. 

5.  Vergleichen Sie die TextPortraits der Texte „interview2“ und „inter-

view4“. Was fällt Ihnen auf? 

6.  Finden Sie mit Hilfe des Code-Matrix-Browsers heraus, in welchem 
Text die meisten Textstellen zum Code „Jugend“ zu finden sind. Se-
hen Sie sich die Textstellen an. 

7.  Aktivieren  Sie  alle  Codes  einschließlich  ihrer  Subcodes.  Sehen  Sie 
mit Hilfe der Funktion „Codeliner“ die Sequenz der Codierungen für 
einige Texte an. 

 

 

11  Praktisches Arbeiten mit Kategoriensystemen 

 

11.1  Typen von Kategoriensystemen 

Die Definition von Kategorien und Subkategorien spielt beim Arbeiten mit 
QDA-Software eine zentrale Rolle für das Organisieren, Sortieren und spä-
tere  Wiederfinden  von  Textpassagen.  Je  nach  Wissenschaftsdisziplin  und 
Forschungsmethode  findet  man  unterschiedliche  Bezeichnungen  für  die 
Kategorien,  z.B.  Codes,  Stichworte,  Schlagworte,  Keywords  und  derglei-
chen mehr. Dementsprechend spricht man dann von Kategoriensystem, In-
dexsystem,  Schlagwortkatalog,  Stichwortverzeichnis  oder  Codesystem.  Fak-
tisch steht hinter dieser Vielfalt von Begriffen immer ein ähnliches Instru-
mentarium, nämlich eine gewisse Anzahl von analytischen Kategorien. 

Kategorien  können  Phänomene  auf  sehr  unterschiedlichen  Abstrakti-
onsebenen erfassen. Schon der Begriff Kategoriensystem kann in der Scienti-
fic Community der qualitativen Forscher nicht mit einhelliger Zustimmung 
rechnen, denn wer sich mehr am offenen Codieren der Grounded Theory 
orientiert oder auf das Emergieren von Kategorien aus dem Datenmaterial 
setzt, der vermutet hinter dem Begriff „System“ eine vom Forscher vorge-
nommene  Vorab-Konstruktion  von  aufeinander  bezogenen  und  gegenei-
nander  abgegrenzten  Kategorien,  mit  der  er  sich  nur  schwer  anfreunden 
kann. Ob es sich aber bei den definierten Kategorien um ein System von Ka-
tegorien handelt, und wie die Eigenschaften des Systems definiert werden, 
ist  Angelegenheit  des  Benutzers  von  QDA-Software.  Die  QDA-Pro-
gramme schreiben hier ebenso wenig bestimmte Eigenschaften von Kate-
goriensystemen vor, wie dies Karteikästen tun. Es ist die Entscheidung des 
Benutzers, ob sich die Kategorien eines Kategoriensystems gegenseitig aus-
schließen  sollen,  ob  die  Überlappung  von  Kategorien  erlaubt  und  ob  das 
Kategoriensystem induktiv aus dem Textmaterial gebildet wird oder auf ein 
bereits vorhandenes und in der Forschung bewährtes Kategoriensystem zu-
rückgegriffen wird. Formal lassen sich hinsichtlich der Struktur drei Arten 

Typen von Kategoriensystemen 

199 

von  Kategoriensystemen  unterscheiden:  lineare,  hierarchische  und  netz-
werkstrukturierte. 

Unter einem linearen Kategoriensystem ist eine sequentielle Liste von Codes 
zu verstehen, wie z.B. die folgenden thematischen Kategorien, die in einem 
Projekt über die Motivation von ehrenamtlichen Helfern benutzt wurden: 
„Anerkennungsaspekt“,  „Beziehung  zum  Helfen“,  „Beziehung  zu  den 
Klienten“,  „Lebensphilosophie“,  „Selbstreflexion“,  „persönliche  Kompe-
tenzdefizite“, „Berufsorientierung“ und „Aufstiegsorientierung“. Die Kate-
gorien können durchaus untereinander in Beziehung stehen, aber der Liste 
ist  dies  nicht  anzusehen,  dort  erscheinen  alle  Kategorien  gleichrangig  zu 
sein, es gibt weder Subkategorien noch Verbindungen. 

Hierarchische Kategoriensysteme bestehen nicht nur aus einer solchen einfa-
chen Liste von Codes, sondern setzen die Codes in Beziehung zueinander, 
und zwar dergestalt, dass einzelne Konzepte, wie etwa das Konstrukt „Ein-
stellungen“, in Form von Ober- und Unterkategorien erfasst werden. Sol-
che hierarchischen Kategoriensysteme bestehen dann aus Einzelteilen nach 
folgendem Muster: 

Einstellungen 

positiv 

negativ

Liebe 

Sympathie

Hass

Antipathie

 

Das Arbeiten mit hierarchischen Kategoriensystemen ist in der qualitativen 
Sozialforschung und in der Inhaltsanalyse weit verbreitet. Die Dimensiona-
lisierung von Codes, wie von Strauss beschrieben (vgl. Kap. 3.2), stellt ein 
solches hierarchisches Konzept von Codes dar. Wenn Codes induktiv aus 
dem  Material  gewonnen  werden,  ist  ihre  Bündelung  zu  Hauptkategorien 
oder Oberkategorien eine gängige Praxis (vgl. Mayring 2002: 116 ff.). 

Hierarchische Kategoriensysteme besitzen meist eine Baumstruktur. Sie 
haben  sich  in  vielen  Bereichen  als  sehr  praktische  Ordnungsschemata  er-
wiesen. Der Windows Explorer, den fast jeder PC-Nutzer kennen dürfte, 
ist eine typische Anwendung dieses Prinzips hierarchischer Ordnungsstruk-
tur. Auch bei den weithin bekannten Mind Maps (vgl. Buzan 2004) handelt 
es sich um solche Baumstrukturen. 

 

200 

Praktisches Arbeiten mit Kategoriensystemen 

Netzwerkstrukturierte  Kategoriensysteme  unterscheiden  sich  von  hierarchi-
schen dadurch, dass Beziehungen zwischen den Kategorien nicht auf hier-
archische Relationen beschränkt sind. Ein solches Kategoriensystem kann 
beispielsweise folgende Struktur besitzen: 

Entdramatisierung 

Verantwortungsdelegation 

Umweltbewusstsein 

Krisendenken 

Umweltignoranz 

Umweltengagierte 

Nachhaltigkeitsbewusstsein 

 

Die  Idee,  Netzwerke  zur  Analyse  von  sozialwissenschaftlichen  Texten  in 
der Forschung zu verwenden, ist noch relativ neu. Der Vorteil eines netz-
werkstrukturierten Kategoriensystems liegt in dem höheren Grad an Flexi-
bilität,  der  Nachteil  in  der  im  Vergleich  zu  Baumstrukturen  geringeren 
Übersichtlichkeit und dem Verlust der klaren Struktur. 

11.2 Konstruktion von Kategoriensystemen: induktiv oder 

deduktiv? 

Über die verschiedenen Wege und Möglichkeiten, Kategoriensysteme in der 
Forschungspraxis aufzubauen und mit ihnen zu arbeiten, existiert nur wenig 
Literatur.  In  Kapitel  4  wurden  verschiedene  Modelle  kategorienbasierter 
Analyse  und  Umsetzungsmöglichkeiten  mit  QDA-Software  ausführlich 
vorgestellt.  Im  Folgenden  soll  noch  einmal  konkreter  nachgefasst  und  an 
Forschungsbeispielen  die  Konstruktion  von  Kategoriensystemen  und  die 
potenzielle Unterstützung durch QDA-Software beleuchtet werden. 

Wie kann Software diesen Prozess der Konstruktion des Kategoriensys-
tems unterstützen? Kann Sie das überhaupt? Generell gilt, dass es in den 
meisten Fällen wohl nützlicher sein dürfte, seine Daten zu ordnen und zu 
organisieren,  als  dies  zu  unterlassen.  So  wie  auch  in  einem  aufgeräumten 

Konstruktion von Kategoriensystemen: induktiv oder deduktiv? 

201 

Zimmer die Chance, etwas wiederzufinden, größer ist als in einem unaufge-
räumten. Die Aufräummetapher macht es verständlich, dass auch der Vor-
gang des Aufräumens und Organisierens selbst von großer Bedeutung sein 
kann.  Nicht  der  Vergleich  von  zwei  statischen  Zuständen  (aufgeräumt/ 
nicht aufgeräumt) ist es, der für das Organisieren spricht, sondern beim Auf-
räumen wird vieles entdeckt und wiedergefunden: Organisieren ist analysieren – 
das  Codieren  des  Materials  ist  im  Kontext  sozialwissenschaftlicher  For-
schung  eine  Theorie  produzierende  Aktivität.  Strauss  formulierte  „Codes  are 
theoretical directives“. Aber, auch dies muss ehrlicherweise gesagt werden, 
das  Organisieren  und  Codieren  von  Texten  macht  häufig  ebenso  wenig 
Spaß, wie das Aufräumen von Zimmern, es erscheint vielfach geradezu als 
das Gegenteil von Kreativität. 

Die  Bildung  von  Kategorien  kann  induktiv,  aus  dem  Material  heraus, 
oder deduktiv, auf der Grundlage eines theoretischen Ansatzes, geschehen. 
Man kann gewissermaßen bereits vor dem Aufräumen eine Schublade mit 
einer Aufschrift (z.B. „Lego-Steine“) versehen oder erst beim Aufräumen 
eine solche Kategorie bilden. Das Beispiel zeigt, dass induktive und deduk-
tive Kategorienbildung nicht so grundverschieden sind, wie dies in kontro-
vers geführten Diskussionen um Sinn oder Unsinn von Theoriebezogenheit 
von  Forschung  oder  um  qualitative  oder  quantitative  Methoden  oft  er-
scheint. Die Kategorie „Lego-Steine“ wird nur dann aus dem Material emer-
gieren,  wenn  bereits  eine  Vorab-Kategorisierung  in  den  Köpfen,  ein 
Vor“urteil“  im  Sinne  Gadamers28  vorhanden  ist.  In  der  Forschungspraxis 
geschieht  die  Kategorienbildung  häufig  so,  dass  deduktive  und  induktive 
Vorgehensweisen  miteinander  verzahnt  werden.  Dort,  wo  das  Vorwissen 
oder  das  Detailwissen  über  den  Gegenstand  der  Analyse  nicht  ausreicht, 
wird man immer zur induktiven Kategorienbildung neigen. Hingegen wird 
es in Feldern, in denen bereits eine Menge an gesichertem Wissen vorhan-
den ist, ratsam sein, sich auch darauf zu beziehen und nicht der Fiktion der 
Tabula rasa zu erliegen. 

Nach der schematisierenden Darstellung von Mayring (2003: 74 f.) lässt 
sich ein aus sechs Schritten bestehendes Ablaufmodell für die induktive Ka-
tegorienbildung skizzieren. In der Spalte „Beispiele bei Mayring“ der Abb. 
72  sind  Beispiele  aus  dem  Projekt  „Lehrerarbeitslosigkeit  in  den  neuen 
Bundesländern“ angeführt. 
                                                           
 
28 Gadamer argumentiert, dass ohne solche „Vorurteile“, die quasi Folge der Enkulturation 
des  Einzelnen  sind,  Urteile  gar  nicht  möglich  wären  (vgl.  de  Haan/Kuckartz  1996: 
204 f.).  

 

202 

Praktisches Arbeiten mit Kategoriensystemen 

 

Schritte 

Beispiele bei Mayring 

1  Möglichst genaue Definition 

der Thematik der 
Kategorisierung 

Kategorisiert wird die subjektive Bedeutung des Lehrerberufs, d.h. 
was dem Einzelnen der Lehrerberuf bedeutet, warum er ihn 
ergriffen hat und wie sein Selbstverständnis zu DDR-Zeiten 
aussah. 

2  Vorgehensweise im Detail 

und Selektionsregel 
bestimmen 

Die Interviewtexte werden in einer Zeile-für-Zeile-Analyse 
bearbeitet. Die Textstellen, die der obigen Fragestellung 
entsprechen, werden markiert und ihnen wird eine 
Auswertungskategorie zugeordnet. 

3  Neubildung von Kategorien 

Für relevante Textstellen werden die Kategorien nahe am Text 
gebildet, z.B. wird der Textstelle „Die Freude am Beruf entstand 
durch viele Erfolgserlebnisse“ der Kategorie „Freude am 
Lehrerberuf“ zugeordnet. 

4  Neubildung von Kategorien 

oder Subsumption unter eine 
schon bestehende Kategorie 

Für alle weiteren relevanten Textstellen ist zu entscheiden, ob 
neue Kategorien zu bilden sind oder ob eine bereits definierte 
Kategorie zugeordnet wird. 

5  Bilden von Oberkategorien 

Das so entstandene Set von Kategorien wird geordnet, und es 
werden Oberkategorien, in diesem Falle sieben, gebildet. 

6  Gegebenenfalls Bildung von 

noch höher aggregierten 
Hauptkategorien 

In einem weiteren Schritt werden die 7 Oberkategorien zu 2 
Hauptkategorien „Lehrer aus Freude am Beruf“ und „Lehrer aus 
dem Engagement für den Sozialismus heraus“ zusammengefasst. 

Abb. 72: Ablauf induktiver Kategorienbildung nach Mayring 

In der Forschungspraxis wird man das induktive Codieren nur solange be-
treiben, bis das Kategoriensystem gesättigt ist, d.h. bis keine neuen Katego-
rien mehr auftauchen. In dem Augenblick, in dem man, wie Mayring in die-
sem Beispiel, Ober- bzw. Hauptkategorien gebildet hat, ist es natürlich zeit-
sparender, das verbleibende Datenmaterial nur im Hinblick auf diese Kate-
gorien zu codieren. 

Stammen die Kategorien nicht aus dem Material selbst, so spricht man 
von deduktiven Kategorien. Damit ist noch wenig über die Herkunft der Kate-
gorien ausgesagt. Sie können aus der Theorie abgeleitet sein, aus anderen 
Untersuchungen  stammen  oder  auch  direkt  aus  dem  Interviewleitfaden 
übernommen worden sein. Im Grunde ist es auch in dem obigen Beispiel 
für induktive Kategorienbildung so, dass in dem Augenblick, in dem nach 
einem Durchgang durch eine Teilmenge des Materials (laut Mayring 10 bis 
50%) das Kategoriensystem gesättigt erscheint und Oberkategorien gebildet 
werden, man es im Weiteren mit der Anwendung von deduktiven Katego-
rien zu tun hat, denn diese werden ja nicht mehr am restlichen Material neu 
entwickelt, sondern allenfalls weiterentwickelt. 

Wie viele Kategorien sind notwendig? 

203 

11.3 Wie viele Kategorien sind notwendig? 

Noch  in  den  1990er  Jahren  fand  man  in  dem  seinerzeit  viel  beachteten 
Buch von Renata Tesch (1990) den Hinweis, normalerweise würde in der 
qualitativen Forschung mit Kategoriensystemen gearbeitet, die zwischen 20 
und  50  Codewörter  aufweisen.  Vermutlich  aufgrund  der  seither  weitaus 
besseren computertechnischen Möglichkeiten, mit differenzierten Codesys-
temen zu arbeiten, hat sich der Umfang der Kategoriensysteme seither stark 
verändert. Selbst dann, wenn nur relativ wenig Codes gebildet werden, wird 
die  Möglichkeit,  Subkategorien  zu  definieren,  meist  in  Anspruch  genom-
men In einem Projekt aus der Schulforschung findet man z.B. eine Defini-
tion der Kategorie „Kooperation“ mit fünf Subkategorien, die jeweils ver-
schiedene Kooperationspartner bezeichnen: 

Kooperation 

Ämter 

Anwohner 

Lehrer 

Schüler 

Schulen 

 

In einer Studie über Raucher arbeitet das Kategoriensystem mit drei hierar-
chisch gestaffelten Ebenen. Die Subkategorie Image besitzt hier sechs Sub-
kategorien. 

Rauchen 

Image 

Kontext 

Effekte 

Gründe 

Vergnügen 

smart, cool 

soziales 

aufregend 

ungesund 

störend 

 

Die Verwendung von Subkategorien hat zur Konsequenz, dass sich die Ge-
samtzahl der verwendeten Codes meist jenseits der von Tesch empfohlenen 
Zahl von 20 bis 50 bewegt. Die meisten Forschungsarbeiten operieren heu-
te  mit  relativ  umfangreichen  Kategoriensystemen.  Bei  Auswertungen  von 

 

204 

Praktisches Arbeiten mit Kategoriensystemen 

Leitfadeninterviews  findet  man  überwiegend  Codesysteme,  die  auf  zwei 
Ebenen ausdifferenziert sind. Die erste Ebene wird häufig vor der Auswer-
tung  des  Materials  festgelegt  und  folgt  der  Struktur  des  Leitfadens.  Die 
zweite Ebene entsteht auf der Basis des Materials in Form induktiver Kate-
gorien während des Auswertungsprozesses. 

Je mehr es zum Alltag gehört, QDA-Software einzusetzen, desto häufi-
ger findet man komplexere Codesysteme, die mittlerweile auch oft auf drei 
Ebenen oder mehr ausdifferenziert sind. Die gestiegenen technischen Mög-
lichkeiten verlocken natürlich dazu, mit der Konstruktion von Kategorien-
systemen  zu  „spielen“.  Kein  Zweifel:  Kategorien  sind  nützlich,  sie  lassen 
sich  elektronisch  einfach  verändern  und  umorganisieren  –  aber  dennoch: 
Das Codieren von Text kostet enorm viel Zeit und die zeitlichen und fi-
nanziellen Restriktionen im Forschungsprozess haben nicht selten zur Fol-
ge,  dass  nach  dem  Codieren  und  einem  ersten  interpretativen  Durchlauf 
durch das codierte Material kaum noch Zeit verbleibt, um weitere komple-
xe Auswertungen in Angriff zu nehmen. Häufig gelangt man nicht viel wei-
ter  als  zum  „Initial  Coding“,  obwohl  man  doch  ein  so  mächtiges  System 
zum Explorieren der Daten besitzt. Deshalb sei der Rat gestattet, den ers-
ten Codierungsprozess eher zügig zu bewältigen, um wieder in eine Phase 
der Exploration einzutreten bzw. solche Textabschnitte erneut zu studieren, 
die zu bestimmten Kombinationen von Kategorien gehören. 

Codieren  ist  nicht  immer  eine  interessante  und  entdeckende  Tätigkeit, 
sie kann im Forschungsalltag auch repetitiv und langweilig werden. Im Falle 
von Fakten-Codes etwa werden die Texte mehr oder weniger mechanisch 
auf bestimmte Merkmale hin durchgesehen und, falls diese gefunden wer-
den, erfolgt die Zuordnung des entsprechenden Codes. Ähnlich verhält es 
sich, wenn bei einer Gruppendiskussion die Sprecher zu codieren sind oder 
bei  einem  Leitfadeninterview  die  zu  den  einzelnen  Fragen  gehörenden 
Segmente identifiziert und codiert werden. In diesen Fällen lassen sich die 
repetitiven Arbeiten aber vermeiden, wenn die Texte entsprechend vorbe-
reitet werden, so dass die Möglichkeiten des automatischen Codierens ge-
nutzt werden können. 

Das  Arbeiten  mit  dem  Kategoriensystem  und  den  codierten  Segmenten 
nimmt im Prozess der computergestützten Analyse qualitativer Daten gro-
ßen Raum ein. Vor allem dann, wenn das Kategoriensystem sehr umfang-
reich ist und vielleicht mehr als hundert Codes umfasst, ist es notwendig, 

Einfaches Kategoriensystem in einer leitfadenorientierten Interviewstudie 

205 

über  entsprechende,  schnell  und  einfach  zu  handhabende  Management-
funktionen zu verfügen. Dazu gehören solche Funktionen wie: 
 

1.  problemloses Löschen und Definieren von neuen Kategorien 
2.  leichtes  Umcodieren  von  Segmenten,  d.h.  verändern  der  Segment-

grenzen oder Zuordnung eines anderen Codes 

3.  direktes Anspringen des gewünschten Codes in der Liste der Codes 
4.  Ausblenden  von  Subkategorien,  um  einen  besseren  Überblick  über 

das Kategoriensystem zu gewinnen 

5.  Druckausgabe des Kategoriensystems 
6.  Angaben über die Häufigkeiten der Kategorienzuordnung 

 
Von eminenter Wichtigkeit ist die Fähigkeit des QDA-Programms, globale 
Modifikationen  des  Kategoriensystems  vornehmen  zu  können,  d.h.  wenn 
Veränderungen am Kategoriensystem vorgenommen werden, dann sollten 
sich diese automatisch auf alle hiermit codierten Segmente auswirken. Will 
man  etwa  induktiv  definierte  Kategorien  zu  Hauptkategorien  zusammen-
fassen, so kommt es darauf an, dass auch alle entsprechend codierten Seg-
mente automatisch umcodiert werden. 

In den folgenden Abschnitten werden Beispiele für die Anwendung von 
deduktiven Kategorien gegeben. In Kapitel 11.4 geht es um Kategorienbil-
dung in direkter Relation zu einem Leitfaden, in Kapitel 11.5 um ein Kate-
goriensystem, das auf den kategorialen Rahmen einer Argumentationstheo-
rie aufbaut, und in Kapitel 11.6 um die Leitbildanalyse. 

11.4 Einfaches Kategoriensystem in einer leitfadenorientierten 

Interviewstudie 

Schauf/Schünemann (1995) führten eine Studie zur Jugendsozialarbeit/Ju-
gendberufshilfe durch und untersuchten die institutionellen Rahmenbedin-
gungen  und  die  Probleme  von  Jugendlichen  in  der  Übergangsphase  zwi-
schen Schule und Ausbildung. In diesem Kontext führten sie offene Grup-
peninterviews  und  Experteninterviews  mit  Personen,  die  unmittelbar  mit 
dieser Gruppe von Jugendlichen befasst sind, u.a. mit Lehrern, Ausbildern, 
Sozialarbeitern in der Jugendarbeit und Mitarbeitern der Jugendgerichtshil-
fe.  Für  die  Interviews  wurde  ein  Leitfaden  entwickelt,  der  unter  anderem 
folgende Fragen enthielt: Bereitet Schule ausreichend für den „Start ins Le-

 

206 

Praktisches Arbeiten mit Kategoriensystemen 

ben“ vor? Welche Voraussetzungen sind wichtig, um auf dem Arbeitsmarkt 
erfolgreich bestehen zu können? Welche Schlüsselqualifikationen sind heu-
te erwünscht? Ist die Berufsberatung zufriedenstellend? Gibt es genügend 
Ausbildungsplatzangebote  in  Maßnahmen?  Wie  werden  die  bestehenden 
Einrichtungen der Jugendhilfe eingeschätzt? Sind Folgen der Einigung Eu-
ropas im Ausbildungsbereich bereits spürbar? 

Von diesem Leitfaden ausgehend wurde ein Kategoriensystem (Abb. 73) 

gebildet und die Interviewtexte wurden in systematischer Weise codiert: 

Kategorie 

Abbrecher 
 

Ausbildung 

Berufsberatung 

Europa 

Institutionen 

.... 

Subkategorie 

außerbetrieblich 
betrieblich 

außerbetrieblich 
betrieblich 
Vergleichbarkeit 
Übernahme 1. Arbeitsmarkt 

Fortbildung 
Kritik 
Zeitpunkt 

Austausch 
Projektfinanzierung 

Informationsstand 
Kooperation  
Öffentlichkeitsarbeit 

 

Perspektive der Arbeit  
 

Berufsbilder 
Handlungsspielraum 

Schule 

Arbeitslehre 
Praktikum 

Abb. 73: Kategoriensystem einer Jugendhilfe-Studie (Auszug) 

Im Laufe des Codierungsprozesses wurden einige Kategorien präziser defi-
niert, bei anderen Kategorien entschied man sich, diese zusammenzufassen, 
und  einige  Kategorien  wurden  noch  zusätzlich  in  das  Kategorienschema 
aufgenommen. Diese Vorgehensweise ist relativ typisch für eine bestimmte 
Art von qualitativer Studie, nämlich für Auftragsstudien mit einem relativ 
genau vorgegebenen Frageraster. Wenn man schon mit einem Leitfaden ar-
beitet, bietet es sich an, Kategorien in direkter Anlehnung an diesen zu de-
finieren.  Da  die  Codierung  des  Materials  arbeitsaufwändig  ist,  werden  im 
Auswertungsprozess  in  der  Regel  nur  relativ  geringe  Veränderungen  am 

Kategoriensystem einer Argumentationsanalyse 

207 

Kategoriensystem vorgenommen. Stattdessen setzt man Schwerpunkte, ggf. 
auch unter Berücksichtigung von Wünschen des Auftraggebers, und nimmt 
für einige ausgewählte Fragestellungen eine vertiefte Auswertung mit erneu-
tem Materialdurchlauf vor. In diesem Forschungsprojekt wurden dazu Be-
wertungen des codierten Materials in Form von Fallvariablen vorgenommen 
(vgl. Schauf/Schünemann 1995), beispielsweise um zu erfassen, welcher Art 
die  geäußerte  Kritik  an  der  Schule  ist  und  wie  das  Vorhandensein  von 
Schlüsselqualifikationen  bei  den  Schulabgängern  beurteilt  wird.  Es  wurde 
z.B. eine dreistufige Variable „Schulkritik“ mit folgender Definition gebildet: 
„Welche Art von Kritik wird von den Experten zum Themenbereich Schule 
geäußert?“ (Variablenwerte: 0=keine Aussage, 1=keine Kritik, 2=allgemeine 
Kritik, 3=konkrete, konstruktive Kritik). Diese erneute Klassifikation von 
Teilen des Datenmaterials macht es einfach, solche Fragen wie „Welche Be-
fragtengruppe äußert die stärkste Kritik an der Schule“ präzise zu beantwor-
ten. 

Das Kategoriensystem reflektiert die Forschungsfragen in diesem  Feld 
der Jugendhilfeforschung. Es ist eher praktisch als theoretisch ausgerichtet 
und in dieser Hinsicht durchaus charakteristisch für substanzwissenschaft-
lich orientierte Auftragsforschung. 

11.5 Kategoriensystem einer Argumentationsanalyse 

Ein anderer Typ von Kategoriensystem nimmt ähnlich wie das Codierpara-
digma von Strauss seinen Ausgang von einem formalen Schema der Systematisie-
rung, das theoretische Bezüge aufweist. Bei Glaser und Strauss ist es ein all-
gemeines Handlungsmodell, das als heuristischer Rahmen gesetzt wird und 
aufgrund  dessen  sechs  formale  Kategorien  wie  z.B.  „Phänomene,  auf  die 
sich  das  Handeln  richtet“,  „Kausale  Bedingungen  für  diese  Phänomene“ 
definiert werden (vgl. Kap. 4.1). Geschieht die erste Codierung der Texte 
auf  der  Basis  eines  solchen  formalen  Kategoriensystems,  so  erreicht  der 
Analyseprozess von vornherein eine abstraktere Ebene. 

Eine  vergleichbare  Vorgehensweise  wählten  Bukova  und  Hellstern 
(1995)  für  die  Analyse  von  Argumentationen,  einer  in  den  Sozialwissen-
schaften häufig vorkommenden Aufgabenstellung. Die traditionelle quanti-
tative Inhaltsanalyse offeriert nur Verfahren, die mehr an einfachen Text-
merkmalen  –  Vorkommen  von  Wörtern,  Auszählen  von  Themen,  Ver-

 

208 

Praktisches Arbeiten mit Kategoriensystemen 

gleich von Wortbeständen – orientiert sind als an komplizierteren Proble-
men der Semantik. Eine methodisch kontrollierte Analyse von Argumenten 
und Argumentationen, die den Ansprüchen einer Argumentationstheorie ge-
recht  wird,  ist  mit  diesen  Verfahren  schwerlich  möglich.  Nun  existieren 
nicht nur die Methoden traditioneller Inhaltsanalyse, die man für die Analy-
se von Argumentationen heranziehen könnte, sondern im Bereich der Phi-
lologien  haben  hermeneutisch  orientierte  Verfahren  eine  lange  Tradition. 
Solche  hermeneutisch  orientierten  Methoden  sind  auch  in  den  Sozialwis-
senschaften  verbreitet,  beispielsweise  die  an  Goffman  (2000)  orientierte 
„Rahmenanalyse“, doch mangelt es bislang an methodischer Präzision (vgl. 
König 2004). 

In  einem  Projekt  zur  Analyse  der  Hochschulreformdebatte  unternah-
men  Bukova  und  Hellstern  den  Versuch,  an  eine  aus  dem  Bereich  der 
Sprachwissenschaften  stammende  Argumentationstheorie  anzuknüpfen 
und die dort beschriebenen Verfahren in ein Analyseinstrumentarium um-
zusetzen. Angesetzt wurde an der Argumentationstheorie Toulmins (1975), 
von der einige Grundelemente hier zum besseren Verständnis des gebilde-
ten  Kategoriensystems  kurz  beschrieben  werden.  Toulmin  zufolge  ist  die 
Voraussetzung für eine Argumentation, dass ein Sachverhalt kollektiv frag-
lich ist und sozialer Druck in Richtung auf eine Lösung besteht. 

„Eine Argumentation ist der Versuch, etwas kollektiv Fragliches (Quaestio) 
mit Hilfe des kollektiv Geltenden (Argument) in kollektiv Geltendes (Ant-
wort auf Quaestio) zu überführen“ (Bukova/Hellstern 1995: 3). 

Kollektiv  Geltendes  wird  von  allen  Mitgliedern  der  Sozietät  anerkannt. 
Hierzu gehören faktische und normative Aussagen sowie solche, die besa-
gen, wie von welchen Aussagen zu welchen anderen Aussagen übergegan-
gen werden kann (Schließregeln). Bei Toulmin findet man dazu folgendes 
allgemeine Modell: 

 

Datum: 
Schließregel: 
Schluss: 

 

Harry was born in London 
A man born in Britain will generally be a British citizen 
Presumably Harry is a British citizen

Die  Quaestio,  d.h.  die  Definition  des  Tatbestandes,  ist  bereits  von  ent-
scheidender Bedeutung. Als Beispiel mag man sich den geplanten Bau eines 
Behindertenheims vor Augen führen und zwei unterschiedliche Problembe-
schreibungen,  zum  einen  „Erwartbare  Wertminderung  von  Anwohner-
grundstücken“ und zum anderen „Integration von Behinderten in die Ge-

Kategoriensystem einer Argumentationsanalyse 

209 

sellschaft“.  Die  Konstitution  eines  Problems  als  Problem  entscheidet  zu-
gleich darüber, welche argumentativen Problemzugänge als relevant zu ge-
lten haben. Für die Akteure stellt sich die Aufgabe, kollektiv geltende Aus-
sagen  kohärent  zu  verknüpfen,  so  dass  gewissermaßen  logisch  zwingend 
eine den Interessen des Akteurs entsprechende Antwort gefolgert werden 
muss.  Unterscheiden  lassen  sich  induktive,  deduktive  und  metaphorische 
Schließregeln,  wobei  die  metaphorischen  Schließregeln  (Analogiebeweise) 
die größte Überzeugungskraft besitzen. Besonders häufig werden Stereoty-
pe  („Hausbesitzer  sind  Spekulanten“)  und  soziale  Topoi  („Das  BAFöG 
reicht nicht zum Leben“) als Metaphern benutzt. 

Quaestio, welche 
Quaestio, warum 
Aussagen 

Codewortsystem für eine Argumentationsanalyse nach Bukova/Hellstern 
 
1. Titel 
2. Themen 
3. Fragestellungen 
4. Instanzen 
Selbstexplikation 
 
Kontaktierung 
 
Reaktion auf Beiträge 
 
 
Reaktion auf Reaktionen 
5. Teilaufgaben einer Argumentation 
 
 
 
                    begründet 
                        Stereotyp 
                            Begründung 
 
 
 
 
 
 
 
 
 
 
 
 

         Topos 
             Begründung 
         Unmetaphorisch 
            Begründung 
     unbegründet 
         Stereotyp 
         Topos 
         Unmetaphorisch 
Aussagen verknüpfen 
Bezug zur Opposition 
Schließregel 
Antwort auf Quaestio 

Abb. 74: Codesystem für eine Argumentationsanalyse nach Bukova/Hellstern 

Aufgrund  eines  solchen  argumentationstheoretischen  Rahmens  lässt  sich 
ein  Kategoriensystem  konstruieren  (Abb.  74).  Für  jeden  Text  werden  die 
Punkte 1 bis 5 nacheinander durchlaufen, deshalb empfiehlt es sich  auch, 
das Kategoriensystem nicht alphabetisch, sondern in der Reihenfolge dieser 
fünf Punkte zu organisieren. 

 

210 

Praktisches Arbeiten mit Kategoriensystemen 

Wird  das  gesamte  Textmaterial,  das  hier  aus  Diskussionsbeiträgen  zur 
Hochschulreform besteht, mit diesen Kategorien codiert, so lässt sich die 
prozessuale Entwicklung eines Diskurses gut nachzeichnen. Bei der Analy-
se  kann  zwischen  einer  Makroebene  und  einer  Mikroebene  differenziert 
werden: Die zeitliche Entwicklung des gesamten Diskurses, die Verteilung 
der Themen über die Zeit (auch in quantitativer Hinsicht) sowie die Akteu-
re stellen die Makroebene der Auswertung dar. Die Mikroebene befasst sich 
mit  den  vorgebrachten  Argumentationen  und  Argumenten  im  Einzelnen, 
d.h. mit deren Abfolge und Relationen in den einzelnen Diskussionsbeiträ-
gen. 

Es lassen sich folgende Forschungsfragen stellen: 

 
auf der Ebene der Argumente: 

(cid:120)  Welche Quaestiones dominieren? Wann? 
(cid:120)  Welche Beziehungen haben die Argumente zu den Quaestiones? 
(cid:120)  Das  kollektiv  Geltende:  Was  wird  wann  wie  eingebracht?  Welche 
Verschiebungen finden statt? Was wird zum kollektiv Geltenden in 
diesem Prozess? 
auf der Ebene der Akteure: 

(cid:120)  Wer greift wann in die Diskussion ein? 
(cid:120)  Ändern sich die Akteure? 
(cid:120)  Ändern  sich  ihre  Argumente  (Betrachtung  einzelner  Akteure  im 

Zeitverlauf)? 

auf der Ebene der Schließregeln: 

(cid:120)  Welche Schließregeln werden verwendet? 
(cid:120)  Welche  Art  der  Beweisführung  herrscht  vor,  eher  induktive  oder 

(cid:120)  Welche  metaphorischen  Argumentationen,  Stereotype  und  Topoi 

eher deduktive? 

tauchen auf? 

11.6 Kategoriensystem in einer Leitbildanalyse 

Die Leitbildanalyse ist ein Beispiel für eine Arbeitsweise mit Kategorien, bei 
der  bereits  zu  Beginn  der  Analyse  ein  formales  Systematisierungsschema 
existiert. Als ein analytischer Rahmen für empirisch-sozialwissenschaftliche 
Fragestellungen  wurde  die  Leitbildanalyse  Anfang  der  1990er-Jahre  am 
Wissenschaftszentrum  Berlin  (WZB)  entwickelt  (vgl.  Marz/Dierkes  1992, 

Kategoriensystem in einer Leitbildanalyse 

211 

Marz 1993) und seither vor allem in der Technikgeneseforschung und der 
sozialwissenschaftlichen Umweltforschung eingesetzt (vgl. Giesel 2007). 

Das Kategorienschema wird im Laufe der Analyse in induktiver Weise 
weiter  ausgearbeitet,  dimensionalisiert  und  inhaltlich  gefüllt.  Die  Leitbild-
analyse gibt der Datenauswertung eine Zielrichtung vor – nämlich die Iden-
tifikation und möglichst genaue Beschreibung von Leitbildern – und sie of-
feriert ähnlich wie das Codierparadigma der Grounded Theory eine vorab 
festgelegte Anzahl von Perspektiven, die bei der Betrachtung des Datenma-
terials  einzunehmen  sind.  Der  Kern  eines  Leitbildes  lässt  sich  wie  folgt 
schematisieren. 

t1 

Leitbild 

Machbarkeits- 

projektion 

Wunsch- 
projektion 

t0 

Machbares 

Basislinie 

Wünschbares 

 

Abb. 75: Ein Leitbild als Projektion von Wünschbarem und Machbarem 

Im Projekt „Umweltkommunikation und Lokale Agenda 21“ wurden Ak-
teure der Agenda 21-Initiativen des kommunalen Umfeldes mit Hilfe eines 
Interviewleitfadens befragt, der inhaltlich auf die Dimensionen der Leitbild-
analyse hin konzipiert war (vgl. de Haan/Kuckartz/Rheingans 2000). Der 
an die sorgfältige Lektüre des transkribierten Materials anschließende Ana-
lysegang ist in der folgenden Abbildung schematisiert. 

 

212 

Praktis

sches Arbeiten m

mit Kategoriens

systemen 

 

Abb. 76

6: Analysephas

sen bei der com

mputergestützt

ten Leitbildana

alyse 

Grobcodierung
r Basis einer Z
m aus der Tec
e (vgl. Marz/
. Ferner werd
Kategorien, w

werden  die
Zeile-für-Zeil
chnikgenesefo
Dierkes 1992
den weitere, d
wie beispielsw

Interviews  s
le Analyse we
orschung stam
2) verschiede
direkt mit den
weise die Kat

systematisch 
erden Textpa
mmenden K
enen Leitbildd
n Themen de
tegorie „Erfo

durch-
assagen 
Konzept 
dimen-
es Leit-
olgskri-

r  Phase  der 
In  der
eitet. Auf der
gearbe
rechend dem
entspr
eitbildanalyse
der Le
n zugeordnet
sionen
s assoziierte K
fadens
“, codiert. 
terien“
In 
der Phase II
pretation und
Interp
bilddim
mensionen  c
onen werden
mensio
et.  Beispielsw
gebild
nsionen  „öko
dimen
welche
e  Bereiche  si
oziale Dimen
Die so
nen“, „Partizi
Vision
„Umg
gestaltung des

I, der Dimens
d die Systema
codierten  Tex
n induktiv, d. 
weise  zur Kat
onomisch“,  „
ich  die  geäuß
nsion wird da
ipation/Polit
s lokalen Leb

sionalisierung, s
atisierung der
xtsegmente  im
h. in den Da
tegorie „Mac
ökologisch“ 
ßerten  Mach
ann weiter un
tik“, „Öffentl
bensraums“. 

stehen die Zu
r unter den v
m  Zentrum.
ten gegründe
chbarkeitsproj
und  „sozial“
hbarkeitsvorst
ntergliedert in
lichkeit“, „LA

usammensch
verschiedenen
Zu  den  Leit
ete, Subdimen
jektionen“  di
“,  je  nachdem
tellungen  bez
n „Gesellscha
A 21-Initiativ

hau, die 
n Leit-
tbilddi-
nsionen 
ie  Sub-
m,  auf 
ziehen. 
aftliche 
ve“ und 

Kategoriensystem in einer Leitbildanalyse 

213 

Diese  neu  gebildeten  Subcodes  werden  in  der  Phase  III,  der Feincodie-
rung, auf das Material angewendet, d.h. alle in Phase I codierten Segmente 
werden  neu  zugeordnet.  Mit  diesem  zweistufigen  Codierprozess  sind  alle 
notwendigen Vorarbeiten geleistet: Gegründet auf den inhaltlich zugeord-
neten  Textsegmenten  kann  eine  Zusammenstellung  und  systematische 
Interpretation  des  Materials  erfolgen  und  ein  Forschungsbericht  geschrie-
ben werden, der den Kategorien des Leitbildkonzepts folgt (Phase IV). Da-
bei können auch quantitative Aspekte eine Rolle spielen, denn es ist durch-
aus von Belang, ob 20 von 30 Agenda-Akteuren Erfolgskriterien definieren, 
die sich selbstbezüglich auf die Entwicklung der Agenda Initiativen bezie-
hen, oder ob dies nur in wenigen Fällen zu registrieren ist. Die Differenz zu 
quantitativ argumentierender Forschung ist aber, dass es nicht auf das Be-
richten der bloßen Zahlen bzw. von Prozentanteilen ankommt, sondern auf 
die Wörter und Argumentationen, mit denen die Frage der „Erfolgskrite-
rien“ von den Befragten thematisiert wird. QDA-Software kann die fallbe-
zogenen  Code-Häufigkeiten  der  verschiedenen  Dimensionen  und  Subdi-
mensionen direkt zur Verfügung stellen, so dass leicht unterschieden wer-
den kann, ob es sich um ein von vielen Befragten genanntes Kriterium (das 
dann zu Recht als ein „typischerweise von Akteuren genanntes Kriterium“ 
bezeichnet  werden  kann)  oder  lediglich  um  eine  randständige  Einzelmei-
nung handelt. Zur Verdeutlichung stehen jeweils Zitate zur Verfügung, de-
ren „Repräsentativität“ kontrollierbar und nachprüfbar ist. Einer bloß epi-
sodischen  Evidenz,  wie  sie  qualitativer  Analyse  häufig  vorgeworfen  wird, 
kann so wirksam vorgebeugt werden. 

Im Auswertungsprozess erweist sich eine Visualisierung der vorgenom-
menen  Codierungen,  wie  sie  in  MAXQDA  in  Form  des  Code-Matrix-
Browser verfügbar ist, als sehr hilfreich. Auf einen Blick lässt sich ersehen, 
welche Personen zu welchen Themen viele bzw. nur wenige Codierungen 
aufweisen. In Abbildung 2 werden die Spalten durch die Personen und die 
Zeilen durch die Codes bzw. Subcodes gebildet. Die Größe der Knoten in 
den einzelnen Zellen der Matrix entspricht der relativen Häufigkeit der ent-
sprechenden  Codierungen.  Im  Text  „koep5“  ist  beispielsweise  sehr  viel 
über „interne fördernde Faktoren“ die Rede, während darüber in den Tex-
ten „koep2“ und „koep4“ kaum etwas zu finden ist. Die visuelle Darstel-
lung ist vor allem für die Exploration sehr nützlich und unterstützt eine sys-
tematische Analyse des Datenmaterials – so lassen sich recht einfach aus-
gewählte Personen zum Vergleich nebeneinander anordnen. Für weiterge-

 

214 

Praktisches Arbeiten mit Kategoriensystemen 

hende statistische Analysen kann eine Matrix Texte mal Codes erstellt wer-
den, die die Zahlen der jeweils vorhandenen Textsegmente enthält. Diese 
Matrix ist Ausgangspunkt für die in Phase V vorgenommene Klassifikation. 
In dieser Phase geht es darum, die Strukturen und Zusammenhänge zwi-
schen Kategorien zu ermitteln. Dazu dient einerseits die Interpretation und 
systematische Suche nach dem gleichzeitigen Vorkommen von Kategorien 
und die Identifikation spezifischer Muster und Konfigurationen. 

 

 Abb. 77: Visualisierung der codierten Segmente pro Text 

11.7 Praktische Hinweise für MAXQDA 

Im hierarchisch organisierten Codesystem von MAXQDA können die Codes 
beliebig  arrangiert,  gruppiert  und  modifiziert  werden.  Codes  können  zu 
Subkategorien  anderer  Codes  werden  und  es  lassen  sich  jederzeit  neue 
Obercodes definieren. Vom Verschieben der Codes in der Struktur des Ka-

Praktische Hinweise für MAXQDA 

215 

tegoriensystems ist das Verschieben der codierten Segmente zu unterschei-
den, denn hierbei geht es gewissermaßen um die Verschiebung der Inhalte 
der Schubladen. 

Codes fusionieren 
Oft kommt es vor, dass man zwei Codes z.B. solche, die in der Phase des 
freien  Codierens  entstanden  sind,  zusammenfassen  will.  Bei  Codes  der 
höchsten Hierarchieebene gibt es dann die unten skizzierte Situation. 

Die Ausgangssituation 

Das Ziel 

 
 

 
 

 
 
 
 
 
 
 
 

 
 
 
 
 
 
 
 

Code 

 
 
 
 
 
 
 
 
Abb. 78: Codes fusionieren 

Code 

 
 
 
 
 
 
 
 

A 

B 

 
 
 
 
 
 
 
 

 
 
 
 
 
 
 
 

 
 
 
 

 
 

Code 
A+B 

Bildlich  gesprochen  sollen  die  in  den  Schubladen  A  und  B  befindlichen 
Karteikarten in eine Schublade zusammengeführt werden.  

Oberkategorie für zwei Codes einfügen 
Wenn man zu Beginn der Textauswertung im Stile des freien Codierens ei-
ne  Vielzahl  von  Codes  definiert  hat,  entsteht  bei  der  weiteren  Arbeit  mit 
den  Codes  häufig  der  Wunsch,  eine  neue  Oberkategorie  zu  bilden,  unter 
der die Codes subsumiert werden. 

Auch hier handelt es sich um eine Veränderung der Struktur des Code-
systems, bei der die zu einem Code vorhandenen Karteikarten gewisserma-
ßen  en  bloc  verschoben  werden  –  eine  Aufgabe,  die  mit  QDA-Software 
problemlos zu realisieren ist. 

 

216 

Praktisches Arbeiten mit Kategoriensystemen 

Code 

Die Ausgangssituation 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 
 
 
 
 
 
 
 
 
 
 
 
 
 

Code 

Code 

A

B

C

D

Code 

Das Ziel

Code

A

Code
Neu

Code

C

 
 
 
 
 
 
 
 
 
 
 
 
 
 

Code

B

Code

D

Abb. 79: Obercode für zwei Codes definieren 

Codes ausdifferenzieren 
Eine ebenfalls häufig eintretende Situation ist die, dass man eine Kategorie 
des Codesystems ähnlich wie bei der oben skizzierten Leitbildanalyse aus-
differenzieren möchte. So wurde im Projekt „Umweltkommunikation“ die 
Kategorie „Wunschprojektion/sozial“ definiert, um zu erfassen, welche auf 
den sozialen Bereich zielenden Wunschvorstellungen die Akteure der Initia-
tiven explizit oder implizit äußern. In den Interviewtexten wurden die ent-
sprechenden Textpassagen in der Phase der Grobcodierung codiert. Wäh-
rend der Analyse erschien es nun – wie oben skizziert – sinnvoll, verschie-
dene  Arten  von  sozialen  Wunschvorstellungen  (abgekürzt  als  WP/sozial) 
zu unterscheiden. Die folgende Abbildung schematisiert den Ablauf für den 
Fall, dass drei Subkategorien unterschieden werden sollen. 

Die Ausgangssituation 
 
 
 
 
 
 
 
 
 

 
 
 
Codewort 
 
  WP/sozial 
 
 
 

 
 
 
 
 
 
 
 

Das Ziel

Codewort
WB/sozial

Abb. 80: Codes ausdifferenzieren 

Ges. 
Visionen

Öffent-
lichkeit

LA 21 Ini

selbst

Bei  der  Ausdifferenzierung  von  Codes  ist  zunächst  dafür  zu  sorgen,  dass 
sich alle betreffenden Segmente in der „Liste der Codings“ hintereinander 

Praktische Hinweise für MAXQDA 

217 

befinden,  so  dass  die  Neuzuordnungen  nacheinander  vorgenommen  wer-
den können. Die Liste wird beginnend mit dem ersten Segment abgearbei-
tet:  Man  entscheidet  jeweils,  zu  welcher  der  neuen  Subkategorien  dieses 
Segment zugeordnet werden soll und wählt den zutreffenden Code in der 
Liste der Codes aus. 

Gleichzeitig mit dieser Feincodierung besteht die Möglichkeit, die Rele-
vanz  von  Segmenten  zu  markieren.  MAXQDA  erlaubt  es,  mit  jedem  co-
dierten Textsegment eine Gewichtungsvariable („Relevanz-Score“) zu asso-
ziieren. Es lassen sich dann für den späteren Forschungsbericht unschwer 
jene  Textstellen  markieren,  die  geradezu  prototypisch  für  eine  bestimmte 
Kategorie  sind.  Der  Wert  des  Relevanz-Scores  –  in  MAXQDA  kann  ein 
Wert zwischen 0 und 100 eingestellt werden – bringt dann zum Ausdruck, 
inwieweit  die  Leitbilddimension  bei  einem  bestimmten  Textsegment  zu-
trifft. 

Übungen 

1.  Definieren  Sie  einen  Code  „Agenda“  und  suchen  Sie  im  „Inter-
view1“  nach  Textpassagen,  in  denen  die  befragte  Person  über  die 
Agenda 21 spricht. Formulieren Sie freie Codes nahe am Text. Defi-
nieren  Sie  die  Codes  als  Subkategorie  von  „Agenda“  und  codieren 
Sie die Textpassagen entsprechend. 

2.  Versehen Sie die Codes mit farblichen Unterscheidungsmerkmalen: 
„Agenda“ –> rot; „Einstellungen/politisch“ –> gelb; „Verhalten“ –
> blau; „Intentionen“ –> rot. 

3.  Die Kategorie „Agenda“ kann man eigentlich als einen Subcode zu 
„Einstellungen/politisch“  sehen.  Deshalb  ändern  Sie  die  Position 
des Codes entsprechend. 

4.  Nun  haben  Sie  sich  doch  entschlossen,  auf  eine  Subkategorie 
„Agenda“  zu  verzichten  und  wollen  die  vorhandenen  Codierungen 
von „Agenda“ der Subkategorie „Einstellungen/politisch“ zuordnen. 
Löschen Sie danach die leere Subkategorie „Agenda“. 

5.  Ihr Kategoriensystem scheint nun fertig zu sein und sie möchten es 
exportieren um es z.B. in einer E-Mail zu verschicken. Exportieren 
Sie Ihr Kategoriensystem in eine Datei mit Namen „Codes“ und sehen 
Sie sich anschließend die Datei an. 

 

12  Wortbasierte Analysefunktionen 

 

12.1 Wortlisten und Diktionäre 

Neben der Grounded Theory ist die traditionelle, quantitativ orientierte In-
haltsanalyse die zweite sozialwissenschaftliche Forschungsmethode, die sich 
sehr intensiv mit dem Thema Kategorienbildung auseinandersetzt. Die Me-
thode der quantitativen Inhaltsanalyse hat eine lange Tradition, die (zumin-
dest) bis zu Max Weber zurückreicht, der schon 1910 auf dem ersten deut-
schen Soziologentag ein auf die Inhaltsanalyse aufbauendes Forschungspro-
gramm forderte: 

„...und  wir  werden  nun,  deutlich  gesprochen,  ganz  banausisch  anzufangen 
haben damit, zu messen, mit der Schere und mit dem Zirkel, wie sich denn 
der Inhalt der Zeitungen in quantitativer Hinsicht verschoben hat im Lauf 
der letzten Generation...“ (Weber 1911: 52) 

Den Sinn und Zweck der klassischen Inhaltsanalyse, die im Zuge der inter-
disziplinären  amerikanischen  Kommunikationsforschung  der  1940er  Jahre 
methodisch ausgearbeitet wurde, hat Berelson, einer der Pioniere der Me-
thode, prägnant beschrieben. Ihm zufolge ist die Inhaltsanalyse eine Unter-
suchungstechnik,  die  der  „objektiven,  systematischen,  und  quantitativen 
Beschreibung  des  manifesten  Inhaltes  von  Mitteilungen  aller  Art  dient“ 
(Berelson 1952). Zuvor festgelegte Merkmale von Kommunikationsinhalten 
sollen systematisch und objektiv erfasst werden. Kategorien haben in die-
ser, an der Forschungslogik des Kritischen Rationalismus orientierten Me-
thode den Status von Variablen, welche durch Indikatoren operationalisiert 
werden. Die in den Hypothesen enthaltenen Begriffe werden als Variablen 
formuliert,  operationalisiert  und  gemessen.  Variablenzusammenhänge  las-
sen sich dann quantitativ-statistisch überprüfen. Das Kategoriensystem ist 
in dieser Konzeption ein Messinstrument mit angebbaren Gütekriterien. 

Wortlisten und Diktionäre 

219 

Eine Vielzahl von inhaltsanalytischen Verfahren ist entwickelt worden: 
Themenanalyse,  Frequenzanalyse,  Kontingenzanalyse,  Bewertungsanalyse  und  andere 
spezielle Methoden mehr.29 Klaus Merten hat die einzelnen Verfahren im 
Detail  beschrieben  (vgl.  Merten  1995).  Viele  der  vorgestellten  Techniken 
werden aber in der Forschungspraxis nur selten eingesetzt. Von größerem 
Verbreitungsgrad sind Verfahren der Themenanalyse bzw. Frequenzanalyse, die 
sich für die Häufigkeit von Worten und Wortkombinationen im Text bzw. 
in  Texten interessieren  (vgl. Früh 2004:  135 ff.). Die  berechneten  Häufig-
keitstabellen können etwa dazu dienen, verschiedene Texte zu vergleichen 
und  aus  der  Differenz  von  Wortbeständen  inhaltliche  und  theoretische 
Schlüsse zu ziehen. Ferner lassen sich Konkordanzen und Wortassoziatio-
nen ermitteln. 

Seit den 1960er Jahren bestehen Bemühungen, die traditionelle Inhalts-
analyse  als  Computerunterstützte  Inhaltsanalyse  (CUI)  zu  betreiben.  Entspre-
chende Software wurde entwickelt, zunächst für den Großrechner (z.B. das 
Programm General Inquirer), seit den 1980er-Jahren auch für den PC, z.B. 
Textpack  (vgl.  Züll/Mohler/Geis  1991),  Intext  (vgl.  Klein  1997),  Oxford 
Concordance und eine Reihe weiterer Programme.30 

Im Rahmen der Auswertung von qualitativen Daten sind Techniken der 
computergestützten  quantitativen  Inhaltsanalyse  bisher  kaum  beachtet 
worden. Dabei hat die von ihren Protagonisten „CUI“ (Züll/Mohler 1992) 
genannte Form der computerunterstützten Inhaltsanalyse durchaus einiges 
an Anregungen zu bieten, denn dort sind Techniken entwickelt worden, die 
einer explorativen, heuristisch angelegten Forschung wertvolle Dienste er-
weisen  können.  Wortlisten,  Diktionäre  und  diktionärsbasierte  Codierung 
können auch bei der Auswertung qualitativen Materials gewinnbringend ein-
gesetzt werden. Zudem hat sich die CUI schon seit längerer Zeit mit Fragen 
und  Problemen  befasst,  die  zunehmend  auch  im  Bereich  der  qualitativen 
Datenanalyse  diskutiert  werden,  beispielsweise  mit  der  Frage  der  Qualität 
von Codierungen, der Organisation des Codierens im Team und der Über-
einstimmung von Codierern. Das Verfahren der CUI wird in vielen Diszi-
                                                           
 
29 Überblicke über die verschiedenen Verfahren bzw. Darstellungen des Ablaufs der klassi-
schen Inhaltsanalyse geben Merten (1995), Früh (2004) und Rössler (2005). Eine Vielzahl 
von Beispielen aus der Forschungspraxis sind enthalten in Bos/Tarnai (1989 und 1996), 
Züll/Mohler (1992) und Wirth/Lauf (2001). 

30 Einen  guten  Überblick  hierzu  geben  Alexa/Züll  (1999).  Links  auf  die  Software  findet 

man auf der von Harald Klein unterhaltenen Webseite www.textanalysis.info. 

 

220 

Wortbasierte Analysefunktionen 

plinen verwendet, nicht nur in der Kommunikationswissenschaft und Pub-
lizistik, sondern auch in den Sozialwissenschaften, der Psychologie und der 
Medienforschung (Züll/Mohler 1992).  

In der Tradition von Lasswell, Berelson u.a. befasst sich die Inhaltsana-
lyse also nicht mit Interpretationen und nicht mit dem latenten Inhalt von 
Texten (vgl. Merten 1995, Wirth/Lauf 2001). Eine Schlüsselposition besit-
zen die Kategorien, die den Kern der inhaltsanalytischen Methode darstel-
len. Die computergestützte Variante CUI arbeitet mit Wortlisten, Wortin-
dex und Diktionär. 

Eine Wortliste ist eine Zusammenstellung aller in einem Text oder einer 
Gruppen von Texten vorkommenden  Wörter.  Dabei ist ein Wort für die 
Inhaltsanalyse jede Abfolge von Zeichen, die sich zwischen zwei Leerzei-
chen  bzw.  abzutrennenden  Zeichen  (bspw.  Komma,  Semikolon,  Doppel-
punkt, Punkt etc.) befindet. Wortlisten können als alphabetische Wortliste 
oder als Häufigkeitswortliste sortiert sein. Spezielle Wortlisten stellen die so 
genannten Stopp-Listen und Go-Listen dar. Während Stopp-Listen solche 
Wörter enthalten, die bei der Auswertung nicht interessieren (z.B. bestimm-
te und unbestimmte Artikel, Pronomina, Konjunktionen, Zahlwörter Kon-
junktionen, nicht sinntragende Wörter), bestehen Go-Listen umgekehrt aus 
einer Sammlung von Worten, die im Fokus der Aufmerksamkeit liegen und 
auf die sich die Auswertung beschränken soll. 

Ein Wortindex ist eine Liste von Wörtern und ihren Referenzen, d.h. der 

Stellen, wo sie im Text bzw. in den Texten vorkommen. 

Ein Diktionär oder Wörterbuch besteht aus Kategorien und Wörtern bzw. 
Zeichenketten,  die  diesen  Kategorien  zugeordnet  sind.  Einer  Kategorie 
„Europa“ können bspw. die Wörter „England“, „Italien“, „Deutschland“, 
„Belgien“,  „Niederlande“,  „Schweiz“  und  „Spanien“  zugeordnet  werden. 
Diktionäre sind im Prinzip projektunabhängig, sie können theoretisch im-
mer wieder verwendet werden. 

12.2 Das Prinzip diktionärsbasierter Inhaltsanalyse 

Startpunkt der CUI ist ein Textkorpus, bestehend aus Einzeltexten. Diese 
können ggf. in Abschnitte unterteilt sein, wie ein Buch in verschiedene Ka-
pitel  gegliedert  ist.  Diese  Abschnitte  werden  auch  als  Texteinheiten  oder 
Codiereinheiten bezeichnet. Angenommen man habe in einer schriftlichen 

Das Prinzip diktionärsbasierter Inhaltsanalyse 

221 

Befragung drei offene Fragen gestellt, so liegt es nahe, die Daten so aufzu-
bereiten, dass man drei  Texteinheiten (Antwort auf  Frage 1, Antwort auf 
Frage 2, Antwort auf Frage 3) definiert. Das Diktionär ist Grundlage für die 
Vercodung der Texte. Es besteht einerseits aus den Kategorien und ande-
rerseits aus Wörtern, Wortstämmen oder Mehrwortkombinationen, die die-
sen Kategorien zugeordnet sind – so wie im unten abgebildeten Beispiel die 
Wörter „Belgien“ und „Niederlande“ zur Kategorie „Europa“ gehören. 

Texte 
 
- Text 1 
- Text 2 
- … 
- Text n 

Kategorien 
 
1 Asien 
2 Nordamerika 
3 Europa 
4 Australien 
5 Südamerika 

Wörterbuch 
 
Aalräucherei 
.. 
Belgien 
.. 
.. 
Niederlande 
.. 
.. 
.. 
Zylinderstifte 

Durchsucht alle Texte daraufhin, ob Wörter des Diktionärs vorkommen 

und hält die Häufigkeit des Vorkommens fest 

Codierfunktion 

Ergebnistabelle 

eine Matrix Texteinheiten x Kategorien 

 
Kategorien 

Nordamerika 

 
 
Text 1 
Text 2 
Text n 

Asien 

3 
.. 
8 

31 
.. 
9 

Europa 

11 
.. 
41 

Australien 

8 
.. 
2 

Statistische Analyse der Ergebnistabelle 

 

Abb. 81: Schema einer diktionärsbasierten Inhaltsanalyse 

Unter  Codieren  wird  dabei  etwas  anderes  als  bei  der  qualitativen  Daten-
analyse verstanden. Es geht nicht um die Zuordnung einer Kategorie zu ei-
ner einschlägigen Textpassage, sondern um einen Vorgang der Klassifikati-

 

222 

Wortbasierte Analysefunktionen 

on und  anschließendes Zählen der Kategorienhäufigkeiten. Dabei stellt das 
Wörterbuch die Basis des Codierens in der CUI dar. Der eigentliche Codier-
vorgang  verläuft  sequentiell  und  beginnt  mit  dem  ersten  Wort  des  ersten 
Textes. Wann immer ein Wort gefunden wird, das im Wörterbuch enthal-
ten ist, wird der Zähler der betreffenden Kategorie um 1 erhöht. Wenn der 
gesamte Text durchgearbeitet ist, wird eine Statistik für diesen Text erstellt, 
die folgende Informationen enthält: Anzahl der insgesamt codierten Worte, 
Anzahl der codierten Stellen für Kategorie 1, Anzahl der codierten Stellen 
für  Kategorie  2  usw.31  Nach  diesem  Schema  wird  auch  mit  den  übrigen 
Texten verfahren, so dass am Ende eine Tabelle Texte mal Kategorien als 
Ergebnis produziert wird. Diese Ergebnistabelle, die pro Text die Häufig-
keit der Kategorien enthält, kann anschließend statistisch analysiert werden. 

12.3 CUI und qualitative Datenanalyse 

Wozu  können  die  Funktionen  der  quantitativen  Inhaltsanalyse  nun  im 
Rahmen  der  qualitativen  Datenanalyse  dienen?  Im  Vordergrund  stehen 
eindeutig Heuristik und Exploration, denn die auf Interpretation und intel-
lektuelle Codierung abstellende qualitative Analyse ist nur in Ausnahmefäl-
len an der automatischen Vercodung interessiert. Das gilt insbesondere für 
eine Vercodung, die auf Wortbasis stattfindet und insofern weit hinter den 
Stand  menschlichen  Fremdverstehens  zurückfällt.  In  Ansätzen  wie  der 
Grounded Theory wird, wie in Kap. 4 ausgeführt, mit einem völlig anderen 
Begriff von Codieren gearbeitet. Während die Inhaltsanalyse unter Codie-
ren einen Klassifikationsvorgang unter eine präzise beschriebene Kategorie 
versteht, betrachtet die Grounded Theory das Codieren als einen Vorgang 
der Generierung von etwas Neuem, nämlich Konzepten, Hypothesen und 
Theorien.  Einerseits  werden  gewissermaßen  theoriebasierte  Daten  erzeugt, 
indem Textstellen bzw. präziser gesagt Wörter in ein theoretisch legitimiertes 
Kategoriensystem übersetzt werden, andererseits wird datenbasierte Theorie 
generiert.  Die  Perspektiven  sind  also  geradezu  gegenläufig.  Während  die 
Inhaltsanalyse gespannt auf die Entwicklung von Algorithmen wartet, die in 
                                                           
 
31 Eine andere Form der Aufzeichnung der Codierergebnisse besteht darin, die Codiervor-
gänge in ihrer Abfolge festzuhalten, so dass Sequenzanalysen der Kategorien ermöglicht 
werden. 

Praktische Hinweise für MAXQDA 

223 

der  Lage  sind,  Sprache  automatisch  zu  erkennen  und  zu  verstehen,  lässt 
diese Perspektive die qualitative Position völlig kalt, denn bei der Generie-
rung von Theorien kann so etwas mitnichten helfen, denn es ist nicht zu 
erwarten, dass Maschinen den Menschen im Theoretisieren übertreffen und 
selbst wenn es so wäre, bliebe es wahrscheinlich unbemerkt. 

Qualitative Forschung arbeitet primär mit Sprache und diese besteht aus 
Wörtern und so hat die qualitative Analyse sehr wohl ein Interesse daran, 
zu eruieren, welche Wörter von wem benutzt werden, wie häufig Wörter in 
bestimmten Texten auftauchen und in welchem Kontext sie stehen. Alpha-
betische Wortlisten und Häufigkeitswortlisten für einzelne Texte oder für 
speziell zusammengestellte Textgruppen sind für die qualitative Analyse al-
so durchaus interessant. Ferner existieren auch Formen von verbalen Da-
ten, deren Merkmale durchaus eine automatische Vercodung erlauben. Wir 
fragen beispielsweise in einer Befragung von PädagogikstudentInnen in wel-
chen Arbeitsfeldern und mit welchem Klientel sie gerne nach der Diplom-
prüfung  arbeiten  würden.  Forschungsmethodisch  ist  es  vorzuziehen  diese 
Frage  offen zu stellen, anstatt eine lange Liste von möglichen Antworten 
vorzugeben. Hier kann es – vor allem dann, wenn man viele Personen be-
fragt – zeitsparend und vor allem reliabler sein, wenn man automatisch ver-
codet. 

12.4 Praktische Hinweise für MAXQDA 

MAXDictio,  ein  Zusatzmodul  von  MAXQDA,  erschließt  die  Techniken 
der CUI für die qualitative Datenanalyse. Es lassen sich Wortbestände von 
Texten ermitteln und miteinander vergleichen, Worthäufigkeiten auszählen, 
Gruppenvergleiche vornehmen sowie Go-Listen und Stopp-Listen erstellen 
und  bei  der  Auszählung  des  Materials  benutzen.  Zu  jedem  Wort  einer 
Wortliste  –  sei  sie  nun  alphabetisch  oder  nach  Häufigkeit  sortiert  –  lässt 
sich ein Wortindex anfertigen mit der Möglichkeit, von jedem Indexeintrag 
zu der zugrunde liegenden Textstelle zu springen. Dies ermöglicht es, so-
gleich zu ermitteln, in welchem Kontext bestimmte Wörter im Datenkor-
pus auftauchen. 

Für die wortbasierte Codierung und Häufigkeitsauszählung können Dik-
tionäre mit beliebig vielen Kategorien aufgebaut werden. Die Suchbegriffe 
können  direkt  aus  einer  Wortliste  in  das  Wörterbuch  transferiert  werden. 

 

224 

Wortbasierte Analysefunktionen 

Die  diktionärsbasierte  Codierung  kann  auf  bestimmte  Texte  oder  auf  die 
mit einem bestimmten Code versehenen Segmente beschränkt werden. So 
lassen  sich  beispielsweise  die  Sprecher  einer  Gruppendiskussion  getrennt 
auswerten oder wie das folgende Beispiel zeigt nur Antworttexte auf aus-
gewählte offene Fragen bearbeiten. Die Resultate einer diktionärsbasierten 
Inhaltsanalyse  können  mittels  einer  Validierungsdatei,  die  den  gesamten 
Text  und  die  vorgenommenen  Zuordnungen  enthält,  überprüft  werden. 
Die Ergebnistabelle lässt sich zum Zwecke der statistischen Analyse expor-
tieren. 

Forschungsbeispiel 
In  einer  regelmäßig  durchgeführten  Befragung  von  StudienanfängerInnen 
werden  u.a.  offene  Fragen  zu  den  Motiven  für  die  Auswahl  des  Studien-
fachs  und  Studienorts  und  zur  gewünschten  späteren  Berufstätigkeit  ge-
stellt.  Solche  offenen  Fragen  gibt  man  am  besten  in  einer  strukturierten 
Form ein (vgl. Kap. 2.7), so dass die Antworten der Befragten von vornhe-
rein  bestimmten  Fragen  zugeordnet  sind,  genauer  gesagt  wird  ihnen  eine 
Fragenummer  oder  ein  inhaltliches  Kürzel  zugeordnet.  Die  diktionärsba-
sierte  Inhaltsanalyse  der  Antworten  zum  Thema  „angestrebte  spätere  Be-
rufstätigkeit“ durchläuft nun folgende Schritte. 

Schritt 1: Erstellen einer Häufigkeitswortliste 
Alle Texte der Befragten und die Kategorie „Spätere berufliche Tätigkeit“ 
werden aktiviert. Das Resultat ist eine vollständige Liste aller auf diese Fra-
ge  gegebenen  Antworten.  Für  die  Gesamtheit  der  Antworten  wird  eine 
Häufigkeitswortliste  erstellt.  Dabei  erweist  sich  eine  Stopp-Liste,  die  eine 
Sammlung  von  nicht  inhaltstragenden  Worten  enthält,  als  sehr  nützlich, 
weil die Häufigkeitswortliste dann nur noch die für eine Codierung interes-
santen Wörter beinhaltet. Mit Hilfe dieser bereinigten Häufigkeitsliste lässt 
sich das Diktionär im nächsten Schritt erstellen, ohne dass man Suchbegrif-
fe eintippen muss. 

Schritt 2: Konstruktion des Diktionärs 
Wir definieren nun die Hauptkategorien anhand der klassischen pädagogi-
schen  Berufsfelder:  Erwachsenenbildung,  Sozialarbeit/Sozialpädagogik, 
Sonderpädagogik und Therapie. Ferner definieren wir eine Kategorie „weiß 
noch nicht“. Am besten bearbeitet man nun die sortierte Häufigkeitswort-

Praktisc

che Hinweise fü

ür MAXQDA

225 

n systematisc
liste in
en Worten u
mende
ung zweifelha
ordnu
tellen werden
Textst
um ein
ndeutige Zuo
en. 
werde

cher Weise: M
nd ordnet sie
aft ist, wird ei
n zunächst ge
ordnungen zu

Man beginnt m
e den Katego
n Wortindex
enauer inspiz
u erreichen, M

mit den am h
orien zu. Bei 
x erstellt und 
ziert. Unter U
Mehrwort-Su

häufigsten vo
Worten, dere
die entsprech
Umständen m
uchbegriffe de

orkom-
en Zu-
henden 
müssen, 
efiniert 

Schritt 
Probe
jeder T
stellt, 
Protok
ersten
man  n
noch i
Codie
lange d

t 3: Probeweises
eweise wird d
Text Wort fü
in der alle Z
kolldatei  („V
ns hinsichtlich
nicht  intendi
in das Diktio
rung  auslöse
durchlaufen, 

s Codieren und 
die diktionärs
ür Wort durc
Zuordnungen
Validierungsd
h von möglic
ert  hat,  und 
onär aufgenom
en.  Die  Schri
bis eine zufr

Überprüfen der
basierte Cod
chgegangen. 
n von Katego
datei“)  sollte 
cherweise vor
zweitens  hin
mmen werde
itte  2  und  3 
rieden stellend

r Codierungen
dierung durch
Es wird eine
orien eingetra
sorgfältig  k
rgenommene
nsichtlich  de
en müssen, w
werden  in  z
de Codierung

hgeführt, dab
e Protokollda
agen werden.
kontrolliert  w
en Codierung
er  Suchbegrif
weil sie bislang
zirkulärer  We
g erreicht ist. 

ei wird 
atei er-
. Diese 
werden, 
gen, die 
ffe,  die 
g keine 
eise  so 

Schritt 
Nun  e
Codie
tet. W
keitsei
eine T
deren 

t 4: Ausführen 
erfolgt  der  e
rung. Beginn
Wörter, die im
intrag  in  der 
Tabelle wie di
Statistik-Soft

der automatisch
ndgültige  Du
nend mit dem
m Diktionär g
betreffenden
ie in Abb. 82
ftware exporti

hen Codierung 
urchlauf  durc
m ersten Text 
efunden werd
n  Kategorie 
2 wiedergegeb
iert werden k

und Export de
ch  die  Texte
werden alle 
den, bewirke
um  1  erhöh
bene, die zu S
kann. 

er Ergebnistabe
  mit  automa
sequentiell b
en, dass der H
ht  wird.  Es  en
SPSS oder ein

elle 
atischer 
earbei-
Häufig-
ntsteht 
ner an-

 

Abb. 82

2: Resultat des

s Codiervorgan

ngs 

 

226 

Übungen 

Wortbasierte Analysefunktionen 

1.  Für  alle  folgenden  Übungen  benötigen  Sie  die  Datei  „Bibel.mx3“ 

(Download: www.maxqda.de/downloads/Bibel-NT.mx3). 

2.  Öffnen Sie diese Datei und aktivieren Sie den Text „Lukas“. 
3.  Erstellen Sie eine Tabelle der Worthäufigkeiten nur für diesen Text. 

Welche Wörter tauchen am häufigsten im Text „Lukas“ auf?  

4.  Sortieren Sie die Tabelle alphabetisch (aufsteigend, absteigend). 
5.  Sortieren Sie erneut nach Häufigkeit. Befördern Sie die bestimmten 
und  unbestimmten  Artikel  und  nicht  sinntragende  Worte  in  die 
Stopp-Liste.  Speichern  Sie  die  Stopp-Liste  unter  dem  Namen 
„stoppliste1“. 

6.  Erstellen Sie einen Wortindex für „Petrus“. Wie oft wird Petrus im 
Lukas-Evangelium erwähnt? Sehen Sie sich einige Fundstellen durch 
Anklicken an. 

7.  Starten Sie die Diktionärsfunktion. Speichern Sie das leere Diktionär 
unter dem Namen „dictionaer1“. Definieren Sie jetzt die Diktionärs-
kategorien „Natur”, „Böses”, „Frauen” und „Engel” und speichern 
Sie das Diktionär als „dictio2“. 

8.  Definieren Sie zur Kategorie „Frauen” den Suchbegriff „Frau” und 

zur Kategorie „Engel” den Suchbegriff „Engel”. 

9.  Begrenzen Sie die Zählung der Worthäufigkeiten auf die Diktionärs-
worte und zählen Sie den Text Lukas aus. Welche Ergebnisse haben 
Sie? 

10. Zählen Sie nun erneut alle Wörter des Textes „Lukas“ aus, d.h. nicht 
nur  die  Diktionärsworte.  Blättern  Sie  durch  das  Zählergebnis  der 
Worthäufigkeiten. Wenn Sie auf Wörter stoßen, die Indikatoren für 
eine der vier Kategorien sind, transferieren Sie diese in das Diktio-
när. Führen Sie dies für mindestens 20 Wörter durch. 

11. Begrenzen Sie die Zählung der Worthäufigkeiten jetzt auf die Dik-
tionärsworte und zählen Sie den Text „Lukas“ aus. Welche Ergeb-
nisse haben Sie? 

 

13  Kombination mit statistischen Verfahren: 

Ähnlichkeiten, Muster und Typologien 

13.1 Über Klassifikationsverfahren 

Das folgende Kapitel stellt einige Möglichkeiten vor, wie quantitative Ver-
fahren sinnvoll in den Prozess der Analyse qualitativer Daten zu integrieren 
sind. Es ist vermutlich für jene, die mit statistischen Verfahren wenig ver-
traut sind, nicht leicht zu lesen. Intention ist es, zu zeigen, dass die Kombi-
nation von qualitativen und quantitativen Methoden mit Gewinn praktiziert 
werden kann. 

Auch die qualitative Datenanalyse verfolgt das Ziel, Muster in den Da-
ten zu entdecken und spricht in diesem Zusammenhang von Typen, Orientie-
rungsmustern u. Ä.. Die Technik der Kategorisierung und Codierung der Da-
ten ist eine Vorgehensweise, die zunächst Textstellen de-kontextualisiert und 
die Texte zergliedert. Um im Verlauf der Analyse zu Typen und Orientie-
rungsmustern zu gelangen, bedarf es einer Re-Aggregation. Qualitative Daten 
sind,  weit  mehr  noch  als  quantitative,  hoch  komplex,  und  angesichts  der 
Fülle des Materials ist es außerordentlich schwierig, Muster in den Daten zu 
finden,  die  diesen  auch  tatsächlich  gerecht  werden.  Man  mag  sich  an  die 
Aussagen von Alfred Schütz erinnern, dass Menschen  auch in ihrem All-
tagsleben  mit  Hilfe  von  Abstraktionen  und  Typisierungen  operieren  und 
infolgedessen Prozeduren der Klassifikation und der Typenbildung unter-
schwellig  immer  am  Werke  sind,  auch  dann,  wenn  keine  expliziten  Zähl-
vorgänge im mathematischen Sinne in Erscheinung treten. Wenn der Um-
fang  der  zu  verarbeitenden  Daten  die  eigenen  Wahrnehmungskapazitäten 
übersteigt, läuft man Gefahr, vorschnell  Typisierungen vorzunehmen und 
das  Datenmaterial  anschließend  nur  noch  in  bloß  affirmativer  Weise  mit 
Blick auf die Bestätigung der mehr intuitiv vorgenommenen Typisierungen 
zu selektieren. Nun ist die Suche nach Mustern in den Daten eine ganz be-
sondere Stärke von Computern. Hat man eine solche klassifizierende Vor-
arbeit wie die Codierung von Textsegmenten bereits geleistet, so lassen sich 

228 

Kombination mit statistischen Verfahren: Ähnlichkeiten, Muster und Typologien 

diese  Fähigkeiten  gewinnbringend  nutzen.  Dies  gilt  insbesondere  dann, 
wenn  man  Fallvariablen  zur  Bewertung  des  Datenmaterials  definiert  hat 
und diese nun auf Koinzidenzen und Kovariationen hin untersuchen will. 

Zu diesem Zwecke kann man auf eine Reihe von statistischen Verfahren 
zur Entdeckung von komplexen Mustern zurückgreifen. Diese reichen von 
der eher deskriptiven Konfigurationsfrequenzanalyse bis hin zur Faktoren- 
und  Clusteranalyse,  der  Latent  Class  Analyse  und  log-linearen  Modellen. 
Der Einsatz dieser statistischen Verfahren ist aber nicht immer problemlos 
möglich,  denn  zum  einen  stellt  die  meist  nur  relativ  geringe  Populations-
größe von qualitativen Studien ein Problem dar, zum anderen das Skalenni-
veau der vorgenommenen Codierungen, denn dieses ist in den meisten Fäl-
len dichotom oder nominal und erreicht nur selten metrisches Niveau. 

Besonders geeignet für diesen Datentyp sind deshalb Verfahren wie die 
Konfigurationsfrequenzanalyse und die Clusteranalyse, die nicht von beson-
deren Verteilungsannahmen ausgehen und die in der Lage sind, auch mit 
nicht-metrischen Daten komplexe Muster zu identifizieren. Der Grundge-
danke  lässt  sich  am  Beispiel  der  Vorgehensweise  der  Konfigurationsfre-
quenzanalyse (KFA) erläutern. Zweck der KFA ist es, typische Kombinatio-
nen, d.h. überzufällig häufige oder seltene Kombinationen herauszufinden. 
Angenommen, man habe in einer Studie aus der Schulforschung drei dicho-
tome Merkmale definiert: a) Unterrichtsform (Frontal/Gruppe), b) Schüler-
urteil über Lehrerverhalten (freundlich/unfreundlich), c) Schülerzufrieden-
heit (gern/ungern zur Schule), so ergeben sich 8 Konfigurationen: 

1 
2 
3 
4 
5 
6 
7 
8 

Unterricht frontal 
Unterricht frontal 
Unterricht frontal 
Unterricht frontal 
Unterricht Gruppe 
Unterricht Gruppe 
Unterricht Gruppe 
Unterricht Gruppe 

Lehrer freundlich 
Lehrer unfreundlich 
Lehrer freundlich 
Lehrer unfreundlich 
Lehrer freundlich 
Lehrer unfreundlich 
Lehrer freundlich 
Lehrer unfreundlich 

gern zur Schule 
gern zur Schule 
ungern zur Schule 
ungern zur Schule 
gern zur Schule 
gern zur Schule 
ungern zur Schule 
ungern zur Schule 

Anhand  der  Daten  lässt  sich  überprüfen,  welche  der  acht  Kombinations-
möglichkeiten überhaupt vorkommen. Ferner lassen sich – und hier wird 
die Angelegenheit statistisch – Erwartungswerte von Konfigurationen be-
rechnen, und zwar in ähnlicher Weise wie die Berechnung von Chi-Quadrat 
bei  der  Analyse  von  Kontingenztabellen,  nämlich  als  Produkt  der  Wahr-

Über Klassifikationsverfahren 

229 

scheinlichkeiten der einzelnen Kategorien, d.h. ihrer Randverteilungen. Bei 
einer  Stichprobengröße  von  N=80  und  einer  Gleichverteilung  der  drei 
Merkmale – z.B. 40-mal Frontalunterricht, 40-mal Gruppenunterricht – wür-
de  man  für  jede  Konfiguration  N=10  Personen  erwarten.  Zeigt  sich  nun, 
dass  bestimmte  Konfigurationen,  z.B.  „Gruppenunterricht,  Lehrer  freund-
lich, Schüler gehen gerne zur Schule“ häufiger als zehnmal, andere hingegen 
seltener oder gar nicht vorkommen, so kann man dies als das Vorliegen ei-
nes Musters interpretieren. Es liegt nahe, die empirischen Häufigkeiten ei-
ner Konstellation mit den erwarteten Häufigkeiten zu vergleichen und ei-
nen entsprechenden Test, z.B. den Chi-Quadrat-Test, durchzuführen. 

Ist das Textmaterial einmal codiert, dann bereitet es nur wenig zusätzli-
che Mühe, auf diese formalisierte Weise nach Mustern zu suchen. So vor-
zugehen, verstößt auch nicht gegen Ansprüche einer interpretativen Analy-
se, denn das statistische Verfahren wird hier lediglich als Hilfsmittel bei ei-
nem bestimmten Analyseschritt eingesetzt. Anschließend können und müs-
sen die entdeckten Muster wieder interpretativ gefüllt werden. 

In Bezug auf die Mustererkennung kann man zwischen einer variablen-
orientierten  und  einer  fallorientierten  Vorgehensweise  unterscheiden.  Die  va-
riablenorientierte Vorgehensweise wird bei quantitativen Forschungen be-
vorzugt  angewandt.  Gesucht  wird  nach  Konstellationen  von  Merkmalen, 
d.h. danach, welche Merkmale miteinander kovariieren und korrelieren. Die 
fallorientierte  Vorgehensweise  ist  hingegen  in  der  Mainstream  Survey-
Forschung, mit Ausnahme der Lebensstilforschung, nur selten anzutreffen. 
Hier  wird  nach  Konstellationen  von  Personen  gesucht:  Welche  Personen 
ähneln einander? Welche Gruppen von Personen lassen sich identifizieren, 
deren Mitglieder untereinander ähnlich sind, die sich aber wechselseitig von-
einander stark unterscheiden? 

In  den  beiden  folgenden  Abschnitten  werden  beide  Vorgehensweisen 
anhand  von  Beispielen  skizziert.  Das  Datenmaterial  stammt  wieder  aus 
Projekten der Umweltforschung. Wenn qualitative Daten nach einer Phase 
der Codierung von Textsegmenten im Hinblick auf das Vorkommen von 
Mustern  und  Typen  betrachtet  werden,  wird  die  Forschungsfrage  in  den 
meisten  Fällen  eher  eine  fallorientierte  Vorgehensweise  nahe  legen.  Der 
folgende Abschnitt thematisiert im Detail, wie hierbei vorzugehen ist. Dass 
aber auch eine variablenorientierte Vorgehensweise durchaus Sinn machen 
kann, zeigt das Kapitel 11.3, in dem es um die Identifikation von Orientie-
rungsmustern im Rahmen der oben skizzierten Leitbildanalyse geht. 

 

230 

Kombination mit statistischen Verfahren: Ähnlichkeiten, Muster und Typologien 

13.2 Ähnlichkeiten zwischen Personen ermitteln 

Vergleiche  anzustellen,  Fälle  zu  kontrastieren  und  Ähnlichkeiten  heraus-
zuarbeiten, dies gehört zu den wesentlichen Zielsetzungen qualitativer Da-
tenanalyse. Es geht darum, Muster zu erkennen und die Bedingungen von 
Konstellationen  zu  ermitteln,  etwa  wie  Hopf  u.a.  (1995)  dies  in  ihrer 
Rechtsextremismus-Studie  tun,  um  bestimmte  Beziehungserfahrungen  der 
Probanden  auf  ihren  Zusammenhang  zu  rechtsextremen  Orientierungen 
hin zu untersuchen. 

Eine Frage, die sich in diesem Kontext mehr oder weniger automatisch 
stellt, ist: „Welche Personen ähneln einander und welche sind sich gänzlich 
unähnlich?  Im  gleichen  Atemzuge  stellt  sich  natürlich  die  Frage:  Ähneln 
sich, in welcher Hinsicht? Welche Merkmale und Eigenschaften sind für die 
Forschungsfrage  von  primärer  Relevanz,  welche  sind  eher  sekundär.  Bei 
einer Studie über die Bewältigung von Arbeitslosigkeit wird man vielleicht 
feststellen, dass es charakteristische Veränderungen im Verhalten von Per-
sonen gibt: Ihr Leben verlangsamt sich, sie lesen weniger Bücher, gehen so-
gar  langsamer  über  die  Straßenkreuzung  (vgl.  Jahoda/Lazarsfeld/Zeisel 
1980). Man wird dieses Muster dann z.B. als apathischen Haltungstyp bezeich-
nen. Nun ist es keineswegs einfach, solche Muster zu erkennen und mit ei-
ner  eingängigen  Bezeichnung  zu  versehen.  Auch  bei  intensiver  Kenntnis 
der vorliegenden Interviews ist man normalerweise nicht in der Lage, ohne 
zusätzliche  Hilfsmittel  eine  Reihe  von  Merkmalen  und  Charakteristika  in 
einer systematischen Typologie darzustellen. Man kann sich in diesem Feld 
durchaus nutzbringend des Hilfsmittels der Formalisierung mittels mathe-
matischer Verfahren bedienen. Formalisierte Methoden der Ähnlichkeitsbe-
stimmung  erlauben  es,  multivariate  Konstellationen  zu  identifizieren,  und 
dies kann für die Arbeit des Forschers eine wertvolle Hilfe darstellen. Sol-
che Methoden werden mit explorativer und heuristischer Intention einge-
setzt  und  nicht,  um  Signifikanzkoeffizienten  zu  berechnen  oder  Theorien 
zu testen. Doch sie dienen der Systematisierung und Organisierung des Ma-
terials und können die datenbasierte Theoriekonstruktion befördern. 

 

Beispiel: Aus den Informationen eines leitfadenstrukturierten Interviews las-
sen sich verschiedene umweltrelevante Verhaltensweisen aus den Bereichen 
Verkehr und Einkauf herausarbeiten. Zu acht Verhaltensweisen (Abb. 83) 

Ähnlichkeiten zwischen Personen ermitteln 

231 

wurde jeweils codiert, ob die Befragten angeben, das Verhalten zu praktizie-
ren oder nicht. 

Verkehrsverhalten 

Praktiziert 

Profil Person A 

Nicht mit dem Auto zur Arbeit fahren 

Keine Flugzeugbenutzung bei längerer Fahrt  
(mehr als 6 Stunden) 

Wochenendausflug ohne Auto 

Urlaubsreise nicht mit dem Flugzeug 

Einkaufsverhalten  

Kauf von Recycling-Toilettenpapier 

Kauf von Mehrkomponentenwaschmittel 

Kein Kauf von Treibhaussalat im Winter 

Kein Kauf von Früchten und Gemüsen wie  
Erdbeeren unabhängig von der Jahreszeit 

ja/nein 

ja/nein 

ja/nein 

ja/nein 

 

ja/nein 

ja/nein 

ja/nein 

ja/nein 

1 

0 

0 

1 

 

0 

1 

0 

0 

Abb. 83: Umweltrelevante Verhaltensweisen und das Profil der Person A 

Die Verhaltensweisen jedes Interviewten lassen sich als ja-nein-Merkmale, 
beispielsweise mit den Codes j (=ja) und n (=nein) oder mit 0/1 codieren, 
und  zwar  derart,  dass  das  Vorhandensein  einer  umweltgerechten  Verhal-
tensweise mit 1, das Nicht-Vorhandensein mit 0 codiert wird. Der in der 
dritten Spalte dargestellte Musterbefragte „A“ fährt also nicht mit dem Au-
to zur Arbeit und verzichtet auf das Flugzeug bei der Urlaubsreise. Bei zwei 
der vier erfragten Indikatoren für Verkehrsverhalten verhält er sich umweltge-
recht (1 und 4). Beim Einkaufsverhalten sieht es etwas ungünstiger aus, von 
vier Verhaltensweisen wird hier nur einmal die umweltgerechte Verhaltens-
variante praktiziert. 

Da SPSS Distanz- und Ähnlichkeitsmatrizen nur mit numerischen Va-
riablen berechnet, müssen ggf. als Stringvariable eingegebene Werte auto-
matisch recodiert werden, am besten zu  einer 0/1 Codierung, denn dann 
lässt sich mit SPSS sehr einfach ermitteln, welche Personen sich in ihrem 
Verhaltensmuster ähneln. 

Wie  ist  nun  „Ähnlichkeit“  zu  definieren  und  vor  allem,  wie  ermittelt 
man diese? Angenommen, man wolle den obigen Befragten, Person A, mit 
einer anderen Person C vergleichen: Person C besitzt kein Auto und zeigt 
mit Ausnahme der Flugreise in die Ferien ein umweltgerechtes Verkehrs-

 

232 

Kombination mit statistischen Verfahren: Ähnlichkeiten, Muster und Typologien 

verhalten. In Abb. 84 sind die Daten von Person A und Person C unter-
einander dargestellt. Man erkennt, dass Person C bei den Verhaltensweisen 
1, 2 und 3 den Wert 1 besitzt – sich also umweltgerecht verhält – und dass 
die Verhaltensweisen im Einkaufsbereich mit Ausnahme von Item 8 (Kauf 
von  Früchten  und  Gemüse  nur  in  der  jeweiligen  Saison)  allesamt  nicht 
umweltgerecht sind. 

 
Person A 
Person C 

ITEM1 

ITEM2 

ITEM3 

ITEM4 

ITEM5 

ITEM6 

ITEM7 

ITEM8 

1 

1 

0 

1 

0 

1 

1 

0 

0 

0 

1 

0 

0 

0 

0 

1 

Abb. 84: Die Verhaltensweisen von zwei Vergleichspersonen mit 0/1-Codierung 

Ist das Umweltverhalten der beiden Beispielpersonen nun ähnlich oder gibt 
es  große  Distanzen  zwischen  ihrem  Umweltverhalten?  Die  Formulierung 
soll  deutlich  machen,  dass  Ähnlichkeit  und  Distanz  quasi  zwei  Seiten  der 
gleichen Medaille sind: Je ähnlicher zwei Personen oder, allgemein formu-
liert, zwei Objekte einander sind, desto geringer ist ihre Distanz. Auf den 
ersten Blick würde man die Frage nach der Ähnlichkeit des Umweltverhal-
tens der beiden Personen wahrscheinlich so beantworten, dass sie sich nicht 
sonderlich ähnlich sind, aber dass sie sich andererseits auch nicht völlig ver-
schieden voneinander verhalten. Um ein genaueres Bild zu erhalten, kann 
man  den  Vergleich  von  zwei  Merkmalsreihen  dieser  Art  in  einer  Vier-
Felder-Tafel zusammenfassen (Abb. 85). 

 
 

 
 

          Merkmale der Person A 
vorhanden 

nicht vorhanden 

Merkmale  
der Person C 

vorhanden 

nicht vorhanden 

A (1) 

C (2) 

Abb. 85: Vierfeldertafel für binäre Merkmale 

B (3) 

D (2) 

In Zelle A der Vierfeldertafel wird die Anzahl der 1/1-Übereinstimmungen 
festgehalten, d.h. hier die Anzahl der Verhaltensweisen, bei denen sich bei-
de Personen umweltgerecht verhalten. Das ist hier nur einmal (bei Item 1) 
der Fall. In Zelle B halten wir fest, bei wie vielen Verhaltensweisen es vor-
kommt,  dass  Person  C  sich  umweltgerecht  verhält,  Person  A  aber  nicht. 
Hier  gibt  es  3  solcher  1/0-Kombinationen.  Zelle  C  summiert  den  umge-

Ähnlichkeiten zwischen Personen ermitteln 

233 

kehrten Fall, nämlich die Anzahl der 0/1-Kombinationen. Im obigen Bei-
spiel ist diese gleich 2, denn bei Item 4 und Item 6 verhält sich Person A 
umweltgerecht, Person C aber nicht. Zelle D schließlich enthält die Anzahl 
der 0/0 Übereinstimmungen, d.h. beide Personen verhalten sich nicht um-
weltgerecht. Dies ist zweimal, nämlich bei Item 5 und Item 7 der Fall. 

Der erste Eindruck, dass die Ähnlichkeit zwischen den beiden Personen 
nicht sonderlich ausgeprägt ist, findet nun eine zahlenmäßige Bestätigung. 
Immerhin  gibt  es  aber  drei  gleichartige  Verhaltensweisen,  nämlich  „mit 
dem  Auto  zur  Arbeit“,  „Recycling-Papier“  und  „Treibhaussalat“.  Intuitiv 
würde man nun vielleicht formulieren, dass das Verhalten der beiden Per-
sonen in drei von acht Fällen (=37,5%) übereinstimmt. Die maximale Ähn-
lichkeit wäre dann erreicht, wenn 8 von 8 Verhaltensweisen (=100%) über-
einstimmen, die minimale Ähnlichkeit bei 0 von 8 Verhaltensweisen (=0%). 
Es  stellt  sich  nun  allerdings  die  Frage,  ob  man  Positiv-positiv-Überein-
stimmungen genauso bewerten will wie Negativ-negativ-Übereinstimmungen. 
Dazu  ist  abzuwägen,  ob  die  Übereinstimmung  im  Nicht-Besitz  eines 
Merkmals wirklich als eine Ähnlichkeit zwischen Personen bewertet werden 
soll. Zum Beispiel würde es wohl schwerlich als Indikator für Ähnlichkeit 
gewertet werden können, wenn zwei Personen bislang keine sechs Richti-
gen im Lotto gehabt haben. In manchen Fällen mag es allerdings so sein, 
dass eine Negativ-negativ-Übereinstimmung mehr aussagt als eine Positiv-
positiv-Übereinstimmung,  beispielsweise,  wenn  zwei  Personen  beide  be-
wusst keinen  Fernseher im Haushalt besitzen. Die Entscheidung, wie der 
Nicht-Besitz  von  Merkmalen  zu  bewerten  ist,  muss  letzten  Endes  nach 
theoretischen Kriterien erfolgen. Sie determiniert die  Wahl des  adäquaten 
Ähnlichkeitskoeffizienten. SPSS offeriert eine Reihe verschiedener Koeffi-
zienten,  die  sich  vor  allem  im  Hinblick  auf  die  Behandlung  der  Negativ-
negativ-Übereinstimmung unterscheiden. Vier geeignete Koeffizienten sind 
der „Simple matching“-Koeffizient, der „Dize“-, „Russell/Rao“- und „Ja-
card“-Koeffizient32.  Sie  weisen  jeweils  eine  Spannweite  zwischen  0  (keine 
Ähnlichkeit) und 1 (identische Datenkonstellation) auf. 
                                                           
 
32 Diese vier Koeffizienten sind wie folgt definiert: a) Simple matching: (a+d)/(a+b+c+d), 
im obigen Beispiels also 3/8= 0,375 – es werden alle Übereinstimmungen gewertet, auch 
die  negativen,  es  wird  keine  Gewichtung  vorgenommen;  b)  Russell  and  Rao: 
a/(a+b+c+d) hier =1/8=0,125. Negative Übereinstimmungen werden nicht im positiven 
Sinn  gewertet,  aber  sie  erscheinen  im  Nenner;  c)  Jaccard:  a/(a+b+c)  hier  1/(1+3+2) 
=1/6=0,166.  Negativ-negativ-Übereinstimmungen  werden  ganz  aus  der  Berechnung 

 

234 

Kombination mit statistischen Verfahren: Ähnlichkeiten, Muster und Typologien 

Für  jedes  Paar  von  Probanden  wird  ein  Ähnlichkeitskoeffizient  ermit-
telt, so dass eine neue Matrix („Ähnlichkeitsmatrix“) entsteht, die n Zeilen 
und n Spalten umfasst. Die Matrix ist klappsymmetrisch, da die Ähnlichkeit 
zwischen Person A und Person B natürlich gleich der Ähnlichkeit zwischen 
Person B und Person A ist. Die Diagonale der Matrix enthält die Ähnlich-
keiten der Person mit sich selbst, also jeweils den Wert 1 (siehe Abb. 88). 

Zur Berechnung einer Ähnlichkeitsmatrix existiert im SPSS-Menü „Analy-
sieren“33 die Funktion „Korrelation>Distanzen“. Folgende Parameter sind 
zu setzen (Abb. 86): 
 

1.  Auswahl der Variablen zur Berechnung der Ähnlichkeit: Im Beispiel 
sind dies die acht Verhaltensweisen Item 1 bis Item 8. Diese müssen 
in der Variablenliste markiert und in die Auswahlliste übernommen 
werden. 

2.  Wahl zwischen objektorientierter  oder variablenorientierter Berech-
nung: Da hier die Ähnlichkeiten zwischen Personen und nicht zwi-
schen Variablen zu berechnen ist, muss „Zwischen den Fällen” ge-
wählt werden. 

3.  Auswahl  zwischen  Ähnlichkeits-  und  Distanzmessung:  Eine  Ähn-
lichkeitsmatrix ist zu berechnen, folglich ist „Ähnlichkeiten” zu wäh-
len. 

4.  Wahl  des  gewünschten  Ähnlichkeitskoeffizienten  (in  der  folgenden 
Abbildung ist „Einfache Übereinstimmung“ ausgewählt), indem das 
Dialogfeld „Maße“ angeklickt wird. 

                                                                                                                                  
 

ausgeschlossen;  d)  Dice:  2a/(2a+b+c),  hier  2/(2+3+2)=  2/7  =0,285,  also  die  Positiv-
positiv-Übereinstimmungen werden stärker gewichtet, die negativen Übereinstimmungen 
werden wie beim Jaccard-Koeffizienten weggelassen. 

33 SPSS kann nicht nur Ähnlichkeits-, sondern auch Distanzmatrizen berechnen. Distanz ist 
reziprok zu Ähnlichkeit definiert: Je stärker zwei Objekte in ihren Merkmalen überein-
stimmen, desto ähnlicher sind sie sich. Je stärker sie sich voneinander unterscheiden, des-
to größer ist ihre Distanz. Distanzmessungen sind vor allem bei höherwertigen Skalen in 
Verbindung mit varianzanalytisch orientierten Verfahren der Clusteranalyse von Interes-
se. Als Distanzkoeffizient für binäre Merkmale wird üblicherweise  die  euklidische  Dis-
tanz bzw. die quadrierte euklidische Distanz gewählt. In der Terminologie der Vierfelder-
tafel bedeutet dies: Die quadrierte euklidische Distanz ist gleich b+c. Es werden also nur 
die  Matrixfelder  der  Nicht-Übereinstimmung  von  Merkmalen 
(1/0  bzw.  0/1-
Kombinationen) zur Berechnung der Distanz zwischen einem Personenpaar herangezo-
gen: Je häufiger diese nicht übereinstimmen, desto größer ist der Distanzkoeffizient.  

Ähnlichkeiten zwischen Personen ermitteln 

235 

Abb. 86: Die SPSS-Dialog-Box Distanzen 

 

Um  auf  dem  späteren  Ausdruck  die  Personen  leichter  identifizieren  zu 
können, kann den Personen eine Fall-Beschriftung zugeordnet werden. In 
der Dialog-Box „Distanzen Ähnlichkeitsmaße“ ist zunächst die Skalenart – 
intervall oder binär – zu bestimmen. SPSS offeriert daraufhin eine Liste mög-
licher  Koeffizienten  (hier  ist  „Einfache  Übereinstimmung“  ausgewählt). 
SPSS geht davon aus, dass binäre Variablen in Form von 0/1-Werten co-
diert werden, d.h. das Vorhandensein eines Merkmals wird immer mit dem 
Wert 1 codiert. Ist dies nicht der Fall, müssen die voreingestellten Werte für 
vorhandene Merkmale und nicht vorhandene Merkmale in der Dialog-Box 
geändert werden. 

Abb. 87: SPSS-Dialog-Box Ähnlichkeitsmaße 

 

 

236 

Kombination mit statistischen Verfahren: Ähnlichkeiten, Muster und Typologien 

Alle Variablen der Auswahlliste müssen in der gleichen Weise codiert sein, 
d.h. es ist nicht möglich, einige Variablen mit 0/1 zu codieren und bei an-
deren Variablen das Vorhandensein eines Merkmals mit dem Wert 2 zu co-
dieren. Die von SPSS berechnete Ähnlichkeitsmatrix (Abb. 88) wird als un-
tere Dreiecksmatrix ausgegeben. Sie ist zu lesen wie eine Entfernungstabelle 
im Autoatlas. 

Die  Personen  werden  gemäß  ihrer  Reihenfolge  in  der  Datenmatrix 
durchnummeriert.  Für  die  Ähnlichkeit  zwischen  unseren  Beispielfällen  1 
und 3 enthält die Matrix den Wert .50. Unschwer kann man nun ermitteln, 
zwischen welchen Personen die größten Ähnlichkeiten im Hinblick auf ihr 
Umweltverhalten bestehen. Person 1 weist im Matrixausschnitt mit .625 die 
größte Ähnlichkeit zu Person 5 auf. Bei acht Variablen bedeutet ein Simple-
matching  Koeffizient  von  .625,  dass  5  der  8  Verhaltensweisen  überein-
stimmen.  Sehr  unähnlich  sind  sich  etwa  die  Personen  2  und  5  (.25):  Sie 
stimmen nur in zwei der acht Verhaltensweisen überein. 

Näherungsmatrix

 Ähnlichkeitsmaß der einfachen Übereinstimmung

2
,375
1,000
,375
,375
,250
,625

3

,500
,375
1,000
,750
,375
,500

4

,500
,375
,750
1,000
,375
,750

5

,625
,250
,375
,375
1,000
,625

6

,500
,625
,500
,750
,625
1,000

 

1
2
3
4
5
6

1
1,000
,375
,500
,500
,625
,500
Ä

Abb. 88: Von SPSS erstellte Matrix der Ähnlichkeiten für Person 1 bis 6 

Die Ähnlichkeitsmatrix ist ein gutes Hilfsmittel, um Strukturen in den Da-
ten zu identifizieren. In qualitativen Panel-Studien kann sie beispielsweise 
dazu  benutzt  werden,  um  Paare  von  Vergleichsfällen  zu  bilden.  Aus  der 
Tabelle der Ähnlichkeiten lässt sich auch problemlos eine „Liste der näch-
sten Nachbarn“ erstellen, aus der für jeden Befragten hervorgeht, welches 
die jeweils ähnlichsten Personen sind. 

Typenbildung durch Clusteranalyse 

237 

13.3 Typenbildung durch Clusteranalyse 

Typenbildung  ist  eine  der  zentralen  Zielsetzungen  der  qualitativen  Sozial-
forschung und hat in der Geschichte der Sozialforschung eine große Tradi-
tion. So wurden in der bekannten Marienthal-Studie (Jahoda u.a. 1980) eine 
Typologie  arbeitsloser  Familien  gebildet,  die  aus  den  vier  verschiedenen 
Typen  „ungebrochen“,  „resigniert“,  „verzweifelt“  und  „apathisch“  be-
stand:34 Die Bildung von Typen löst sich von der Besonderheit des einzel-
nen Falles. Der Einzelne wird als typischer Stellvertreter einer Art, Gruppe 
oder Gattung betrachtet. Die Entscheidung für Typenbildung impliziert, so 
Lamnek  (2005:  230 ff.),  eine  Entscheidung  gegen  den  Zufall  und  für  eine 
theoretisch-systematische  Auswahl.  Typenbildung  heißt  nicht,  komplexe 
Sachverhalte  auf  einzelne  Variablen  oder  Variablenkorrelationen  zu  redu-
zieren, vielmehr wird eine eher ganzheitliche Sicht bevorzugt. Es geht um 
die Herausarbeitung von Gemeinsamkeiten zwischen den Fällen oder, all-
gemein  gesprochen,  um  die  Klassifikation  von  Elementen  in  möglichst 
homogene Gruppen (Bacher 1996: 1 ff.). 

Diese fallorientierte Vorgehensweise wird in der traditionellen quantita-
tiven  Forschung  weit  seltener  als  die  variablenorientierte  angewandt,  so 
dass die Schritte des Verfahrens kurz skizziert werden sollen. Während die 
variablenorientierte Analyse nach kausalen Modellen für die Beziehung zwi-
schen den Variablen sucht, fokussiert die fallorientierte Analyse die Bezie-
hungen  zwischen  den  Fällen,  untersucht  also  Ähnlichkeitsstrukturen  und 
zielt auf eine empirische Klassifikation der Fälle. 

Die ersten beiden Schritte einer Clusteranalyse bestehen aus der im vor-
angehenden Abschnitt beschriebenen Auswahl der Variablen und der Be-
rechnung  der  Ähnlichkeiten  zwischen  den  Personen.  Die  Clusteranalyse 
stellt quasi eine Form der systematischen Auswertung der Ähnlichkeitsma-
trix dar. Diese lässt sich zwar gut nutzen, um beispielsweise eine Liste der 
nächsten  Nachbarn  zu  erstellen  oder  Informationen  über  die  Ähnlichkeit 
von Personen zu erhalten, doch eine Gruppierung der Probanden in homo-
gene Gruppen lässt sich durch Inspektion der Matrix nicht erreichen. Dies 
ist nun genau die Aufgabe der Clusteranalyse. Es existiert eine Vielzahl un-
terschiedlicher clusteranalytischer Verfahren, die an anderer Stelle ausführ-
lich  beschrieben  sind  (vgl.  Bacher  1996).  Im  Folgenden  wird  die  Vorge-
                                                           
 
34 Eine kurze Beschreibung der Vorgehensweise findet sich bei Diekmann (2000: 461 ff.). 

 

238 

Kombination mit statistischen Verfahren: Ähnlichkeiten, Muster und Typologien 

hensweise  der  Johnsonschen  Maximum-Methode  („Complete  Linkage“) 
skizziert, eines bewährten  und vielfach  benutzten clusteranalytischen Ver-
fahrens. Bei dieser Methode handelt es sich um ein verteilungsfreies Ver-
fahren, das keine besonderen Vorbedingungen an die Skalenqualität stellt. 
Insofern ist sie für die durch qualitative Analyse gewonnenen Daten, die ja 
normalerweise kein Intervallskalenniveau aufweisen und für die auch keine 
Verteilungsannahmen bestehen, recht gut geeignet. Die Schritte der Analyse 
lassen sich in drei Phasen systematisieren: 
 

1.  Die Phase der Pre-Analyse besteht aus der Auswahl der Variablen, der 
Entscheidung  für  einen  bestimmten  Ähnlichkeitskoeffizienten  und 
der Berechnung der Ähnlichkeitsmatrix. 

2.  Die Hauptphase besteht aus der eigentlichen Clusteranalyse, in der die 

Gruppierung bzw. mehrere Gruppierungen vorgenommen werden. 

3.  Die Phase der Post-Analyse arbeitet die Ergebnisse der Clusteranalyse 
auf.  Die  vorgenommenen  Gruppierungen  werden  evaluiert,  die  er-
mittelten Muster werden interpretiert und es wird eine Entscheidung 
für eine „optimale“ Clusterlösung getroffen. 

 
Im Anschluss an das oben bereits dargestellte Procedere der Erstellung der 
Ähnlichkeitsmatrix durchläuft die Clusteranalyse folgende Schritte: 
 

1.  Beginn  des  Clusterprozesses  auf  der  Basis  der  Ähnlichkeitsmatrix. 
Begonnen wird mit n Clustern, also in unserem Beispiel mit so vielen 
Clustern wie Personen befragt wurden. 

2.  In  n-1  Schritten  werden  die  Personen  zu  Clustern  gruppiert.  Die 

Clustermitgliedschaften der Personen werden festgehalten. 

3.  Verschiedene Clusterlösungen werden evaluiert, d.h. die Verteilungen 
der  Variablen  werden  für  jedes  Cluster  gesondert  ausgewertet.  Die 
Merkmalskonstellationen werden geprüft und miteinander verglichen. 
Eine  Entscheidung  für  eine  gut  interpretierbare  Clusterlösung  wird 
getroffen. 

 
Die Clusteranalyse nach Johnson geht bei der Gruppenbildung so vor, dass 
die Ähnlichkeitsmatrix nach dem maximalen Ähnlichkeitskoeffizienten ab-
gesucht  wird  und  die  beiden  zugehörigen  Personen  (A  und  B)  zu  einem 
Cluster zusammengefasst werden. Die Analyse beginnt also mit n Clustern, 
die sich nach dem ersten Clusterschritt um 1 vermindern. Nach der Fusion 
von A und B werden die Ähnlichkeiten des neu gebildeten Clusters zu den 

Typenbildung durch Clusteranalyse 

239 

übrigen Clustern (Personen) neu bestimmt, wobei für die Berechnung die 
Regel gilt: Ähnlichkeit (A+B; X) = Minimum (Ähnlichkeit (A-X), Ähnlich-
keit (B-X)), d.h. die Ähnlichkeit zwischen dem neuen Cluster und den an-
deren Clustern bzw. Personen der Matrix wird definiert als minimale Ähn-
lichkeit zwischen einem Clustermitglied und einer Person X. 

In  SPSS  ist  die  Clusteranalyse  über  die  Menüoption  „Klassifizieren  > 
Hierarchische Clusteranalyse“ des Menüs „Analysieren“ zugänglich. In der 
Dialog-Box  „Hierarchische  Clusteranalyse“  werden  die  Variablen  für  die 
Clusterbildung ausgewählt (hier: Item 1 bis Item 8). Die Personen können 
ein  Label  erhalten  und  verschiedene  Statistiken  und  graphische  Dar-
stellungen (Plots) können angefordert werden. Ferner muss zwischen fall-
orientierter  und  variablenorientierter  Analyse  gewählt  werden  (Auswahl 
hier: „Cluster Fälle“). 

Als nächstes ist die Dialog-Box „Methode“ anzuklicken. Diese dient zur 
Wahl  des  clusteranalytischen  Verfahrens.  Die  Johnsonsche  Maximumme-
thode firmiert hier als „Entferntester Nachbar“. Die Angabe der Skalenqua-
lität  geschieht  in  der  Rubrik  „Maß”:  Zu  wählen  ist  hier  „binär“.  Ferner 
muss der gewünschte Koeffizient (hier: „Einfache Übereinstimmung”) aus 
der Liste ausgesucht werden. 

Jeder  Schritt  der  Clusteranalyse  wird  von  SPSS  in  einer  Zuordnungs-
übersicht dokumentiert, so dass die Reihenfolge der Zusammenfassungen 
ersichtlich ist (vgl. Bacher 1996: 157). Die Analyse durchläuft n-1 Schritte, 
bis  schließlich  alle  Personen  in  einem  einzigen  Cluster  zusammengefasst 
sind. Der Ablauf des Clusterprozesses kann auch graphisch in Form eines 
Baum-Diagramms („Dendrogramm“) dargestellt werden. 

Die  Clusteranalyse  von  SPSS  ist  nicht  sonderlich  benutzerfreundlich, 
denn es bereitet einige Mühe, die gebildeten Gruppierungen inhaltlich aus-
zuwerten. Auf dem Ausdruck fehlen sogar die Angaben der Clustergrößen. 
SPSS  kann  aber  die  Angaben  zur  Cluster-Mitgliedschaft  der  Personen  als 
neue Variable in der Datenmatrix speichern. Hierzu ist im Cluster-Menü die 
Option „Speichern“ zu wählen und die gewünschte Anzahl der Cluster in 
der Rubrik „Einzelne Lösung“ einzutragen. Trägt man dort die Zahl 4 ein, 
speichert SPSS die Cluster-Mitgliedschaften für die Lösung mit vier Clus-
tern in Form einer neuen Variablen, deren Häufigkeiten dann ausgewertet 
werden können. 

 

240 

Kombinati

on mit statistisc

chen Verfahren: 

Ähnlichkeiten, 

Muster und Typ

pologien 

Auswe
Vorran
interes
wertun
tion „B

ertung der Clust
ngig ist man 
ssiert. Da die
ngsroutine fü
Berichte: Ber

ter und Weiterv
natürlich an
e Clusteranaly
ür die gebilde
richte in Spalt

verwendung der
 den inhaltlic
yse-Prozedur
eten Cluster e
ten“ zurückg

r Ergebnisse 
chen Charakt
r von SPSS k
enthält, muss
greifen.  

teristika der C
keine speziell
 man auf die

Cluster 
le Aus-
 Funk-

 

Abb. 89

9: SPSS Dialog

gfeld für Berich

hte 

Nach 
rechne
Werte
Cluste
tensva
(Abb. 
der  Pe
Person
laubsr
hingeg
sind in

Clustern auf
et  diese  für 
en  größer  als
er, der sich u
ariante wurde
90) enthält f
ersonen,  die 
nen  ohne  Au
reise  nicht  m
gen Cluster 4
n den letzten 

fgeschlüsselt 
ausgewählte 
  Null.  Diese
umweltgerech
e ja jeweils mi
für jedes Clu
das  Merkma
uto  zur  Arbe
mit  dem  Flug
4: Hier komm
Urlaub geflo

(hier erfasst 
Variablen  d
es  ist  der  An
ht verhält, de
it 1 codiert. D
uster (Zeile 1
al  besitzen.  I
eit  (Item  1) u
gzeug  unterno
men alle mit 
ogen. 

mit der Var
den  Prozenta
nteil  der  Pers
enn die umw
Die von SPSS
 bis 4) den p
In  Cluster  1 
und  100%  h
ommen  (Item
dem Auto zu

riable CLU2_
anteil  der  Fä
onen  im  jew
weltgerechte V
S erstellte Üb
prozentualen 
kommen  90
aben  die  letz
m  4).  Völlig 
ur Arbeit un

_1) be-
älle  mit 
weiligen 
Verhal-
bersicht 
Anteil 
0%  der 
zte  Ur-
anders 
nd 75% 

 

Typenbildung durch Clusteranalyse 

241 

Cluster 

Item1 >0 

Item2 >0 

Item3 >0 

1 

2 

3 

4 

90,0% 

77,3% 

84,6% 

,0% 

Total 

56,9% 

90,0% 

95,5% 

76,9% 

90,0% 

89,2% 

20,0% 

40,9% 

38,5% 

10,0% 

27,7% 

Item4 >0 

100,0% 

36,4% 

23,1% 

25,0% 

40,0% 

Item5 >0 

20,0% 

81,8% 

92,3% 

40,0% 

61,5% 

Abb. 90: SPSS-Bericht über die Merkmalsverteilungen in den vier Clustern (hier nur 

für Item 1 bis Item 5 gelistet) 

Die Tabelle ist nun die Basis für eine sorgfältige erneute Textinterpretation. 
Die vier hier gebildeten Cluster lassen sich schlaglichtartig beschreiben als: 
 
Typ 1 – Die Autolosen, aber wenig Umweltengagierten 
Typ 2 – Die Umweltsensiblen 
Typ 3 – Die Hedonisten des Sowohl-als-auch 
Typ 4 – Die Autofahrer 
 
Hinter  diesen  plakativen  Verdichtungen  verbergen  sich  charakteristische 
Kombinationen von Verhaltensweisen. Der Typ 1 etwa ist ein Verhaltenstyp, 
dessen Verkehrsverhalten sehr umweltgerecht ist. 90% kommen ohne Auto 
zur Arbeit und nehmen bei längeren Fahrten nicht das Flugzeug. Bei nie-
mandem war die letzte Urlaubsreise eine Flugreise. Das Einkaufsverhalten 
ist aber keineswegs umweltgerecht: Nur 20% kaufen Recycling-Papier. 80% 
kaufen im Winter Treibhaussalat und gar 90% Früchte und Gemüse außer-
halb  der  Saison,  wenn  sie  von  weit  her  eingeflogen  werden  müssen.  Die 
Vermutung liegt  nahe, dass das umweltgerechte Verkehrsverhalten daraus 
resultiert,  dass  den  Mitgliedern  dieses  Clusters  schlichtweg  kein  Auto  zur 
Verfügung steht. 

Die gebildeten Gruppen lassen sich gut interpretieren. Bevor man sich 
für  diese  Clusterlösung  entscheidet,  empfiehlt  es  sich  aber,  auch  andere 
Clusterlösungen,  etwa  die  5-Cluster-Lösung,  näher  zu  inspizieren.  Dem 
heuristischen Charakter des Verfahrens entsprechend ist die Entscheidung 
für eine bestimmte Anzahl von Clustern in erster Linie von dem erwünsch-
ten Grad an Differenzierung und der Evidenz der Interpretation der Typo-
logie abhängig. Bei einigen clusteranalytischen Verfahren existieren zudem 
auch  statistische  Kriterien  für  die  Wahl  einer  bestimmten  Clusterlösung 
(vgl. Bacher 1994: 253 ff.), doch haben auch diese Koeffizienten in erster 

 

242 

Kombinati

on mit statistisc

chen Verfahren: 

Ähnlichkeiten, 

Muster und Typ

pologien 

Linie 
termin
kann f
sie geh
die SP
forma
Textan
werde
Cluste
Di
kann s
auch 
Codes
diese z
der op
keiten 
kompl
riablen
sich n
tiven R

Hinweischar
nistisch fest. N
für jede Perso
hört. Diese In
PSS-Datenma
ation der Zuge
nalyse zu ben
n  –  man  kö
er-Zugehörigk
e Verwendun
sowohl auf d
auf  der  Basi
s bzw. Variab
zu SPSS expo
ptimalen Typ
für alle Perso
lette Datenm
n  im  Text-Re
nun im Weite
Retrievals du

rakter  und  le
Nach der En
on angegeben
nformation lä
atrix anfügen.
ehörigkeit zu 
nutzen. Dazu 
önnte  sie  z.B
keiten müssen
ng der Cluste
der Basis der 
is  der  Codie
blen, die Grun
ortiert und di
pologie sind d
onen einzuge
matrix von SP
etrieval  zu  be
ren die im K
urchführen. 

egen  die  Anz
ntscheidung fü
n werden, zu 
ässt sich, wie 
. Nun ist es v
einem bestim
muss lediglic
.  „Umweltve
n eingegeben 
eranalyse als H
Fallvariablen
erungen  gesc
ndlage der Ty
ie Analyse wi
die Informatio
eben. MAXQ
PSS zu impor
enutzen.  Mit 
Kapitel 9 besc

zahl  der  Clus
ür eine bestim
welchem der
oben darges
von großem 
mmten Typ au
ch eine neue F
erhaltenstyp“ 
bzw. importi
Hilfsmittel be
n – wie in di
hehen.  Nach
ypenbildung 
ird durchgefü
onen über di
DA enthält d
rtieren und d
der  Clusterz
chriebenen T

ster  keineswe
mmte Cluster
r gebildeten C
tellt, als Varia
Interesse, di
uch im Kont
Fallvariable d
nennen  –  u
iert werden. 
ei der Typenb
iesem Beispie
h  der  Auswa
sein sollen, w
ührt. Nach A
ie Clusterzuge
die Möglichke
die importiert
zugehörigkeit
echniken des

egs  de-
rlösung 
Cluster 
able an 
ese In-
text der 
efiniert 
und  die 

bildung 
el – als 
ahl  der   
werden 
Auswahl 
ehörig-
eit, eine 
ten Va-
t  lassen 
s selek-

Abb. 91

1: Zusammens

spiel von QDA

-Software und 

Statistik-Softw

ware 

Codemuster erkennen: Faktorenanalyse von Codierungen 

243 

13.4 Codemuster erkennen: Faktorenanalyse von Codierungen 

Explorative  Faktorenanalysen  zur  Entdeckung  von  Mustern  im  codierten 
Material können sowohl auf der Basis der Kategorienzuordnungen wie auf 
der Basis der Fallvariablen durchgeführt werden. Das folgende Beispiel ar-
beitet,  anders  als  das  zuvor  dargestellte,  nicht  mit  den  Fallvariablen,  son-
dern mit den Codierungen und knüpft an die in Kapitel 11.6 gegebene Dar-
stellung der Leitbildanalyse an. Die Ausgangsfragestellung für die Analyse 
lautet: Welche Muster enthält das Material in Bezug auf die vorgenommenen Codierun-
gen nach dem Modell der Leitbildanalyse? 

Für alle Befragten lässt sich leicht ihr je spezifisches Muster von Codie-
rungen ermitteln. Diese Matrix der Codehäufigkeiten kann direkt als Einga-
bedatei für ein Statistikprogramm dienen. Die folgende Abbildung gibt die 
Codierhäufigkeiten  der  Befragten  W.  für  den  Bereich  der  Wunschprojek-
tionen wieder: 

Codes 

Anzahl der Segmente 

Wunschprojektion/ sozial/ gesellschaftliche Visionen 

Wunschprojektion/ sozial/ LA 21-Initiative 

Wunschprojektion/ sozial/ Öffentlichkeit 

Wunschprojektion/ sozial/ Partizipation/Politik 

Wunschprojektion/ sozial/ Umgestaltung lok. Lebensraums 

Wunschprojektion/ ökologisch 

Wunschprojektion/ ökonomisch 

Abb. 92: Codehäufigkeiten für die Befragte W. 

3 

1 

1 

1 

1 

1 

0 

Man erkennt, dass in diesem Interview insgesamt 8 Textstellen existieren, in 
denen  von  Wünschen  im  Sinne  des  Kategorienschemas  die  Rede  ist.  Die 
meisten  Wünsche  beziehen  sich  auf  den  sozialen  Bereich,  in  erster  Linie 
sind sie als „gesellschaftliche Visionen“ codiert worden. Mit diesem Code 
sind drei Textpassagen codiert. Ökonomische Wünsche werden im gesam-
ten Interview, das zeigt die Tabelle, nicht geäußert. Diese verdichteten In-
formationen über den Inhalt des Interviews lassen sich für die gesamte Stu-
die in einer Matrix zusammenstellen: Jedes Interview bildet eine Zeile und 
jeder Code bzw. Subcode eine Spalte. Abb. 93 zeigt dies für den Bereich 
der Wunschprojektionen (in der Tabelle abgekürzt als WP). Verfährt man 

 

244 

Kombination mit statistischen Verfahren: Ähnlichkeiten, Muster und Typologien 

nach diesem Muster mit allen 30 Interviews und den übrigen Leitbildkate-
gorien, so entsteht eine Matrix von 30 Zeilen (Befragte) mal 25 Kategorien. 
Mittels der explorativen Faktorenanalyse lässt sich nun nach Mustern in den 
Kategorien suchen. 

Inter-
view 

WP. 
sozial. 
gesell. 
Visionen 

WP. 
sozial. 
LA 21-
Initiative 

WP. 
sozial. 
Öffent-
lichkeit  

W. 

A. 

.. 

3 

 

 

1 

 

 

1 

 

 

WP. 
sozial. 
Partizipati
ti-
on/Politik 

1 

 

 

WP. 
sozial. 
Umges.lok. 
Lebensraum

WP. 
ökolo-
gisch  

WP. 
ökono-
misch 
 

1 

 

 

1 

 

 

0 

 

 

Abb. 93: Die Ausgangsmatrix für die Faktorenanalyse 

Die methodische Vorgehensweise der Faktorenanalyse ist in den gängigen 
Statistikbüchern  (z.B.  Bortz  2005:  511 ff.)  hinreichend  beschrieben.  Das 
Verfahren durchläuft sieben Schritte: 
 
1.  Auswahl der in die Faktorenanalyse einzubeziehenden Codes 
2.  Erstellen der Matrix Personen mal Codes 
3.  Durchführen der Faktorenanalyse 
4.  Interpretation der Ergebnisse, d.h. der Faktorenstruktur und Variablen-

ladungen 

5.  Berechnen der Faktorenwerte für jede Person 
6.  Zuordnung der Faktorenwerte zu den Texten, Rückbezug auf die Texte 
7.  Interpretative  Auswertung  der  codierten  Textsegmente  der  Leitperso-

nen, die die identifizierten Muster prototypisch repräsentieren 

 
Die beiden ersten Schritte wurden oben bereits beschrieben. Die Variablen 
der  Faktorenanalyse  bestehen  hier  aus  25  Codes,  nämlich  den  relevanten 
Leitbilddimensionen.  Sieben  Codes  hiervon  sind  die  oben  dargestellten  
Codes der Leitbildkategorie „Wunschprojektion“. 

Der  dritte  Schritt,  die  technische  Durchführung  der  Faktorenanalyse, 
wird  mit  der  entsprechenden  SPSS-Prozedur  realisiert.  Die  Interpretation 
der Ergebnisse erfolgt auf  der Grundlage der rotierten Faktormatrix. Auf 
der Basis dieser Analyse berechnet SPSS für jede Person Faktorenwerte für 
die vier Faktoren. An den Werten lässt sich ersehen, welche Personen das 

Codem

muster erkennen:

 Faktorenanaly

yse von Codie

erungen

245 

einen  Fakto

or  bezeichne

ete  Kategorie

enmuster  bes

sonders  ausg

geprägt 

durch 
repräs

sentieren. 

Abb. 94

4: Von der Fak

ktorenanalyse z

zur Textinterpr

retation 

 

Ander
hier n
tion  v
segme
der  K
bunge
tizipat
Kucka
 
1. 

rs als in der q
nicht den End
von  Mustern 
ente wird nun
Konstellation  d
en der Muster
tionsformen…
artz/Rheinga
Das Leitbild 
dieses Typs 
zeichnet,  da
Initiativen  b
Die hohe M
einher,  ohne
Lösungen  z
Phantasterei
des Individu

quantitativ or
dpunkt der A
und  hierfür 
n zurückgegr
der  Faktorlad
r in Form vo
…“  wurden  d
ans 2000): 
d des starken p
sind durch e
as  sich  nicht
bezieht,  sond
Motivation geh
e  allerdings  d
zu  verlieren. 
ien  in  Hinbl
ualverkehrs) d

rientierten Fo
Analyse dar, s
repräsentativ
riffen. Auf di
dungen  –  las
on Leitbildern
die  Leitbilde

orschung stel
sondern sie d
ven  Personen
ieser Basis –
ssen  sich  dan
n geben. Im P
r  wie  folgt  s

llt die Faktor
dient zur Iden
n.  Auf  deren
und nicht au
nn  dichte  Be
Projekt „Neu
skizziert  (de 

rmatrix 
ntifika-
n  Text-
ufgrund 
eschrei-
ue Par-
Haan/ 

persönlichen En
ein hohes per
t  nur  auf  di
dern  auch  de
ht mit einem
den  Blick  fü
Man  empfi
lick  auf  Verä
die Arbeitsgr

ngagements iden
rsönliches En
ie  Aktivitäte
en  persönlich
 gewissen mi
ür  pragmatisc
ndet  es  als 
änderungen  (
uppen beher

ntifizieren. A
ngagement g
n  in  den  A
hen  Alltag  um
issionarischen
che  Aktivitäte
frustrierend,
(etwa:  Absch
rschen. Reali

Akteure 
gekenn-
Agenda-
mfasst. 
n Eifer 
en  und 
,  wenn 
haffung 
istische 

 

246 

Kombination mit statistischen Verfahren: Ähnlichkeiten, Muster und Typologien 

Einschätzungen des Machbaren dominieren – wie auch das Interesse 
an solchen Themen und Aktionsplänen, die sich in kleinen Schritten 
umsetzen lassen. 

2.  Das zweite identifizierte Leitbild gruppiert sich um die Vorstellung, es 
käme vor allem auf die sich engagierenden Politiker und alles ordnenden Äm-
ter an. Das persönliche, private Engagement steht nicht im Zentrum 
der Betrachtung. Das „man“ dominiert in der Rede gegenüber dem 
„ich“. Die Staatsmacht soll durchsetzen, was „man“ selbst für richtig 
hält.  Um  die  Durchsetzung  von  Aktionsplänen,  Konzepten  und 
Ideen kreisen generell viele Gedanken innerhalb dieses Typs. Daher 
verwundert es auch nicht, dass bei der Frage nach den Erfolgskrite-
rien  für  eine  Lokale  Agenda  viele  Ordnungswünsche  und  der 
Wunsch nach einem ordentlich aussehenden Stadtbezirk laut werden. 
3.  Ein drittes Leitbild ist durch den Glauben an die große LA 21-Gemeinde 
geprägt. Auch hier wird – wie im zweiten Leitbild – das persönliche 
Verhalten nicht so sehr in den Vordergrund gestellt. Man glaubt eher 
an die Fachkräfte, die in den Initiativen den Prozess der Ausgestal-
tung einer Agenda voranbringen können und sollen. Dieses Votum 
wird zugleich gebrochen von der Vorstellung, man müsse möglichst 
viele  Bürger  –  also  Laien  –  mit  in  das  „Agenda-Boot“  holen.  Das 
geht, so weiß man, nur durch eine hohe Motivation der zu erschlie-
ßenden Personenkreise und attraktive Arbeitsformen in den Initiati-
ven. Von daher neigt man auch bei der Frage nach Erfolgskriterien 
dazu, den Prozess der Kommunikation als ein solches, entscheiden-
des  Kriterium  auszuweisen.  Selbstreferentialität  dominiert  dann  ge-
genüber einer Orientierung an spezifischen Themen. 

4.  Das vierte  Leitbild  sieht  –  ähnlich  dem  zweiten  –  im  Staat  den  großen 
Agenda-Akteur.  Nun  allerdings  mit  einer  sehr  pessimistischen  Sicht 
auf den Normalbürger. Dieser, so die Vermutung, würde sich nicht 
ändern lassen, es sei denn, man verordnet diese Veränderungen. Die 
Zahl der konkreten Vorschläge, wo mit Verordnungen etwas zu be-
wegen sein müsste, ist außerordentlich lang. Und man selbst nimmt 
nun an den Agenda-Initiativen teil, weil man der Auffassung ist, hier 
dem Staat helfend beiseite stehen zu müssen. 

 

14  Die Zukunft der computergestützten qualitativen 

Datenanalyse 

In den letzten Jahren haben die Methoden zur computergestützten Analyse 
qualitativer Daten beachtliche Fortschritte gemacht. Neue, verbesserte Ver-
sionen der QDA-Software sind erschienen und viele Wünsche, die auf der 
Wunschliste qualitativer Forscher obenan standen, sind mittlerweile erfüllt 
worden. Methodische Aspekte und Probleme der QDA-Software haben in 
den letzten Jahren in der sozialwissenschaftlichen Methodendiskussion ver-
stärkt eine Rolle gespielt. Dabei lassen sich folgende Hauptthemen des Me-
thodendiskurses identifizieren: 

1.  Effektivierung der Forschung durch QDA-Software, d.h. inwieweit das qua-
litative  Forschen  durch  Computereinsatz  erleichtert  und  verbessert 
wird. Während die Mehrheit der  Diskutanten die positiven  Effekte 
hervorhebt (so Flick 2007a: 455 ff.), Kelle 2000, Gibbs/Friese/Man-
gabeira 2002), finden sich auch Kritiker (z.B. Mruck 2000), die dem-
gegenüber eher den kreativen und einer Kunstlehre ähnlichen Cha-
rakter qualitativen Forschens betonen. 

2.  Transparenz, Dokumentation und Glaubwürdigkeit: Thema ist die erhöhte 
Transparenz,  die  sich  durch  computergestützte  Verfahren  erzielen 
lässt und  ein  damit verbundener  Gewinn an interner Validität  (vgl. 
Kelle/Laurie  1995).  Mit  dem  Gewinn  an  Konsistenz  und  Konse-
quenz  steige  auch  die  Glaubwürdigkeit  qualitativer  Forschung  (vgl. 
Seale  1999).  Es  ergebe  sich  ein  Prestige-  und  Reputationsgewinn 
„entgegen den Vorwürfen des bloß Subjektivistischen und Essayisti-
schen qualitativer Sozialforschung“ (Mruck 2000: 29). 

3.  Verbesserung von Teamarbeit: Bei diesem Diskursstrang geht es um die 
Organisation  von  Teamarbeit  und  ihre  Qualität.  Autoren  wie  Gibbs 
u.a. (2002) und Ford u.a. (2000) sehen hier Zugewinne, weil Codierun-
gen leicht nachvollzogen und überprüft werden können. Der interne 
Kommunikationsprozess  zwischen  den  Mitgliedern  einer  Forscher-

248 

Die Zukunft der computergestützten qualitativen Datenanalyse 

gruppe  werde  intensiver  und  Daten  und  Analyseergebnisse  ließen 
sich  zwischen  weit  entfernt  voneinander  arbeitenden  Teammitglie-
dern austauschen. 

4.  Archivierung und Sekundäranalyse: Das Problem der Archivierung quali-
tativer Studien und der Bereitstellung der Daten für Sekundäranalyse 
ist immer wieder Gegenstand der Diskussion gewesen, denn anders 
als in der quantitativen Forschung sind in der qualitativen Forschung 
Sekundäranalysen bisher weitgehend unbekannt. In diesem Kontext 
sind  bereits  praktische  Vorschläge  entwickelt  worden  (z.B.  Kluge 
und Opitz 1999) und Datenarchive gegründet worden, wie das Bre-
mer  „Archiv  für  Lebenslaufforschung“35.  Die  Einrichtung  eines 
bundesweiten  Archivs  für  qualitative  Interviewdaten  ist  allerdings 
immer  noch  ein  Desiderat.  Auch  international  sind  entsprechende 
Diskussionen  und  Aktivitäten  zu  verzeichnen,  z.B.  die  Einrichtung 
des Qualidata-Archivs in Essex, in dem qualitative Daten archiviert 
und für weitere Lehre und Forschung zur Verfügung gestellt werden 
(Corti 2000). Die Standards zur Archivierung digitalisierter qualitati-
ver Daten sind allerdings auch weiterhin Gegenstand der Diskussion 
(Carmichael 2002, Muhr 2000). 

5.  Methodische Weiterentwicklungen und Integration qualitativer und quantitativer 
Methoden:  Diskutiert  werden  sowohl  einzelne,  an  spezielle  theoreti-
sche Ansätze gebundene methodische Entwicklungen (z.B. das Ga-
bek  Verfahren  bei  Buber/Zelger  (2000)),  als  auch  generalisierende 
Ansätze  wie  das  Testen  von  formalisierten  Hypothesen  (Hesse-
Biber/Dupuis  1996,  Huber  1992,  Kelle  1997a  und  1997b),  die  Ty-
penbildung  (Kelle/Kluge  1999,  Kluge  1999,  Kuckartz  1999  und 
2001) und die Integration von quantitativen und qualitativen Metho-
den  (Flick  2007b,  Kuckartz  1999,  Mayring  2001,  Kluge  1999,  Kel-
le/Kluge 1999). 

6.  Gefahren  des  Computereinsatzes.  Immer  wieder  ist  eine  Diskussion  um 
vermeintliche  Gefahren  des  Arbeitens  mit  QDA-Software  aufgefla-
ckert (Glaser 2002, Coffey et al. 1996), wobei sich die Kritik vor allem 
auf  die  analytische  Technik  des  Codierens  bezieht.  So  warnen  etwa 
Fielding/Lee  (1998:  119)  davor,  dass  die  extensive  Nutzung  von 
QDA-Software dazu führen könne, dass das Codieren gewissermaßen 

                                                           
 
35 Informationen findet man unter www.lebenslaufarchiv.uni-bremen.de. 

Codemuster erkennen: Faktorenanalyse von Codierungen 

249 

die Analyse ersetze und man durch die De-kontextualisierung, die mit 
dem  Segmentieren  und  Codieren  einhergeht,  das  eigentliche  Phäno-
men  aus  den  Augen  verliere.  Kritiker  wie  Glaser  (2002)  und  Ro-
berts/Wilson  (2002)  sehen  sogar  prinzipielle  Gegensätze  zwischen 
Computern  und  qualitativer  Forschung:  „Computer  techniques  of 
logic and precise rules are not compatible with the unstructured, am-
biguos nature of qualitative data and so it may distort or weaken data 
or stifle creativity“ (ebd.: 15). 

 
Diese  Hauptstränge  der  Diskussion  lassen  bereits  die  Richtungen  der  zu-
künftigen  Entwicklung  von  QDA-Software  erahnen.  Hinzu  kommt,  dass 
trotz  aller  Fortschritte  auch  heute  noch  zahlreiche,  bislang  nicht  erfüllte 
Wünsche auf dem Wunschzettel der qualitativ Forschenden stehen. Diese 
beziehen  sich,  wie  das  bei  Wünschen  so  üblich  ist,  auf  Machbares  und 
(scheinbar) Unmögliches. Ganz oben auf dem Wunschzettel steht die au-
tomatische Transkription von Tonbandinterviews. Ein Wunsch, der derzeit 
als  kaum  erfüllbar  gelten  muss.  Die  Entwicklung  solcher  Tools  ist  auch 
nicht direkt zum Aufgabenkreis von QDA-Programmen zu zählen, sondern 
gehört eher in den Bereich von Spracherkennungsprogrammen. Möglich ist 
inzwischen aber bereits die digitale Aufnahme von Interviews mit recht ein-
fachen  Mitteln  und  die  Bereitstellung  der  Audioaufzeichnung  im  QDA-
Programm (ohne dass aber eine automatische Umwandlung in Text statt-
findet). 

Nimmt man solche, nach wie vor bestehenden Wünsche der Nutzer zu 
den  Hauptpunkten  der  Methodendiskussion  hinzu,  so  erscheint  es  nicht 
allzu riskant, die Hauptlinien der Weiterentwicklung von QDA-Software in 
folgenden fünf Bereichen zu prognostizieren: 

Teamwork 
Desiderat sind erweiterte Möglichkeiten zum Teamwork, wozu auch Werk-
zeuge  zu  rechnen  sind,  die  die  Übereinstimmung  von  Codierungen  zwi-
schen  verschiedenen  Teammitarbeitern  zu  überprüfen  erlauben.  Dieser 
Punkt  wird  vor  allem  im  Rahmen  der  zunehmend  wichtiger  werdenden 
Diskussion um die Qualität qualitativer Forschung eine wichtige Rolle spie-
len. Ferner ist das gleichzeitige Arbeiten mehrerer Personen mit den glei-
chen  Daten  besonders  bei  größeren  Forschergruppen  ein  nach  wie  vor 
unerfüllter Wunsch. 

 

250 

Die Zukunft der computergestützten qualitativen Datenanalyse 

Visualisierung 
Hier geht es um noch bessere visuelle Darstellungen der in Daten vorfind-
baren  Beziehungen,  und  zwar  sowohl  zwischen  den  Kategorien  als  auch 
zwischen den Texten bzw. Dokumenten und Memos.  
Multimedia-Integration 
QDA-Software  wird  vermutlich  mehr  und  mehr  mit  der  sie  umgebenden 
Softwarewelt zusammenwachsen, d.h. Techniken des Transfers von Daten 
und Objekten zwischen verschiedenen Programmen werden verstärkt ent-
wickelt. Dazu könnte etwa gehören, die digital aufgenommenen Texte di-
rekt in das QDA-Programm zu transkribieren. 
Mixed Methods, Triangulation, Methodenintegration 
Die Zeiten der strikten Gegenüberstellung von qualitativen und quantitati-
ven  Methoden  sind  längst  vorüber.  Auf  beiden  Seiten  ist  eine  gesteigerte 
Offenheit festzustellen, und es besteht zunehmend Interesse daran, qualita-
tive und quantitative Forschungstechniken miteinander zu kombinieren. 
Ausbreitung in neue Anwendungsfelder, z.B. die Online-Forschung 
Schließlich wird die QDA-Software auch neue bzw. bislang noch wenig er-
schlossene Anwendungsfelder erobern, zu denen beispielsweise die Evalua-
tionsforschung und die Online-Forschung gehören könnten. 
 
Es  liegt  in  der  Natur  der  Sache,  dass  sich  Zukunft  schlecht  vorhersagen 
lässt, vor allem in einem Bereich, der einem solch schnellen Entwicklungs-
tempo unterliegt. So mag es auch sein, dass es gar nicht die oben beschrie-
benen  potenziellen  Entwicklungsfelder  der  Text-  und  Inhaltsanalyse  sind, 
aus denen die stärksten Impulse für die Weiterentwicklung von QDA-Soft-
ware  kommen,  sondern  allgemeine  Fortschritte  der  Informationstechnik 
und  PC-Software.  QDA-Software  ist  jedenfalls  heute,  wer  hätte  dies  An-
fang der 1990er-Jahre für möglich gehalten, aus dem Alltag qualitativ For-
schender kaum mehr wegzudenken. 

 

Anhang 

Übersicht QDA-Software 

Im Folgenden wird eine Übersicht über die derzeit gebräuchlichsten QDA-
Software gegeben (Stand: September 2009). In ihrem umfangreichen Buch 
„Using Software in Qualitative Research“ haben Lewins und Silver 2007 die 
verschiedenen Programme und ihre Funktionen gesichtet und systematisch 
dargestellt. Drei Programme werden dort als führende Prorgamme heraus-
gestellt  und  ausführlich  in  ihrer  Funktionalität  und  Handhabung  getestet, 
nämlich ATLAS.TI, MAXQDA und NVivo.  
Darüber  hinaus  werden  auch  die  Programme  HyperRESEARCH,  QDA 
Miner, Qualrus und das Videoanalyseprogramm Transana im Anhang vor-
gestellt.  

Die folgende  Liste enthält  für diese sowie für drei andere Programme 
(AQUAD,  Kwalitan  und  The  Ethnograph)  Informationen  zu  deren  Her-
stellern sowie die jeweilige Webadresse, unter der weiterführende Informa-
tionen und in den meisten Fällen eine Demoversion erhältlich ist: 

AQUAD 

ATLAS.TI 

HYPERRESEARCH 

KWALITAN 

Version 6  
Hersteller: Verlag Ingeborg Huber 
www.aquad.de  
Version 6  
Hersteller: Scientific Software GmbH  
www.atlasti.com (englisch), www.atlasti.de (deutsch) 
Version 2.8  
Hersteller: Researchware Inc. 
www.researchware.com  
Version 5  
Hersteller: Vincent Peters 
www.kwalitan.net  

252 

MAXQDA 

NVIVO 

QDA MINER 

 

QUALRUS  

THE ETHNOGRAPH  

TRANSANA 

Anhang 

Version 10  
Hersteller: Verbi GmbH 
www.maxqda.de (deutsch), www.maxqda.com (englisch) 
Version 8  
Hersteller: QSR 
www.qsrinternational.com 
Version 3.2  
Hersteller: Provalis Research  
www.provalisresearch.com  
Version 2  
Hersteller: Edward Brent 
www.qualrus.com  
Version 6  
Hersteller: Qualis Research Ass. 
www.qualisresearch.com 
Version 2.3  
Hersteller: David Woods 
www.transana.org 

 
Alle  Programme  sind  als  englischsprachige  Versionen  erhältlich,  eine 
deutsche  Version  mit  deutschem  Handbuch  existiert  von  MAXQDA, 
ATLAS.TI und AQUAD. Von einigen Programmen sind spanische Versio-
nen  verfügbar  (z.B.  MAXQDA  und  AQUAD),  seltener  sind  Versionen  in 
japanischer,  chinesischer  oder  arabischer  Sprache.  Alle  aufgeführten  Pro-
gramme laufen unter Windows XP und Vista. Der Betrieb von QDA-Soft-
ware auf dem MAC stellt allerdings seit dem Umstieg Apples auf Intel Pro-
zessoren  kein  unüberwindbares  Problem  mehr  dar,  denn  mit  Virtualisie-
rungssoftware  (z.B.  Parallels)  lässt  sich  jetzt  auch  Windows  auf  Apple 
Rechnern betreiben.  

Wer QDA-Software für die eigene Arbeit auswählt, sollte sich zunächst 
darüber klar werden, welche Art von Auswertungen durchgeführt werden 
sollen und welche Funktionen einer QDA-Software  hierfür benötigt wer-
den.  Zu  berücksichtigen  sind  auch  Art  und  Umfang  des  Materials,  denn 
manche  QDA-Programme  sind  nicht  für  die  Bearbeitung  von  größeren 
Projekten mit Daten im Umfang von mehreren Megabyte geeignet. Ein ein-
faches qualitatives Projekt besteht vielleicht nur aus einer Einmalerhebung 

Übersicht QDA-Software 

253 

von offenen Interviews mit wenigen Probanden. Komplexe Projekte arbei-
ten u.U. mit mehreren Erhebungszeitpunkten, verschiedenen Gruppen von 
Probanden,  verschiedenen  Datentypen  und  umfassen  viele  Probanden. 
Auch die Arbeitsorganisation ist von großer Bedeutung, d.h. wie viele Per-
sonen an der Analyse beteiligt sein werden und in welcher Form sie koope-
rieren sollen. Die von den meisten QDA-Programmen erhältlichen Demo-
versionen machen es möglich, die Analysefunktionen auszuprobieren. Lei-
der  lassen  aber  nicht  alle  Programme  einen  realitätsnahen  Test  zu,  da  sie 
dem Benutzer teilweise nur erlauben, mit einigen wenigen Texten oder ei-
ner  beschränkten  Anzahl  von  Codes  zu  arbeiten.  Für  die  Auswertung 
komplexer Projekte lässt sich so nur schwer ein Praxistest durchführen. Bei 
der Auswahl von Programmen sollte man folgende Leitfragen bei der Eva-
luation eines Programms stellen. 

Hard- und Softwareerfordernisse 
Welche  Systemanforderungen  werden  mindestens  gestellt?  Vor  allem  der 
minimal benötigte RAM-Speicher ist von Belang. 

Texte 
Wie müssen die Texte vorbereitet werden? Welche Begrenzungen hinsicht-
lich Format, Anzahl der Texte, Länge der Texte etc. gibt es? Müssen Text-
einheiten vorab definiert werden? Müssen die Texte eine bestimmte Struk-
tur aufweisen, z.B. eine bestimmte Zeilenlänge? Texte in welchen Sprachen 
kann die Software bearbeiten? Unterstützt sie den internationalen Zeichen-
satz-Standard Unicode. 

Codes/Kategoriensystem 
Wie ist ein Code im Programm definiert? Lassen sich Subcodes definieren? 
Wie  viele  Hierarchieebenen  sind  möglich?  Welchen  Typs  ist  das  Katego-
riensystem? Wie geht das Codieren vonstatten? Kann man das gleiche Seg-
ment mehrmals codieren? Werden Codierungen visuell dargestellt, in wel-
cher Form? Kann man Codes farblich kennzeichnen? Dürfen Codierungen 
sich überlappen oder ineinander verschachtelt sein? Wie einfach sind Ver-
änderungen von Codierungen und Kategoriensystem, z.B. Codierungen lö-
schen,  Codes  fusionieren  und  ausdifferenzieren?  Lässt  sich  die  Relevanz 
von  Textsegmenten  markieren?  Wird  ein  mehrstufiger  Codierprozess 

 

254 

Anhang 

(Grobcodierung/Feincodierung)  unterstützt,  d.h.  lassen  sich  leicht  neue 
Codes zuordnen. 

Memo 
Wie sieht ein Memo aus, aus welchen Angaben besteht es? Lassen sich Au-
tor und Erstellungsdatum eines Memos festhalten? Welche Arten von Me-
mos sind möglich? Wie werden Memos angezeigt? Gibt es Begrenzungen 
hinsichtlich der Anzahl und des Umfangs von Memos? Lassen sich Codes 
zu Memos zuordnen? Wie ist die gesamte Sammlung von Memos organi-
sierbar? Kann man in Memos suchen? Lassen sich Memos nach bestimm-
ten Codes selektieren? 

Fallvariablen 
Kann man Fallvariablen definieren? Welchen Typs können die Fallvariablen 
sein? Wieviele Variablen sind erlaubt? Wie übersichtlich ist die Darstellung? 
Gibt  es  Import-Export-Möglichkeiten  zu  SPSS  und  anderen  Statistikpro-
grammen? Kann man Fallvariablen und Text-Retrieval verbinden? 

Text-Retrieval 
Wie werden codierte Segmente wiedergefunden? Gibt es eine Zusammen-
stellung der Segmente in einer Liste? Kann man vom codierten Segment in 
den  Herkunftstext  springen?  Ist  selektives  Retrieval  in  Abhängigkeit  von 
Fallvariablen möglich. Welche Funktionen zur Evaluierung von gleichzeiti-
gem Vorkommen von Codes gibt es? 

Lexikalische Suche/automatische Codierung 
Ist die lexikalische Suche in den Texten möglich? Kann für den Suchpro-
zess  eine  Auswahl  von  Texten  nach  bestimmten  Kriterien  vorgenommen 
werden? Ist eine  automatische Codierung der  Treffer möglich? Lässt sich 
ein  Keyword-in-Context  erstellen?  Lassen  sich  aufeinander  aufbauende 
Suchrecherchen durchführen? 

Teamarbeit 
Unterstützt die Software Teamarbeit? Wenn ja, in welcher Weise – wie 
muss man die Zusammenarbeit organisieren? Kann man die Texte arbeits-
teilig bearbeiten? Können mehrere Personen den gleichen Text codieren? 

Interessante Internet-Seiten rund um QDA-Software und qualitative Datenanalyse 

255 

Sprache 
Welche Sprachversionen existieren von der Software? Gibt es eine deutsche 
Version? Gibt es Handbücher, in welcher Form, in welchen Sprachen? 

Datenorganisation 
Wie effizient werden die Daten organisiert? Wie viel Speicherplatz nimmt 
ein durchschnittliches Projekt ein? Aus wie vielen Dateien besteht ein Pro-
jekt? Wie leicht ist die Datensicherung? Werden die Texte von der Software 
importiert und kontrolliert oder können Sie von außen verändert werden.  

Support 
Gibt es einen Support bei Problemen? Wie findet der Support statt (E-Mail, 
Telefon)? Ist der Support kostenpflichtig? 

Interessante Internet-Seiten rund um QDA-Software und 
qualitative Datenanalyse 

Zur computerunterstützten Analyse qualitativer Daten existieren eine Reihe 
von interessanten Web-Quellen: 

caqdas.soc.surrey.ac.uk 
Das  „Computer  Assisted  Qualitative  Data  Analysis  Networking  Project”, 
englischsprachiges  Projekt  zur  Unterstützung  und  zur  Information  von 
Nutzern  von  Programmen  zur  qualitativen  Datenanalyse.  Es  finden  sich 
Hinweise  auf  Workshops,  viele  weiterführende  Weblinks  und  andere  In-
formationen. 

www.qualitative-research.net 
Forum  Qualitative  Sozialforschung,  Online-Zeitschrift  zu  Methoden  und 
Themen der qualitativen Sozialforschung mit Themenbänden zu zentralen 
Themen.  Neben  der  Einsicht  in  Buchrezensionen  und  Interviews  besteht 
die Möglichkeit, Themen der qualitativen Sozialforschung zu diskutieren. 

www.qualitative-forschung.de 
Online-Portal für qualitative Forschung, es finden sich allgemeine Informa-
tionen (zu Institutionen und Personen, zur Forschung, zur Weiterbildung, 

 

256 

Anhang 

Verweise auf Online-Ressourcen etc.), Kommunikationsangebote (Mailing-
liste, Chat und Pinboard) sowie Hinweise auf Beratungen und Schulungen. 

www.methodenlernen.de 
Umfangreiches  Online-Angebot  des  Arbeitsgebiets  Empirische  Pädagogik 
an  der  Philipps-Universität  Marburg  mit  Schwerpunkt  qualitative  Metho-
den. Das Angebot umfasst Texte und Quellen (überwiegend PDF) und ist 
für alle TeilnehmerInnen an Online-Lehrangeboten zugänglich. 

www.nova.edu/ssss/QR 
The Qualitative Report, seit 1990 bestehendes, englischsprachiges Online-
Journal der Graduate School of Humanities and Social Sciences an der No-
va  Southeastern  University  mit  dem  Schwerpunkt  der  qualitativen  For-
schung. 

www.textanalysis.info 
Von Harald Klein unterhaltene Webseite mit sehr vielen Links und Infor-
mationen zur qualitativen und quantitativen Textanalyse. 

www.qualitativeresearch.uga.edu/QualPage 
Sammlung von Ressourcen zur qualitativen Sozialforschung (englischspra-
chig),  u.a.  finden  sich  Links  zu  Ankündigungen  von  Konferenzen  und 
Workshops, zu Diskussionsforen, zu elektronischen Zeitschriften, Organi-
sationen und Interessengruppen etc. 

http://www.uni-magdeburg.de/iew/zbbs  
Homepage des Zentrums für qualitative Bildungs-, Beratungs- und Sozial-
forschung  mit  eigener  Zeitschrift  und  Mailingliste,  darüber  hinaus  finden 
sich Texte zu qualitativen Methoden, Workshops u.v.m. 

onlineqda.hud.ac.uk 
Eine  von  der  University  of  Huddersfield  in  Kooperation  mit  dem  CAQ-
DAS-Projekt der University of Surrey unterhaltene Site, die viele Materia-
lien zu QDA-Software enthält. 

www.ualberta.ca/~iiqm 
Homepage  des  interdisziplinären  „International  Institute  for  Qualitative 
Methodology, Edmonton/Alberta (Canada)“ 

Interessante Internet-Seiten rund um QDA-Software und qualitative Datenanalyse 

257 

www.car.ua.edu 
Von Willliam Evans u.a. gestaltete Site zur quantitativen Inhaltsanalyse. Die 
Site enthält eine Literatur- und eine Softwareliste, weiterführende Links so-
wie eine Mailing-Liste. 

 

 

Literatur 

Alexa, M./Züll, C. (1999): A review of software for text analysis. ZUMA-Nachrichten Spezi-

Bacher,  J.  (1996):  Clusteranalyse.  Anwendungsorientierte  Einführung.  (2.  Aufl.).  Mün-

al Band 5. Mannheim: ZUMA. 

chen/Wien: Oldenbourg. 

Banks, M. (2001): Visual methods in social research. London: Sage. 
Barton, A.H./Lazarsfeld, P.F. (1984): Einige Funktionen von qualitativer Analyse in der So-
zialforschung. In: Hopf, C./Weingarten, E. (Hrsg.): Qualitative Sozialforschung. Stutt-
gart: Klett Cotta, 41-111. 

Bauer,  M./Gaskell,  G.  (Ed.)  (2000):  Qualitative  researching  with  text,  image  and  sound. 

Thousand Oaks u.a.: Sage. 

Bazeley, P. (2009): Mixed methods data analysis. In: S. Andrew & E. Halcomb (Eds.), Mixed 
methods research for nursing and health sciences, Chichester, UK: Wiley-Blackwell, 84-
118. 

Berelson, B. (1952): Content analysis in communication research. Glencoe: Free Press. 
Blasius, Jörg/Greenacre, Michael Hrsg. (1998): Visualization of Categorical Data. San Diego: 

Academic Press. 

Böhm, A. (2005): Theoretisches Codieren: Textanalyse in der Grounded Theory. In: Flick, 
U./von  Kardorff,  E./Steinke,  I.  (Hrsg.):  Qualitative  Sozialforschung.  Ein  Handbuch. 
Reinbek: Rowohlt, 475-484. 

Böhm,  A./Muhr,  T./Mengel,  A.  (Hrsg.)  (1994):  Texte  verstehen:  Konzepte,  Methoden, 

Werkzeuge. Konstanz: Universitätsverlag. 

Bortz,  J.  (2005):  Statistik  für  Sozialwissenschaftler  (6.  Auflage).  Berlin/Heidelberg/New  

York: Springer. 

Bos, W./Tarnai, C. (Hrsg.) (1989): Angewandte Inhaltsanalyse in der Empirischen Pädago-

gik und Psychologie. Münster u.a.: Waxmann. 

Bos, W./Tarnai, C. (Hrsg.) (1996): Computerunterstützte Inhaltsanalyse in den Empirischen 

Sozialwissenschaften. Theorie – Anwendung – Software. Münster u.a.: Waxmann. 

Buber,  R./Zelger,  J.  (Hrsg.)  (2000):  GABEK  II.  Zur  qualitativen  Forschung.  Innsbruck/ 

Wien/München: Studien Verlag. 

Bukova, A./Hellstern, G.-M. (1995): Computergestützte Argumentationsanalyse der Hoch-
schulreformdebatte mit Hilfe von WINMAX 1.0. In: Kuckartz, U. (Hrsg.) (1995): Com-
putergestützte  Auswertung  qualitativer  Daten:  Praxis,  Erfahrungen,  Zukunft.  1.  MAX 
Benutzerkonferenz. Berlin. 

Buzan, T. (2004): Das kleine Mind-Map-Buch. München: Goldmann. 
CAQD  (2005):  Computergestützte  Analyse  Qualitativer  Daten.  winMAX/MAXQDA  An-
wenderkonferenz Philipps-Universität Marburg. Tagungsband mit erweiterten Abstracts 
der Tagungsvorträge. Verfügbar über: http://www.caqd.de (Zugriff: 02.09.2009). 

Literatur 

259 

CAQD  (2006):  Computergestützte  Analyse  Qualitativer  Daten.  winMAX/MAXQDA  An-
wenderkonferenz Philipps-Universität Marburg. Tagungsband mit erweiterten Abstracts 
der Tagungsvorträge. Verfügbar über: http://www.caqd.de (Zugriff: 02.09.2009). 

Carmichael, P. (2002): Extensible Markup Language and Qualitative Data Analysis (39 para-
graphs). Forum Qualitative Sozialforschung/Forum Qualitative Social Research [Online 
Journal],  3(2).  Verfügbar  über:  http://www.qualitative-research.net/fqs/fqs-eng.htm 
(Zugriff: 02.09.2009). 

Coffey,  A./Holbrook,  B./Atkinson,  P.  (1996):  Qualitative  data  analysis:  technologies  and 
representations.  Sociological  Research  Online,  vol.  1,  no.1.  Verfügbar  über: 
http://www.socresonline.org.uk/1/1/4.html (Zugriff: 15.03.2005). 

Corbin, Juliet/Strauss, Anselm (2008): Basics of Qualitative Research. Techniques and Pro-
cedures for Developing Grounded Theory. Third Edition. Thousand Oaks: SageCorti, 
L. (2000): Progress and Problems of Preserving and Providing Access to Qualitative Da-
ta  for  Social  Research  –  The  International  Picture  of  an  Emerging  Culture  [58  para-
graphs].  Forum  Qualitative  Sozialforschung/Forum:  Qualitative  Social  Research  [On-
line  Journal],  1(3).  Verfügbar  über:  http://www.qualitative-research.net/fqs-texte/3-
00/3-00corti-e.htm (Zugriff: 02.09.2009). 

Creswell, John (2007): Qualitative Inquiry and Research Design. Choosing among five ap-

proaches. Second Edition. Thousand Oaks: Sage. 

Creswell, John /Piano, Vicky (2007): Designing and Conducting Mixed Methods Research. 

Thousand Oaks: Sage. 

Creswell,  J.W./Maietta,  R.C.  (2002):  Qualitative  Research.  In:  Miller,  D.C./Salkind,  N.J. 
(Eds.): Handbook of Research Design and Social Measurement (6th edition). Thousand 
Oaks u.a.: Sage, 143-200. 

de Haan, G./Kuckartz, U. (1996): Umweltbewußtsein. Denken und Handeln in Umweltkri-

sen. Opladen: Westdeutscher Verlag. 

de Haan, G./Kuckartz, U./Rheingans, A. (2000): Bürgerbeteiligung und Lokale Agenda 21-
Initiativen. Analysen zu Kommunikations- und Organisationsformen. Opladen: Leske+ 
Budrich. 

Denzin, N.K./Lincoln, Y.S. (Eds.) (2000): Handbook of Qualitative Research (2nd. edition). 

Thousand Oaks u.a.: Sage. 

Dey, I. (1993): Qualitative Data Analysis. London u.a.: Routledge. 
Diekmann, A. (2000): Empirische Sozialforschung. Grundlagen, Methoden, Anwendungen. 

Dittmar, N. (2002): Transkription. Ein Leitfaden mit Aufgaben für Studenten, Forscher und 

Reinbek: Rowohlt. 

Laien.  

Feldmann, Klaus (2003): Du sollst dir kein Bild machen! (Nicht)Visualisierung in der Sozio-
logie. In: TRANS. Internet-Zeitschrift für Kulturwissenschaften. No. 14/2002. Verfüg-
bar unter: http://www.inst.at/trans/14Nr/feldmann14.htm. (Zugriff: 07.09.2009) 

Fielding, N./Lee, R. (1998): Computer Analysis and Qualitative Research. Thousand Oaks 

Fielding, N./Lee, R. (Eds.) (1991): Using computers in qualitative research. Thousand Oaks 

u.a.: Sage. 

u.a.: Sage. 

Fielding, N.G./Lee, R.M. (2002): New patterns in the adoption and use of qualitative soft-

ware. Field methods 14:2 (5), 197-216. 

 

260 

Literatur 

Fischer,  F.  1998:  Mappingverfahren  als  kognitive  Werkzeuge  für  problemorientiertes  Ler-

nen. Frankfurt/M., Lang. 

Flick, U. (2007a): Qualitative Sozialforschung. Eine Einführung. Reinbek: Rowohlt. 
Flick, U. (2007b): Triangulation – Methodologie und Anwendung. Wiesbaden: VS Verlag. 
Flick, U./v. Kardoff, E./Steinke, I. (Hrsg.) (2005): Qualitative Sozialforschung. Ein Hand-

buch. Reinbek: Rowohlt. 

Ford, K./Oberski, I./Higgins, S. (2000): Computer-Aided Qualitative Analysis of Interview 
Data: Some Recommendations for Collaborative Working. The Qualitative Report (On-
line Journal), 4(3/4). Verfügbar über:  
http://www.nova.edu/ssss/QR/BackIssues/index.html (Zugriff: 12.03.2005). 

 
Friebertshäuser, B./Prengel, A. (Hrsg.) (1997): Handbuch Qualitative Forschungsmethoden 

in der Erziehungswissenschaft. Weinheim/München: Juventa. 

Früh, W. (2004): Inhaltsanalyse. Theorie und Praxis (5. Auflage). Konstanz: UVK Verlagsge-

sellschaft mbH. 

Gerhardt, U. (1986): Patientenkarrieren. Frankfurt/M.: Suhrkamp. 
Gerhardt, U. (1995): Typenbildung. In: Flick, U./v. Kardoff, E./Keupp, H./v. Rosenstiel, 
L./Wolff,  S.  Hrsg.):  Handbuch  Qualitative  Sozialforschung.  Weinheim:  Beltz,  PVU, 
435-439. 

Gibbs,  G.R.  (2002):  Qualitative  Data  Analysis:  Explorations  with  NVivo.  Buckingham:  

Open University Press. 

Gibbs,  G.R./Friese,  S./Mangabeira,  W.C.  (2002):  Technikeinsatz  im  qualitativen  For-
schungsprozess. Einführung zu FQS Band 3(2) (34 Absätze). Forum Qualitative Sozial-
forschung/Forum  Qualitative  Social  Research  [Online  Journal],  3(2).  Verfügbar  über: 
http://www.qualitative-research.net/fqs/fqs.htm (Zugriff: 31.07.2002). 

Giegler, H. (1992): Zur computerunterstützten Analyse sozialwissenschaftlicher Textdaten: 
Quantitative und qualitative Strategien. In: Hoffmeyer-Zlotnik, J.P. (Hrsg.) (1992): Ana-
lyse verbaler Daten. Opladen: Westdeutscher Verlag, 335-388. 

Giesel,  Katharina  (2007):  Leitbilder  in  den  Sozialwissenschaften:  Begriffe,  Theorien  und 
Forschungskonzepte.  Wiesbaden:  VS.  Glaser,  B.  (1978):  Theoretical  Sensitivity.  Ad-
vances in the Methodology of Grounded Theory. Mill Valley: Sociology Press. 

Glaser,  B.  (1992):  Emergence  vs.  forcing.  Basics  of  grounded  theory  analysis.  Mill  Valley: 

Sociology Press. 

Glaser, B. (2002): Data Management: Computer Data Collection. Manuskript o.O. 
Glaser, B./Strauss, A. (1998): Grounded Theory. Bern: Hans Huber. 
Goffman, E. (2000): Rahmen-Analyse (5. Auflage). Frankfurt/M.: Suhrkamp. 
Greenstein, D.I. (1994): A Historian’s Guide to Computing. Oxford: University Press. 
Grunenberg, H. (2001): Die Qualität qualitativer Forschung. Eine Metaanalyse erziehungs- 
und  sozialwissenschaftlicher  Forschungsarbeiten.  Diplomarbeit  FB  Erziehungswissen-
schaften Marburg. Verfügbar über: http://www.g-berg.de/forschung.htm 

Helsper, W./Herwartz-Emden, L./Terhart, E. (2001): Qualität qualitativer Forschung in der 

Erziehungswissenschaft. Zeitschrift für Pädagogik, (47), 251-269. 

Hempel, C.G./Oppenheim, P. (1936): Der Typusbegriff im Lichte der neuen Logik. Wissen-
schaftstheoretische Untersuchungen zur Konstitutionsforschung und Psychologie. Lei-
den: Sijthoff. 

Herwartz-Emden (1986): Arbeitsplatz Hochschule – Eine qualitative Inhaltsanalyse. DFG-

Projektbericht. Technische Universität Berlin. 

Literatur 

261 

Hesse-Biber, S./Dupuis, P. (1996): An Automatic Hypothesis Tester for Qualitative Analy-
sis. In: Bandilla, W./Faulbaum, F. (Eds.). SoftStat ‘95: Advances in Statistical Software 5. 
Stuttgart, 353-360. 

Hopf, C. u.a. (1995): Familie und Rechtsextremismus: Familiale Sozialisation und rechtsex-

treme Orientierungen junger Männern. Weinheim/München: Juventa. 

Hopf,  C./Hartwig,  M.  (2001):  Liebe  und  Abhängigkeit.  Partnerschaftsbeziehungen  junger 

Frauen. Weinheim/München: Juventa. 

Hopf, C./Hopf, W. (1997): Familie, Persönlichkeit, Politik. Eine Einführung in die  politi-

sche Sozialisation. Weinheim/München: Juventa. 

Hopf,  C./Nevermann,  K./Schmidt,  I.  (1985):  Wie  kamen  die  Nationalsozialisten  an  die 
Macht. Eine empirische Analyse von Deutungen im Unterricht. Frankfurt/M.: Campus. 
Hopf,  C./Schmidt,  C.  (Hrsg.)  (1993):  Zum  Verhältnis  von  innerfamilialen  sozialen  Erfah-
rungen,  Persönlichkeitsentwicklung  und  politischen  Orientierungen.  Dokumentation 
und Erörterung des methodischen Vorgehens in einer Studie zu diesem Thema. Institut 
für Sozialwissenschaften der Universität Hildesheim. Verfügbar über: http://w2.wa.uni-
hannover.de/mes/berichte/rex93.htm (Zugriff: 02.09.2009). 

Hopf, C./Weingarten E. (Hrsg.) (1979): Qualitative Sozialforschung. Stuttgart: Klett-Cotta. 
Huber,  G.  (1996):  Theoriebildung  und  Rekonstruktion  subjektiver  Sichtweisen  mit  Aquad 
Vier.  In:  Bos,  W./Tarnai,  C.  (1996):  Computergestützte  Inhaltsanalyse  in  den  empiri-
schen Sozialwissenschaften. Münster u.a.: Waxmann, 193-208. 

Huber,  G.L.  (Hrsg.)  (1992):  Qualitative  Analyse:  Computereinsatz  in  der  Sozialforschung. 

München/Wien: Oldenbourg. 

Huberman, A.M./Miles, M.B. (1983): Drawing Valid Meaning from Qualitative Data: Some 

Techniques of Data Reduction and Display. In: Quality and Quantity 17, 281-339. 

Huberman, A.M./Miles, M.B. (1994): Data Management and Analysis Methods. In: Denzin, 
N./Lincoln,  Y.  (Eds):  Handbook  of  Qualitative  Research.  Thousand  Oaks  u.a.:  Sage, 
428-444. 

Jahoda,  M./Lazarsfeld,  P.F./Zeisel,  H.  (1980):  Die  Arbeitslosen  von  Marienthal.  Frank-

furt/M.: Suhrkamp. 

Kelle, U. (1994): Empirisch begründete Theoriebildung. Zur Logik und Methodologie inter-

pretativer Sozialforschung. Weinheim: Deutscher Studien Verlag. 

Kelle, U. (1997a): Capabilities for Theory Building & Hypothesis Testing. In: Software for 

Computer Aided Qualitative Data Analysis. Data Archive Bulletin, No.65. 

Kelle, U. (1997b): Theory building in Qualitative Research and Computer Programs for the 

Management of Textual Data. Sociological Research Online Vol. 2, No. 2. 

Kelle, Udo (2008): Die Integration qualitativer und quantitativer  Methoden in der empiri-
schen  Sozialforschung:  Theoretische  Grundlagen  und  methodologische  Konzepte. 
Wiesbaden: VS. 

Kelle, U. (2000): Computergestützte Analyse qualitativer Daten. In: Flick, U./v. Kardorff, 
E./Steinke, I. (Hrsg.): Qualitative Forschung – Ein Handbuch. Reinbek: Rowohlt, 485-
501. 

Kelle, Udo (2005, May). "Emergence" vs. "Forcing" of Empirical Data? A Crucial Problem 
of "Grounded Theory" Reconsidered [52 Absätze]. Forum Qualitative Sozialforschung 
[On-line Journal], 6(2). 

Kelle,  U.  (Ed.)  (1995):  Computer-Aided  Qualitative  Data  Analysis.  Theory,  Methods  and 

Practice. Thousand Oaks u.a.: Sage. 

 

262 

Literatur 

Kelle, U./Kluge, S. (1999): Vom Einzelfall zum Typus. Fallvergleich und Fallkontrastierung 

in der qualitativen Sozialforschung. Opladen: Leske+Budrich. 

Kelle, U./Laurie, H. (1995): Computer Use in Qualitative Research and Issues of Validity. 
In: Kelle, U. (1995): Computer-Aided Qualitative Data Analysis. Theory, Methods and 
Practice. Thousand Oaks u.a.: Sage. 

Klein, H. (1997): Overview on text analysis software. In: Bandilla, W./Faulbaum, F. (Eds.): 

SoftStat '97 – Advances in Statistical Software. Stuttgart: Lucius & Lucius. 

Kluge, S. (1995): Klassische und computergestützte Typenbildung im Vergleich: Ein Beispiel 
aus der Forschungspraxis. In: Kuckartz, U. (Hrsg.) (1995): Computergestützte Auswer-
tung qualitativer Daten: Praxis, Erfahrungen, Zukunft. 1. MAX Benutzerkonferenz, Ber-
lin. 

Kluge,  S.  (1999):  Empirisch  begründete  Typenbildung.  Zur  Konstruktion  von  Typen  und 

Typologien in der qualitativen Sozialforschung. Opladen: Leske+Budrich. 

Kluge, S./Opitz, D. (1999): Die Archivierung qualitativer Interviewdaten: Forschungsethik 
und  Datenschutz  als  Barrieren  für  Sekundäranalysen?  Soziologie,  Mitteilungsblatt  der 
DGS, Nr. 4, 48-63. 

König,  T.  (2004):  CAQDAS  in  der  Frame  Analysis.  In:  Kuckartz,  U./Grunenberg, 
H./Lauterbach,  A.  (Hrsg.):  Qualitative  Datenanalyse  computergestützt.  Methodische 
Hintergründe und Beispiele aus der Forschungspraxis. Wiesbaden: VS Verlag, S. 81-93. 

Kowall,  S./O’Connell,  D.C.  (2000):  Zur  Transkription  von  Gesprächen.  In:  Flick,  U./v. 
Kardorff,  E./Steinke,  I.  (Hrsg.):  Qualitative  Forschung  –  Ein  Handbuch.  Reinbek: 
Rowohlt, 437-447. 

Kracauer, S. (1952). The challenge of qualitative content analysis. Public Opinion Quarterly, 

16, 631-642. 

Krempel, Lothar (2005): Visualisierung komplexer Strukturen. Grundlagen der Darstellung 

mehrdimensionaler Netzwerke, Frankfurt/M.: Campus. 

Kriz, J./Lisch, R. (1988): Methoden-Lexikon. Weinheim/München: PVU. 
Kuckartz, U. (1988): Computer und verbale Daten: Chancen zur Innovation sozialwissen-

schaftlicher Forschungstechniken. Frankfurt/M.: Perte Lang. 

Kuckartz, U. (1995): Case-oriented quantification. In: Kelle, U. (Ed.): Computer-Aided Qua-

litative Data Analysis. Theory, Methods and Practice. Thousand Oaks u.a.: Sage. 

Kuckartz, U. (1996): Argumentationen und Leitbilder computergestützt analysieren. In: His-

torical Social Research. Historische Sozialforschung, Vol 21, No.3, 115-136. 

Kuckartz, U. (1999): Computergestützte Analyse qualitativer Daten. Eine Einführung in Me-

thoden und Arbeitstechniken. Opladen: Westdeutscher Verlag. 

Kuckartz, U. (2001): Aggregation und Dis-Aggregation in der sozialwissenschaftlichen Um-
weltforschung. Methodische Anmerkungen zum Revival der Typenbildung. In: de Haan, 
G./Lantermann, E.-D./Linneweber, V./Reusswig, F. (2001): Typenbildung in der sozi-
alwissenschaftlichen Umweltforschung. Opladen: Leske+Budrich. 

Kuckartz, U./Grunenberg, H./Lauterbach, A. (2004): Qualitative Datenanalyse computerge-
stützt. Methodische Hintergründe und Beispiele aus der Forschungspraxis. Wiesbaden: 
VS Verlag. 

Kuckartz/Grunenberg/Dresing (Hrsg.) (2007): Qualitative Datenanalyse: computergestützt: 
Methodische Hintergründe und Beispiele aus der Forschungspraxis. Wiesbaden: VS Ver-
lag. 

Literatur 

263 

Kuckartz,  U./Dresing,  T./Rädiker,  S./Stefer,  C.  (2008):  Qualitative  Evaluation.  2.  Aufl., 

Wiesbaden: VS Verlag. 

Kuckartz, U./Ebert, T./Rädiker, S./Stefer, C. (2009): Evaluation Online. Internetgestützte 

Befragung in der Praxis. Wiesbaden: VS Verlag.  

Lamnek, S. (2005): Qualitative Sozialforschung. Lehrbuch (4. Auflage). Weinheim: Beltz. 
Lazarsfeld, P.F. (1972): Qualitative analysis. Historical and critical essays. Boston: Allyn and 

Bacon. 

logie. 3, 64-75. 

Lee, R.M./Fielding, N. (1996): Qualitative Data Analysis: Representations of a Technology: 
A Comment on Coffey, Holbrook and Atkinson. In: Sociological Research Online Vol. 
1, No. 4. 

Legewie, H./Schervier-Legewie, B. (1995): Anselm Strauss im Gespräch. Journal für Psycho-

Lewins,  Ann/Silver,  Christina  (2007):  Using  Software  in  Qualitative  Research.  A  Step-by-
Step  Guide.  Thousand  Oaks:  Sage.Lofland,  J./Lofland,  L.H.  (1984):  Analyzing  social 
settings:  A  guide  to  qualitative  observation  and  analysis  (2.  Auflage).  Belmont/CA.: 
Wadsworth. 

Ludwig-Mayerhofer, W. (2005): ILMES – Internet-Lexikon der Methoden der empirischen 

Sozialforschung. Verfügbar über: www.lrz-muenchen.de/~wlm/ilmes.htm. 

Marz,  L.  (1993):  Leitbild  und  Diskurs  (Eine  Fallstudie  zur  diskursiven  Technikfolgenab-

schätzung von Informationstechniken). WZB Papers FS II Berlin, 93-106. 

Marz,  L./Dierkes,  M.  (1992):  Leitbildprägung  und  Leitbildgestaltung.  Zum  Beitrag  der 
Technikgenese-Forschung  für  eine  prospektive  Technikfolgen-Regulierung.  WZB  Pa-
pers FS II Berlin, 92-105. 

Mayring, P. (2001): Kombination und Integration qualitativer und quantitativer Analyse (31 
Absätze). Forum Qualitative Sozialforschung/Forum: Qualitative Social Research [On-
line Journal], 2(1). Verfügbar über: http://qualitative-research.net/fqs/fqs.htm (Zugriff: 
02.09.2009). 

Mayring, P. (2002): Einführung in die qualitative Sozialforschung. Eine Anleitung zu qualita-

tivem Denken (5. Auflage). Weinheim: Beltz. 

Mayring,  P.  (2003):  Qualitative  Inhaltsanalyse.  Grundlagen  und  Techniken  (8.  Auflage). 

Merten, K. (1995): Inhaltsanalyse. Einführung in Theorie, Methode und Praxis (2. Auflage). 

Weinheim: Deutscher Studien Verlag. 

Opladen: Westdeutscher Verlag. 

Merton, Robert K./Barber, Elinor: (2004a) The Travels and Adventures of Serendipity: A 
Study  in  Sociological  Semantics  and  the  Sociology  of  Science.  Princeton  University 
Press, Princeton 

Merton, Robert K. (2004b): Auf den Schultern von Riesen. Suhrkamp, Frankfurt am Main 
Mey, Günter/Mruck, Katja (Hrsg.) (2007). Grounded Theory Reader (Reihe: HSR Supple-
ment 19). Köln: ZHSF. Miles, M.B./Huberman, M. (1994): Qualitative Data Analysis. 
An Expanded Sourcebook (2nd edition). Thousand Oaks u.a.: Sage. 

Miller,  D.C./Salkind,  N.J.  (Eds.)  (2002):  Handbook  of  Research  Design  and  Social  Mea-

surement (6th edition). Thousand Oaks u.a.: Sage. 

Mruck, K. (2000): Qualitative Sozialforschung in Deutschland (54 Absätze). Forum Qualita-
tive Sozialforschung/Forum Qualitative Social Research [Online Journal], 1(1). Verfüg-
bar über: http://qualitative-research.net/fqs (Zugriff: 02.09.2009). 

 

264 

Literatur 

über: 

Muhr, Th. (2000): Forum: Increasing the Reusability of Qualitative Data with XML: Forum 
Qualitative  Sozialforschung/Forum  Qualitative  Social  Research  [Online  Journal],  3(2). 
Verfügbar 
(Zugriff: 
02.09.2009). 

http://www.qualitative-research.net/fqs/fqs-eng.htm 

Prein, G./Kelle, U./Bird, K. (1995): An Overview of Software. In: Kelle, U. (Ed.) (1995): 
Computer-Aided  Qualitative  Data  Analysis.  Theory,  Methods  and  Practice.  Thousand 
Oaks u.a.: Sage. 

Ragin,  C.  (1987):  The  comparative  method.  Moving  beyond  qualitative  and  quantitative 

strategies. Berkeley/Los Angeles/London: University of California Press. 

Ragin, C. (1994): Constructing Social Research: The Unity and Diversity of Method. Thou-

sand Oaks u.a.: Sage. 

Richards, T./Richards, L. (1994): Using computers in qualitative analysis. In: Denzin, N. K./ 
Lincoln,  Y.  S.  (Eds.)  (1994):  Handbook  of  qualitative  research.  Thousand  Oaks  u.  a.: 
Sage. 

Roberts,  K.A./Wilson,  R.W.  (2002):  ICT  and  the  Research  Process:  Issues  Around  the 
Compatibility  of  Technology  with  Qualitative  Data  Analysis  (52  paragraphs).  Forum 
Qualitative Sozialforschung/Forum: Qualitative Social Research [Online Journal], 3(2). 
Verfügbar über: http://www.qualitative-research.net/fqs-texte/2-02/2-02robertswilson-
e.htm (Zugriff: 02.09.2009). 

Rössler,  Patrick  2005:  Inhaltsanalyse  Schauf,  G./Schünemann,  R..  (1995):  Experteninter-
views in der Jugendhilfeforschung. In: Kuckartz, U. (Hrsg.) (1995): Computergestützte 
Auswertung qualitativer Daten: Praxis, Erfahrungen, Zukunft. 1. MAX Benutzerkonfe-
renz, Berlin. 

Schmidt, C. (1997): „Am Material“: Auswertungstechniken für Leitfadeninterviews. In: Frie-
bertshäuser, B./Prengel, A. (1997): Handbuch Qualitative Forschungsmethoden in der 
Erziehungswissenschaft. Weinheim/München: Juventa. 

Schnell, R./Hill, P./Esser, E. (2004): Methoden der empirischen Sozialforschung. München: 

Oldenbourg Wissenschaftsverlag. 

Schründer-Lenzen, A. (1996): Inhaltsanalyse als Instrument methodisch kontrollierter Typen-
bildung:  Das  Textanalysesystem  MAX  in  der  Forschungspraxis.  In  Bos  W./Tarnai  C. 
(Hrsg.):  Computergestützte  Inhaltsanalyse  in  den  empirischen  Sozialwissenschaften. 
Münster u.a.: Waxmann, 135-148. 

Schründer-Lenzen, A. (1997): Triangulation und idealtypisches verstehen in der (Re-)Kon-
struktion  subjektiver  Theorien.  In:  Friebertshäuser,  B./Prengel,  A.  (Hrsg.):  Handbuch 
Qualitative Forschungsmethoden in der Erziehungswissenschaft. Weinheim/München: 
Juventa. 

Schütz, A. (1962): Collected Papers I. The Problem of Social Reality. The Hague: Nijhoff. 
Seale, C. (1999): The Quality of Qualitative Research. Thousand Oaks u.a.: Sage. 
Seale, C./Silverman, D. (1997): Ensuring rigour in qualitative research. European Journal of 

Silverman, D. (1993): Interpreting Qualitative Data: Methods for Analysing Talk, Text and 

Public Health, H.7, 379-384. 

Interaction. Thousand Oaks u.a.: Sage. 

Spöhring, W. (1995): Qualitative Sozialforschung. Stuttgart: Teubner. 
Steinke,  I.  (1999):  Kriterien  qualitativer  Forschung.  Ansätze  zur  Bewertung  qualitativ-

empirischer Sozialforschung. Weinheim/München: Juventa. 

Literatur 

265 

Strauss,  A.  (1991):  Grundlagen  qualitativer  Sozialforschung.  Datenanalyse  und  Theoriebil-

dung in der empirischen und soziologischen Forschung. München: Fink. 

Strauss, A./Corbin, J. (1996): Grundlagen qualitativer Sozialforschung. Weinheim: Beltz. 
Strübing,  Jörg  (2004):  Grounded  Theory:  Zur  sozialtheoretischen  und  epistemologischen 
Fundierung  des  Verfahrens  der  empirisch  begründeten  Theoriebildung.  VS  Verlag  für 
Sozialwissenschaften, Wiesbaden 2004 

Strübing,  Jörg  (2007):  Anselm  Strauss.  Konstanz:  UVK.Tesch,  R.  (1990):  Qualitative  Re-
search: Analysis Types and Software Tools. New York/Philadelphia/London: The Fal-
mer Press. 

Toulmin, S.E. (1975): Der Gebrauch von Argumenten. Kronberg/Ts.: Scriptor. 
Weber,  M.  (1911):  Geschäftsbericht  auf  dem  1.  Deutschen  Soziologentag  vom  19.–22. 
10.1910 in Frankfurt/Main. In: Verhandlungen der Deutschen Soziologentage, Tübin-
gen, 39 – 52. Stuttgart: Enke. 

Weber, M. (1964): Wirtschaft und Gesellschaft. Grundriß der verstehenden Soziologie. Stu-

dienausgabe, hrsg. von J. Winckelmann. Köln/Berlin: Kiepenheuer & Witsch. 

Weitzman, E./Miles, B. (1995): Computer Programs for Qualitative Data Analysis: A Soft-

ware Sourcebook. Thousand Oaks u.a.: Sage. 

Wirth, W./Lauf, E. (2001): Inhaltsanalyse. Perspektiven, Probleme, Potentiale. Köln: Her-

bert von Halem Verlag. 

Witzel, A. (1982): Verfahren der qualitativen Sozialforschung. Frankfurt: Campus. 
Witzel, A. (2000): Das problemzentrierte Interview [26 Absätze]. Forum Qualitative Sozial-
forschung/Forum: Qualitative Social Research [On-line Journal], 1(1). Verfügbar über: 
http://www.qualitative-research.net/fqs-texte/1-00/1-00witzel-d.htm  
(Zugriff: 02.09.2009). 

Züll, C./Mohler, P. (Hrsg.) (1992): Textanalyse, Anwendungen der computergestützten In-

haltsanalyse, Opladen: Westdeutscher Verlag. 

Züll, C./Mohler, P.P./Geis, A. (1991): Computergestützte Inhaltsanalyse mit TEXTPACK 

PC. Stuttgart/New York: Fischer. 

 

 

Index 

A 

Absatzzeichen  49, 55, 131 
Ähnlichkeit  231 
Ähnlichkeitskoeffizienten  233 
Ähnlichkeitsmatrix  231, 234 
Aktionsforschung  19 
Analyseeinheit  35 
Analyseformen  18 
Ankerbeispiele  134 
Anonymisierung  33, 47 
Antworttexte auf offene Fragen  50 
AQUAD  251 
Argumentationsanalyse  207 
Argumentationstheorie  208 
ATLAS.TI  251 
Auswertung qualitativer Interviews  109 
Automatisches Codieren  127 

B 
Bandbasierte Analyse  39 
Beobachtungsstudien  128 
Bewertungsanalyse  219 
C 

CAQDAS  9 
Clusteranalyse  28, 237, 238 
Codeliner  189 
Code-Matrix-Browser  193 
Code-Memo  144 
Code-Memos  83, 137, 138 
Code-Notizen  135 
Code-Relations-Browser  194 
Codes 

ausdifferenzieren  216 
bewertende  62, 170 
emergieren  63 
fusionieren  215 

 

Häufigkeiten  117 
Hierarchie  114 
Obercode einfügen  215 
überschneidende  114 

Codes for human analysis of transcripts 

(CHAT)  42 
Codetypen  61 
Codiereinheiten  94 
Codieren  57, 59, 64, 91 

automatisches  127 
axiales  77 
farbig  66 
induktives  202 
konsensuelles  88 
kooperatives  149 
offenes  67, 75 
selektives  77 

Codierparadigma  77 
Codierte Segmente  65 
Coding Stripes  180 
Computerunterstützte Inhaltsanalyse (CUI)  

219 

Cross-Case Displays  184 
Cut-and-paste  64 

D 
Datenvorbereitung  36 
Deduktive Kategorienbildung  201 
Deduktive Vorgehensweise  60 
Dekontextualisierung  62 
Diagramme  178 
Dialektfärbungen  43 
Digitale Aufnahme  38 
Diktionär  220, 224 
Dimension  62 
Dimensionalisieren  76 
Dimensionalisieren und Feincodierung  

100 

Dimensionalisierung  212 

Index 

Diskurs-Datenbank (DIDA)  42 
Diskurstranskription nach du Bois  42 
Dokumentenanalysen  128 
Drag-and-drop  51 

E 

Effektivierung  247 
Effizienzsteigerung  19 
Einleseprozedur  50 
Einschätzungsdimensionen  151 
Entfernungsoperatoren  163 
Ethnographie  19 
Explikation  93 

F 

Faktencodes  61 
Faktorenanalyse  28, 243, 244 
Fallorientierte Vorgehensweise  229 
Fallvariablen  27, 102, 146 
Feincodierung  213 
Feldforschungen  128 
Forenbeiträge im Internet  49 
Fotos  31, 34 
Frequenzanalyse  219 
G 

Gedächtnisbasierte Auswertung  39 
Gefahren des Computereinsatzes  248 
Generalisierende Analyse  109 
Generalisierung  96 
Gesprächsanalytisches 

Transkriptionssystem (GAT)  42 

Grafiken  31, 34 
Grobcodierung  212 
Grounded Theory  19, 40, 73, 133 

codieren  74 
Umsetzung mit QDA-Programm  82 
Vorgehen  79 

Gruppendiskussion  48, 49, 131 

H 

HalbinterpretativeArbeitsTranskription 

(HIAT)  42 

Handlungsmodell  77 
Handlungstypen  98 
Häufigkeitsauszählung  89 
Hermeneutik  19 

 

267 

Hierarchisches Kategoriensystem  199 
Hyperlinks  24 
HYPERRESEARCH  251 
Hypothesen  58 

testen  166 

I 

Index der Codierungen  116 
Induktive Kategorienbildung  95, 201 
Induktive Vorgehensweise  60 
Inhaltsanalyse  74 
Integration qualitativer und quantitativer 

Methoden  248 

Inter-Coder-Reliabilität  61 
Intra-Coder-Reliabilität  61 
In-Vivo-Codes  75, 83 
In-Vivo-Codieren  68 
K 

Kategorien  58, 62 
Kategorienbegriff  58 
Kategorienbildung  58, 87 

deduktive  202 
induktiv  201 

Kategoriensystem  25, 198 

Aufbau  200 
hierarchisch  199 
linear  199 
netzwerkstrukturiert  200 
Typen  199 

Kernkategorie  77 
Keyword-in-context (KWIC)  121, 128, 

130 

Komparatistik  125 
Konfigurationsfrequenzanalyse  228 
Kontingenzanalyse  219 
Kontrastierung  112, 146 
Konversationsanalyse  46 
Konzept  62, 75 
Konzept Maps  186 
Korrespondenzanalyse  28 
Kritischer Rationalismus  58 
KWALITAN  251 
KWIC-Listen  121 

L 

Leitbildanalyse  211 

268 

Leitfaden  124, 125 
Leitfadeninterviews  49, 205 
Lexikalische Suche  46, 121, 128 
Lineares Kategoriensystem  199 

M 
MAXDICTIO  123, 223 
Maxqda  252 

Code-Matrix-Browser  213 
Codesystem  214 
Diktionäre  223 
Fallvariablen  154 
farbige Codes  180 
Gewichtungsvariablen  175 
komplexes Text-Retrieval  174 
logische Aktivierung  173 
Memo-Manager  144 
Variablen importieren  155 
Visualisierungen  195 
Memos  25, 83, 133, 180 

Regeln  137, 141 

Memotypen nach Strauss  135 
Mengenoperatoren  166 
Merkmal  62, 75 
Merkmalsraum  103 
Mind Maps  185 
MP3-Format  38 
Multimedia-Integration  250 
Muster erkennen  230 
N 

Netzwerkstrukturiertes Kategoriensystem  

200 

Nominaldefinitionen  58 
Notizen  24, 133 
NVIVO  252 

O 

OCR 

Einscannen  37 

OLE-Objekte  31, 33 
Online-Forschung  250 
P 
Paraphrasierung  94, 96 
Phänomenologie  19 
Planungs-Memos  135, 138 

Index 

Präsentation  178, 184 
Preprozessor  54 
Protokollbasierte Analyse  39 

Q 

QDA MINER  252 
QDA-Software 

Analyseschritte  21 
Anwendungsfelder  15 
Übersicht  251 

Qualität qualitativer Forschung  91 
Qualitative Evaluation  19 
Qualitative Inhaltsanalyse  92 
QUALRUS  252 
Quantitative Inhaltsanalyse  60, 63, 207, 

218 

R 

Rahmendaten  147 
Relevanz-Score  157, 217 
Reliabilität  61, 172 
Rich-Text-Format  33 
S 
Sample-Umfang  102 
Schließregeln  208 
Schlüsselkategorien  83 
Segment  65 
Segmentierung  64 
Sekundäranalyse  248 
Selektion von Fällen  146 
Sequenzoperatoren  163 
Sinneinheiten  63 
Skalenniveau  147 
Skalierung  151 
Sozio-demographische Merkmale  126, 146 
Sprachliche Färbungen  43 
Sprecherbezeichnung  46 
SPSS  152, 231 

Ähnlichkeitsmatrix  234 
Clusteranalyse  239 
Clusterauswertung  240 

Stichprobengröße  50 
Stopp-Liste  220, 224 
Strukturierende Inhaltsanalyse  150 
Strukturierung  93 
Support  255 

269 

Typenbildung  97, 103, 227 
Typisierende Generalisierung  109 
Typologische Analyse  99 
U 

Überlappung von Codes  113, 163 
Überschneidung von Codes  113, 164 
Unicode  35 

V 
Validierungsdatei  225 
Validität  61 
Variablen  58, 218 
Variablenmatrix  148, 154 
Variablennamen  151 
Variablenorientierte Vorgehensweise  229 
Visualisierung  157, 178, 250 
Vorab-Codierung  48, 54, 125 

W 

Windows-Zwischenablage  51, 53 
Within-Case Displays  184 
WMA-Format  38 
Word  32 
Wörterbuch  220 
Wortindex  220 
Wortlisten  220 

Z 
Zeichenformatierung  34 
Zeichenketten  45 
Zeichensatz 

Unicode  35 

Zeilen-Layout  49 
Zeilennummerierter Text  57 
Z-Regeln  95 
Zuordnung von Kategorien  57 
Zusammenfassung  93 

Index 

Symbolischer Interaktionismus  19 
Systemanforderungen  253 

T 
Teamarbeit  57, 247, 254 
Teamwork  249 
Text 

Beschränkungen  29 
einscannen  16 
extern-strukturiert  123 
Länge  30 
strukturiert  49 

Texteinheit  35, 48, 52 
Textexploration  125 
Textformat  34 
Textgruppen  53 
TextPortrait  189 
Text-Retrieval  26, 108, 111 

Entfernungsoperatoren  162 
komplexes  27, 161 
Mengenoperatoren  162 
selektives  157 
Textsegmente  23 

Gewichtung  157 
Herkunftsangabe  111 
kontrastieren  112 
Länge  65 

Textverarbeitungsprogramm  15, 31 
THE ETHNOGRAPH  252 
Themenanalyse  100, 219 
Theoriebildung  78 
Theorie-Memos  83, 135, 139 
Transkriptbasierte Analyse  39 
Transkription  38 

Auswahl  40 
Zeitaufwand  40 

Transkriptionsregeln  41 
Transkriptionssystem  44 
Transparenz  247 
Two-step-Codieren  64 
 

 

