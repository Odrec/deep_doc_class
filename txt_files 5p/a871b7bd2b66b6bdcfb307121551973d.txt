MINDS, BRAINS, AND PROGRAMS
Presentation by Helena Wasle & Julia Wippermann

OVERVIEW
‚û§ Who is Searle? 
‚û§ What is his general position in the Philosophy of Mind? 
‚û§ Minds, brains, and programs 
‚û§ What is intentionality 
‚û§ Strong AI and its appeal 
‚û§ Why AI can‚Äôt produce intentionality 
‚û§ The Chinese Room experiment 
‚û§ Criticism to Searles theory 

‚û§ Personal remarks 
‚û§ Questions & Discussion

WHO IS SEARLE?
‚û§ John Rogers Searle (*1932) 
‚û§ started University in 1949 (University of Wis-‚Ä®

consin) 

‚û§ Interested mostly in philosophy of speech and‚Ä®

mind, metaphysics and social ontology 

‚û§ professor at University of California, Berkeley since 1959 
‚û§ published 28 books, translated into 21 languages 
‚û§ supporter of the Free Speech Movement in 1964

WHAT IS SEARLES GENERAL POSITION IN THE PHILOSOPHY OF MIND

‚û§ intentionality is a basic requirement 
‚û§ intentionality can not be assigned to robots or computers 
‚û§ Turing-Test is not suÔ¨Écient to test intelligence 
‚û§ pro naturalism (‚Üí the brain is only a biological phenomenon) 
‚û§ against reductionism (‚Üí everything can be explained by 

looking at the components) 

‚û§ Searle argues that reductionism is not able to explain 

qualia 

‚û§ argues against dualism

MINDS, BRAINS, AND PROGRAMS: WHAT IS INTENTIONALITY?

‚û§ ‚ÄûIntentionality is the power of minds to be about, to represent, or to 

stand for, things, properties and states of aÔ¨Äairs.‚Äú ‚Ä®
 - Stanford Encyclopedia of Philosophy 

‚û§ ‚ÄûIntentionality in human beings (and animals) is a product of causal 

features of the brain. [‚Ä¶] Certain brain processes are suÔ¨Écient for 
intentionality.‚Äú‚Ä®
 - Searle, Minds, brains, and programs p. 419

MINDS, BRAINS, AND PROGRAMS: STRONG AI AND ITS APPEAL

‚û§    

Weak AI

Strong AI

AI and programs as a tool to test 

psychological hypotheses

Programs can be said to produce 
cognitive states by themselves

Searle: üëç

Searle: ‚ÄûThe distinction between 
the program and its realization 
[‚Ä¶] proves fatal to the claim that 
simulation could be duplication‚Äú

‚û§ Reasons for the appeal of AI according to Searle: 

‚û§ Confusion about the notion of ‚Äûinformation processing‚Äú 

‚û§ computers don‚Äôt do information processing as the human brain does, but 

formal symbol manipulation 

‚û§ Residual behaviorism and operationalism 
‚û§ dualism in AI

MINDS, BRAINS, AND PROGRAMS: WHY AI CAN‚ÄôT PRODUCE INTENTIONALITY

‚û§ ArtiÔ¨Åcial intelligence concerns itself only with programs, not their 

implementation 

‚û§ (1) intentionality is dependent on causal powers 
‚û§ (2) causal powers are dependent on the physical composition of the 

machine 

‚û§ (3) programs do not have a physical composition 
‚û§ (‚à¥) programs cannot produce intentionality 

‚û§ Strong AI can never build a program that by itself is capable of 

producing mental states (intentionality)

MINDS, BRAINS, AND PROGRAMS: THE CHINESE ROOM EXPERIMENT

http://theness.com/neurologicablog/wp-content/uploads/2015/10/c-room.gif

‚û§ Though the output suggests that the man understands Chinese he does 

not know anything about the semantics of the responses he gives‚Ä®
‚Üí programs do not think but apply simple rule manipulation‚Ä®
‚Üí the composition of the system is not suÔ¨Écient to produce‚Ä®
     understanding

MINDS, BRAINS, AND PROGRAMS: CRITICISM TO SEARLES THEORY

‚û§ The systems reply 

‚û§ though the man in the room does not understand anything, the system 

as a whole does understand Chinese. 

‚û§ Searle: Why should the conjunction of two elements 

understand when neither of them does by itself? 

‚û§ The robot reply 

‚û§ If we designed a program to operate a humanoid robot which processes 

‚Äösensory‚Äò information etc., this robot would have cognitive states 

‚û§ Searle: The addition of perceptual and motor capacities adds 

nothing to the capability of understanding; the Chinese 
Room experiment still applies

MINDS, BRAINS, AND PROGRAMS: CRITICISM TO SEARLES THEORY

‚û§ The brain simulator reply 

‚û§ A program that simulates what is happening in the brain at the level of 

neurons can‚Äôt be any diÔ¨Äerent from our understanding 

‚û§ a simulation of a process does not produce what the process by 

itself produces (‚Üí the simulation of a cow does not produce 
real milk) 

‚û§ The combination reply 

‚û§ A robot which operates like a human and whose brain-shaped computer 

is programmed with all the neurons of a human brain would be much 
more convincing 

‚û§ We would attribute intentionality to it but only as long as we 

knew nothing about the insides and program of the robot

MINDS, BRAINS, AND PROGRAMS: CRITICISM TO SEARLES THEORY

‚û§ The other minds reply 

‚û§ How can you know that other people understand Chinese? We 
attribute understanding based on behavior therefore it must be 
linked to it 

‚û§ ‚ÄûIn cognitive science one presupposes the reality and 

knowability of the mental in the same way that in 
physical science one has to presuppose the reality and 
knowability of physical objects.‚Äú (Searle: p.422)

MINDS, BRAINS, AND PROGRAMS: CRITICISM TO SEARLES THEORY

‚û§ The many mansions reply 

‚û§ ‚ÄûEventually we will be able to build devices that have these 

causal processes, and that will be artiÔ¨Åcial intelligence‚Äú (Searle p. 
422) 

‚û§ This completely dismantles what AI is all about - 

separating the software from its realization - but in 
theory this complies with the theory

PERSONAL REMARKS
‚û§ His answer to e.g. the systems reply is rather unconvincing, 
he does not explain why the conjunction of two elements can 
not understand something that each individual part does not 
(fully) understand 

‚û§ The Chinese Room experiment doesn‚Äôt really apply in the case 

of the brain simulator reply 

‚û§ Searle never explains what he imagines the ‚Äûcausal powers‚Äú 

he sees as fundamental for intentionality to be

QUESTIONS
‚û§ Is the Chinese room experiment a useful tool in discussing 

ArtiÔ¨Åcial intelligence? Is it realistic? 

‚û§ In his criticism to Searles text, Robert P. Abelson writes: ‚Ä®

‚ÄûThe computer is merely crunching away on statements in program code 
producing other statements in program code which are applauded by 
outside observers for being [‚Ä¶] perhaps even clever. What kind of 
understanding is that? It is [‚Ä¶] very much the kind of understanding 
that people display in exposure to new content via language or other 
symbol systems.‚Äú ‚Ä®
What are your thoughts on this argument? 

‚û§ Do you agree with Searle? Is it impossible for ArtiÔ¨Åcial 

Intelligence to succeed?

REFERENCES
‚û§ http://ist-socrates.berkeley.edu/~jsearle/‚Ä®
‚û§ http://plato.stanford.edu/entries/intentionality/‚Ä®

visited on 19.5.16 

visited on 19.5.16 

‚û§ photo of Searle: http://3.bp.blogspot.com/_jQhfH-_kwQI/

S7l6ahjJwDI/AAAAAAAADbY/3y8zEfJnQ_g/s1600/
searle.jpg‚Ä®
visited on 19.5.16 

‚û§ John Searle: ‚ÄúMinds, Brains, and Programs.‚Äù Behavioral and 

Brain Sciences, 1980, 3, 417‚Äì424.

