Algorithmen II

VO 2

Nachtrag: Linearzeit-Sortieren

Amortisierte Analyse

Prof. Dr. Markus Chimani

Theoretische Informatik, Uni Osnabrück

Wintersemester 2014/15

CountingSort

Wiederholung

Algorithmus:
Sei C ein k-elementiges Integerarray, mit 0en initialisiert.
for all i = 1 . . . n:

C[key(oi)] += 1
for all i = 2 . . . k:
C[i] += C[i − 1]

// Erhöhe entspr. „Bucketgröße“ um 1

// Errechne Endindex des i-ten Buckets

Sei R ein n-elementiges Objektarray, anfangs leer.
for all i = n . . . 1:

// Von hinten nach vorne!

R[ C[key(oi)] ] = oi
C[key(oi)] –= 1

return R

// Bucket-Endindex nach vorne schieben.

Laufzeit: Θ(n + k). Falls k = O(n) ⇒ Laufzeit Θ(n)
Selbe O-Notation wie BucketSort, aber auf Arrays statt Listen.

Sowohl BucketSort als auch CountingSort sind stabil.

Warm Up: Formale Grundlagen & Sortieren Sortieren in Linearzeit

VO 2 — 24

Ein Meta-Sortierverfahren: RadixSort

1 Was, wenn die zu sortierenden natürlichen Zahlen zwar < k ist,
k jedoch eine sehr große Zahl, z.B. 1 000 000? Soviele Buckets
oder Counter wären in der Praxis böse...

2 Was, wenn man Zeichenketten sortieren will? Die einzelnen

Symbole kommen nur aus einer kleinen Schlüsselmenge (z.B.
a, b, c, ..., z), die Strings können jedoch lang sein...

Radix ≈ Wurzel ≈ Basis einer Zahlendarstellung
RadixSort ist ein Sortierschema, dass intern ein anderes (lineares)
stabiles Sortierverfahren benutzt (z.B. Bucket- oder CountingSort)

Idee: Sortiere die Elemente mehrmals, jeweils nur gemäß einer
Stelle (bei Zahlen: 1er-, 10er-, 100er-Stelle...; bei Zeichenketten
erstes, zweites, drittes Symbol,...)

Zwei Varianten:

LSD: least signiﬁcant digit ﬁrst (z.B. für 1 )
MSD: most signiﬁcant digit ﬁrst (z.B. für 2 )

Warm Up: Formale Grundlagen & Sortieren Sortieren in Linearzeit

VO 2 — 25

RadixSort: LSD & MSD

1 LSD: least signiﬁcant digit ﬁrst

Gegeben: n jeweils (cid:96)-stellige Zahlen. Sei Stelle 1 hinten.
for all i = 1 . . . (cid:96): Sortiere Objekte stabil gemäß (cid:96)-ter Stelle

Beispiel: Gegeben:

652, 103, 012, 301, 537, 131, 102

nach Iteration i = 1:
nach Iteration i = 2:
nach Iteration i = 3:

301, 131, 652, 012, 102, 103, 537
301, 102, 103, 012, 131, 537, 652
012, 102, 103, 131, 301, 537, 652

2 MSD: most signiﬁcant digit ﬁrst

Sortiere die vorderste Stelle ⇒ k Buckets; Elemente eines
Buckets haben immer die gleiche vorderste Stelle („ungefähr
gleich groß“, lexikographische Sortierung). Sortiere jeden
Bucket ohne vorderster Stelle rekursiv wieder mit RadixSort.
Laufzeit: LSD Θ((cid:96)(n + k)), MSB Ω(n + k), O((cid:96)(n + k)).
k ≤ n → Θ(n(cid:96)) vs. Ω(n) ∪ O(n(cid:96)). k und (cid:96) konstant → beide Θ(n).
Nat. Zahlen < M: Θ(n log M) bzw. Ω(n + log M), O(n log M)

Amortisierte Analyse

Amortisierte Analyse

VO 2 — 27

Amortisierte Analyse: Können Sie, keine Angst!

Fahrpreise bei einer Sommerrodelbahn:

1 Fahrt . . . . . . . . . 2 e
5 Fahrten . . . . . . 9 e

Wieviel kostet eine Fahrt asymptotisch, also wenn man viele
Fahrten (n) macht?

1 Jede Fahrt einzeln zahlen ⇒ 2 e / Fahrt
2 Sei r ≤ 4 der Rest der Division n/5. Kaufe für die ersten n − r
Fahrten insgesamt (n − r)/5 5er-Tickets, dann r Einzeltickets.
Durchschnittl. Fahrpreis: 9e·(n−r)/5+2e·r
5 + r
Asymptotisch, d.h. n → ∞:
limn→∞ 9

= 9n/5−9r/5+2r

5 + 0 = 1, 80 e / Fahrt

5 + limn→∞ 9

5n = 9

5 + r

5n ≤ 9

n

n

= 9

5n

3 Asymptotisch kann man also, unabhängig von r, einfach immer

auch ausschließlich (cid:100)n/5(cid:101) 5er-Tickets kaufen.

4 Naïve Worst-Case Algorithmenanalyse: „Wenn kein Ticket
(mehr), kaufe ein 5-Fahrten-Ticket (siehe 3 ).“ ⇒ Vor der Fahrt
zahlt man entweder 0e oder 9e ⇒ Jedes mal max. 9 e zahlen
⇒ obere Schranke 9 e / Fahrt

Amortisierte Analyse

VO 2 — 28

Wachsende Arrays, Grimm

Aufgabe: Speichere Elemente in eine Datenstruktur. Welche?

Jacob: Nimm ein Array, das ist klein, einfach und ﬂott.
Wilhelm: Nein, dazu müsste man die Anzahl vorab wissen. Benutze
eine Liste!
Jacob: Listen benötigen so viel Overhead durch die Zeiger. Ich fange
einfach mit einem kleinen Array an, und lasse es wachsen, wenn zu
viele Elemente kommen.
Wilhelm: Dann kannst Du aber nicht mehr in O(1) Zeit ein Element
einfügen, weil Du womöglich das ganze Array umkopieren musst...
Jacob: Kein Problem, ich kann amortisierte Analyse! Im
Durchschnitt benötige ich immer noch nur O(1).

Amortisierte Analyse

Wachsende
Arrays

Laufzeit pro
Operation?
pop: O(1)
push: O(cap)

VO 2 — 29

class Stack:
int num
int cap
data A[1 . . . cap]

// Anzahl der Elementa am Stack
// Aktuelle Kapazität des Stack
// Array, gefüllt für Indizes 1 . . . num
// O(1) oder O(cap)
// Array ist zu klein
cap = 2 · cap; neues größeres A; kopiere Daten

void push(data a):

if num = cap:

A[++num] = a

data pop():

return A[num – –]

//O(1)

Amortisierte Laufzeit einer Operation = durchschnittliche
Laufzeit einer Operation im Worst Case einer Anwendung.

Anwendung: n viele Aufrufe der Stackoperationen auf einem
anfangs leeren Stack mit konstanter Anfangskapazität C.

Amortisierte Analyse

VO 2 — 30

Wachsende Arrays

Amortisierte Laufzeit einer Operation = durchschnittliche
Laufzeit einer Operation im Worst Case einer Anwendung.

Anwendung: n viele Aufrufe der Stackoperationen auf einem
anfangs leeren Stack mit konstanter Anfangskapazität C.
Best Case: immer abwechselnd push und pop → jeweils O(1)
Worst Case: nur push Operationen.
„C mal O(1), dann O(C), dann C mal O(1), dann O(2C), dann 2C
mal O(1), dann O(4C), dann 4C mal O(1),...“
⇒ O(n) „billige“ Operationen mit jeweils Laufzeit O(1)
⇒ „Teure“ Laufzeiten (teuerste zuerst): O(n), O(n/2), O(n/4),. . .
⇒Summe alle Laufzeiten:
O(n · 1) + O(n + n/2 + n/4 + . . .) = O(n) + O(n) = O(n)
⇒ Durchschnittliche Laufzeit = Summe-der-Laufzeiten

Anzahl-der-Operationen = O(n)/n = O(1)

Amortisierte Analyse

VO 2 — 31

Binärzahlen inkrementieren

Operation BinIncr: Sei α eine Binärzahl mit n vielen Stellen. Erhöhe
α um eins. Wieviele Bit-Rechenschritte benötigt das?
Algorithmus?
Mit αi bezeichnen wir die i-te Bit von α,
beginnend mit dem least signiﬁcant
(„Einer-Stelle“, ganz rechts).
Zahl „111 . . . 111111“: Schleife wird O(n) mal durchlaufen.
⇒BinIncr benötigt O(n) Zeit... ja, aber...
Asymptotische Analyse: Was ist der durchschnittliche
Aufwand, wenn man BinIncr n mal hintereinander aufruft?

αi = 1 − αi
if αi = 1 then return

for i = 1 . . . n + 1:

Laufzeit von BinIncr ist linear abhängig von der Anzahl der
ausgeführten Bit-Flips. Nicht jeder BinIncr-Aufruf ﬂippt jedes Bit:
α1 wird jedes mal geﬂippt, α2 jedes 2. Mal, α3 jedes 4. Mal,...
Summe über alle Bit-Flips bei n Aufrufen:

n + n/2 + n/4 + n/8 + ... ≤ n ·(cid:80)∞

i=0 2−i = 2n

Durchschnittliche Anzahl an Bit-Flips ≤ 2n/n = O(1)

(cid:3)

Amortisierte Analyse

VO 2 — 32

Beweistechniken der Asymptotischen Analyse

Bisher:

(cid:73) Aggregationsmethode (aggregate analysis).

Idee: Erkenne den WorstCase, summiere alle Laufzeiten der n
Operationen, und dividiere diese Laufzeitsumme durch n.

Vorteil: Einfach zu verstehen.
Nachteil: Klappt nur, wenn man (a) den WorstCase gut ﬁnden &
beschreiben kann, (b) die Summe gut berechnen kann, und (c) keine
unterschiedlichen Operationen mit unterschiedlichen Kosten hat.

Daher gibt es als Alternative auch:

(cid:73) Buchhaltermethode (accounting method).

Idee: Man beweist, dass eine Operation amortisiert max. R Zeit
benötigt. Man verwaltet ein „Konto“ K. Jede auszuführende
Operation zahlt zunächst R Einheiten in K ein. Danach
entnimmt sie so viele Einheiten aus K wie sie tatsächlich Zeit
benötigt. Man zeigt, dass K nie negativ wird.
(cid:73) Potentialmethode (potential method).

Idee: ... später, zunächst Buchhaltermethode...

Amortisierte Analyse

VO 2 — 33

Buchhaltermethode @ Wachsendes Array

Beispiel: Wachsendes Array
Beobachtung: Wieviele Zeiteinheiten benötigt push/pop?

push: Entweder O(1), sagen wir 1; oder O(cap), sagen wir cap.
pop: O(1), sagen wir 1.

Behaupt.: push benötigt amortisiert O(1), sagen wir 3, Zeiteinh.
Beweis mittels Buchhaltermethode.
Super: keine explizite Argumentation über WorstCase nötig!
Initial ist K = 0. Zeige, dass nach jeder Operation K ≥ 0 gilt.
Aufruf von pop: K := K + 1 − 1 ⇒ K ändert sich nicht, K ≥ 0.
Aufruf „billiges“ push: K := K + 3 − 1. ⇒ K wächst um 2, K ≥ 0.
Aufruf „teures“ push: Seit letztem teuren push sind mindestens
cap/2 billige pushs passiert. Direkt nach dem letzten teuren push
galt K ≥ 0, nun gilt also K ≥ 2 · cap/2 = cap. ⇒ Auch nach
Entnahme von cap Einheiten für den teuren push bleibt K ≥ 0.

(cid:3)

Amortisierte Analyse

VO 2 — 34

Buchhaltermethode @ BinIncr

Beispiel: BinIncr
Für jedes Bit-Flippen benötigen wir O(1) Zeit → „1 Münze zahlen“.
Beh.: BinIncr benötigt amortisiert O(1) Zeit → 2 Münzen.
Beweis mittels Buchhaltermethode.
Jedes Binärstelle von α hat ein eigenes Konto. Invariante: Jedes 1-Bit
erhält eine Münze. Anfangs α = 0.
Beobachtung: Schleife wird nur fortgesetzt, wenn αi von 1 auf 0
geﬂippt wird.

Aufruf von BinIncr: Die Operation hat 2 Münzen zur Verfügung um
für seine Schritte zu bezahlen, und die Invariante zu erhalten.
Wenn BinIncr auf eine 1 trifft, benutzt es die dort vorhandene
Münze um den Flip auf 0 zu bezahlen.
Wenn BinIncr auf eine 0 trifft, benutzt es seine erste eigene Münze
um den Flip auf 1 zu bezahlen, und übergibt seine zweite Münze
dem neuen 1-Bit (um die Invariante zu erhalten).

(cid:3)

Amortisierte Analyse

VO 2 — 35

Potentialmethode

Ähnlich Buchhaltermethode, aber doch etwas anders...
Statt einem oder mehrerer Konten hat man eine
Potentialfunktion Φ für die Datenstruktur D. Diese speichert
„Energie“ um die Datenstruktur zu betreiben.

Sei: ci = Kosten der i-ten Operation.

Φi−1, Φi Potential vor und nach Operation i.
Meist: Φ0 = 0
⇒ Amortisierte Kosten ¯ci := ci + (Φi − Φi−1)

i=1(ci + Φi − Φi−1) =(cid:80)n

i=1 ci + (Φn − Φ0)

Summe:(cid:80)n

i=1 ¯ci =(cid:80)n

Falls Φn ≥ Φ0 ⇒ Summe der amortisierte Kosten ist obere Schranke
für Summe der echten Kosten.
Wenn man Φi − Φ0 für alle i zeigt → Buchhaltermethode!
Mächtigkeit der Potentialmethode („Kosten müssen nicht vorab
bezahlt werden“, Φi < 0 erlaubt für 0 < i < n) nur selten notwendig.

Amortisierte Analyse

VO 2 — 36

Potentialmethode @ BinIncr

(cid:73) Deﬁniere geeignete Potentialfunktion:

Φ gibt stets die Anzahl der 1-Bits in α an ⇒ Φi ≥ 0, ∀0 ≤ i ≤ n

⇒ ci := ti + 1

(cid:3)

(cid:73) Berechne amortisierte Kosten:

i-tes BinIncr ﬂippt ti + 1 bits (t1mal 1→0; 1mal 0→1)
⇒ (Φi − Φi−1) = (Φi−1 − ti + 1) − Φi−1 = 1 − ti
⇒ ¯ci := ci + (Φi − Φi−1) = ti + 1 + 1 − ti = 2
(cid:73) Falls initial α = 0: Φ0 = 0 ≤ Φn ⇒ fertig!
(cid:73) Falls initial α > 0 (k 1er-Bits): womöglich Φ0 > Φn :-(

... aber:(cid:80)n
i=1 ci =(cid:80)n

i=1 ¯ci − (Φn − Φ0) =(cid:80)n

i=1 2 − (Φn − Φ0) ≤ 2n + k

Falls k = O(n) ist die Kostensumme also O(n)!
⇒ Sobald n = Ω(k) Operationen ausgeführt werden, haben wir
(cid:3)
O(1) amortisierte Kosten für BinIncr.

