Information Sciences 180 (2010) 3434â€“3443

Contents lists available at ScienceDirect

Information Sciences

j o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m / l o c a t e / i n s

Covariance intersection based image fusion technique with
application to pansharpening in remote sensing
Qing Guo a,b, Siyue Chen b, Henry Leung b, Shutian Liu a,*
a Harbin Institute of Technology, Department of Physics, Harbin 150001, PR China
b Department of Electrical and Computer Engineering, University of Calgary, Calgary, Alberta, Canada T2N 1N4

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 14 November 2009
Received in revised form 29 April 2010
Accepted 6 May 2010

Keywords:
Covariance intersection
Image fusion
Expectation maximization
Multi-spectral image
Panchromatic image
Pansharpening

1. Introduction

Image fusion of multi-spectral images and panchromatic images has been widely applied
to imaging sensors. Multi-spectral images are rich in spectral information whereas pan-
chromatic images have relatively higher spatial resolution. In this paper, we consider the
image fusion as an estimation problem, that is to estimate the ideal scene of multi-spectral
images at the resolution of panchromatic images. We propose a method of combining the
covariance intersection (CI) principle with the expectation maximization (EM) algorithm to
develop a novel image fusion approach. In contrast to other fusion methods, the proposed
scheme takes cross-correlation among data sources into account, and thus provides consis-
tent and accurate estimates through convex combinations. Since the covariance informa-
tion is usually unknown in practice, the EM method is employed to provide a maximum
likelihood estimate (MLE) of the covariance matrix. Real multi-spectral and panchromatic
images are used to evaluate the effectiveness of the proposed EMâ€“CI method. The proposed
algorithm is found to preserve both the spectral information of the multi-spectral image
and the high spatial resolution information of the panchromatic image more effectively
than the conventional image fusion techniques.

Ã“ 2010 Elsevier Inc. All rights reserved.

With the rapid growth of the internet and other electronic sources of information, the problem of coherent merging infor-
mation from multiple sources has become an important issue [21,30,31]. As one type of information processing technique,
the image fusion is widely used in many practical applications. Images captured by multiple sensors often contain comple-
mentary and redundant information. An effective fusion process will result in an improved image, which contains more com-
plete information and should be more suitable for human visual perception and object recognition [2,20]. In this study, we
consider fusion of multi-spectral (MS) images and panchromatic (Pan) images, which are widely used in remote sensing. This
fusion scheme is often referred as pansharpening [13]. The MS images, such as acquired by IKONOS and QuickBird satellites,
usually have four bands of spectral information (i.e., red (R), green (G), blue (B), and near infrared (NIR)). Meanwhile, the Pan
image has good spatial resolution. Therefore, the goal of fusing these images is to generate a high-resolution MS image,
which can be used more effectively for applications, such as land classiï¬cation and road detection.

Image fusion can be classiï¬ed as pixel-level, feature-level and symbol-level [3]. Fusion of MS and Pan images at pixel-le-
vel is traditionally handled by the intensity-hue-saturation (IHS) transform methods [4,6], the Brovey transform methods
[7], the principal component analysis (PCA) methods [6,5,24], the highpass ï¬ltering (HPF) method [25] and by the wavelet

* Corresponding author. Tel./fax: +86 451 86418042.

E-mail address: stliu@hit.edu.cn (S. Liu).

0020-0255/$ - see front matter Ã“ 2010 Elsevier Inc. All rights reserved.
doi:10.1016/j.ins.2010.05.010

Q. Guo et al. / Information Sciences 180 (2010) 3434â€“3443

3435

transform (WT) method [9,14,23,33]. The IHS transform method ï¬rst transforms three MS bands from RGB color space to the
spatial (I) and spectral (H, S) information space. Fusion is then performed by replacing the intensity components in the IHS
space with the Pan image. The IHS method can preserve the spatial resolution of the Pan image, however, according to Prasad
et al. [22], it severely distorts the spectral information of the MS image. The method based on Brovey transform is a simple
color normalized method. It also usually introduces distortion to the spectral information. The same problem of spectral dis-
tortion is also found in the PCA method because fusion is performed by replacing the ï¬rst principal component of the MS
image with the Pan image, which results in a signiï¬cant loss of spectral information. The HPF method simply adds the
high-frequency components of the Pan image to the MS image. However, choosing a proper ï¬lter size is difï¬cult in this
method.

The fusion method based on WT is also popular. Zhou et al. [33] employ WT to fuse landsat TM and SPOT Pan images. The
SPOT image and each spectral band of the TM images are decomposed into an orthogonal wavelet representation at a given
resolution, which consists of an approximation image and a set of spatially-oriented detailed images. Band by band, the
approximation image from each TM band is combined with the detailed image from SPOT. Then the inverse WT is performed
to obtain the fused image. The spectral and spatial quality of the fused image based on this method is better than those based
on the IHS transform, PCA, and the Brovey transform [33].

In this paper, our motivation is to generate a high resolution MS image with more information and better quality than
those provided by individual sensor image alone. The image fusion problem is considered as a statistical estimation problem.
More speciï¬cally, the objective is to estimate the ideal high-resolution MS image from the observed MS image and the ob-
served Pan image. To this end, covariance intersection (CI), which has been widely used in radar track fusion [28], is em-
ployed. CI can produce consistent estimate for any degree of cross-correlation between the input sources through convex
combination [12,18]. In addition, CI enforces estimation consistency by means of convex combination of the inverse of
covariance matrices. When CI is applied to image fusion, it treats the ideal high-resolution MS image as a linear combination
of the ideal MS and Pan images and the fused coefï¬cients are selected through the convex combination of weight optimiza-
tion. However, many image fusion methods, such as conventional WT, choose the fused coefï¬cients simply by selecting lar-
ger or by replacement [32,19,15], without using any rigorous procedure.

To use the convex combination in CI, the covariance information of the estimation error is required. But for most imaging
applications, this information is not available. Here, we use the expectation maximization (EM) to give a maximum likeli-
hood estimate (MLE) of the covariance information. Formalized by Dempster et al. [8], the EM algorithm is an iterative pro-
cedure that estimates both the parameters and the missing or unobservable data during an iteration. The approach ï¬rst
computes the approximation to the expectation of the log-likelihood function of the complete data conditioned on the cur-
rent parameter estimate, which is referred as the expectation (E-step). In this step, the current incomplete data estimate is
calculated. Next, a new parameter estimate is computed by ï¬nding the value of the parameter that maximizes the function
found in the E-step. This is called the maximization step (M-step). In this study, the ideal MS and Pan images are treated as
the missing data, and the covariances of them are treated as the parameters to be estimated by EM.

The remainder of this paper is organized as follows. The problem of fusing the MS image and the Pan image is formu-
lated in Section 2. This formulation justiï¬es the capability of CI to give a consistent and unbiased estimation for any de-
gree of the cross-correlation, and can be used to optimally fuse the images. In Section 3, the EM is developed to help
performing CI and the fast performing CI with weight in a suboptimal linear way to give the consistent estimation through
convex combination is presented. Performance evaluation of the EMâ€“CI method using real image sensory data is accom-
plished in Section 4 and shows that the EMâ€“CI method preserves the spectral information very well. Section 5 concludes
this paper.

2. Problem formulation

The observed MS image and the observed Pan image are denoted as ~x1 and ~x2, respectively, which are the vectors com-
posed of pixel values. To simplify the derivation, one band of the MS image as ~x1 is used for the derivation example, the other
bands have the same expressions. Due to sensor distortion and noise in the capture process of MS and Pan images, the ob-
served images can be modeled as â€˜â€˜linear observation plus Gaussian noiseâ€ [10,16]. That is,

i Â¼ 1; 2;

~xi Â¼ Hixi Ã¾ ni;

Ã°1Ã
where xi denotes the vector of pixel values from an ideal image, Hi represents the linear observation operator which is a
known observation matrix. Typical examples of the linear observation operator Hi include optical blur, motion blur, tomo-
graphic projections. ni is assumed to be zero-mean white Gaussian noise with covariance
Pxixi which is deï¬ned in the next
paragraph.

b

From (1), it is noted that neither the ideal image xi nor its statistics are available. However, the consistent estimate ^xi can

be obtained. That is, if we deï¬ne

b
Pxixi Â¼ Ã°~xi   ^xiÃÃ°~xi   ^xiÃT ;

i Â¼ 1; 2:

and

Pxixi Â¼ EÂ½Ã°xi   ^xiÃÃ°xi   ^xiÃTÂŠ;

i Â¼ 1; 2;

Ã°2Ã

Ã°3Ã

3436

Q. Guo et al. / Information Sciences 180 (2010) 3434â€“3443

we have [11]

b

i Â¼ 1; 2:

Pxixi P Pxixi ;

Ã°4Ã
The inequality is in the sense of matrix positive deï¬niteness, i.e., A > B if and only if A   B is positive deï¬nite. It should be
noted that the matrix ^Pxixi represents the estimation error covariance which is considered to be equivalent to the covariance
matrix of the noise ni. We further deï¬ne the cross-correlation as

Px1x2 Â¼ EÂ½Ã°x1   ^x1ÃÃ°x2   ^x2ÃTÂŠ:

Our objective is to construct a linear, unbiased estimate ^x that combines ^x1 and ^x2, i.e.,

^x Â¼ M1^x1 Ã¾ M2^x2;

so that

EÂ½x   ^xÂŠ Â¼ 0;

provided that

Ã°5Ã

Ã°6Ã

Ã°7Ã

M1 Ã¾ M2 Â¼ I:

Ã°8Ã
In addition, we want to determine a consistent estimate ^Pxx, for Pxx Ã°Pxx Â¼ EÂ½Ã°x   ^xÃÃ°x   ^xÃTÂŠÃ, and to ï¬nd a pair of M1 and M2
such that the upper bound ^Pxx is optimal in the sense of minimal trace.

According to the deï¬nition of Pxx, we have

Pxx Â¼ M1Px1x1MT

1 Ã¾ M1Px1x2MT

2 Ã¾ M2Px2x1MT

1 Ã¾ M2Px2x2MT
2:

b

b

Pxx Â¼ M1

Px2x1MT
If Px1x2 Â¼ 0, for any given M1 and M2, the estimate

Px1x2MT

Px1x1MT

1 Ã¾ M1

2 Ã¾ M2

1 Ã¾ M2

Px2x2MT
2:

b
b

b

b
b

Similarly,b
b
b

Px2x2MT
2

Px1x1MT

Pxx Â¼ M1

1 Ã¾ M2
b
will be consistent Ã°
b
b
b
x1x1 Ã¾
x2x2Ã 1;
P 1
P 1
b
b
b
Px1x1 Ã¾
x1x1 Â¼
Px2x2Ã°
P 1
Pxx
Px1x1 Ã¾
Px1x1Ã°
x2x2 Â¼
P 1
Pxx

Pxx Â¼ Ã°
M1 Â¼
M2 Â¼

b
b
b

b
b
Px2x2Ã 1;
Px2x2Ã 1:

Pxx P PxxÃ as a direct consequence of (4). The trace of the above

b

Pxx is then minimized by

Ã°9Ã

Ã°10Ã

Ã°11Ã

Ã°12Ã

Since the cross-correlation between x1 and x2 is generally non-zero and unknown, CI is employed here to deal with the sit-
uation when Px1x2

â€“0.

3. EMâ€“CI for image fusion

By virtue of statistical property of noise ni in (1), we can compute the conditional probability density function (PDF) of ~xi

as [1]


b
Pxixij 1=2 exp   1
2
b
Pxixij   S
2

n

b

b



o

pÃ°~xijxiÃ Â¼ Ã°2pÃ S=2j

Â½~xi   HixiÂŠT

P 1
xixi

Â½~xi   HixiÂŠ

;

i Â¼ 1; 2;

Ã°13Ã

where S denotes the number of pixels within the vector ~xi. Taking the logarithm of (13), the logarithmic likelihood function is
thus

b
LÃ°xij~xiÃ Â¼   1
2
Pxixi is the diagonal matrix under the white Gaussian noise assumption. The E-step of EM computes the

logÃ°2pÃ   1
2

xixiÂ½~xi   HixiÂŠ
P 1

Â½~xi   HixiÂŠT

i Â¼ 1; 2:

Ã°14Ã

logj

;

In factor analysis,
expected log-likelihood function, i.e.,

Â½

b
EP Â¼ E LÃ°xij~xiÃj~xi
In the M-step, ^xi and
lihood function are set as zero. With the constant term ignored, we have,

ÂŠ;
Ã°15Ã
Pxixi are obtained by maximizing (15). More speciï¬cally, the partial derivatives of the expected log-like-

i Â¼ 1; 2:

Q. Guo et al. / Information Sciences 180 (2010) 3434â€“3443

i

i Â¼ 0;
HT
i Ã¾ Hi^xi^xT

i Â¼ 1; 2;
Ã¾ 1
2

i HT
i

b
Pxixi Â¼ 0;

i Â¼ 1; 2:

b

b

P 1
xixi

h

i   Hi^xi
HT

~xi~xT

i   2Hi^xi~xT
b

P 1
xixi

~xi;

b

@EP
@xi
@EP
Pxixi
@

Â¼ ~xi
P 1
xixi
Â¼   1
2
b

Solving these equations generate

^xi Â¼ Ã°HT

i

P 1
xixi

HiÃ 1HT

i

i Â¼ 1; 2;

and

b
b
Pxixi Â¼ ~xi~xT
i   2Hi^xi~xT
i Â¼ 1; 2:
Based on ^xi and
Pxixi, i = 1,2, we can combine ^x and
of the points

i Ã¾ Hi^xi^xT

i HT
i ;

b

Ã°19Ã
Pxx using CI. For a covariance matrix P, the covariance ellipse is the locus

3437

Ã°16Ã

Ã°17Ã

Ã°18Ã

BPÃ°gÃ Â¼ fx : Ã°x   xÃTP 1Ã°x   xÃ Â¼ gg;

Ã°20Ã
where g is a constant and x is the mean of x. The covariance ellipse is a convenient way of visualizing the relative size of
covariance matrices. If P1 < P2, BP1Ã°gÃ  BP2Ã°gÃ. From the geometric interpretation of (10), the covariance ellipse of
Pxx always
lies within the intersection of the covariance ellipses of
Px1x2 , as shown in Fig. 1.
Hence, a method which ï¬nds a
Pxx which encloses the intersection region must be consistent even if there is no knowledge
about Px1x2 [26,27]. When Px1x2 is unknown, in order to obtain an upper bound of (9), the inequality

Px2x2 , for any possible choice of

Px1x1 and

b

b

b

b

b

(


ï¬ƒï¬ƒï¬ƒ

c

p

E

M1Ã°x1   ^x1Ã   1ï¬ƒï¬ƒï¬ƒ

cp M2Ã°x2   ^x2Ã




ï¬ƒï¬ƒï¬ƒ

c

p

M1Ã°x1   ^x1Ã   1ï¬ƒï¬ƒï¬ƒ


cp M2Ã°x2   ^x2Ã

)

is utilized, where c > 0 is a scalar. It follows that

cM1Px1x1MT

1 Ã¾ 1
c

M2Px2x2MT

2 P M1Px1x2MT

2 Ã¾ M2Px2x1MT
1:

From (4) and (22), a consistent estimate

Pxx for Pxx can be obtained as

b

b




1 Ã¾ 1 Ã¾ 1
c

b

Pxx Â¼ Ã°1 Ã¾ cÃM1

Px1x1MT

M2

Px2x2MT
2:

The value of c is then chosen to minimize the trace of

b

Pxx. Note that

b

T

P 0

Ã°21Ã

Ã°22Ã

Ã°23Ã

b

Pxx always lies inside the intersection.

Fig. 1. Covariance

b

3438

TrÃ°

PxxÃ Â¼ TrÃ°M1

Q. Guo et al. / Information Sciences 180 (2010) 3434â€“3443

b

b
ï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒ
q
2Ã
Px2x2MT

b
1Ã Ã¾ TrÃ°M2

b

q
ï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒ
1Ã Ã¾ 1
2Ã Ã¾ cTrÃ°M1
c
1Ã
Px1x1MT

1ÃTrÃ°M2

Px1x1MT

Px2x2MT

Px1x1MT

Px1x1MT

TrÃ°M1

TrÃ°M1

b

b

Â¼

b

ï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒ
q
b
2Ã P TrÃ°M1
2Ã
Px2x2MT

Px2x2MT

TrÃ°M2

2

;

TrÃ°M2

Ã¾

b

Px1x1MT

1Ã Ã¾ TrÃ°M2

b
b
b
P 1
Pxx
x1x1
Pxx Â¼

b
b
; M2 Â¼ x2
Px2x2 ; c Â¼ x2
x1
PxxÃ°x1
x1x1 Ã¾ x2
P 1
Pxx;

x2x2Ã
P 1

b

b

b

b

Pxx

, (23) can be further written as

b
b
b

where the equality holds when

Ã¾ 2

ï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒ
vuut
2Ã
Px2x2MT
1Ã
Px1x1MT

TrÃ°M2
TrÃ°M1

:

c Â¼

b

b

For a particular choice, i.e., if M1 Â¼ x1
P 1
x2x2

Pxx Â¼ x1

Pxx Ã¾ x2

P 1
x1x1

Pxx

Pxx

b

b
b

b
b
which is satisï¬ed by
x1x1 Ã¾ x2
P 1
b
Meanwhile, (6) becomes

xx Â¼ x1
P 1
b

P 1
x2x2

:

b

b

^x Â¼ x1

Pxx

P 1
x1x1

^x1 Ã¾ x2

Pxx

b

P 1
x2x2

^x2

b

2Ã
Px2x2MT

Ã°24Ã

Ã°25Ã

Ã°26Ã

Ã°27Ã

Ã°28Ã

Ã°29Ã

Ã°30Ã

Ã°31Ã

Ã°32Ã

with nonnegative coefï¬cients x1 and x2 obeying

x1 Ã¾ x2 Â¼ 1:

Here, (27) and (28) as the CI equations are obtained.

b

The weighting coefï¬cients, x1 and x2, are usually chosen to minimize the trace of

Pxx. The minimizing process requires
b
optimization of a nonlinear cost function which is convex with respect to x1 and x2 [18]. The minimized trace is obtained by
b
an exhaustive search of x1 and x2 within the range of [0,1]. This process has a high computational burden. Therefore a sub-
b
b
optimal non-iterative linear algorithm is necessary. It is well known that the trace of the covariance matrix
Pxixi , i = 1,2, pro-
vides the uncertainty measure of the estimation on ^xi, i = 1,2. If TrÃ°
Px2x2Ã, it infers that ^x2 has a much larger
estimation error than ^x1. We thus have ^x 
Px2x2Ã,
Px1x1Ã Â¼ TrÃ°
it is expected that ^x  1
2. Considering these, an additional linear
Pxx
constraint

b
Px1x1Ã  TrÃ°
P 1
x1x1
^x2. In other words, x1 Â¼ x2 Â¼ 1

^x1, which implies x1  1 and x2  0. Similarly, if TrÃ°

^x1 Ã¾ 1

b

b

b

2

is proposed. Substituting (29) into (30), it is obtained that

x1TrÃ°

2

Pxx

b

b

P 1
x1x1

Pxx
P 1
x2x2

b
b
b
Px1x1Ã   x2TrÃ°
Px2x2Ã Â¼ 0
b
b
b
b
Px2x2Ã Â¼ 0;
Px1x1Ã   Ã°1   x1ÃTrÃ°
b
Px1x1Ã   x2 TrÃ°
Px2x2Ã Â¼ 0:
b
Px2x2Ã > 0, x1 and x2 can be computed by
b
Px2x2Ã
b
Px1x1Ã Ã¾ TrÃ°
b
Px1x1Ã
b
Px1x1Ã Ã¾ TrÃ°
PxixiÃ P 0 ensure that 0 6 xi 6 1, i = 1,2.

b
Px2x2Ã ;
b
Px2x2Ã :

TrÃ°

TrÃ°

TrÃ°

x1TrÃ°
b
Ã°1   x2ÃTrÃ°
Px1x1Ã Ã¾ TrÃ°
TrÃ°

x1 Â¼

x2 Â¼

When TrÃ°

It is noted that TrÃ°

4. Performance evaluation

We treat image fusion as an estimation problem in this paper. The observed images (MS and Pan images) are modeled as a
linear transformation of the ideal images plus Gaussian noise. The goal is to recover the ideal images and combine them
through convex combination of the inverse of covariance matrices. And we use the trace of the covariance matrix of the esti-
mation error as the metric of image fusion performance. The expression of this metric cannot be derived, because there is no
way to get the cross-correlation between x1 and x2. But its upper bound can be obtained due to the CI theory. To minimize
the upper bound, the covariance matrix
Pxi;xi and the unbiased estimate ^xi are estimated using the EM algorithm. The weights
w1 and w2 for the observed images, respectively, are also obtained by an exhaustive search. Furthermore, to reduce the com-
puting complexity required to ï¬nd w1 and w2, we also derived a suboptimal linear algorithm.

b

In this paper, QuickBird MS and Pan images are used to evaluate the performance of the proposed EMâ€“CI method. The
spatial resolution of the MS image is 2.8 m (meters) while it is 0.7 m for the Pan image. The low-resolution MS image is

Q. Guo et al. / Information Sciences 180 (2010) 3434â€“3443

3439

re-sampled using cubic interpolation to the same size as the high-resolution Pan image, as shown in Figs. 2(a) and 3(a). The
Pan images are shown in Figs. 2(b) and 3(b).

Our objective is to increase the spatial resolution of MS image by injecting spatial details of the Pan image into the MS
image, while preserving spectral information of the MS image as much as possible. It is known that the spatial detailed infor-
mation of Pan image is mostly carried by its high-frequency components, while the spectral information of MS image is

Fig. 2. Experiments on the ï¬rst pair of QuickBird images: (a) the re-sampled multi-spectral image; (b) the panchromatic image; (c) the fused image by EMâ€“
CI; (d) the fused image by WT; (e) the fused image by PCA.

3440

Q. Guo et al. / Information Sciences 180 (2010) 3434â€“3443

Fig. 3. Experiments on the second pair of QuickBird images: (a) the re-sampled multi-spectral image; (b) the panchromatic image; (c) the fused image by
EMâ€“CI; (d) the fused image by WT; (e) the fused image by PCA.

mostly carried by its low-frequency components. If the high-frequency components of the MS image are simply substituted
by the high-frequency components of the Pan image [33,15], the spatial resolution is improved but with the loss of spectral
information from the high-frequency components of MS image. To avoid this, WT is ï¬rst applied to the MS and Pan images to
extract the spatial detailed information and spectral information, respectively. Then keeping the spectral information of MS
image untouched, the spatial details of the MS and Pan images are fused using EMâ€“CI. After the inverse WT, the fused images
can be obtained, which are shown in Figs. 2(c) and 3(c). In order to further minimize the spectral distortion, histogram

Q. Guo et al. / Information Sciences 180 (2010) 3434â€“3443

3441

matching [17] is applied to the Pan image to make its brightness and contrast best match that of each MS image band by
band. The fusion process of Pan details is applied with a ï¬xed decomposition scale which is given by the spatial resolution
of Pan and MS images (log2 of scale ratio).

The performance of EMâ€“CI is compared to two conventional methods. One is WT method. WT is ï¬rst applied to each MS
band and Pan images. Band by band, the approximations are kept untouched and the spatial details are replaced by corre-
sponding coefï¬cients of the Pan image. Then, the inverse WT is performed to obtain the fused images, which are shown in
Figs. 2(d) and 3(d). Another method is based on PCA. The MS image is transformed with PCA, and the principle components
are obtained. The ï¬rst principle component of the MS image is replaced with the histogram-matched Pan image. The fused
images are obtained when the new ï¬rst principle component and the other principle components are transformed with the
inverse PCA transform, and are shown in Figs. 2(e) and 3(e). In these ï¬gures, WT and EMâ€“CI methods utilize the same WT
decomposition scale.

From these ï¬gures, it is observed that the fused images using EMâ€“CI preserve most of the spectral information of MS
images and improve the spatial resolution simultaneously. As for the fused images by WT, the spectral performance is a little
inferior to that of EMâ€“CI, and the spatial performance is improved. For the PCA results, they have serious spectral distortion,
especially in the white areas of the fused image, also with the improved spatial details.

Besides the subjective evaluation, the quantitative assessment of fusion performance is also necessary. Two sets of criteria
are used in our study to evaluate the spectral and spatial performance, respectively. The spectral quality of the fused image
can be measured by the correlation coefï¬cient (CC) and the spectral discrepancy (SPD). CC describes the correlation degree
between two images, which provides a similarity measure of the spectral information between the fused image and the mul-
ti-spectral image. For each band, the deï¬nition of CC can be written as

P
P
P
M
mÂ¼1
nÂ¼1Â½MSFÃ°m; nÃ   lÂŠ
N

q
ï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒ
P
nÂ¼1Â½MSRÃ°m; nÃ   lMSRÂŠ

nÂ¼1Â½MSFÃ°m; nÃ   lÂŠÂ½MSRÃ°m; nÃ   lMSRÂŠ

P

P

M
mÂ¼1

M
mÂ¼1

N

N

CC Â¼

;

Ã°33Ã

where MSF(m, n) and MSR(m, n), respectively, denote the pixel value of the fused MS image and the reference image at the
position (m, n), M  N is the image size, and l and lMSR are the intensity averages of MSF and MSR, respectively. Because we
do not have any MS image at 0.7 m to compare with, following the Wald protocol [29], the original MS image at the reso-
lution of 2.8 m is used as MSR. The fused image MSF is obtained by fusing the MS and Pan images at the degraded scale. More
speciï¬cally, the original MS image at the resolution of 2.8 m is degraded to the one at the resolution of 11.2 m. Meanwhile,
the resolution of the original Pan image is also reduced from 0.7 m to 2.8 m. Both the degraded MS image and the degraded
Pan image are then fused to generate MSF at the resolution of 2.8 m. And CC is computed using MSF and MSR at a degraded
scale, i.e., 2.8 m. The desirable value of CC is 1.

:

Ã°34Ã

At each band, the SPD function is computed by

P
m;njMSFÃ°m; nÃ   MSRÃ°m; nÃj

MN

SPD Â¼

A small SPD indicates a good spectral performance.

vuut
ï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒ

X



RMSEÃ°kÃ

kÂ¼K

2

lÃ°kÃ

kÂ¼1

ERGAS Â¼ 100

dh
dl

1
K

These indices deï¬ned above only evaluate the spectral difference between corresponding bands of the original and fused
images. In order to evaluate the global spectral quality, the following index is used. The ERGAS coefï¬cient is calculated as the
global spectral quality description on all the fused multi-spectral bands. It is deï¬ned as

;

Ã°35Ã

where dh/dl is the ratio between resolutions of the high-resolution Pan image and the low-resolution MS image (for Quick-
Bird data, dh/dl = 1/4), l(k) is the average value of the kth band and K is the number of bands. The RMSE(k) of each spectral
band is computed by

ï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒ
vuut
X
X

Â½ MSFkÃ°m; nÃ   MSRkÃ°m; nÃÂŠ2

M

N

:

RMSEÃ°kÃ Â¼ 1
MN

mÂ¼1

nÂ¼1

Ã°36Ã

Lower values of the ERGAS coefï¬cient imply higher spectral quality for the fussed image. The desirable value of ERGAS is
therefore 0.

For the spatial quality evaluation, we use the average gradient (AG) index. AG describes the changing feature of image
texture and the detailed information. Larger values of the AG index correspond to higher spatial resolution. The AG index
of the fused images at each band can be computed by

ï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒ
h
i

i

h

AG Â¼ 1
MN

@MSFÃ°m;nÃ

@m

2 Ã¾ @MSFÃ°m;nÃ
2

@n

2

:

Ã°37Ã

vuut

X

M

X

N

mÂ¼1

nÂ¼1

3442

Q. Guo et al. / Information Sciences 180 (2010) 3434â€“3443

Table 1
Objective evaluation of fusion performance using the ï¬rst pair of QuickBird images.

Fusion method

Band

Spectral quality

Spatial quality

EMâ€“CI

WT

PCA

R
G
B

R
G
B

R
G
B

CC

0.9801
0.9770
0.9799

0.9489
0.9418
0.9474

0.8972
0.8721
0.8733

SPD

6.7148
6.2489
6.8925

11.1940
10.1281
11.5785

13.7137
12.5861
15.1401

Table 2
Objective evaluation of fusion performance using the second pair of QuickBird images.

Fusion method

Band

Spectral quality

EMâ€“CI

WT

PCA

R
G
B

R
G
B

R
G
B

CC

0.9775
0.9762
0.9792

0.9463
0.9428
0.9478

0.9117
0.9226
0.8977

SPD

6.7511
6.7138
6.9887

10.8203
10.5158
11.3393

13.2300
11.9986
14.7983

ERGAS

2.6290

4.1885

6.2148

ERGAS

3.4483

5.3411

6.7806

AG

25.3757
20.9784
25.7214

28.1817
23.6103
28.9022

25.3470
23.4976
26.0551

Spatial quality

AG

23.5711
21.0510
24.1559

26.3574
23.3114
27.4033

24.6685
23.7542
25.9798

The results of these objective evaluations on the two pairs of testing images are listed in Tables 1 and 2. From these values, it
is obvious that the spectral distortion introduced by EMâ€“CI is less than that of WT and PCA for both the local and global eval-
uation of spectral quality. For the spatial performance, EMâ€“CI has a slightly degraded performance comparing with WT and
PCA. As human visual system is more sensitive to the spatial resolution than to the spectral one, results of EMâ€“CI approach
are not seem to be signiï¬cantly better than WT approach. The WT method preserves the detailed spatial information through
the multi-scale decomposition and through the complete replacement by the Pan image at each discrimination scale. How-
ever, due to this replacing process, the partial spectral information still contained in the high-frequency components of MS
image is lost. For PCA, the simple replacement results in the serious loss of spectral information, because the ï¬rst principle
component of the MS image, which contains much spectral information, is completely discarded.

In contrast, EMâ€“CI utilizes all the information from the two source images, while keeping the low-frequency components
of MS image untouched. In addition, EMâ€“CI uses convex combination and weight optimization to fuse two images in order to
minimize the spectral distortion. This guarantees that EMâ€“CI does not cause signiï¬cant spectral distortion in fusion. These
two reasons explain the superior spectral performance of EMâ€“CI over WT and PCA. Meanwhile, EMâ€“CI optimally injects spa-
tial details of the Pan image into the MS image. Thus, the detailed information from both images is preserved. Overall speak-
ing, EMâ€“CI is capable of enhancing the spatial quality of the MS image while preserving the spectral content to a greater
extent. Comparing with WT and PCA methods, the proposed EMâ€“CI method preserves more signiï¬cant spectral information
at the cost of slightly lower improvement on spatial quality.

5. Conclusions

Covariance intersection, which combines multiple data sources through convex combinations for any degree of cross-cor-
relation, is one of the most popular information fusion approach. In this paper, we propose a novel EMâ€“CI approach for fusion
of MS and Pan images. More speciï¬cally, the ideal MS and Pan images are estimated by EM along with the covariance matri-
ces of the estimation error. Then, CI is applied to combine the two images and provide a consistent estimate of the high-res-
olution MS image. The proposed method can accurately preserve both the spectral information and the high-resolution
spatial information. Its effectiveness is demonstrated with the real remote sensing images.

Acknowledgements

This work was supported by the National Natural Science Foundation of China under Grant Nos. 10674038 and 10974039,
and jointly supported by the State Scholarship of the China Scholarship Council for study abroad (Grant No. [2007]3020). Ms.

Q. Guo et al. / Information Sciences 180 (2010) 3434â€“3443

3443

Qing Guo thanks Rob Edwards for his help with the English wording of the manuscript. The authors would like to thank the
anonymous reviewers for their comments and suggestions.

References

[1] J.A. Bilmes, A gentle tutorial of the EM algorithm and its application to parameter estimation for Gaussian mixture and hidden Markov models,

Technical Report, University of California, Berkeley, ICSI-TR-97-021, 1998.

[2] F. Bovolo, L. Bruzzone, L. Capobianco, A. Garzelli, S. Marchesi, F. Nencini, Analysis of the effects of pansharpening in change detection on VHR images,

IEEE Geoscience and Remote Sensing Letters 7 (1) (2010) 53â€“57.

[3] D.M. Bulanona, T.F. Burksa, V. Alchanatisb, Image fusion of visible and thermal images for fruit detection, Biosystems Engineering 103 (2009) 12â€“22.
[4] W.J. Carper, T.M. Lillesand, R.W. Kiefer, The use of intensity-hue-saturation transformations for merging SPOT panchromatic and multispectral image

data, Photogrammetric Engineering and Remote Sensing 56 (1990) 459â€“467.

[5] P.S. Chavez, A.Y. Kwarteng, Extracting spectral contrast in Landsat thematic mapper image data using selective component analysis, Photogrammetric

Engineering and Remote Sensing 55 (1989) 339â€“348.

[6] P.S. Chavez, S.C. Sildes, J.A. Anderson, Comparison of three different methods to merge multiresolution and multispectral data: Landsat TM and SPOT

panchromatic, Photogrammetric Engineering and Remote Sensing 57 (1991) 295â€“303.

[7] D.L. Civco, Y. Wang, J.A. Silander, Characterizing forest ecosystems in Connecticut by integrating Landsat TM and SPOT panchromatic data, Proceedings

of the ACSM/ASPRS Annual Convention, Charlotte, NC, vol. 2, ASPRS, Reston, VA, 1995, pp. 216â€“224.

[8] P. Dempster, N. Laird, D. Rubin, Maximum likelihood from incomplete data via the EM algorithm, Journal of the Royal Statistical Society Series B 39

(1977) 1â€“38.

[9] B.G. Duport, The use of multiresolution analysis and wavelet transform for merging Spot panchromatic and multispectral

image Data,

Photogrammetric Engineering and Remote Sensing 62 (1996) 1057â€“1066.

[10] M.A.T. Figueiredo, R.D. Nowak, An EM algorithm for wavelet-based image restoration, IEEE Transactions on Image Processing 12 (8) (2003) 906â€“916.
[11] A.H. Jazwinski, Stochastic Processes and Filtering Theory, Academic Press, 1970.
[12] S.J. Julier, J.K. Uhlmann, A non-divergent estimation algorithm in the presence of unknown correlations, Proceedings of the American Control

Conference 4 (1997) 2369â€“2373.

[13] M.M. Khan, J. Chanussot, L. Alparone, Hyperspectral pansharpening using QNR optimization constraint, in: WHISPERS Conference, 2009.
[14] H. Li, B.S. Manjunath, S.K. Mitra, Multisensor image fusion using the wavelet transform, Graphical Models and Image Processing 57 (1995) 235â€“245.
[15] S. Li, J.T. Kwok, Y. Wang, Using the discrete wavelet frame transform to merge Landsat TM and SPOT panchromatic images, Information Fusion 3 (2002)

17â€“23.

[16] J.S. Lim, Two-Dimensional Signal and Image Processing, Prentice Hall Press, New Jersey, USA, 1990.
[17] J. Morovic, J. Shaw, P.L. Sun, A fast, non-iterative and exact histogram matching algorithm, Pattern Recognition Letters 23 (2002) 127â€“135.
[18] W. Niehsen, Information fusion based on fast covariance intersection ï¬ltering, in: IEEE Proceedings of the Fifth International Conference on

Information Fusion, vol. 2, 2002, pp. 901â€“904.

[19] J. NÃºÃ±ez, X. Otazu, O. Fors, A. Prades, V. PalÃ , R. Arbiol, Multiresolution based image fusion with additive wavelet decomposition, IEEE Transactions on

Geoscience and Remote Sensing 37 (1999) 1204â€“1211.

[20] C. Pohl, J.L. Van Genderen, Multisensor image fusion in remote sensing: concepts, methods, and application, International Journal of Remote Sensing 19

(1998) 823â€“854.

[21] L.I. Perlovsky, Cognitive high level information fusion, Information Sciences 177 (2007) 2099â€“2118.
[22] N. Prasad, S. Saran, S.P.S. Kushwaha, P.S. Roy, Evaluation of various image fusion techniques and imaging scales for forest features interpretation,

Current Science 81 (2001) 1218â€“1224.

[23] P. Scheunders, S.D. Baeker, Fusion and merging of multispectral images using multiscale fundamental forms, Journal of the Optical Society of America A

18 (2001) 2468â€“2477.

[24] V.P. Shah, N.H. Younan, R.L. King, An efï¬cient pan-sharpening method via a combined adaptive PCA approach and contourlets, IEEE Transactions on

Geoscience and Remote Sensing 46 (5) (2008) 1323â€“1335.

[25] V.K. Shettigara, A generalized component substitution technique for spatial enhancement of multispectral images using a higher resolution data set,

Photogrammetric Engineering and Remote Sensing 58 (1992) 561â€“567.

[26] J.K. Uhlmann, Dynamic map building and localization: new theoretical foundations, PhD Thesis, University of Oxford, 1995.
[27] J. Uhlmann, General data fusion for estimates with unknown cross covariances, in: Proceedings of the SPIE Aerosense Conference, 1996, pp. 165â€“173.
[28] N.G. Wah, Y. Rong, Comparison of decentralized tracking algorithms, in: Information Fusion, Sixth International Conference, 2003, pp. 107â€“113.
[29] L. Wald, T. Ranchin, M. Mangolini, Fusion of satellite images of different spatial resolutions: assessing the quality of resulting images, Photogrammetric

Engineering and Remote Sensing 63 (6) (1997) 691â€“699.

[30] R.R. Yager, A framework for multi-source data fusion, Information Sciences 163 (2004) 175â€“200.
[31] G. Yang, Y. Lin, P. Bhattacharya, A driver fatigue recognition model based on information fusion and dynamic Bayesian network, Information Sciences

180 (2010) 1942â€“1954.

[32] D.A. Yocky, Multiresolution wavelet decomposition image merger of Landsat Thematic Mapper and SPOT panchromatic data, Photogrammetric

Engineering and Remote Sensing 62 (1996) 1067â€“1074.

[33] J. Zhou, D.L. Civco, J.A. Silander, A wavelet transform method to merge Landsat TM and SPOT panchromatic data, International Journal of Remote

Sensing 19 (1998) 743â€“757.

