Minutes
Representation Learning: 
A Review and New Perspectives (Part II)

Minutes - Auto-Encoders

● Model which tries to reconstruct its input
● Regularized AE

○

Bottleneck to constrain data

● Sparse AE

○ Achieved by penalizing hidden units, set units to zero

● Denoising AE

○

Reconstruct clean input from corrupt data

● Contractive AE

○

Keeps only good information

2

Minutes - Boltzmann Machines and Convolution

● Boltzmann Machines

Extract meaningful features
Restricted BM → no connections within layers

○
○
○ Deep BM

■

Stacked RBMs → harder to train

● Convolution

○

Tries to find structure 

■

In for example 2D images

○ Done by defining local receptive fields

■ Applied to whole picture
■ Checks for local features appearing in different parts of picture

3

Minutes - Conclusion

● Choosing the right hyperparameters is tricky

○ Many variants → exploration needed

● Deep networks:

○ Success in supervised learning
○

Problems with unsupervised learning

4

The interaction of representation 
and reasoning

Alan Bundy, 2013

Outline
1. Automated reasoning

a. Applications
b.

Resolution

2. Reasoning Failures
3. Repairs

a. Agent’s representation of other agents
b.
c. Mathematics proofs

Physics theories

4. Reformation algorithm
5. Conclusion

6

Automated reasoning
● Knowledge represented as a set of axioms:

○ Female(Elizabeth), Mother(Charles)=Elizabeth, Loves(Elizabeth,Charles)

● Inference rules are represented in this way: 

○ Modus ponens:

● Reasoning is done by applying rules of inferences to axioms and old theorems 

in order to derive new theorems. 
○ Axioms include: Mother(Charles)=Elizabeth, Mother(c)=m ⇒ Female(m)
○ With modus ponens we can derive:  Female(Elizabeth)

7

Applications

● reasoning about programs: It can be used to show that a program is safe, 

secure and reliable for an infinite number of possible inputs.

● forming plans eg. autonomous robots

○ Axioms: possible actions and environment conditions
○ Goals would be conjectures you want to prove 
○

Required plan: byproduct of the proof  

● question answering: looks if the answer can be derived from the stored 

knowledge

8

Recap first order logic 
● Terms: 

○ Constants: Charles,Elizabeth
○
○

Variables: c,m
Functions applied to terms: Mother(m)

● Propositions:

○ Give truth values back: Female(Charles) 

● Formulas:

○ Constructed from propositions using logical connectives and quantifier

● Different kinds of objects: 

○
Logical sequence can be represented as pair <Sig(T),Ax(T)>
○
Sig(Family)={Charles: P, Elizabeth: P, Mother: P-->P, Female: P-->B}  
○ Ax(Family)= {Mother(Charles)=Elizabeth, Mother(c)=m==>Female(m)}

9

Resolution (rule of inference)
● Negation of the conjecture to be proven should lead to a contradiction 

(empty clause ). The original conjecture is then proven. 

● In order to apply resolution we need

○ Clausal from
○

Substitution and unification

Clausal form
● Conjunction of Disjunction (CNF)

○

10

Elimination of Quantifiers (Clausal Form)
● Skolemization: each existentially quantified variable gets 

replaced by a function with N arguments. N being the number 
of universal quantifiers that occur before.

● Now all occurring variables are universally quantified 

therefore the universal quantifier can be left away

11

Substitution and Unification

● Substitution is a set of pairs of the form{ variable/term, variable/term…}

○ Loves(x,y) with substitution {x/Elizabeth,y/Charles}
○ Evaluates in Loves(Elizabeth,Charles)

● Unification is an algorithm for creating substitutions

○ Given two propositions s and t it tries to create a substitution called unifier o such 

that so=to

○ Creates the most general unifier (will not instantiate a variable  if it is not 

necessary)

○ Loves(Elizabeth,y) and Loves(u,w) most general unifier: {u/Elizabeth,w/y}

12

Standard Unification Algorithm

-> If two things are the same they are already unified

 -> same function, same unity 

->check if arguments are unifiable

-> different functions are not unifiable

->assign variable x to term s

-> add {x/s} to the unifier so far

->father(X) =? father(father(X))   
>father(father(X)) != father(father(father(X))) 

  try  o= X/father(X) -

13

Binary resolution rule

● Applied to two clauses it derives a third one
●
First transform the axioms into clausal form
●
Then transform negated conjecture to be proven into clausal form
●
Try to derive the empty set by applying the Binary resolution rule

Sigma is the substitution which unifies P1 and P2
Because P can not be true and false at the same time either C1 or C2 must also be true 

14

Importance of representation for reasoning 

1. Multiple realization problem

a lot of ways to represent an 
everyday object 

->

choosing the right representation is 
crucial for success

15

2. Mutilated checker board problem

Change of representation makes a 
dramatic difference to the efficiency of 
problem-solving 

16

Reasoning failures and possible repairs

1. Proof of a false conjecture:

Capital(Japan)= Tokyo

Capital(Japan)=Kyoto

repair:

● remove one
● Create a new predicate:  

○ WasCapital(Japan)=Kyoto

● Add a new argument to the original predicate: 

○ Capital(Japan,now)=Tokyo 
○ Capital(Japan,past)=Kyoto

17

2. Failure  to prove a true conjecture:

● Query: ?- Female(Elizabeth)
● Axioms: Mother(Charles)= Elizabeth, MomOf(c)=m ⇒ Female(m)

repair:

● change  Mother to MomOf or vica versa

18

Motivation for automated reasoning repair
● possibility to adapt to different environments

○

○

needed in finance and commerce

● understanding of other  representations

interaction with other agents

● world to rich to represent, so for each task representation can change 

accordingly

● less work and faster if representation changes automatically

○

emergency response

19

Repairing an agent’s representation of other 
agents
● ORS(Ontology Repair System) uses a planning agents (A) representations of 

the services provided by a service-providing agent (B) to construct a plan 
composed of those services.

● Assumption: Ontologies of A and B might slightly differ, but originally are the 

same. As both agents work in a dynamic manner though, they diverged. Agent 
A is now interested in updating his representation of the ontology of agent B.

● Ways of fixing the ontologies: Surprising question

20

Example: Online travel planning

● Submission of the camera-ready copy of an accepted paper to a conference, 

then making plans to attend the conference

● It uses a peer-to-peer multi-agent system
● Agents:

Planning Agent: forming and executing the overall plan
Publication Agent: takes copy in the proceedings
Registration Agent: registers conference attendees

○
○
○
○ Accommodation Agent: accommodation for delegates
○

Paper conversion Agent: convert papers into different formats

21

Example: Online travel planning

Planning Agents ontology: 
(SendPaper Researcher My-Paper.ps Ai-Conf), 
(Register Researcher Ai-Conf Registration-Cost), 
(BookAccom Researcher Ai-Conf Accommodation-Cost)

1. Action SendPaper fails. Before the failure the publication agent sent a query (Format My-Paper.ps 

Pdf-Paper)
Format is a Precondition for Sendpaper as it happened beforehand. Our paper is in ps format. As 
SendPaper failed the Planning agent can deduce that the format has to be pdf
It now creates (Convert-Paper Researcher My-Paper.ps My-Paper.pdf)

2.

3.

22

Example: Online travel planning

(Register Researcher Ai-Conf Registration-Cost), 
(BookAccom Researcher Ai-Conf Accommodation-Cost)

1. Register Fails following the surprising question (Money PA Credit-Card ?

Amount). Expected was (Money PA 100)

2. Agent changes action to (Register Researcher Ai-Conf Credit-Card 

Registration-Cost)

23

Repairing physics theories

● Guided Analysis of Logical Inconsistencies Leads to Evolved Ontologies 

system

● Ontology Repair Plans

○
○

Trigger Formula
some representation of repair instructions

● one ontology to represent the theory and another to represent the conflicting 

experimental evidence.

24

Example
● Most commonly applicable ORP is „Where’s my Stuff“

● Ox might be the representation of a physics theory and Oy that of some 

conflicting experimental evidence.

● attribute f of some stuff is predicted to take the value vx, but experiment 

shows it to have a different value vy

25

Change of ontologies signatures

26

Change of ontologies axioms

27

Repairing faulty mathematics proofs

● Example: The limit of a convergent series of continuous functions is itself 

continuous

28

Convergence

29

Whats going wrong?
● The mistake that happens when we try to unify the ontologies that describe 

Cauchy’s faulty limit theorem is a failed “occurs check” error. As we know we 
can remove this error by removing the disentangled variables from all 
dependent formulas. This is done by switching up the quantifiers.

30

Reformation algorithm

● Deals with 2 out of the 3 failures:

○
○

Failure to proof a true conjecture
Proof of a false conjecture

● Not Running out of ressources
● Completely automatic
● Unblock: failed, but wanted unification
● Block: successful but unwanted unification

31

Reformation algorithm - Rules

32

Reformation algorithm - Example
Failed unification: Money(£ 200) and Money(£ 200,Credit_Card)

→ Money(£ 200) 

Inconsistency: f(stuff) = f(stuff)

Rename one → f(stuff) != f(visibleStuff)

33

Reformation algorithm - Properties

● Efficiency is the same as Unification → Exponential in the size of input
● Always found the desired repair
● Problem: huge number of repairs

Some make intuitive sense

○
○ Others not

■ Heuristics are needed

● Example: protect some functions

○

+ or =

34

Related Work

● Belief revision:

○ Adding new belief that might result in inconsistency. Facts or rules need to be deleted again

■ Complementary: suggest changes to language instead

● Abduction:

○ Adding explanatory hypotheses. Adding axioms

■ Complementary: suggest changes to language instead

● Ontology evolution:

○ Manual construction and maintenance of an ontology

■ Different: automatic identification of changes

● IBIS System:

○ Automated ontology repair (polysemy, single/multiple over-generalization)

■

Extended reformation algorithm suggests repairs for all three

35

Conclusion

● Finding the right representation is key to reasoning
● Conceptual change is possible via language repair
● Automated repair is set to be a key research area in automated reasoning and 

machine learning

● Previously: 

○ Manually designed by knowledge engineers
○
○

For narrowed application
Repairs needed to be done offline and manually

● Now:

Environment and task dynamically evolving

○
○ Multi-agent cooperation more common → may have different representations

36

Discussion

● Is the reformation algorithm useful?
● If no: 

○ Why?
○ What is needed for it to become useful?

37

References

“The interaction of representation and reasoning” - Alan Bundy

38

