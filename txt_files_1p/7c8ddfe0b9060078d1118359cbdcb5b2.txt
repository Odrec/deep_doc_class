Questions Chapter 3 (Artificial Neural Networks) 

other 

network 

1. Name and describe the three properties decisive for the functioning of a 
- Architecture of the network, describes how the neurons are connected to each 
- Learning algorithm, used to set the weights of the network 
- While the connections between the neurons determine whether they can 
- Activation function which determines the output of each neuron  

influence each other, the weights define the strength of this influence  

2. Explain the functioning of a formal neuron and illustrate its structure 
- building blocks of ANN’s 
- Compared to biological neurons, it is a very simple abstraction and rather 
- Explain by means of figure: 

primitive 
- we have d input signals that form an input vector  
- each input is multiplied by a synaptic weight (can be positive or negative) 
- they determine how much influence the output of a neuron has on other, 
- in addition to the weights, an artificial neuron is subject to a bias b 
- acts as a threshold by either increasing or decreasing the activation of the 
- if we sum over the weighted inputs and the bias we get the activation of the 
- usually, the bias is included in the sum by adding a constant component to the 
- the output y of the neuron in computed by applying an activation function to 

connected neurons 

input vector 

neuron 

neuron 

the activation 

3. Name and describe the three types of architectures 
- The simplest form of a neural network is a single-layer network 
- Consists of only an input layer which projects directly onto an output layer, 
- The layers don’t have to be fully connected 
- Various forms of partially connected nets are also possible 
- Regarding the name: input layers are typically not counted as layers since they 

usually in a feedforward fashion 

do not perform any computation 

observed from either the input or the output of the network 

- A network with several layers is called a multilayer network  
- Has not only input/output layer but also hidden layer(s) 
- called ”hidden” because their structure and properties cannot be directly 
- Harder to design than input/output layers because #neurons and their 
- Hidden layers perform certain computation of the input and transform it before it 
- Presence of hidden layers makes multilayer networks much more powerful and 

connections are not directly predicted by the external problem 

is passed on to the next layer 

provides them with the ability to solve more complicated problems 

