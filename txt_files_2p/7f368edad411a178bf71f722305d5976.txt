Technical Report

Social Data Mining

Kim Gerbaulet

Sebastian Höﬀner

November 09, 2014

1 Used tool
We decided to stay with Python, which worked really good and we already knew what we had to do for this
task.

2 Solving the task
2.1 Recycling the data
In task 1 we chunked the data into each hour of the day and already solved the problem of CR and LF. In
some programming languages (as in Python and R) CR was interpreted as a LF which resulted in corrupted
data. Thus we used the chunked data to avoid this problem. We read in the data with a for loop in which
we fetched the whole day at once.

f o l d e r = " . . / data / "
folder_2 = " chunks /201407 " + str ( day ) + " 00 " + " 0000. csv "
hashtag = {}
hashcount = {}
for hour in hours :

i f hour < 10 and hour > 0:

folder_2 = ( " chunks /201407 " + str ( day ) + " 0 " + str ( hour )

e l i f hour >= 10:

+ " 0000. csv " )

folder_2 = " chunks /201407 " + str ( day ) + str ( hour ) + " 0000. csv "

with open( f o l d e r + folder_2 ,

" r " ) as

c s v f i l e :

csvreader = csv . reader ( c s v f i l e , d e l i m i t e r=’ \ t ’ )
for entry in csvreader :

tweet ) = ( entry [ 2 ] ,

entry [ 6 ] )

( date ,
c s v f i l e . c l o s e ()

2.2 Finding the Hashtags
To ﬁnd the 20 most common hashtags, we wanted only the tweets with hashtags. We used a dictionary to
save those hashtags with their amounts of occurrence.
for entry in csvreader :

tweet ) = ( entry [ 2 ] ,

entry [ 6 ] )

( date ,
i f

’#’ not in tweet :
continue

1

r e s u l t s = re . f i n d a l l ( r "#(\w+)" ,
for r e s u l t

in r e s u l t s :

i f

r e s u l t
hashcount [ r e s u l t ] += 1

in hashcount :

tweet )

else :

hashcount [ r e s u l t ] = 1
hashtag [ entry [ 0 ] ] = ( date ,

r e s u l t )

c s v f i l e . c l o s e ()

2.3 Finding the 20 common hashtags
After having an idea how much hashtags we have, we needed only the 20 most common hashtags for one day.
To ﬁnd these, we just sorted the dictionary into a list and stored the results into a new csv ﬁle.
hashcount_sorted = sorted ( hashcount . items ( ) , key=operator . itemgetter (1) ,

r e v e r s e=True )

top20 = [ ]
with open( f o l d e r + " processed /top_ " + str ( day ) + " . csv " ,

tweetWriter = csv . writer ( procFile , d e l i m i t e r=’ \ t ’ )
for i

in range ( 2 0 ) :

"wb" ) as procFile :

(k , v ) = hashcount_sorted [ i ]
tweetWriter . writerow ( [ k , v ] )
print hashcount_sorted [ i ]

procFile . c l o s e ( ) ;

2.4 Finding the distribution change of the three most common tags
To ﬁnd the distribution change we counted all occurrences of the most common tags into minute-sized bins.
These bins were then simply plotted.

N = numTopTweets
topN = [ None ] ∗ N
topNdata = {}
g r a n u l a r i t y = 100
for topInd in range (N) :

for ( tagDate ,

(k , v ) = hashcount_sorted [ topInd ]
topN [ topInd ] = k
tagDate = str ( int ( tagDate ) − ( int ( tagDate ) \% g r a n u l a r i t y ))
for topTag in topN :

in hashtag . values ( ) :

tag )

i f

tag == topTag :
tup = ( tagDate ,
i f

tag )
tup in topNdata :
topNdata [ tup ] += 1

else :

break

topNdata [ tup ] = 1

2

