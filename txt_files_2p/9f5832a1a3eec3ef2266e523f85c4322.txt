Review

TRENDS in Cognitive Sciences Vol.10 No.7 July 2006

Special Issue: Probabilistic models of cognition

Bayesian decision theory in
sensorimotor control
Konrad P. Ko¨ rding1 and Daniel M. Wolpert2

1Brain and Cognitive Sciences, Massachusetts Institute of Technology, Building NE46-4053, Cambridge, Massachusetts, 02139, USA
2Department of Engineering, University of Cambridge, Trumpington Street, Cambridge, CB2 1PZ, UK

Action selection is a fundamental decision process for
us, and depends on the state of both our body and the
environment. Because signals in our sensory and motor
systems are corrupted by variability or noise, the
nervous system needs to estimate these states. To
select an optimal action these state estimates need to be
combined with knowledge of the potential costs or
rewards of different action outcomes. We review recent
studies that have investigated the mechanisms used by
the nervous system to solve such estimation and
decision problems, which show that human behaviour
is close to that predicted by Bayesian Decision Theory.
This theory deﬁnes optimal behaviour in a world
characterized by uncertainty, and provides a coherent
way of describing sensorimotor processes.

Introduction
The central nervous system (CNS) constantly sends motor
commands to our muscles. Determining the appropriate
motor command is fundamentally a decision process. At
each point in time we must select one particular motor
command from the set of possible motor commands. Two
components jointly deﬁne the decision problem: knowl-
edge of the state of the world (including our own body) and
knowledge of our objectives.

The sensory inputs of humans are plagued by noise
[1,2] which means that we will always have uncertainty
about our hand’s true location (Figure 1a). This uncer-
tainty depends on the modality of the sensory input: when
we use proprioception to locate our hand we may have
more uncertainty about its position compared to when we
can see it. Moreover, our muscles produce noisy outputs
[3,4] and when we quickly move to a target location
(shown as a red ! in Figure 1a) our ﬁnal hand position
will typically deviate from the intended target. Even if our
sensors were perfect they would only tell us about the part
of the world that we can currently sense. This uncertainty
places the problem of estimating the state of the world and
the control of our motor system within a statistical
framework. Bayesian statistics [5–8] provides a systema-
tic way of solving problems in the presence of uncertainty
(see the online article by Grifﬁths and Yuille associated
with this issue: Supplementary material online).

Corresponding author: Ko¨rding, K.P. (kording@mit.edu).

The approach of Bayesian statistics is characterized by
assigning probabilities to any degree of belief about the
state of the world (see also Conceptual Foundations
editorial by Chater, Tenenbaum and Yuille).

Bayesian statistics deﬁnes how new information should
be combined with prior beliefs and how information from
several modalities should be integrated. Bayesian decision
theory [9–11] deﬁnes how our beliefs should be combined
with our objectives to make optimal decisions. Under-
standing the way the CNS deals with uncertainty might
be key to understanding its normal mode of operation.

The cost of each movement (such as energy consumed)
must be weighed against the potential rewards that can be
obtained by moving. In the framework of decision theory a
utility function should quantify the overall desirability of
the outcome of a movement decision. We should choose a
movement so that as to maximize utility. Several recent
papers have addressed what functions people optimize
with their movements. Understanding what human
subjects try to optimize is a necessary step towards a
rational theory of movement selection.

The selection of a movement can be described as the
rational choice of the movement that maximizes utility
according to decision theory (see Box 1). This approach
thus asks why people behave the way they do. An
increasing number of laboratories have addressed this
question within this framework. Here we review recent
studies that ﬁnd human movement performance to be
close to the predictions obtained from optimally combining
probability estimates with movement costs and rewards.
The approach has the potential to embed human
behaviour into a coherent mathematical framework.

Estimation using Bayes rule
We need to estimate the variables that are relevant for our
choice of movement. For example, when playing tennis we
may want to estimate where the ball will bounce. Because
vision does not provide perfect information about the ball’s
velocity there is uncertainty as to the bounce location.
However, if we know about the noise in our sensory system
then the sensory input can be used to compute the
likelihood – the probability of getting the particular
sensory inputs for different possible bounce locations
(shown in red in Figure 1b). We can combine this with
information that is available over repeated experience of
tennis: the position where the ball hits the ground is not

www.sciencedirect.com 1364-6613/$ - see front matter Q 2006 Elsevier Ltd. All rights reserved. doi:10.1016/j.tics.2006.05.003

320

Review

TRENDS in Cognitive Sciences Vol.10 No.7 July 2006

(a)

Sensor noise

Motor noise

Box 1. Decision theory

Visual

X

Proprioceptive

(b)

(c)

Projector

Likelihood

Posterior

*

***

(d)

r
o
i
r
p

 
f

o

 
t

i

h
g
e
W

1

0

Prior

***

σ

0

σ

M

σ

L

σοο

Screen

Mirror

Sensor

Subject

(e)

)

U
A

(
 
r
o
i
r
p

 

d
e
r
r
e

f

n

I

1

0
–0.5

1

2.5

Increasing perceptual uncertainty

Lateral shift (cm)

TRENDS in Cognitive Sciences 

Figure 1. Bayesian integration. (a) Perception and movement lead to uncertainty.
When we brieﬂy look at our hand we cannot be certain where exactly it is. The
resulting uncertainty is sketched as the grey probability distribution around the
ﬁnger at upper left. When we only feel our hand without looking we might have
more uncertainty (below). Right: if we make a fast movement from a starting
position to a target we will not always hit the target (red X) but there will be some
probability distribution of endpoint position. (b) Example: The other player is hitting
the ball. Seeing the ball, we can estimate that it will land in the red region (with a
likelihood proportional to the saturation). We have prior knowledge that the ball is
likely to land in the green region (with a probability proportional to the saturation).
The black ellipses denote the posterior, the region where the Bayesian estimate
would predict the ball to land. (c) The experimental set-up in typical movement
psychophysics experiments. (d) Human subjects’ reliance on the prior as a function
of increasing perceptual uncertainty. (e) The inferred prior for the different
conditions and subjects. The actual distribution used in the experiment is shown
in red. (Data for (d) and (e) replotted from [12]).

uniformly distributed over the court. For example the
bounce locations are likely to be concentrated within the
conﬁnes of the court and the distribution might be highly
peaked near the boundary lines where it is most difﬁcult to
return the ball. This distribution of positions is called the
‘prior’ (sketched in green) and could be learned through
experience. Bayes Rule deﬁnes how to combine prior and
likelihood to make an optimal estimate of the bounce
location (see Box 2).

Bayesian integration in motor control
Bayes rule makes it clear that to perform optimally we
must combine prior knowledge of the statistic of the task

www.sciencedirect.com

Decision theory quantiﬁes how people should choose in the context
of a given utility function and some partial knowledge of the world.
The expected utility is deﬁned as:

E Utility

pðoutcomejactionÞUðoutcomeÞ

X



h

possible
outcomes

where p(outcomejaction) is the probability of an outcome given an
action and U(outcome) is the utility associated with this outcome.
According to decision theory people choose the action so as to
maximize the expected value of utility. Choosing according to this
criterion is the deﬁnition of choosing rationally. Within the frame-
work of economics, numerous problems have been described in
these terms. For example, people’s decision about the ratio of risky
to non-risky assets in their portfolio has been described in terms of
people having partial knowledge about their future earnings while
maximizing their future utility [59]. Companies’ decisions about
wages and employment of workers have been modelled in terms of
the company having partial information about workers’ ability and
maximizing proﬁts [60]. Moreover, the decisions of the central bank
to increase or decrease interest rates has been modelled in terms of
optimally reducing the uncertainty about future inﬂation [61].
Economics tries to understand both how agents should optimally
behave when deciding under uncertainty and how they actually
behave in such cases. Bayesian decision making is the systematic
way of combining Bayesian estimates of probability with
utility functions.

Optimal control aims to solve similar problems where the decision
is not just happening at one point of time but a continuous output
(such as muscle force). The expected utility changes constantly
according to new information coming in. Solutions to this problem
typically use the notion of ‘cost-to-go’ the average integrated cost
from a current state to a target state.

with the likelihood obtained from the sensory input. In a
recent experiment [12], it was tested whether people use
such a strategy. Instead of the bounce location of a tennis
ball subjects had to estimate the position of a cursor
relative to their hand (Figure 1b). Subjects could use two
sources of information: The distribution of displacements
over the course of many trials (prior), as well as what they
see during the current trial (likelihood). The quality of the
visual feedback was also varied, in some cases a ball was
shown at the position of the cursor giving precise feedback
whereas in other trials a large cloud was shown at the
position of the cursor thereby increasing the variability
(noise) in the sensory input (see Figure 1d).

In this experiment, the Bayesian estimation process
deﬁnes the optimal estimate as a weighted combination of
the mean location of the prior and the peak of the sensory
likelihood (see Box 2). Moreover, it predicts that with
increasing noise in the sensory feedback subjects should
increase the weight of the prior and decrease the weight of
their sensory feedback in their ﬁnal estimate of the
location. Figure 1d shows that this Bayesian strategy is
observed. From the data it is possible to infer the prior
that people are using – assuming that they use an optimal
Bayesian strategy. Figure 1e shows that people used a
prior that was very close to the optimal one.

This experiment therefore shows that subjects in this
task exhibit a strategy very similar to the one predicted
by optimal Bayesian statistics. Some experiments could

