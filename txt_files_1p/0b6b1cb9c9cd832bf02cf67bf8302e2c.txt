IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS—I: REGULAR PAPERS, VOL. 57, NO. 8, AUGUST 2010

2109

Improved Quasi-Newton Adaptive-Filtering

Algorithm

Md Zulﬁquar Ali Bhotto, Student Member, IEEE, and Andreas Antoniou, Life Fellow, IEEE

Abstract—An improved quasi-Newton (QN) algorithm that per-
forms data-selective adaptation is proposed whereby the weight
vector and the inverse of the input-signal autocorrelation matrix
are updated only when the a priori error exceeds a prespeciﬁed
error bound. The proposed algorithm also incorporates an im-
proved estimator of the inverse of the autocorrelation matrix. With
these modiﬁcations, the proposed QN algorithm takes signiﬁcantly
fewer updates to converge and yields a reduced steady-state mis-
alignment relative to a known QN algorithm proposed recently.
These features of the proposed QN algorithm are demonstrated
through extensive simulations. Simulations also show that the
proposed QN algorithm, like the known QN algorithm, is quite
robust with respect to roundoff errors introduced in ﬁxed-point
implementations.

Index Terms—Adaptation algorithms, adaptive ﬁlters, conver-
gence speed in adaptation algorithms, quasi-Newton algorithms,
steady-state misalignment.

I. INTRODUCTION

T HE least-mean-squares (LMS) algorithm minimizes the

Weiner-Hopf function iteratively by using the instanta-
neous values of the autocorrelation function of the input signal
and the crosscorrelation function between the input and desired
signals [1]. Due to its simplicity, the LMS algorithm is fre-
quently used in current practice. However, when the input signal
is highly colored or bandlimited, the LMS algorithm as well as
other algorithms of the steepest-descent family converge slowly
and the capability of such algorithms in tracking nonstationar-
ities deteriorates. In such situations, more sophisticated algo-
rithms that belong to the Newton family are preferred. However,
the computational complexity of these algorithms is usually pro-
hibitively large especially in real-time applications where low-
cost digital hardware must be employed. Numerical instability
is also a major issue in these algorithms. The conventional re-
cursive least-squares (CRLS) algorithm converges much faster
than algorithms of the steepest-descent family [1]. However, it
can become unstable and if a large forgetting factor is chosen
it can actually lose its tracking capability. The known quasi-
Newton (KQN) algorithm reported in [2], [3] offers better nu-
merical robustness whereas the LMS-Newton (LMSN) algo-

Manuscript received April 14, 2009; revised September 26, 2009; accepted
November 11, 2009. Date of publication February 05, 2010; date of current
version August 11, 2010. This work was supported by the Natural Sciences and
Engineering Research Council of Canada. This paper was recommended by As-
sociate Editor H. Johansson.

The authors are with the Department of Electrical and Computer Engineering,
University of Victoria, Victoria, BC V8W 3P6, Canada (e-mail: zbhotto@ece.
uvic.ca, aantoniou@ieee.org).

Digital Object Identiﬁer 10.1109/TCSI.2009.2038567

rithms reported in [4] offer better convergence performance than
the CRLS algorithm.

Two methods are available for the development of Newton-
type adaptation algorithms: methods based on the direct solu-
tion of the normal equations of a least-squares problem (see
Section II) and methods based on the orthogonal decomposition
of the input-signal matrix. The CRLS, KQN, and the LMSN
algorithms are based on the normal equations and the QR de-
composition algorithm (QRD) is based on the orthogonal de-
composition of the input-signal matrix [5]. The computational
designated as
complexity of these algorithms is of order
. The fast QRD (FQRD) algorithms in [6]–[12] are ac-
tually efﬁcient implementations of the QRD algorithm whose
. Fast RLS (FRLS) algo-
computational complexity is of
are also avail-
rithms with computational complexities of
able in the literature for FIR adaptive ﬁltering and autoregres-
sive (AR) prediction [5], [13]–[16]. FRLS algorithms exploit
the Toeplitz structure of the input-signal autocorrelation ma-
trix. The fast QN (FQN) algorithm reported in [17], which has a
, also exploits the Toeplitz
computational complexity of
structure of the autocorrelation matrix to reduce the computa-
tional complexity. The FRLS and FQRD algorithms suffer from
numerical instability problems that are inherited from the nu-
merical instability problems of the CRLS and QRD algorithms,
respectively, and also the simpliﬁcations used to obtain these
algorithms [8]. However, the FQRD algorithm reported in [8]
offers numerically stable operation in low-precision implemen-
tations and in the absence of persistent excitation. The numer-
ical instability problems associated with the CRLS algorithm
are discussed in [18] where an upper bound on the relative pre-
cision to assure the BIBO stability of the CRLS algorithm in
stationary and nonstationary environments is derived. Formulas
for choosing the forgetting factor to avoid explosive divergence
for a given precision in the CRLS algorithm are also given in
[18]. However, these formulas were derived on the assumption
that the input signal is persistently exciting. Furthermore, the
input-signal statistics must be known a priori in order to use
these formulas. Consequently, a prudent strategy for the deriva-
tion of fast Newton-type algorithms would be to start with a
parent algorithm that is inherently stable. The numerical robust-
ness of the quasi-Newton (QN) algorithm reported in [2], [3] is
achieved by using a biased estimate of the autocorrelation ma-
trix, which can reduce the tracking capability of the algorithm
relative to that of the CRLS algorithm (see [19, p. 678]).

In this paper, we propose an improved version of the QN algo-
rithm reported in [2], [3] that incorporates data-selective adap-
tation. The proposed QN (PQN) algorithm takes fewer weight
updates to converge and yields a reduced steady-state misalign-

1549-8328/$26.00 © 2010 IEEE

