                 HEURISTIC INTERPRETATION OF PREDICATE LOGIC EXPRESSIONS IN GENERAL GAME PLAYING 
 

 
 
 
 
 
 
 

 
 

 
 

 
 
 

 

 

 
 

 

 

 

 

1 

REVIEW:  

HEURISTIC INTERPRETATION OF PREDICATE LOGIC 

EXPRESSIONS IN GENERAL GAME PLAYING 

DANIEL MICHULKE 

SARA EUSTERGERLING, JUSTIN GÜSE, FELIX WÖBKENBERG 

 

 

 

 

 
 

 
 

   
 

 
Abstract. We provide a summary of the paper by Daniel Michulke focussing on new advances in
heuristic interpretation of predicate logic expressions in General Game Playing. The authors present an
 
alternative method that derives features from the goal conditions stated in the game rules, avoiding
 
 
thereby the disadvantages of other standard General Game Playing approaches.  
 
 

 
 

 
 

 
 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

1.  Introduction 

 

 

 

 

 

 

 

 

 

 

 

 

 
 

 
 

 
 

General Game Playing is dealing with the development of agents that are capable of playing games
 
they have never seen before. They receive the games rules some minutes prior the start of the game and
 
 
automatically construct a state value function to guide search, using game tree search. 
   
In this paper Michulke et al. aim to present a new technique of deriving an evaluation function from a
given domain theory. They present a new starting point for state evaluation without the disadvantages
 
related to standard approaches. Furthermore they managed to apply these features without a costly feature
 
 
evaluation and weighting phase. 
 

 
   

 
 

 
 

 
 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

2. The Standard Approach 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

As mentioned above, General Game Playing deals with development of agents that are able to play
 

 
games they have never seen before. 
An important part of this progress is the construction of the state evaluation function that evaluates states
 
and guides the agent to states with a high value. There are two basic types of these functions: 
The first function is called Monte Carlo. They evaluate a state by performing random playouts until a
 
   
terminal state is reached. After some of these playouts, the average of the outcomes becomes the state
 
 
value. The disadvantage of this approach is that it assumes a random opponent behaviour and is not able
to challenge informed or non­random opponents in games with well­studied evaluation functions such as
 
Chess. 
The second function is the deterministic evaluation based on the state itself. Agents of this category
 
 
 
derive candidate features from expressions in the game description and evaluate them to obtain a measure
 
 
 
of usefulness for the game and put this all together, sometimes weighted, to construct the evaluation
function. Although it is perfectly reasonable, it is very time­consuming and therefore not useful for the
 
competition setup. 

 
   

 
 
 

 
 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

