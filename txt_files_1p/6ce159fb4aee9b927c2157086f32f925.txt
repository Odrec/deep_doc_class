Ethics Inf Technol (2013) 15:99–107
DOI 10.1007/s10676-012-9301-2

O R I G I N A L P A P E R

On the moral responsibility of military robots

Thomas Hellstro¨m

Published online: 9 September 2012
Ó Springer Science+Business Media B.V. 2012

Abstract This article discusses mechanisms and princi-
ples for assignment of moral responsibility to intelligent
robots, with special focus on military robots. We introduce
the concept autonomous power as a new concept, and use it
to identify the type of robots that call for moral consider-
ations. It is furthermore argued that autonomous power,
and in particular the ability to learn,
is decisive for
assignment of moral responsibility to robots. As techno-
logical development will lead to robots with increasing
autonomous power, we should be prepared for a future
when people blame robots for their actions. It is important
to, already today, investigate the mechanisms that control
human behavior in this respect. The results may be used
when designing future military robots, to control unwanted
tendencies to assign responsibility to the robots. Indepen-
dent of the responsibility issue, the moral quality of robots’
behavior should be seen as one of many performance
measures by which we evaluate robots. How to design
ethics based control systems should be carefully investi-
gated already now. From a consequentialist view, it would
indeed be highly immoral to develop robots capable of
performing acts involving life and death, without including
some kind of moral framework.
Keywords Moral responsibility  Robots 
Military robots  Autonomy  Robot ethics

T. Hellstro¨m (&)
Department of Computing Science, Umea˚ University,
Umea˚, Sweden
e-mail: thomash@cs.umu.se

Introduction

This article discusses possible mechanisms and principles
for assignment of moral responsibility to intelligent robots.
Special focus is on military robots, which are being mas-
sively introduced by a large number of armies around the
world.1 The military robots will become more and more
autonomous and lethal, and responsibility issues must be
discussed as well as extended to match the new reality. The
article is organized as follows. Section 2 gives an overview
of existing battleﬁeld robots. In Sect. 3, these robots are
classiﬁed based on autonomous power, a new concept
introduced as an extension of the autonomy concept. This
helps to identify the kind of robots that should come into
question when discussing responsibility. Section 4 ana-
lyzes in what way moral responsibility may be applicable
to robots, and how it
relates to autonomous power.
Assignments of moral responsibility in hypothetical war
scenarios with and without robots are analyzed in Sect. 5,
followed by a ﬁnal discussion and conclusions in Sect. 6.

Robots in warfare

The last decade has seen an intense research and devel-
opment of military Unmanned Ground Vehicles (UGVs)
and Unmanned Aerial Vehicles (UAVs). The results are
already put in extensive use in armed conﬂicts around the
world (Wezeman 2007 p. 5–6, Singer 2009a, b). However,
the use of military robots is not at all a new idea. For
instance, UAVs have been used by several armed forces

1 Between 50 and 80 countries either already use or are in the process
of acquiring the technology to start using military robots (ABIre-
search 2011).

123

