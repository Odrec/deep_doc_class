Information Sciences 180 (2010) 3434–3443

Contents lists available at ScienceDirect

Information Sciences

j o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m / l o c a t e / i n s

Covariance intersection based image fusion technique with
application to pansharpening in remote sensing
Qing Guo a,b, Siyue Chen b, Henry Leung b, Shutian Liu a,*
a Harbin Institute of Technology, Department of Physics, Harbin 150001, PR China
b Department of Electrical and Computer Engineering, University of Calgary, Calgary, Alberta, Canada T2N 1N4

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 14 November 2009
Received in revised form 29 April 2010
Accepted 6 May 2010

Keywords:
Covariance intersection
Image fusion
Expectation maximization
Multi-spectral image
Panchromatic image
Pansharpening

1. Introduction

Image fusion of multi-spectral images and panchromatic images has been widely applied
to imaging sensors. Multi-spectral images are rich in spectral information whereas pan-
chromatic images have relatively higher spatial resolution. In this paper, we consider the
image fusion as an estimation problem, that is to estimate the ideal scene of multi-spectral
images at the resolution of panchromatic images. We propose a method of combining the
covariance intersection (CI) principle with the expectation maximization (EM) algorithm to
develop a novel image fusion approach. In contrast to other fusion methods, the proposed
scheme takes cross-correlation among data sources into account, and thus provides consis-
tent and accurate estimates through convex combinations. Since the covariance informa-
tion is usually unknown in practice, the EM method is employed to provide a maximum
likelihood estimate (MLE) of the covariance matrix. Real multi-spectral and panchromatic
images are used to evaluate the effectiveness of the proposed EM–CI method. The proposed
algorithm is found to preserve both the spectral information of the multi-spectral image
and the high spatial resolution information of the panchromatic image more effectively
than the conventional image fusion techniques.

Ó 2010 Elsevier Inc. All rights reserved.

With the rapid growth of the internet and other electronic sources of information, the problem of coherent merging infor-
mation from multiple sources has become an important issue [21,30,31]. As one type of information processing technique,
the image fusion is widely used in many practical applications. Images captured by multiple sensors often contain comple-
mentary and redundant information. An effective fusion process will result in an improved image, which contains more com-
plete information and should be more suitable for human visual perception and object recognition [2,20]. In this study, we
consider fusion of multi-spectral (MS) images and panchromatic (Pan) images, which are widely used in remote sensing. This
fusion scheme is often referred as pansharpening [13]. The MS images, such as acquired by IKONOS and QuickBird satellites,
usually have four bands of spectral information (i.e., red (R), green (G), blue (B), and near infrared (NIR)). Meanwhile, the Pan
image has good spatial resolution. Therefore, the goal of fusing these images is to generate a high-resolution MS image,
which can be used more effectively for applications, such as land classiﬁcation and road detection.

Image fusion can be classiﬁed as pixel-level, feature-level and symbol-level [3]. Fusion of MS and Pan images at pixel-le-
vel is traditionally handled by the intensity-hue-saturation (IHS) transform methods [4,6], the Brovey transform methods
[7], the principal component analysis (PCA) methods [6,5,24], the highpass ﬁltering (HPF) method [25] and by the wavelet

* Corresponding author. Tel./fax: +86 451 86418042.

E-mail address: stliu@hit.edu.cn (S. Liu).

0020-0255/$ - see front matter Ó 2010 Elsevier Inc. All rights reserved.
doi:10.1016/j.ins.2010.05.010

